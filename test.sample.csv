"Intraoperative anaphylaxis is a life-threatening condition with a mortality rate of 3-10% and presents a unique challenge for the anesthesiologist in patients undergoing transplant surgery. It has been shown that the median time interval between the onset of signs and symptoms and cardiac arrest is 5 min in iatrogenic anaphylaxis [1] . Of all anaphylactic reactions, skin symptoms and signs are present in up to 90 percent of episodes while respiratory compromise is present in up to 85% [2, 3] . Although these common signs and symptoms can be helpful in the diagnosis of anaphylaxis and subsequent management, they are not always present. Patients with anaphylaxis who present with only hypotension typically have been exposed to substances to which they are known to be allergic. Here we describe a presentation of a successful renal transplant following anaphylaxis to cefazolin in a patient who had two prior exposures but no known allergy to the offending agent. Written informed consent was obtained from the patient for publication of this case report.@story_separate@A 33-year-old, 50-kg female with end-stage renal disease (ESRD) secondary to reflux nephropathy was scheduled for a zero-mismatch cadaveric renal transplant. She was dependent on peritoneal dialysis, and her past medical history was also notable for anemia and secondary hyperparathyroidism. She was on multiple antihypertensive medications, and she reported no drug allergies, which was also confirmed with a review of the medical record. Notably, however, she did verbalize a reaction to an unknown sedative that she received for a procedure in 2019 that resulted in the sole symptom of pruritus in her lower extremities. Aside from this reaction, she had several previous general anesthetics that had been uncomplicated and had received cefazolin twice in the past without adverse reactions. The patient was hypertensive before induction of anesthesia with systolic blood pressure (SBP) range from 170 s to 200 mmHg and a diastolic blood pressure (DBP) range from 95 to 110 mmHg. Her heart rate was normal in the 70 s and oxygen saturation was greater than 95%. Induction of anesthesia was achieved with propofol and cisatracurium, and anesthesia was maintained with sevoflurane. The lowest blood pressure reading during and after induction was 137/89 mmHg, and the patient state index (PSI) on SedLine was between 10 and 30. The routine peri-transplant immunosuppressive dose of methylprednisolone (total 500 mg) was started 12 min after induction and given over 25 min. A routine bolus of cefazolin (2 g) was given intravenously (IV) over 3 min prior to incision. The surgical team made the incision, and 4 min following the administration of cefazolin, the blood pressure decreased from 140/80 to 75/44 mmHg. No bronchospasm or mucocutaneous signs were appreciated. However, tachycardia, hypotension, and cardiovascular collapse were observed. In addition, the pleth variability index (PVI) increased significantly from 4 to 14, and PSI remained between 20 and 30. She was initially treated with phenylephrine. She was not responsive to the phenylephrine and received epinephrine (total 100 mcg). The hypotension worsened (55/45 mmHg), she had bradycardia in the 50 s, oxygen saturation in the 70 s, and the femoral pulse was not palpable. Sevoflurane and methylprednisolone were both discontinued. The SedLine raw electroencephalogram did not display burst suppression, and PSI was between 20 and 30. The five-lead electrocardiogram was assessed, and no changes were noted. The ventilator showed normal peak pressures, and the capnograph waveform shape was normal. The end-tidal carbon dioxide (ETCO2) had decreased from the high 30 s to the low 20 s. The patient's skin and oral mucosa appeared normal and the lungs were clear bilaterally. The patient was given 1.5 mg of epinephrine followed by 18 units of vasopressin to achieve hemodynamic stability. Within 7 min, hemodynamics improved to baseline. The delivery of sevoflurane was resumed, with the highest PSI noted to be 43. A tryptase level was sent. A discussion was held about whether or not to proceed with the planned surgical procedure. The patient was observed for approximately 20 min during which she remained stable. The decision was made to proceed with the kidney transplant due to the excellent immunologic matching between the donor and recipient (zero antigen mismatch). The surgical procedure was resumed, and the patient remained stable for the rest of the case without the need for additional vasopressors or inotropes. She was admitted to the intensive care unit (ICU) for observation secondary to presumed intraoperative anaphylaxis and a near cardiopulmonary arrest. Her ICU admission was uncomplicated except for the need for oral midodrine on postoperative day 1, which she received to achieve a mean arterial pressure (MAP) goal of > 70 to provide adequate perfusion to the renal allograft. On postoperative day 2, the MAPs ranged in the 80-100 s and midodrine was discontinued. The patient was transferred out of the ICU. She had excellent early graft function and her laboratory results were as expected until discharge on post-operative day 4. Her intraoperative tryptase level was elevated at 51.8 mcg/L (normal < 11 mcg/L), and 1 month following surgery returned to normal (5.5 mcg/L). As part of her intraoperative anaphylaxis work-up, the patient was seen in the Allergy and Immunology Clinic for skin prick testing of multiple agents she had been exposed to intraoperatively. Propofol, penicillin, and amoxicillin skin testing were negative. Methylprednisolone was initially considered as a potential etiologic agent, but since she received large doses subsequently on postoperative days 1 and 2 without any reaction it was excluded. Latex and chlorhexidine were not considered likely culprits given the lack of their temporal relationship between exposure and reaction. The cefazolin skin testing was positive (Fig. 1) , suggesting that cefazolin was the likely cause of her intraoperative anaphylactic episode.@story_separate@Intraoperative anaphylaxis is a medical emergency that poses significant challenges to the anesthesiologist, especially in transplant surgery [4] [5] [6] . During general anesthesia, 60 percent of all anaphylactic reactions are triggered by neuromuscular blocking agents, followed by latex (20 percent), and antibiotics (15 percent) [7] . Penicillins and cephalosporins are responsible for approximately 70 percent of all cases of antibioticinduced anaphylaxis [7] . Anaphylactic and anaphylactoid reactions may have indistinguishable presenting symptoms; however, they are caused by different pathophysiology. An anaphylactic reaction is an IgE-mediated allergic reaction following the massive release of mediators from mast cells as a response to an allergen [5, 8] . Anaphylactoid reactions are non-IgE mediated and occur through a direct nonimmune-mediated release of mediators from mast cells and basophils [5, 8] . The mainstay of treatment of both acute anaphylactic and anaphylactoid reactions is epinephrine [2] . Although other modalities can be used, including antihistamines, corticosteroids, and β-2 agonists, they should only be used as adjuncts to epinephrine as it has been shown that lack of or delayed epinephrine administration has led to worse outcomes and mortality [2] . This patient's initial presentation of severe hypotension without obvious pulmonary or mucocutaneous signs raised the possibility of an anaphylactic reaction after alternative differential diagnoses were ruled out. Fluids, epinephrine, and additional vasopressor support were given to achieve hemodynamic stability. Given that the patient didn't present with the classic features of anaphylaxis, a confirmatory tryptase level was sent and she was followed by the Allergist for skin testing. There are several testable indicators of anaphylactic reactions, including histamine and tryptase. Tryptase is the most specific product of mast cells and basophils, and thus has become one of the more reliant tests to assess for anaphylactic reactions [9] . When anaphylaxis is considered intraoperatively, it is the anesthesiologist's responsibility to manage the clinical situation with supportive therapies and help facilitate the diagnostic workup. If the diagnosis of anaphylaxis is not clear due to a non-traditional presentation, it is recommended to send a tryptase level to confirm or rule out the diagnosis [2, 4, 6] . Tryptase levels peak one and half hours after the onset of anaphylaxis, but levels drawn up to 3 h after symptom onset can support the diagnosis [4, 10] . Additionally, the anesthesiologist should ensure that the patient is counseled regarding the event and a referral placed to see an allergist for skin testing 1 month following the event [6] . Anaphylaxis after induction certainly warrants cancellation of elective surgery because it can be challenging to predict the hemodynamics that will occur over the subsequent few hours, and frequently the patient has vasopressor requirements lasting long after the event. To avoid exposing a renal allograft to hypotension and vasopressors post-operatively, kidney transplants are generally cancelled when the recipient has anaphylaxis. The unique aspect of this case was the immune matching between the deceased donor and recipient, making it extremely unlikely this patient would ever get another deceased donor kidney of equal quality. The surgical and anesthesia teams agreed to move forward with the transplant, to admit the patient to the ICU to watch for a possible biphasic reaction, and midodrine was started preemptively upon admission to the ICU. Biphasic reactions, which are defined as recurrence of anaphylaxis within 72 h of the initial reaction without re-exposure to the offending agent, occur in less than 5% of patients diagnosed with anaphylaxis [11] . It may be prudent to observe patients for an adequate time-period following an acute anaphylaxis episode to monitor for a biphasic reaction, and it is recommended to monitor patients for at least 6-12 h following the event [2, 11] . The patient's skin testing and tryptase levels supported the diagnosis of cefazolin-induced anaphylaxis. Despite an intraoperative emergency presenting in a nontraditional fashion, the patient had a successful kidney transplant and will now avoid cefazolin in the future.","BACKGROUND: While there exist case reports of anaphylaxis occurring during renal transplant surgery, descriptions of continuing transplant surgery post-anaphylaxis have been scarce. Anaphylactic reactions that present solely with hypotension without pulmonary or mucocutaneous signs have yet to be described during renal transplant surgery. CASE PRESENTATION: Here we report a case of a 33-year-old female with end-stage renal disease who underwent cadaveric renal transplant. She developed anaphylaxis following the administration of cefazolin. Despite this reaction, the surgery was ultimately completed after patient stabilization, and the patient had excellent graft function postoperatively. The patient had an elevated tryptase at the time of the reaction and postoperative allergy testing revealed a positive intradermal test to cefazolin. Written informed consent was obtained from the patient for all procedures, studies, and publication of this case report. CONCLUSIONS: This is the first case of a successful zero-mismatch cadaveric renal transplant following an anaphylactic reaction to cefazolin. Although anaphylaxis during transplant surgery typically warrants cancellation due to the hemodynamic effects that may lead to graft dysfunction, here we describe a case where surgery was continued following patient stabilization. The decision to proceed with surgery despite an intraoperative emergency along with the management and workup of intraoperative anaphylaxis are described, which can be beneficial for others who are presented with similar scenarios in the future."
"In many countries annual influenza vaccination has been recommended for the elderly and persons with high-risk medical conditions. In the Netherlands until 2007, the age-threshold for such vaccination was 65 years for non-high-risk groups. In 2008, this threshold was lowered to include all persons aged 60 years and older [1] . In addition in the Netherlands, all high-risk groups are vaccinated, including individuals suffering from chronic conditions, respiratory diseases, cardiac diseases, diabetes mellitus, renal failure, those being immunocompromised and individuals aged less than 18 years of age on chronic salicylates use [1] . Vaccination rates among these high-risk groups under 65 years of age ranged from 66% to 83% in the Netherlands in 2005 [2] . Persons of 65 years and older with a medical indication showed higher vaccination coverages compared to those of the same age without such an indication, at 90% and 76% in 2005, respectively [2] . Influenza may cause acute bronchitis and pneumonia in high-risk groups and elderly and may lead to exacerbations of underlying chronic medical conditions such as cardiovascular diseases, asthma and diabetes, potentially leading to hospitalisations and death. Prevention of influenza infection by vaccination is of high importance for these groups with an increased risk for complications from influenza infection [3] [4] [5] . Although some countries recommend routine influenza vaccination among children aged 6 months to 2 years, clinical data about the impact of vaccination are limited [1, 6] . Yet, vaccination of all healthy children in this age group could be cost-effective or even cost-saving for some societal settings [6] . In the Netherlands, universal influenza vaccination of such children is in debate, however yet the vaccine efficacy and effectiveness for this specific age group is not considered to be sufficiently demonstrated [7] [8] [9] . Therefore, the Dutch Health Council concluded in 2007 , not yet to start with influenza vaccination of these groups [1] . Comparable conclusions were made for healthy children aged 2 years and older. Although vaccination was shown to be effective for these children, influenza was considered not to cause serious morbidity or mortality in the Netherlands in those groups [1] . Next to influenza virus A and B, respiratory syncytial virus (RSV) has been shown to cause similar types of complications, including complications in the respiratory tract. RSV is often recognized as a cause of morbidity and mortality among both children and adults, contributing to a major burden of illness [10] [11] [12] [13] [14] [15] [16] [17] . No preventive vaccine is yet marketed for RSV. In general, it is difficult to estimate the individual contributions of influenza and RSV to the aforementioned disease burdens accurately as influenza and RSV co-circulate during winter seasons. For burden of disease often the label Influenza Like Illnesses (ILI) is considered to primarily comprise disease due to influenza infections, however known to potentially comprise various other agents inclusive RSV, with the identification of the relative contributions of both viruses being strongly hampered [18] [19] [20] [21] . In particular, even further viral agents, such as adeno-, parainfluenza-, and corona-viruses may contribute to the burden of ILI [21, 22] . For exactly analysing the burdens of disease of influenza and RSV separately, which is the goal of our current paper, ILI is therefore an inappropriate concept. Therefore, we chose to analyse isolates exactly related to the respective causal agents. Given the potential complications of influenza and RSV, one may expect excess health-care resource utilization during epidemics [23] . Studies estimating such excess resource utilization have previously been directed to hospital admissions and GP-visits, but there is as yet hardly any information on the association between the occurrence of influenza and RSV and the use of medications among the general population [24] . Drug-use for specific complications of influenza and RSV could certainly temporarily be elevated. In particular, prescriptions for antibiotics, otologicals and cardiovascular medication may be elevated, dispensed for otitis media, cardiac complications, respiratory illness and other pulmonary complications. To address this topic, we investigated the association between weekly reported RSV and influenza isolates in the Netherlands and the weekly number of prescription drugs dispensed by Dutch pharmacies, in particular those for antibiotics, otologicals and cardiovascular drugs. From the preventive point of view, high influenza-associated drug-use may justify more extended use of preventive measures, such as influenza vaccination. In particular, it may enhance the health-economic profile of extended influenza vaccination for currently yet unvaccinated groups. As such, our research may contribute to discussions as to whether, for example, young children should be vaccinated or whether the age limit of the vaccination program should be lowered further.@story_separate@During 1998-2006, the Dutch Working Group on Clinical Virology gathered data from 20 laboratories throughout the Netherlands, testing clinical specimens for respiratory viruses, including RSV and influenza A and B. The number of patients who tested positive for RSV or influenza was reported on a weekly basis. In the absence of any drastic changes in recruiting and testing of specimens the weekly time series can validly be conceived as representing the actual time trend, without requiring any corrections to be applied on the data. To exclude weekly random fluctuations a 3-week moving average was used for presentation ( Fig. 1) and for defining the specific weeks exhibiting elevated activity for influenza and RSV. Two methods for defining weeks with elevated activity of influenza and RSV were applied. The first method defined a week with elevated activity as one with a moving average of more than two times the gross overall average weekly number from week 40 in 1998 onwards to week 39 of 2006 (week 1 obviously being the 1st week in January; week 40 generally being considered as the start of the influenza season). Following Jansen et al., the second method defined the weeks with elevated activity as those weeks from any period of at least 2 consecutive weeks, with each individual week accounting for over 5% of the season's total number of influenzaor RSV-positive specimens [18] . From both methods, it appeared that periods consisting of a number of subsequent weeks resulted, rather than individual weeks or short periods of, for example, 2 weeks only. Such periods would be expected -and were indeed found -to be between week 40 and week 20 in the next year (the non-summer season) [18, 25] . The weeks that contained both influenza and RSV activity were excluded for defining the periods with elevated activity, given the difficulty to separate out the individual influences in these weeks with combined activity. As a result, only those weeks with either elevated influenza or RSV were analyzed. Furthermore, a periseason was defined, containing the weeks from week 40 up to and including week 20 of the next year, which did not belong to the influenza or the RSV periods (seasons). The weeks from week 21 up to and including week 39 were labelled ""summer"". Information on drug-use in the population was provided by a University of Groningen in-house prescription database (www.iadb.nl). The database iadb.nl contains prescription, demographic and population data of 500,000 persons adherent to 50 pharmacies in the North and East of the Netherlands. For analytical purposes, the prescriptions were divided over 5-year age categories. The age category 0-4 years was further divided in the ages 0-1 and 2-4, to enable analysis of infants separately. For presentation the following categorization was applied: 0-1, 2-4, 5-19, 20-49, 50-54, 55-59, 60-64 and 65+. The exact age of any person was determined every year on the 1st of October, close to the period in which in the Netherlands the invitations for influenza vaccination for risk groups are sent out by the GPs, supposedly just prior to the season with increased risk for influenza epidemics from October onwards to May. The annual total population sizes were based on estimates for the 1st of January by the local authorities in the places where the pharmacies are located. Persons who received one of the studied drugs were divided in high-risk and low-risk groups for influenza. The respective populations belonging to both groups were estimated using prescriptions as a proxy, for those medications that are consistent with highrisk indications as specified by the Dutch Health Council [1] and the Dutch GPs (http://nhg.artsennet.nl) and that are uniquely prescribed for these indications [26] . For example, dornase alfa, a drug prescribed for cystic fibrosis, was included to define persons with respiratory diseases. Other medications for cystic fibrosis, such as acetylcysteine, are also prescribed for cough and were therefore not included. Table 1 lists these drugs specifically. For heart medication, diuretic sulfonamides were included. Other diuretics used for lowering blood pressure were excluded, as high-blood pressure is not a high-risk identified condition. Furthermore, only calcium antagonists with ATC-code C08D were included as only these are assumed to have cardiac effects. Beta blockers and RAAS system agents were excluded as these are not exclusively prescribed for cardiac diseases, but also, for example, for high-blood pressure only. For renal diseases, medication for the treatment of hyperkalemia and hyperphosphatemia, and antianemic preparations and sulfonamides were included as these are often prescribed for dialysis or renal insufficiency. To identify immunocompromised patients, immunosuppressives were included, which can be prescribed, for example, for patients after organ transplantation. Also HIV medications were included as also HIV-patients are listed as high-risk group. As mentioned, in the Netherlands, influenza vaccination is recommended to those at the increased risk of complications based on specific medical conditions. To determine which specific patients should be labelled as belonging to the high-risk group, the recommendations of the Dutch Health Council [1] and the guidelines of the Dutch GPs (http://nhg.artsennet.nl, accessed 24th September 2007) for influenza and high-risk indications were used [26] . In particular, persons were labelled belonging to the high-risk group if they had two or more prescriptions from the same group of medications included on the list, on two different dates in the year before the first of October. The latter was supposed to guarantee that the condition would be chronic in that specific year (note that a person's risk status may change from year to year). The population size of the high-risk group was subsequently determined on the 1st of October by counting the number of high-risk persons in iadb.nl; the rest of the population was assumed at low risk. We specifically directed our analysis to the drug groups of antibiotics, otologicals and cardiovascular drugs, as these drugs may be considered for those complications of both viral infections that have yet been published in the scientific literature [23, 24, [27] [28] [29] . From iadb.nl, prescriptions of antibiotics (ATC-code J01), otologicals (ATC-code S02) and medications for the cardiovascular system (ATC-code C) were selected. Antibiotics are commonly prescribed for the treatment of acute otitis media (AOM), in particular for young children in which AOM accounts for approximately half of all antibiotics courses delivered [30] [31] [32] . Otologicals may also be prescribed for AOM, despite that they are not recommended by the Dutch College of General Practitioners (NHG) [29] . In addition, more than average numbers of antibiotics may be prescribed for elderly persons with ILI during periods with elevated activity, as particularly this group may develop acute respiratory illnesses (for example, pneumonia) as a complication of the viral infection (trimethoprim and nitrofurantoin were excluded from the analysis as they are prescribed primarily for urinary tract infections) [33] . For antibiotics and otologicals both initial and next prescriptions within the same year were considered. It is well known that influenza-related complications are more prevalent among persons with cardiovascular and other chronic diseases than in persons without such underlying conditions [4, 34] . In persons of 65 years and older with high-risk conditions an increased rate of hospitalisation for cardiac problems has been reported [17] . Some further recent studies suggest that there might also be an association between cardiovascular problems and influenza epidemics among groups without any cardiovascular history yet, such as the elderly or even among those aged below 65 years of age [23, 35] . For analysing cardiovascular medications, only first prescriptions were considered as our current interest was to investigate whether the viral infections were related to new cardiovascular disease and/or exacerbations of existing -yet untreatedbackground cardiovascular conditions, rather than identify chronic medications for cardiovascular diseases (note that chronic cardiovascular medication use was used as a criterion for assigning persons to the high-risk group). A prescription was defined as a first prescription when a person had not had a prescription for the same drug or a drug from the same subgroup in the year before that specific prescription. After the various periods of elevated activity were determined, the number of prescriptions in the weeks belonging to the influenza and RSV periods/seasons were compared to the number of prescriptions in the peri-season. For comparative purposes also results for comparing with the summer season are presented. This was done in every age group for the total population, the high-risk group and the low-risk group. Incidence rates were calculated and corresponding 95%-confidence intervals were estimated [36] . The incidence rate (I) was calculated as the weekly number of prescriptions per 10,000 person-years: with P i being the number of prescriptions in week i of a season (influenza, RSV, peri or summer), n the number of weeks of that specific period of interest and N the population size (per age group, for high risk or for low risk). The division by 52 is to transfer personweek estimates into person-years (for 2 years 53 instead of 52 had to be used). Microsoft Office Excel 2003 was used for processing the data, calculations and graphics. During the study period, the average weekly number of influenza-positive and RSV-positive specimens were 11.77 and 36.90, respectively. The first method for defining the periods of elevated activity using two times the average number of isolates per week as a lower limit (23.54 for influenza and 73.80 for RSV) resulted in Table 2 , showing the weeks which were labelled as belonging to the influenza, RSV, peri-and summer periods. The second method, defining the periods with elevated activity as at least two consecutive weeks in which each week accounted for over 5% of the season's total number of RSV-or influenza-positive specimens yielded comparable results (data not shown). Hereafter, only for those results where both methods differed, the results of both methods are presented otherwise the results of only the first method are shown. Obviously, periods with elevated activity and the peri-season changed from year to year, both in length (the summer season of course always ranged from week 21 up to and including week 39 of the next year). In some years overlap in influenza and RSV activity weeks were seen, in which case weeks were excluded. Table 3 Person-years during periods of elevated activity per age group for the total population, high-risk group and low-risk group. Table 4 Excess drug prescriptions for the periods with elevated activity compared to the peri-season, shown as numbers of prescriptions per 10,000 person-years (as % of peri-seasonal levels). The number of persons was insufficient for valid estimation. a Result not statistically significant. b Although borderline significant not shown here for the whole age-group as further 5-year age-group specific analyses revealed that significance was related only to a significant and clinically relevant surplus for the age category 45-49: 113.12 (12.95%) and 122.78 (17.06%) for the total population and low-risk group, respectively. Table 3 presents the number of person-years for the influenza, RSV, peri-season and summer periods per age and risk group. For infants and children aged 2-4, the high-risk group was very small with 393 person-years in the influenza period and 454 personyears for the RSV period, and therefore only the figures for both low-and high-risk groups taken together were used for these ages. Furthermore, in all age groups the number of person-years in the high-risk group was lower than the numbers in the low-risk group. We also note, as expected, that the older age groups contained relatively more person-years in the high-risk group than the younger age groups. Fig. 1 shows the number of positive findings for RSV and influenza per week. The annual influenza and RSV epidemics are clearly seen, as is the overlap in some years. Also the number of (first) prescriptions per 10,000 persons for antibiotics, otologicals and cardiovascular medication is plotted for the total population. In particular, for antibiotics a clear pattern is visible in which during influenza and RSV activity periods a peak in antibiotic use occurs. Additionally, we notice that in the younger age groups amoxicillin was the mostly prescribed antibiotic, whereas from the age group 5-19 onwards other antibiotics were mostly prescribed (data not shown). The excess prescriptions per 10,000 person-years during the influenza and RSV periods are presented in Table 4 , as compared to the peri-season. We noted that both methods used for estimating the activity periods showed similar results. The number of prescriptions for antibiotics was significantly elevated during the activity periods in each age group. For the age groups 0-1 and 2-4, excess prescriptions were highest in the RSV periods, in the older age groups surpluses were higher during the influenza periods. For influenza, the low-risk group showed higher excess prescriptions compared to the high-risk group. Prescription of otologicals was significantly elevated during the periods of elevated activity, however only in the youngest age groups of infants and children aged 2-4 years. In contrast to antibiotics, excess prescriptions were higher during influenza periods than during RSV periods. For first cardiovascular medications, the prescription rate in the RSV periods was lower than in the peri-season, although not significant. During the influenza period, higher prescription rates were found for those aged 50 years and older. When the age group of 20-49 was analyzed in 5-year age categories separately, also a significant difference for the age category 45-49 was seen. Fig. 2 shows the prescription rates per 10,000 person-years and confidence intervals for selected aggregated age groups for the different periods per year separately, as well as for the aggregated years. The incidence rates of antibiotics were increased during the influenza and the RSV periods in comparison with the peri-season (and the summer season). This increase was noticeable for every year. For otologicals, the incidence rate was increased but the confidence intervals were wide and therefore not every year rendered a statistically significant difference during the influenza and RSV periods. For first cardiovascular prescriptions also an increase was noticeable during influenza periods as compared to the peri-season, but again not for every year a significant difference was found. Finally, we note from Fig. 1 that elevations in the influenza and RSV periods are not necessarily followed by relatively lower levels in the peri-and/or summer seasons, suggesting that surpluses detected are actual extra prescriptions that are not ""neutralized"" by subsequent dips in prescriptions. Statistically significant excess antibiotic prescriptions during periods with elevated activity of influenza and RSV were found for both viruses in all age groups, each year investigated and irrespective of the method used for exactly defining the influenza or RSV activity periods. For otologicals during both influenza and RSV-active periods, statistically significant surpluses were found in young children only. Oppositely, excess cardiovascular drug prescriptions were identified in adults and elderly in periods with elevated influenza activity. We generally found a tendency for higher percentages of surpluses in low-risk groups than in high-risk groups. For antibiotics and cardiovascular drugs, this can probably be explained by the fact that individuals belonging to a high-risk group have a higher likelihood of being vaccinated against influenza, lowering the chance of infection and secondary bacterial or cardiovascular complications. This tendency also applied to low-risk elderly as compared to highrisk elderly, despite the fact that this whole group is recommended for vaccination. Some choices in our research should be noted. Specifically, the lower limit for the weekly moving-averaged number of isolates for weeks to be labelled as active was chosen by two different methods. The first used a cut-off of two times the average number of influenza or RSV isolates per week. This limit was chosen to achieve continuous periods per year of weeks subsequently labelled as active, i.e. to guarantee epidemic periods rather than fluctuations. The second method was used to be in concordance with a previously performed Dutch study using the weeks which accounted for 5% or more of the season's total number of influenza or RSV isolates [18] . In general, both methods resulted in similar results. By using the influenza and RSV activity periods that excluded weeks of combined activity, possible major influence by the presence of the respective other virus was reduced. However, the exclusion of weeks in which both influenza and RS viruses were active was only necessary in 4 out of the years included in this analysis. Also, in methodology excluded weeks were not included in counting person-years, so the effect of excluding those weeks maybe limited. Yet, possible influence of any other respiratory virus obviously remains present. However, the impact of these viruses is probably limited, as they may have long periods of marginally increased activity rather than a clear seasonal pattern [18] . Furthermore, complications are expected to be milder compared to influenza and RSV infection [18] . We compared our data for the activity periods with the periseason, which provided a more conservative estimation of the surpluses than if we would have compared with the summer period. Yet, some underestimation of the surpluses may be introduced in this way. We do feel, however, that comparison with the peri-season is most appropriate, as other potential influences concerning the climate and possible other viruses that circulate in non-summer periods are probably comparable between the peri-season and the activity periods. Every year, RSV-positive specimens reached a relatively small and intensive peak around week 52. Earlier studies have shown similar tendencies, with RSV isolates peaking every year around the same time [14, 15, 37] . This suggests the presence of potential common strict seasonal factors which might increase both the number of isolates and prescriptions; however probably not invalidating the associations and surpluses found in our analyses, which are truly seen and are in line with other studies [14, 15, 37] . Persons were labelled as belonging to the high-risk group based on specific medication profiles. In particular, persons belonging to the high-risk group were selected based on prescriptions that corresponded rather uniquely to the high-risk indications. Prescriptions potentially meant for other indications, not labelled as high risk, were consistently excluded. Still, it is possible that these selection criteria unjustly labelled individuals as belonging to the high-risk groups. Also, some individuals may have been incorrectly excluded and labelled as non-high-risk. Finally, one may hypothesize that excess prescriptions are merely shifts in time of extra prescriptions later to be outweighed by dips in prescriptions (sometimes referred to as ""the harvesting effect""). Visual inspection of our data however did not give any reason to support this hypothesis in our study. Additionally, a formal statistical comparison of the number of prescriptions during the peri-seasons and during the first 5 weeks after the active seasons did not show any peak-dip pattern (data not shown). Previously, various investigations have been performed on the association between influenza and RSV epidemics, on the one hand, and hospitalisations, mortality and outpatient visits, on the other [14, 17, 18, 24, 33, [37] [38] [39] [40] [41] [42] [43] [44] . Below, we briefly compare the outcomes, knowing that the validity of making such comparisons between studies is limited due to differences in outcome measurement, statistical models, study period, and health-care system concerned. Previously, only one study investigated excess antibiotic use during influenza-activity periods in the general population [24] . This study did show that otherwise healthy children get more prescriptions for antibiotics during these influenza periods. However, the surplus reported was relatively low compared to our findings [24] . Two other studies estimated the excess antibiotic prescriptions during both RSV and influenza-active seasons, focussing on specific target groups [33, 43] . The first study focussed on patients suffering from chronic lung disease, showing the highest surpluses for the youngest age groups [43] . The latter study showed higher surpluses due to influenza as compared to RSV for those living in nursing homes [33] . Both results are in line with our findings for antibiotics [33, 43] . Several other studies indicate that, in general, both during RSV and influenza-activity periods, infants and elderly show the highest morbidity and mortality rates [14, 18, 24, 37, [39] [40] [41] [42] [43] [44] . This is certainly in line with our findings on excess antibiotic and otological prescriptions among the youngest age groups and cardiovascular medication surpluses among the older age groups. In contrast to other studies which showed higher morbidity and mortality among the oldest age groups compared with non-elderly adults, our study shows that the elevation in the prescriptions of antibiotics in the oldest age groups (65 years of age and older) is not higher than in the two younger age groups (55-59 and 60-64). Yet, if compared with other adult age groups, a small increase could be seen. For influenza, this slightly deviating finding compared to non-Dutch settings, might be explained by the high vaccination coverage among elderly in the Netherlands. A recent Dutch study showed that RSV-related excess hospitalisations were considerably higher as compared to those due to influenza [18] . Comparably, a study performed for England and Wales showed greater excess rates for complications during RSVactive periods among the youngest age groups as compared to influenza; similar rates were found for all other age groups [37] . Five other studies focussing on excess morbidity, mortality and hospitalisation among children confirmed these results, showing that RSV was responsible for higher hospitalisation rates than influenza [14, [39] [40] [41] [42] . For the Netherlands, Jansen et al. recently showed excess hospitalisation for cardiovascular complications among the 50-64 years old, during influenza-active periods but not during RSV-active periods [18] . In line with their findings, we showed a significant surplus in first cardiovascular medication prescriptions during influenzaactive periods, but not during RSV-active periods for those aged 45 years and over. Elevated hospitalisation and prescription rates during influenza periods in persons aged around 50 years and beyond suggests that influenza may cause cardiovascular diseases or that it may aggravate existing non-diagnosed cardiovascular diseases in older adults. Another hypothesis explaining this increase might be that increased cardiovascular problems during influenza periods are related to the increased use of analgesics during those periods to alleviate influenza symptoms [45] . Further research is definitely needed into this topic. Thus, in general, our results seem to be comparable with most other studies relating elevated viral activity to the use of health-care resources, morbidity and mortality. All studies consistently show that the highest excess rates for the youngest age groups are mostly due to RSV, whereas those for influenza are seen in elderly. Vaccination may prevent part of the excess prescriptions we have found. For example, healthy children are not recommended to be vaccinated against influenza in the Netherlands, while their vaccination might prevent part of the surplus prescriptions found for this group. In particular, vaccination may prevent influenza infection and potential subsequent bacterial super infection(s) and thus avert antibiotics prescribed for the prevention and treatment of such bacterial super infections. Additionally, reducing the prescription of antibiotics may also be important from the perspective of limiting the development of antibiotic resistance. Such reasoning could be an additional motivation for vaccinating yet uncovered groups against influenza [23] . An effective vaccine against RSV may potentially even prevent more antibiotic prescriptions, especially in young children [37] . Yet the introduction of a vaccine again RSV is not expected in the very near future [18] .@story_separate@During influenza-and RSV-active periods, elevations in antibiotic prescriptions were identified in all age groups. For otologicals, such an elevation was shown in the age groups of 0-1 and 2-4 years, both during influenza-and RSV-active seasons. By vaccinating young children against influenza, a part of these prescriptions for antibiotics and otologicals may be prevented. In persons of 50 years and older an elevation of prescriptions for cardiovascular medication was shown during the period of elevated influenza activity only, in particular for the low-risk population. Also for antibiotic prescriptions, the excess found was higher in the low-risk population than in the high-risk population, possibly indicating the effectiveness of the vaccination program in the highrisk group, in which a relatively high coverage rate is reached in the Netherlands.","Influenza and respiratory syncytial virus (RSV) infections are responsible for considerable morbidity, mortality and health-care resource use. For the Netherlands, we estimated age and risk-group specific numbers of antibiotics, otologicals and cardiovascular prescriptions per 10,000 person-years during periods with elevated activity of influenza or RSV, and compared these with peri-season rates. Data were taken from the University of Groningen in-house prescription database (www.iadb.nl) and virological surveillance for the period 1998–2006. During influenza and RSV periods excess antibiotic prescriptions were estimated for all age groups. In the age groups 0–1 and 2–4 years, excess antibiotic prescriptions during periods with elevated RSV activity (65% and 59% of peri-seasonal rates) exceeded the surpluses estimated during the influenza-activity periods (24% and 34% of peri-seasonal rates) while for otologicals excess prescriptions were higher for influenza (22% and 27%) than for RSV (14% and 17%). Among persons of 50 years and older, notably those without medical high-risk conditions, excess prescriptions for cardiovascular medications were estimated during the influenza periods at approximately 10% (this was also already seen in persons aged 45–49). Our results may have implications for influenza vaccination policies. In particular, extension of influenza vaccination to groups of non-elderly adults and young children may lower excess prescriptions during these influenza periods for all three types of drug prescriptions investigated."
"Coronavirus (CoV) is enveloped, positive-sense singlestranded (ss) RNA genome ranging from 27 to 34 kb in length which are divided into four different genera, for example α, β, γ, and δ. Coronavirus is not a new threat to human being or animal kingdom, it's an old virus and causing the infection in wide numbers of different animals such as Pheasant, Guinea Fowl, Bovine, Beluga whale, rat, rabbit, camel, swine, and other species [1, 2] . CoVs genome contains variable number of open reading frames (ORFs) 6-11. Among ORFs, two-thirds of viral genome located in first orf1a/b which translates two different polyproteins, pp1a and pp1ab. These polyproteins encodes 16 different nonstructural proteins (nsps); however, the rest ORFs encode several accessory and structural proteins. The remaining viral RNA encodes four indispensable structural proteins (spike S glycoprotein, small envelope E, matrix M, and nucleocapsid N protein), in addition, several accessory proteins that assist virus to evade host immune response [2, 3] . Previously, Middle East Respiratory Syndrome (MERS) CoV (2012) and SARS-CoV (2003) caused outbreaks that were considered as the public health threats. But in December 2019, China has reported a novel strain of severe acute respiratory syndrome coronavirus which is renamed as SARS-CoV2 by the World Health Organization [4, 5] . Compared to previous outbreaks, SARS-CoV2 disease (COVID- 19) outbreak has been much disturbing due to its high rate of infection at global level. As of November 21, 2020, there are 57,910,582 positive cases that have been confirmed in which 1,377,762 death occurred as reported by WHO, globally. Moreover, due to high rate of infection of SARS-CoV2 and zoonotic disease, it spreads rapidly throughout the world and became a pandemic and ultimate threat to mankind at this time. Studies have shown that SARS-CoV2 shares 96% genome similarity with Bat CoV RaTG13 and it is assumed that bat could be the natural host for SARS-CoV2 origin [6] [7] [8] . Scientists across the globe are trying to elucidate the genome characteristics using phylogeny, structural, and mutational analysis. Recently, few scientists are able to crystalize the protein of this virus for future computational modeling and drug-related research [9, 10] . Genome sequencing is considered one of the main factors in research which reveals almost everything of the organism, but in this case, there are more than 400 genomes of SARS viruses are submitted in NCBI genome database and many are still being sequenced and analyzed throughout the world. There are many published research suggested few drugs as effective against COVID-19 [11, 12] , but unfortunately, there is no drug as effective to cure from this virus. There are huge complications on designing a drug against any virus due to its mutational adaptation and modification in its genomic islands. In the current work, we have extensively mined the various constraints of the genome like from country, host organism, and reported year and chosen the extensively different data with the SARS-CoV-2 from China and India to get the exact rate of mutations. We have included the data of whale, rat, fowl, camel, and human to get the genomic divergence between all species which are infecting different hosts. Further, we have also created the local database for the genomic reannotation within all species which resulted in the various new annotations from the genome itself and extracted the data for plotting them in graphical format for understanding its various restraints. In addition, we have identified the restriction sites on the genomes of the species and categorized the long-sequence repeat and short-sequence repeat which can be used in future modeling. Genome-based medication is the present requirement for this pandemic; short-sequence repeats (SSRs) can play an important role in this procedure. The predicted mature peptide can be analyzed further for getting the huge implication on targeting the translation mechanism. Our analysis shows a colossal focus on different annotations to get several ideas on the medication after understanding the genome.@story_separate@Genome sequence of all coronaviruses have been downloaded and converted to a comma-separated values (CSV) file and have been analyzed the important features such as the geographical locations, period, and host organism where the suitable one for all meanings was taken into consideration and performed for all the analyses of that coronaviruses. Human SARS-CoV2 has been taken 3 times because of its difference in the sequencing timing and geographical locations. After preparation of the final list of 24 genomes, it was renamed as the serial number_Accession Num-ber_sequence_reporting_country_host_year of submission (Table 1) to avoid any confusion during analysis and for the reader as well. Further, all 24 genomes are enlisted below to understand its sequence reporting country host and the name of the virus. The genome of the different species has been downloaded, through the NCBI plugin in Geneious prime [13] and reannotated through the feature using the local database which creates many new annotations. However, MN996531.1 has been taken as reference for all the analyses. Genomes were aligned using MAFFT [14, 15] with parameters such as Auto algorithm selection and 200PAM/k = 2, Gap open penalty of 1.53, and all the data to find the distance between all the species [14, 15] . Annotation extractions provide a huge specific sequence which was further analyzed and plotted using excel and tableau [16] . The Genome of the SARS-CoV2 is plotted (Fig. 1) using the Geneious prime for better comprehension and understanding by a common reader [13] . All the data have been reannotated with local database feature in Geneious prime and collected the count of each annotation (Table 2) . The transcription factor was predicted using the Geneious prime plugins with the database of REBAS, the Restriction Enzyme Databases have been reannotated using the locally created database to get the same annotations of all species with the huge number of site identification [17] . Phobos was used for the short-sequence repeat analysis with the parameters of extend where the exact search and the repeat unit length were set to 1(min) to 10 (max) bp long, and the percentage of perfection was set to 0 to max 100 [18] . LSR was analyzed and extracted using the default program of repeat finder in geneious prime with the parameters such as minimum repeat length of 100 and ignoring the repeat up to 10 bp and 0% of mismatch which includes further both repeat sequences analyzed then categorized. All the sequences based on the length were plotted separately to get the difference and specific locations. All the data were again aligned using the MAFFT aligner [14, 15] and the single-nucleotide polymorphisms (SNPs) were extracted separately in another column, and afterwards the percentage of the mutation were calculated with the genome size for wide understanding in a lay or easy format. All the data of the untranslated region of 3′ and 5′ were extracted and enlisted separately and plotted after mining. Mature peptides were predicted using the Geneious prime and reannotated again with the local database then extracted the data from the sequence and mined them for the plotting in accordance with the data size and the name of species and the peptide parallelly. The phylogenetic tree was constructed using three programs and steps; first, we have aligned the data using MAFFT aligner [14, 15] because of its fast and accuracy and then plotted the tree using Geneious tree builder [19] and the final editing was done using the iTOL server for the plotting in circular and colorful format [20] . We have used the neighbor-joining method with no-defined outgroup and Tamura-Nei Genetic distance Model as parameters in the Geneious Tree builder [21] . The format of the tree was plotted to be understood for the common person easily and highlighted the specificity such as human-related species.  Here, we have mapped the genomes with the specific features of annotations and plotted the graph of the sequence of the genome. Wuhan SARS-CoV2, a new strain of coronavirus now called severe acute respiratory syndrome coronavirus 2 (SARS-CoV2), [22] is plotted using Geneious prime for the annotation of the data and all information about the genomes is collected and reannotated with the local database feature; after reannotation, the data have been updated and the sequences are plotted gene (green) on CDS (yellow) and found a total of 11 CDS and genes, respectively (Fig. 1 ). The genome is having a total of 129 ORF with small and long read size plotted with copper color in the genome map. We have got a total of 10 restriction sites on the genome of SARS-CoV2 which are PvuI, StuI, XhoI, BamHI, NaeI, SacI, SstI, XmaI, SmaI, and NruI having length of 6 bp and BglI having length of 11 bp. Further, it is plotted within the graph including their names (Fig. 1) . The nucleotide content was plotted from 100% to 0% and forecasted accordingly with the ATrich in green, GC rich in blue, and frame with the red color to avoid any confusion (Fig. 1) . The protein-coding region is plotted using the tcode tool of EMBOSS v.6.5.6 [23, 24] which is in yes or no format it depicts that the blue color graph line comes in the green band are protein-coding and the blue line comes to the red band are not coding part of the genome. CpG islands are plotted along with the black line with the other form. Figure 1 gives an intense view with the name of annotations which will guide the researcher to get the exact information and identify which region is actually responsible for a particular function and where restriction sites are located. Collectively, this information will provide a better idea about the future research on it. We have taken genomes of 24 coronaviruses and renamed them for better presentation. The data have been extracted from Geneious prime and plotted using Excel. The longest length in bp of the genome is beluga whale which is 31,686 bp long, while the genome size of the Indian and Chinese SARS-CoV2 is 29,851 bp and 29,857 bp, respectively (Fig. 2) . When we compared the genome size of the Indian and Chinese SARS-CoV2 with a whale genome, we observed that both had the less genome size of 1835 bp and 1829 bp, respectively. The smallest genome of SARS causing virus is with the genome size of 27,324 bp long. All the genomes are falling within this range (Fig. 2) . The length of the genomes matters because of their elements, the longest genome usually contains a greater number of genes which resulted in more complexity in the system while small genomes usually contain less number of genes which may contain the less number of genes. We have aligned all the genomes together and extracted the data into the matrix format. The data are first generated in the percentage of the similarity and then plotted accordingly and proportionally. The maximum similarity has been found in the two genomes of human SARS-CoV2 which are reported from China and India. similarity with the genomes of the SARS-CoV2 but most of the genomes shows 33% similarity which is still a huge similarity if it is found in the coding region (Fig. 3) . The distance is being plotted in 2D format (Supplementary excel sheet). We have plotted the 2D matrix and we have gotten combo plot for the better understanding, one plot is bar graph plot which shows few species to species genome similarity, while the line shows the up and down in the graph that can be observed very easily because of a different color. Both line and the bar graph show the same data and together make a combo plot of genome distance. This distance matrix shows the shared genomic region which could be visualizes during the phylogeny and it is helpful for the species classifications on the basis of genomic similarity. SNPs are one of the important changes in the genomes which help species to acquire different climate and even helps to develop into a different organism [25] . Personalized medicine development is failing only because of the modification or mutational changes in any position which resulted in the failure of the whole system. We have extensively mined the data after MAFFT alignment [14, 15] and Fig. 4 , we have plotted Y (blue), S (gray), and R (yellow) bar graph; however, M (green), W (orange), N (light blue), and K (violet) depict line graph, and the genome length has been shown with the maroon color in bold bar graph. Taken together, these results suggest that SARS-CoV2 has less chance of mutation. We have collected all annotations from 24 genomes of coronaviruses and plotted them for better understanding about their detail. In annotations, we are taking sequence length, GC content and count of CDS, gene, ORF, repeat regions, untranslated regions, transcription factors, and mature peptides (Fig. 5) In our reannotation procedure, we identified the transcription factor from every species (Fig. 5) . Further, all the details are present in the supplementary sheet with the description from every single  We have used Phobos to identify short-sequence repeats in the genomes of every species and plotted them accordingly. We have found a total of 1250 short-sequence repeats in the sequence of all species. The longest repeat under the SSR is 47 bp long while the smallest repeat is 7 bp long in the sequence of the 24 different genomes of coronaviruses. Short sequences are to be handled in the experimental lab as well as the computational laboratory. Designing antisense mRNA is far easier for the short-sequence repeat to tackle this virus. That could be a better strategy to find the best repeat region which might not found in the human body and targeting to its restriction site together to cut the genome of the coronavirus and that information will be saved in the T cell. Further, reoccurrence of the same virus, the memory T cells will get activated to encounter rapidly and clear it. Though there is the possibility of various complication and failure which needs huge improvements after identifying the right SSRs, we have identified the all short-sequence repeats which are further plotted with the green line. The data were first prepared in the maximum and minimum format to get the exact information of SSRs location. In Fig. 6 , yellow bar shows maximum whereas reddish line shows minimum format; however, SSRs falls in between. There are few SSRs which are unique among the SARS-CoV-2 which does not exist in any species, targeting these SSRs could also be an important strategy for the breaking down mechanism. Phobos considered repeats as the same sequence as well as the complementary sequence as well. In SARS-Cov2, 'AAG AAG AAG' is considered as AAC repeats. In the sequence, we have found 8 AAC repeats which are found with length of 9-11 bp. A trinucleotide repeats have been found with the length of 9 bp. These repeats found at 614-622 and 22,308-22,316 positions of the genome. Long-sequence repeats (LSR) analysis was performed using Geneious default program to identify the location. Repeat region with specific to the higher sequence length, long-sequence repeats (LSR) is extracted. The green line is plotted for the average identification and getting and closer view on data forecasted in the categorization of the genome and the repeat of long sequence will also provide the gap among the genome to cut it specific position and reduce the antigenic protein formation. Collectively, we have plotted the data for complete understanding with its length and the accessions. Further, we have provided the data of the sequence and the positions in the supplementary excel sheet. In molecular biology, an untranslated region alludes to both of the two segments, one on each side of a coding sequence of mRNA strand. When it is present on the 5′ side, it is called the leader sequence and whenever it is located on the 3′ side, it is called the trailer sequence (3′ UTR) [27, 28] . Fig. 8 for comparative analysis of size and species which are containing the UTR and its type. We have also depicted the length and the respective name of the UTR with the accession number in sunburst plot of the data. These UTRs from the above species will be helpful in categorization of the genomic data into the fully functional and nonfunctional range to further accelerate the translational analysis. In molecular biology, sequence-specific DNA-binding factor is called transcription factor (TF) which is a protein that controls the rate of transcription of genetic information from DNA to messenger RNA, by binding to a specific DNA sequence [29] . The function of TFs is to regulate and turn on and off genes to make sure that they are expressed in the right cell at the right time and in the right amount throughout the life of the cell and the organism [30, 31] . The replication and increase in copy numbers of virus in the human body are led by the transcription factors, so blocking TFs could be also a mechanism to tackle the pandemic but having huge complications and limitations. Transcription factors contain at least one DNA-binding domain (DBD), which attaches to a specific sequence of DNA adjacent to the genes that they regulate the functionality of the gene and further it grouped only because of this feature. TFs work alone or with other proteins in a complex, by acting as an activator, or as a repressor of the recruitment of RNA polymerase to specific genes. We have identified a total of 2509 transcriptional factor. There are 84 transcriptional factors are uniquely identified from all 24 species. Length of the transcriptional factors is varying from 19 to 10 bp. All genomes contain mostly similar type of TF and having similar and mismatch in the length as well. We have plotted the data into sunburst plot with the respective length to identify the length differences. All species are containing the TF with exceptional features and the enormous quantity, which could be a great target subject for designing the drug after identification of a unique one. In Fig. 9 , we have added the name of the TF and the length together to get a comparative visualization of the data. These transcriptional factors will be helpful for the experimental laboratories working in the area of gene-based drug design to directly stop the mechanism of replication in viruses.  Mature peptides that control infection, including its replication, transmission, pathogenicity, and host immunologic reactions. The first open reading frame (orf1a/1b) translates two polyproteins, pp1a and pp1ab, and encodes 16 nonstructural proteins (NSP) [32] [33] [34] . After translation, this polyprotein is processed by viral proteases into mature peptides. We have tried to predict mature peptide sequence from the whole genome of 24 coronaviruses and have gotten the mature peptides from only 7 coronaviruses. The length of the mature peptides varies from species to species. There are only two types of mature peptides which are repeated with the difference of the length and the positions. A mature peptide from all species orf1ab is having the longest sequence length of 6087 bp and the smallest length of 39 bp, while the mature peptide from NC_010800.1_Canada_Turkey coronavirus 2018 1ab is having the longest length of 19,503 bp and the smallest length of 529 bp. Moreover, mature peptide 1ab is only present in NC_010800.1 (Canada-Turkey coronavi-rus2018). In NC_038294.1 (UK beta coronavirus), there is only one mature peptide with the length of 42 base pairs and it is found at the position of 13,409-13,450. Further, we have plotted the data in Fig. 10 with the accession number and the name of the peptide with their respective length. Targeting the mature peptides could also be one of the aspects of drug design which may provide a significant way of testing a drug.  We have analyzed all the various functionalities and structures of the genomes and after that aligned the data using MAFFT [14, 15] and then performed the phylogeny using Geneious Tree builder (Fig. 12) . The phylogenetic tree was further modified using the iTOL server for getting a clear view and the node distances as well (Fig. 11 ). As the tree shows that Beluga whale is the outer species in the tree, all 3 strains of SARS-CoV2 (2 from China and one from Kerala India) come under the same clade and NC_004718.3_Canada: SARS2018 is one of the closest species among the 24 considered genomes and plotted in the yellow color. Miniopterus bat (NC_010438.1) coronavirus is not linked or not even in the same clade; it is present under another clade of the tree and plotted in cyan color. SARS-CoV2 genomes are falling in the same clade and further depicted in green color in the circular phylogenetic tree. UK_βCV1 and MERS coronavirus are in the same clade and plotted it with the red color. In Fig. 12 , we have also provided additional information and linear phylogenetic tree for understanding the difference and the divergence of the spices with the clade length.@story_separate@The main aim of this study was to take the genomes of coronaviruses from different geographical locations as well as different host to infer the genomic similarity and Liner phylogenetic tree for the reference dissimilarity in addition to the functional understanding of the genome. We have done various analyses regarding the genomes of different coronaviruses which may cause severe respiratory disease and ultimately death. Our deep analysis to the all annotations and extraction of the data (details provided in excel sheets) provide us various interesting facts and strategies to work on few steps for further research to unveil the attacking site within the genome. Our wide focused analysis of the genome annotations gives an intense view on the genome from a different angle which will be easier to identify the region of the genome and GC content with AT graph, CpG islands, transcriptional factors, and most importantly the region of gene contents and responsible ORF as well. We have also predicted the restrictions sites on the genome in particular to the map for getting the diverge view on that matter and to help future researchers. The length comparison of all the coronaviruses also gives an important fact that the number of genes and other annotations contains within the genomes with base pairs. Analysis of the distance between all the species gives a contrasting view to focus on the coronavirus and the percentage of similarity which means the data of other query species are sharing the either very high or medium amount of genome data. We have aligned all the genome separately with the reference species SARS-CoV2 (MN996531.1) to get the similarity and single-nucleotide polymorphism, which finally revealed that SARS-CoV2 does not have a huge rate of mutations in a gap of few months but it has a wide difference with other coronaviruses infecting animals and the same result was already inferred by the distance matrix which shows almost 99.97% similarity with the SARS-CoV2. NC_004718.3 reported from Canada in 2018 is having the similarity of 79.047% which is highest among after CoV2 while MERS is showing 35.4% of genome similarity. There are only 8 mutations in the SARS-CoV2 reported from India and China. In details, such as 6 SNPs found on the orf1ab gene, 1 SNP at S gene and 1 SNP at NS8 gene at the position of 28,131. NS8 is the main coding region of the protein which codes for the infectious part of the protein. MERS coronavirus is showing the 15,762 mutations which is 49.60% of the total genome. Coronavirus reported from Canada in 2018 is having a total of 6274SNPs which is 20.9% of the whole genome. Further, we have taken the count of the annotations to get the comparison among all which also reveals a huge difference with other old coronaviruses but like the SARS-CoV2 which means the 8 SNPs are almost negligible while translating the data of genome in the process of protein formation. Repeat analysis focuses on the short-and long-sequence repeat analysis, short-sequence analysis, and its identification in the genome of coronavirus can be utilized for drug discovery to another level. Identification of the SSRs and targeting to the SSRs can be a good step towards breaching the genome of the coronavirus, it's a better strategy to break down the genome before it gets translated. There could be many idea and strategy on how to design antisense or directly activating the immune system to produce the antisense mRNA. Identification of long-sequence repeat is also playing a role in the different protein-producing genes and to target them specially. In addition to the basic annotations, we have identified and extracted the data of untranslated regions from different species of coronavirus and categorized them on the behalf of 3′ and 5′ separately. There are only 6 coronavirus genomes which contain the UTR regions. Only 24_MN975262.1_ China_seafood pneumonia2020 contains the UTR region which shares almost 100% similarity the Indian SARS-CoV2. Comparative annotation analysis also unveils all transcriptional factors which are directly related to the division of viruses. Directly taking the action against using specific drugs could directly stop translating the protein and ultimately T cell might automatically identify that viral particle as a foreign pathogen and cleared them from the body. TF is located at different locations of the genome. We have provided detailed information including the sequence in Fig. 9 and full details are available in the supplementary excel sheet. We have also predicted the matured peptides from the different coronaviruses which will clarify the genome complexity of the coronavirus. Phylogenetic analysis also reveals that all coronaviruses are diverse and SARS-CoV2 from china and India is found to be in the same clade. Beluga whale coronavirus is found to be one of the outliers of the all considered genomes. The whole analysis especially SNP and phylogenetic tree suggests that the Indian SARS-CoV2 is having very less 8 mutations on its CDS region while another SARS-CoV2 reported from china is having 7 mutations with the reference species MN996531.1_China_WuhanSARS2_2020 which is almost negligible. Distance analysis between all species also suggests the same update on the genomic evolutions and modifications. NC_010438.1_HK_Miniopterus_bat-2018 coronavirus shares only 37.6% genomic content to the SARS-CoV2 which clarifies the concept that SARS-CoV2 is not originated from the miniopterus bat coronavirus (Figs. 11, 12) . As the maximum amount of genomic content is shared by the NC_004718.3_Canada: SARS, which is reported from Canada in 2018, seems to be the closest species among all 24 considered coronaviruses. We have additionally identified the short-sequence repeats and their position in the genome which could be useful in the further drug development process.","Novel strain of Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV2) causes mild to severe respiratory illness. The early symptoms may be fever, dry cough, sour throat, and difficulty in breathing which may lead to death in severe cases. Compared to previous outbreaks like SARS-CoV and Middle East Respiratory Syndrome (MERS), SARS-CoV2 disease (COVID-19) outbreak has been much distressing due to its high rate of infection but low infection fatality rate (IFR) with 1.4% around the world. World Health Organization (WHO) has declared (COVID-19) a pandemic on March 11, 2020. In the month of January 2020, the whole genome of SARS-CoV2 was sequenced which made work easy for researchers to develop diagnostic kits and to carry out drug repurposing to effectively alleviate the pandemic situation in the world. Now, it is important to understand why this virus has high rate of infectivity or is there any factor involved at the genome level which actually facilitates this virus infection globally? In this study, we have extensively analyzed the whole genomes of different coronaviruses infecting humans and animals in different geographical locations around the world. The main aim of the study is to identify the similarity and the mutational adaptation of the coronaviruses from different host and geographical locations to the SARS-CoV2 and provide a better strategy to understand the mutational rate for specific target-based drug designing. This study is focused to every annotation in a comparative manner which includes SNPs, repeat analysis with the different categorization of the short-sequence repeats and long-sequence repeats, different UTR’s, transcriptional factors, and the predicted matured peptides with the specific length and positions on the genomes. The extensive analysis on SNPs revealed that Wuhan SARS-CoV2 and Indian SARS-CoV2 are having only eight SNPs. Collectively, phylogenetic analysis, repeat analysis, and the polymorphism revealed the genomic conserveness within the SARS-CoV2 and few other coronaviruses with very less mutational chances and the huge distance and mutations from the few other species."
"Working in the Intensive care unit (ICU) is already a source of stress under normal circumstances. Data collected before the COVID-19 pandemic revealed that 13% of ICU professionals were anxious, 4% depressed, and 11% presented symptoms of post-traumatic stress disorder (PTSD) [1, 2] . The risk of developing PTSD was greater in nurses working in ICUs than in other hospital wards [3] . A review conducted before the pandemic [4] found that the prevalence of burnout in ICU healthcare workers ranged from 6-47% and was associated with age, sex, marital status, personality traits, work experience in an ICU, work environment, workload and chats, sending them a brief explanation of the purpose of the study and a link for filling in the online questionnaire. A dedicated website (https://icufiera.marionegri.it/) was created ad hoc for this project. An online, semi-structured questionnaire was developed by using Wordpress, a free open-source content management system (CMS), integrated with SurveyJS (survey library and survey creator), a library to facilitate survey creation and management. The survey script was available for all devices. Online consent was obtained from the participants. The survey questionnaire was anonymous and required approximately 15 minutes for completion. No participant identifier was required or recorded, preserving the anonymity of responders. Once data were extracted, they were checked to prevent duplicates; incomplete questionnaires were excluded from the Maslach Burnout Inventory. The ethics committee of the Besta Neurological Institute in Milan approved the study protocol (Report number 81). All the items of the STROBE checklist for cross sectional studies were met in the present report. The first section comprised demographic questions and information regarding personal and professional experience; this section explored potential associated factors including age, gender, living conditions (people living with the participant), occupation, work hours, length of professional experience, and usual place of work (hospital unit before the pandemic). The second part of the survey focused on mental health outcomes: symptoms of burnout, anxiety and depression were investigated as well as resilience strategies. The following validated assessment tools were used: the Maslach Burnout Inventory (MBI) [23] is a 22-item questionnaire asking respondents, on a 7-point Likert scale (from 0 to 6), the frequency with which they had recently experienced specific feelings related to their work. The MBI evaluates three subscale domains: emotional exhaustion (EE, measures feelings of being emotionally overextended and exhausted by one's work; nine items), depersonalization (DP, measures unfeeling and impersonal response toward recipients of one's service, care or treatment; five items), and personal accomplishment (PA, measures feelings of competence and successful achievement in one's work with people; eight items). Participants were considered to have experienced burnout when the level of emotional exhaustion or depersonalization exceeded the cut-off, regardless of the presence or absence of reduced personal accomplishment, given its lack of evidence as a predictor of clinically diagnosed burnout [15, 24] . Consistent with the Italian literature, we considered the level of burnout to be high if emotional exhaustion scores were ≥24, personal accomplishment scores were ≤29, and depersonalization scores were ≥9; moderate if emotional exhaustion scores were 15-23, personal accomplishment scores were 30-36, and depersonalization scores were 4-8; and low if emotional exhaustion scores were ≤14, personal accomplishment scores were ≥37, and depersonalization scores were ≤3 [25, 26] . The Hospital Anxiety and Depression Scale (HADS) is a 14-item self-report screening scale originally developed to indicate the possible presence of anxiety and depression states in the setting of a medical, non-psychiatric outpatient clinic. The HADS consists of a 7-item anxiety subscale and a 7-item depression subscale. A score of >8 identifies subjects with a positive history for anxiety and/or depression [3, 27, 28] . For each scale, scores of 8-10 indicate mild symptoms (possible case) and a score greater than or equal to 11 indicates moderate/severe symptoms (probable case). The Resilience Scale for Adult (RSA) [29, 30 ] is a 14-item self-report instrument for evaluating six protective dimensions of resilience in adults. Item responses range from 1 (strongly disagree) to 7 (strongly agree) and scores vary between 14 and 98, with higher scores indicating higher levels of resilience. A score <56 indicates a very low resilience level; a score between 57 and 64 indicates a low resilience level; a score between 65 and 73 indicates that resilience level is on the low end; a score between 74 and 81 indicates a moderate resilience level; a score between 82 and 90 indicates a moderately high resilience level; and a score >91 indicates a high resilience level. The Insomnia Severity Index (ISI) questionnaire asks respondents to rate the nature, severity, and impact of insomnia using a Likert-type scale. Questions relate to subjective qualities of the respondent's sleep, including the severity of symptoms, the respondent's satisfaction with his or her sleep patterns, the degree to which insomnia interferes with daily functioning, how noticeable the respondent feels his or her insomnia is to others, and the overall level of distress created by the sleep problem. Though developers point out that their chosen cutoff scores have not been validated, they offer a few guidelines for interpreting scale results: a total score of 0-7 indicates ""no clinically significant insomnia"", 8-14 means ""subthreshold insomnia"", 15-21 is ""clinical insomnia (moderate severity)"", and 22-28 means ""clinical insomnia (severe)"".@story_separate@Data are reported as number and percentage of responders. Data analysis was performed using frequency distributions for categorical variables summarized using proportions and associations tested using chi-square or Fisher's exact test (χ 2 or F), where applicable.) Continuous variables were tested for normality with Kolgorov-Smirnov (""age"" was the only continuous variable that we included, D = 0.0119792, p < 0.01) and summarized using mean, median, and range. To identify factors influencing burnout and the MBI scale, we computed odds ratios (OR) considering the significance of the confidence intervals (CI). Statistical significance was evaluated using 95% confidence interval and a two-tailed p-value of <0.05. In the multivariable analysis, a log-binomial regression model was used. All variables were entered into the model and a stepwise regression analysis was conducted. SAS software, version 9.4 (SAS, Institute Inc., Cary, NC, USA) was used for all statistical analyses. Of a total of 271 nurses and physicians working in this ICU, 150 (55% mean response rate; 71.2% for physicians, 42.4% for nurses) completed the survey questionnaire, of whom 14 (9%) were excluded because of missing data on the MBI. No difference was found between responders and non-responders for gender and profession (physicians vs. nurses). The data on the 136 study participants (84 nurses and 52 doctors) were analyzed ( Table 1 ). The variable ""age"" presented a continuous distribution, and the mean value of the participants was 39.1 years; most (74.1%) were living with others, and 44% had children. The majority (67.4%) of the intensivists had already been working in ICUs before the pandemic, but nearly half (54%) reported difficulties in adapting to the new work environment (COVID-19 ICU). Nearly one out of three participants was not working in an ICU before the pandemic; in particular thirty nurses used to work in other hospital wards: this could have led to a higher percentage of reported difficulties in the ICU environment for nurses (59.7%). The only statistically significant difference between nurses and physicians (p = 0.02) was observed in the fear of spreading the virus to people they lived with: nearly 70% of nurses was very worried vs. 56.7% of physicians. ICU specialists were asked to compare their COVID-19 experience to their prior work. Nearly half of nurses did not report an increased workload, whereas two out of three physicians (68.8%) experienced it. Most nurses stated that the opportunities to discuss important decisions in group were less frequent than before, while physicians reported the opposite. Most of the HCWs (58%) felt protected when working: the most common reported adverse reactions of wearing protectors (personal protective equipment, PPE) for long time were eye strain, thirst, and the impossibility of using the toilet. Shifts were fixed: nurses had longer shifts (mean number of hours per shift) and a higher number of night shifts per month than physicians.  The mean rate for the three dimensions of burnout is shown in Figure 1 . A high level of burnout (60.3%) was frequent among the respondents (Figure 1a ). High levels of depersonalization (DP) were observed in 47.8% of the intensivists (Figure 1b ): more than half of the nurses reported high scores (54.8%), while lower scores were observed in the physicians (36.5%) (Table A1) The proportion meeting the criterion for burnout in this study (high EE or DP) was 60.3% (82 participants), with nearly the same percentages among nurses (61.9%) and physicians (57.7%). 22.7% of participants received a score referring to a high risk of burnout, in the high range for all three; nearly the same prevalence of intensivists (22%) reported low levels in all the three dimensions. Anxiety symptoms were reported by 53% of participants (Figure 2a) , with a statistically significant difference (p = 0.02) between nurses and physicians: while the majority of nurses reported symptoms of anxiety (61.5%), most of the physicians presented normal levels of anxiety (60%). The proportion meeting the criterion for burnout in this study (high EE or DP) was 60.3% (82 participants), with nearly the same percentages among nurses (61.9%) and physicians (57.7%). 22.7% of participants received a score referring to a high risk of burnout, in the high range for all three; nearly the same prevalence of intensivists (22%) reported low levels in all the three dimensions. Anxiety symptoms were reported by 53% of participants (Figure 2a) , with a statistically significant difference (p = 0.02) between nurses and physicians: while the majority of nurses reported symptoms of anxiety (61.5%), most of the physicians presented normal levels of anxiety (60%). Depression symptoms were found in 45.2% of responders ( Figure 2b ). In particular, more than one out of two intensivists (54.8%) reported normal levels of depression, with no differences between nurses and physicians. Overall, nearly one out of five (16.1%) scored above 11 for anxiety on the HADS, indicating the presence of clinical levels of anxiety, whereas 13.9% scored in this clinical range for depression. Participants showed moderate/high levels (82.4%) of resilience ( Figure 2c ). Only 8.7% of the ICU staff was highly resilient, while 17.6% had low or very low scores. 61.5% of the intensivists described insomnia symptoms (Figure 2d) , and there was a significant difference between nurses and physicians (p = 0.005): 71% of nurses reported symptoms of insomnia, while physicians showed lower percentages (54.3%), with clinically significant symptoms in only 17.6%. Depression symptoms were found in 45.2% of responders (Figure 2b ). In parti more than one out of two intensivists (54.8%) reported normal levels of depression no differences between nurses and physicians. Overall, nearly one out of five (1 scored above 11 for anxiety on the HADS, indicating the presence of clinical levels o iety, whereas 13.9% scored in this clinical range for depression. Participants showed moderate/high levels (82.4%) of resilience (Figure 2c ). Only of the ICU staff was highly resilient, while 17.6% had low or very low scores. 61.5% intensivists described insomnia symptoms (Figure 2d) , and there was a significant d ence between nurses and physicians (p = 0.005): 71% of nurses reported symptoms somnia, while physicians showed lower percentages (54.3%), with clinically signi symptoms in only 17.6%. From univariate analyses, factors associated with burnout were: anxiety, depre and insomnia symptoms (Table A2) . The logistic regression analysis (Table 2) showed that working in other ho wards (not ICU) before the pandemic is a possible predictor of lower levels of bu (OR 3.02, 95% C.I. 1.06-8.58, p < 0.05). High levels of depressive symptoms were also as a factor significantly associated with burnout (OR 4.88, 95% C.I. 1.54-15.48, p < 0.  From univariate analyses, factors associated with burnout were: anxiety, depression, and insomnia symptoms (Table A2) . The logistic regression analysis (Table 2) showed that working in other hospital wards (not ICU) before the pandemic is a possible predictor of lower levels of burnout (OR 3.02, 95% C.I. 1.06-8.58, p < 0.05). High levels of depressive symptoms were also found as a factor significantly associated with burnout (OR 4.88, 95% C.I. 1.54-15.48, p < 0.01). Considering intensivists and burnout, high levels of depersonalization were found in 65 out of 82 participants, while a high degree of emotional exhaustion was reported in 56 intensivists. A subgroup analysis was conducted for the three dimensions of burnout (Supplementary Material, Tables S1-S3). Presence of symptoms of anxiety, depression, and high levels of resilience were associated with high emotional exhaustion, high depersonalization, and lower levels of personal accomplishment. Clinical insomnia symptoms among intensivists were strongly associated with high levels of EE. (OR 4.71, 95% C.I. 2.04-10.84). Regarding gender, men reported lower levels of high EE than women (OR 0.46, 95% C.I. 0.22-0.94). Physicians had lower levels of DP than nurses (OR 0.48, 95% C.I. 0.23-0.97). High levels of burnout (high EE/ low PA) were reported in those who did not feel protected when working (respectively OR 2.94, 95% C.I. 1.41-6.09 for EE, and OR 2.98, 95% C.I. 1.44-6.16 for PA) Difficulties in adapting to the new work environment were related (OR 2.34, 95% C.I. 1.11-4.96) to emotional exhaustion: those who described more difficulties were twice as likely to have high levels of burnout than those who did not report them.  The results of the present study confirm that COVID-19 had a significant adverse impact on the psychological well-being of ICU workers. A recent meta-analysis [31] examined the psychological burden of frontline medical staff during pandemics and epidemics and concluded that the prevalence of burnout symptoms was 31.8%. In the present study, burnout levels were higher than those found in other studies: 43% of respondents scored at high risk for burnout on at least one dimension (high EE, high DP or low PA), 60.3% met the criterion for burnout (EE or DP), but only 22.7% were in the high range for all three. Regarding the three dimensions, high levels of reduced personal accomplishment were found in half of the intensivists, followed by high levels of depersonalization and emotional exhaustion scores (47.8% and 41.2%, respectively). Our results are consistent with other studies conducted during the COVID-19 outbreak: a recent study reported that half of the European intensivists (51%) experienced severe burnout [13] . Similar rates (49.5%) of moderate to severe personal burnout were described in another study conducted in Singapore during the same period [32] . A higher prevalence of burnout (82.1%) was reported in China among ICU physicians [33] . Regarding the three dimensions of burnout, an Italian study highlighted higher scores for emotional exhaustion (40.7%) than depersonalization (30.2%) and low personal accomplishment (36.4%) [25] . Lower scores of burnout (high EE = 37%, high DP = 25%) were found in a recent Italian study [34] . A possible reason for this could be that the researchers considered HCW who directly assisted COVID-19 patients, but did not focus specifically on ICU workers. Average levels of emotional exhaustion and depersonalization were described in previous studies concerning Italian HCWs in normal working conditions [35] , but the baseline levels of burnout depended on the subject characteristics. An Indian study showed that, during the emergency, nurses experienced moderate to severe levels of burnout in emotional exhaustion (54.2%) and depersonalization (43.3%), but mild to moderate levels of burn out in reduced personal accomplishment and presented a moderate to high level of resilience [36] . Similar rates of resilience were also reported in the present study (82.4% moderate or high resilience), with no significant differences between nurses and physicians. Findings of one study [1] conducted before the outbreak, and only on ICU staff, showed that the prevalence of burnout was 37%: in contrast with our results, they found that physicians were twice as likely as nurses to be at risk of reporting burnout. Physician fatigue has a negative impact not only on one's well-being but also on patient care and the health care system. This may be consistent with low job satisfaction, decreased work productivity, medical errors, poor quality of patient care, low job satisfaction, early retirement, and healthcare system failure [37] . Moreover, there was a degree of overlap between burnout and other measures of distress, most notably for anxiety. Anxiety and depression symptoms were more common among nurses than doctors. Our findings are comparable to those of an Italian study [38] conducted on HCW during COVID-19 that demonstrated that staff working in ICUs or sub-intensive COVID-19 units had a significantly increased risk of developing adverse psychological outcomes (more specifically, post-traumatic distress symptoms and depression), independent of any other factor, and that nurses had a considerably greater risk of adverse psychological outcomes than physicians. One study conducted in the UK on ICU workers during the pandemic [39] showed that higher levels of anxiety and depression were reported in females and in nurses than physicians. Shen et al. [40] revealed that ICU nurses have to face many difficulties such as working in an unfamiliar environment, lack of experience in caring for infectious patients, anxiety about being infected, heavy workload, extreme exhaustion and depression, due to failure to treat critically ill patients. A recent qualitative study [41] drew attention on the challenges faced by nurses working in intensive care units during the crisis of the COVID-19 pandemic. The study reported that an organization's inefficiency in supporting them, physical exhaustion, living with uncertainty, and the psychological burden of the disease were the most challenging themes associated with caring for COVID-19 patients. In the current study, symptoms of insomnia were frequent among intensivists (61.5%). In particular, 17.6% of the participants reported clinically significant symptoms of insomnia: higher rates of moderate or severe insomnia were more frequent in nurses than in physicians (5.7%). High prevalence of insomnia symptoms was also found in a Chinese study conducted on front-line nurses fighting against COVID-19 [42] , which reported that 52% of nurses showed insomnia. Comparing these results with our findings, it is essential to take into consideration that data were collected in different phases of the pandemic (March 2020, first phase) and assessed with another self-report measure (Ascension Insomnia Scale). A positive relationship between exhaustion and insomnia was also observed [43] : frontline medical staff are under enormous pressure during the COVID-19 pandemic. Expectations leading to anxiety, depression, stress-related symptoms, insomnia, and worry about becoming infected or infecting family members can lead to exhaustion. Stress could be considered the primary cause of insomnia: a relationship between insomnia and other related psychological effects of working in hospitals was identified during the previous SARS outbreak [44] . Concerning resilience, results were not as expected. According to a recent study [17] , resilience is a partial mediator in the relationship between emotional exhaustion and depersonalization with mental health outcomes. In the current study, moderate or high levels of resilience were reported in the majority of participants; our findings are in agreement with another recent study [45] , which reported that 29% of physicians with the highest possible resilience score had burnout. This unexpected result could suggest that the level of resilience was not enough to prevent ICU specialists from developing burnout symptoms, or even that a high level of resilience was not enough to impede the development of extremely high level of burnout during COVID-19 pandemic. The relevance of our findings should be viewed considering a few limitations. Firstly, the sample was not representative of Italian ICU workers because we focused on ICU staff working in the Milano Fiera COVID-19 ward; the results are therefore specific to the involved area and may not necessarily be generalizable to other regions differently affected by the pandemic. Secondly, self-report measures were used to investigate psychological symptoms, and not a disorder that needs an appropriate diagnosis. Lastly, the crosssectional design precluded causation and inferences: there is a lack of comparison with the pre-COVID-19 period and follow-up studies are needed to monitor mental health outcomes over the course of the pandemic and to assess long-lasting effects of psychological symptoms once the imminent threat of COVID-19 recovers. However, a recent study [14] , assessed the prevalence of burnout symptoms in ICU professionals before and during the coronavirus disease 2019 crisis; their findings demonstrated that prevalence rose from 23% before COVID-19 to 36.1% at post-peak time, highlighting that overburdening of ICU professionals during an extended period of time leads to symptoms of burnout. The study was conducted according to the guidelines of the Declaration of Helsinki and approved by the ethics committee of the Besta Neurological Institute in Milan (Report number 81). Informed consent was obtained from all subjects involved in the study. Participants accepted to take part in the survey after filling out the consent form. Participants were provided information on the purposes of the research on the first page of the questionnaire, and had to check a box indicating their informed consent before they could proceed. Participants were also asked to answer sincerely, and were assured that their answers would be confidential. The datasets analyzed during the current study are available from the corresponding author upon reasonable request. The authors would like to acknowledge Chiara Pandolfini for language editing and Daniela Miglio for editing. The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. @story_separate@The COVID-19 pandemic had a negative effect on the mental health and psychological wellbeing of healthcare workers, in particular for those who were in strict contact with COVID-19 patients in the intensive care units. The large presence of burnout among HCWs, without differences between nurses and physicians, suggested that the current situation has influenced the level of distress of all stakeholders, increasing anxiety and depression symptoms and changing sleep rhythms. A protracted exposure to COVID-19 patients in the intensive care unit leads to a psychological burden in medical staff. This study demonstrated that resilience in uncertain, scarcely-supported situations is not enough. For this reason, awareness about healthcare workers' psychological well-being and preventive interventions can positively influence the development of burnout syndrome. Follow-up and tailored procedures should be provided to alleviate the psychological burden to the frontline staff at highest risk. This study was conducted during the second pandemic wave, suggesting that burnout is a persistent risk for ICU workers. Supplementary Materials: The following are available online at https://www.mdpi.com/article/ 10.3390/ijerph18116102/s1, Table S1 : Emotional exhaustion sub score (EE) by severity categories (Reference=Low/Medium); Table S2 : Depersonalization sub score (DP) by severity categories (Ref-erence= Low/Medium); Table S3 : Personal accomplishment sub score (PA) by severity categories (Reference=High/Medium). Author Contributions: M.B., N.S. and E.R.Z. conceived this article and wrote the first draft. G.S., F.S. and A.C. designed the study questionnaire and performed the pilot testing with M.Z. M.Z. was responsible for the data collection and delivery through the web platform set up. R.C. did the statistical analysis and managed the data. All authors interpreted data, reviewed the drafts, and approved the final version of the article. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding. The study had no sponsor, so expenses incurred for study design, data collection, data analysis, data interpretation, and writing of the report were paid for by the department funds. The corresponding author had full access to all the data in the study and had final responsibility for the decision to submit for publication.","The COVID-19 pandemic had a massive impact on the Italian healthcare systems, which became overwhelmed, leading to an increased risk of psychological pressure on ICU workers. The present study aimed to investigate the prevalence of distress (anxiety, depression and insomnia symptoms), burnout syndrome and resilience in healthcare workers during the COVID-19 pandemic and to detect potential factors associated with their psychological response. This cross-sectional, survey-based study enrolled 136 healthcare workers assisting COVID-19 patients in the new COVID-19 ward (Intensive Care Unit), at Milano Fiera, Lombardy. Participants completed an online survey that comprised different validated and standardized questionnaires: Maslach Burnout Inventory (MBI), Resilience Scale for adults (RSA), Hospital Anxiety and Depression scale (HADS) and Insomnia Severity Index (ISI). Socio-demographic and work characteristics were also collected. Out of 136 ICU specialists, there were 84 nurses (62%) and 52 physicians (38%). Over half (60%) met the criteria for burnout, with nearly the same percentages among nurses and physicians. Nurses reported significantly higher scores of anxiety and insomnia levels. Forty-five percent of participants reported symptoms of depression (of whom 13.9% in the clinical range) and most of the staff showed moderate to high levels (82.4%) of resilience. The COVID-19 pandemic can have a significant impact on ICU staff. Effective interventions are needed to maintain healthcare professionals’ mental health and relieve burnout. Follow-up and tailored procedures should be provided to alleviate the psychological burden in the frontline staff at highest risk."
"The common cold (感冒gǎn m ao) or common acute upper respiratory tract infection, is an acute viral infectious disease of the upper respiratory tract caused by rhinovirus, human coronavirus, parainfluenza virus, adenoviruses, respiratory syncytial virus, etc. Symptoms which often appear, such as sore throat, stuffy or runny nose, cough, and malaise, are usually worse in 1e3 days and can last 7e10 days, and sometimes as long as 3 weeks. Although selflimiting, the common cold is highly prevalent. The disease affects adults approximately two to three times/year and children under the age of 2 years, approximately six times/year. Colds are also costly. It is estimated that direct medical costs in the United States, including physician visits, secondary infections, and medications for colds, were an estimated $17 billion/year in 1997. Indirect costs from missed work for illness or to look after a sick child were an estimated $25 billion/year. 1 Because there are no effective antivirals to cure the common cold and few effective measures to prevent it, treatment should focus on symptom relief. The most commonly used treatments include over-the-counter antihistamines, decongestants, cough suppressants, and expectorants. These treatments can be used alone or in combination. 2 Treatment of the common cold in traditional Chinese medicine (中醫 zh ong y ı; TCM) is based on pattern differentiation. According to the TCM theory, the common cold is considered as an exterior syndrome, which can be further divided into the wind-cold type (風 寒型 f eng h an xíng), the wind-heat type (風熱型 f eng r e xíng) and the summer heat dampness type (暑熱型 shǔ r e xíng). 3 The most common type of common cold often caught in winter and spring is the wind-cold type. For thousands of years, Chinese people have treated the wind-cold type common cold with natural herbs, some of which were quite simple, effective, widely used by folk ordinary people, and were called folk prescriptions. However, physical conditions of patients with the wind-cold type are different, i.e., some are normal and others are weak. Therefore, treatment should be chosen inaccordance with the patient's individuality according to the TCM theory. This article introduces some Chinese folk prescriptions (中國民間處方 zh ong gu o mín ji an chǔ f ang) for the wind-cold type common cold with in patients with normal and weak physique. 2. Some Chinese folk prescriptions (中國民間處方 zh ong gu o mín ji an chǔ f ang) for the wind-cold type (風寒型 f eng h an xíng) common cold (感冒gǎn m ao) with normal physique The typical wind-cold type common cold with normal physique, which is the majority of the wind-cold type common cold, is characterized by a history of catching cold, feeling cold, and nasal congestion with clear snivel (鼻塞流清涕 bí s e liú q ıng tì). Treatment for the wind-cold type common cold with normal physique includes ""expelling wind dispersing cold (祛風散寒 q u f eng s an h an)"" and ""relieving exterior syndrome by diaphoresis (發汗解表 f a h an ji e biǎo)"". The following are some recommended Chinese folk prescriptions, many of which contain ginger (生薑 sh eng ji ang), an acrid and warm herb relieving exterior syndrome in TCM and also an edible food in China. Ginger combined with scallion stalk (蔥白 c ong b ai) and brown sugar (紅糖 h ong t ang): 30 g of sliced ginger, 10 g of scallion stalk, and approximate 200 mL of water are put into a pot. Then, the pot is heated softly by a fire until the decoction inside the pot is boiled. After that, add 100e160 g of brown sugar into the decoction for a better taste. Drink the warm decoction (水煎服 shuǐ ji an fú) two to three times daily until the cold is cured. 4 Scallion stalk and ginger: 10 g scallion stalks and 10 slices of ginger are put into a pot, immersed in water, and boiled for a while. Drink the warm decoction and lie down with covered with a quilt until sweating (出汗 ch u h an). Ginger and brown sugar: three slices of ginger and an appropriate amount of brown sugar are put into a cup and stewed with boiling water. Alternatively, 15 g ginger and 30 g brown sugar are put into a pot, immersed in water, and decocted. The warm decoction can be drunk frequently. Usually, the common cold is cured when sweating. Garlic (大蒜 d a su an) and ginger: 15 g garlic and 15 g ginger are processed and taken in by the same way mentioned above for scallion stalk and ginger. Fermented soybean (豆豉 d ou chǐ) stewed with scallion stalk and ginger: scallion stalks with roots (帶鬚蔥白 d ai x u c ong b ai) 30 g, three ginger slices, and 10 g fermented soybean are put into a pot, immersed in water, and boiled. Then, 30 g yellow wine (黃酒 hu ang jiǔ) is poured into the pot. Continue boiling and drink the warm decoction. Pepper (胡椒 hú ji ao) and scallion stalk: half a pepper and three grams scallion stalks are processed by the same way mentioned for scallion stalk and ginger. Drink the warm decoction once or twice daily. Orange peel (橘皮 jú pí), ginger, and brown sugar: orange peel and ginger, both 15 g, are processed by the same way mentioned above for scallion stalk and ginger. Drink the warm decoction after adding 10e20 g of brown sugar. 5 Ginger, tea (茶 ch a), brown sugar, and vinegar (醋 cù): two pieces of ginger, 3 g tea, 10 g brown sugar, and 10 mL vinegar are put into a cup, and then brewed with boiling water for 5 minutes. The upper liquid can be drunk three times daily. 6 Hot noodle soup with white pepper (白胡椒 b ai hú ji ao) powder and scallion stalk: a bowl of hot noodle soup is cooked, and appropriate amounts of white pepper powder and scallion stalk are added to it. Eat the noodle while it is hot and lie down covered with a quilt. After sweating, the cold is cured. 7 Simple decoction 1: Radix Saposhnikoviae (防風 f ang f eng), Schizonepeta (荊芥 j ıng jìe), Peucedanum praeruptorum (前胡 qi an hú), Radix bupleuri (柴胡 ch ai hú), Rhizoma et Radix Notopterygii (the rhizome and root of Notopterygium incisum Ting ex H.T. Chang or Notopterygium forbesii Boiss; 羌活 qi ang hu o), Platycodon grandiflorum(桔梗 ji e g eng) all 10 g, Fructus Aurantii (the unripe fruits of Citrus aurantium L.; 枳實 zhǐ shí) 5 g, and Ligusticum wallichii (川 芎 chu an xi onɡ) 3 g are decocted together with water. The obtained water solution can be taken for the wind-cold type cold. 8 Simple decoction 2: Schizonepeta 10 g, perilla leaf (紫蘇葉 zǐ s u y e) 10 g, tea 6 g, and ginger 6 g are decocted together with water. Add 20 g brown sugar into the decoction. The decoction can be used to treat the wind-cold type common cold especially characterized by headache, fever, and a stuffy nose. 9 Simple decoction 3: the mixture, which consists of honey (蜂蜜 f eng mì) and ginger juice at a ratio of 1:1, can be taken to treat the common cold without type differentiation according to the author's opinion. However, honey and ginger are warm heat (溫熱 w en r e) according to TCM, so the mixture is actually more suitable to treat the wind-cold type cold. 10 @story_separate@In weak patients with the wind-cold type common cold, their syndrome includes poor appetite (食慾不振 shí yù bù zh en), fatigue (乏力 f a lì), spontaneous sweating (自汗 zì h an), fear of wind (畏風 w ei f eng), and recurring cold besides the syndrome mentioned in the beginning of the last part. Treatment for the wind-cold type common cold with weak physique are ""relieving the exterior syndrome by replenishing qi (益氣解表 yì qì ji e biǎo)"", and ""supplement vacuity by support right (扶正補虛 fú zh eng bǔ x u)"". Dietary therapies (食療 shí li ao) are often added to the treatment. Here several decoctions are recommended. Jade Wind-Barrier Powder (Yupingfeng powder; 玉屏風散 yù píng f eng sǎn): Yupingfeng powder is a well-known ancient prescription invented by Wei Shilin, a famous physician in the Yuan Dynasty. 11 The prescription including Radix Astragali (黃耆 hu ang qí), Atractylodes macrocephala Koidz (白朮 b ai zhú), and Radix Saposhnikoviae was also used to treat weak patients with the wind-cold type common cold. The prescription can improve those patients' symptoms and reduce recurrent cases. 12 Radix Astragali-crucian decoction (黃耆鯽魚湯 hu ang qí jì yú t ang): the decoction is composed of crucian 150 g, Radix Astragali 15 g, Atractylodes macrocephala 6 g, and Radix Saposhnikoviae 3 g. Radix Astragali, Atractylodes macrocephala, and Radix Saposhnikoviae, which are actually three components of Yupingfeng powder mentioned above, are decocted together, then crucian is added into the decoction and decocted until boiling. After that, scallion and ginger are added and decocted with soft fire until the fish is cooked. Finally, some salt is added as flavoring. Eat the fish and drink the soup, and patients, especially ""debility in old age (年老體衰 ni an lǎo tǐ shu ai)"", with the wind-cold type common cold will be cured. 13 Purple perilla (紫蘇 zǐ s u) porridge: 50 g of rice are put into a pot, with water added, and cooked. When the porridge is nearly cooked, 10 g of perilla leaves are added. Then the porridge should be boiled for a little while. Eat the porridge. The purple perilla porridge is specified for weak patients with the wind-cold type common cold. 5 Scallion stalk porridge: three to five scallion stalks and 100 g of rice are stewed together to cook porridge. Eat the porridge when it is warm. The porridge is suitable for aged weak people with the wind-cold type common cold. 5  All contributing authors declare no conflicts of interest.@story_separate@For thousands of years, Chinese folk prescriptions (中國民間處方 zh ong gu o mín ji an chǔ f ang) for the common cold (感冒gǎn m ao), as complementary and alternative medicine (CAM; 補充與替代醫學 bǔ ch ong yǔ tì d ai y ı xu e), have been proven to be effective. Similarly, CAM products such as Andrographis paniculata (Kalmcold; 穿 心蓮 chu an x ın li an), Echinacea purpurea, and Pelargonium sidoides (geranium) extract (Umcka Coldcare) were reported effective for the common cold in adults. 14 They are also convenient, cheap, and most importantly, safe; some of them are even daily edible foods such as ginger, scallion stalk, and porridge, i.e., there are no obvious untoward reactions compared with the abovementioned treatments like over-the-counter drugs. Chinese folk prescriptions for the wind-cold type common cold are quite suitable for general practitioners or patients with the wind-cold type common cold to treat the disease. Of course, their pharmacological features and mechanisms of action need to be further studied.","Abstract Although self-limiting, the common cold (感冒gǎn mào) is highly prevalent. There are no effective antivirals to cure the common cold and few effective measures to prevent it, However, for thousands years, Chinese people have treated the common cold with natural herbs, According to the traditional Chinese medicine (TCM) theory (中醫理論 zhōng yī lǐ lùn), the common cold is considered as an exterior syndrome, which can be further divided into the wind-cold type (風寒型 fēng hán xíng), the wind-heat type (風熱型 fēng rè xíng), and the summer heat dampness type (暑熱型 shǔ rè xíng). Since the most common type of common cold caught in winter and spring is the wind-cold type, the article introduced some Chinese folk prescriptions for the wind-cold type common cold with normal and weak physique, respectively. For thousands of years, Chinese folk prescriptions for the common cold, as complementary and alternative medicine (CAM; 補充與替代醫學 bǔ chōng yǔ tì dài yī xué), have been proven to be effective, convenient, cheap, and most importantly, safe. The Chinese folk prescriptions (中國民間處方 zhōng guó mín jiān chǔ fāng) for the wind-cold type common cold are quite suitable for general practitioners or patients with the wind-cold type common cold, to treat the disease. Of course, their pharmacological features and mechanisms of action need to be further studied."
"Lower respiratory tract infections (primarily pneumonia) are the leading cause of death worldwide in infants and children [1, 2] . There are approximately 150 million cases of childhood community-acquired pneumonia (CAP) each year [1, 3] . CAP is a major cause of morbidity and mortality among children in developing countries, which is 10-50 times more common than in developed countries [1, 3] . Bacteria as the principal cause of CAP in children has been widely investigated [3] [4] [5] . In more than 50% of cases, however, there is still a considerable deficit in the aetiologic diagnosis resulting in unnecessary or inappropriate antibiotic prescription [2, 6] . It is clear that the involvement of viruses in CAP have been underestimated due to a lack of understanding of the viral etiology in a clinical setting [7] [8] [9] [10] [11] [12] . In addition, the appropriate sample from infants and young children is critical for the aetiologic diagnosis of CAP. Lung itself is rarely sampled directly, and sputum, representing lower-airway secretions, can rarely be obtained from children [11, 14, 15] . Among children, CAP may be caused by a wide variety of microbes, including ''typical'' bacteria (e.g., Streptococcus pneumonia) and atypical bacteria, Mycobacterium tuberculosis and fungi. Viral infections are also involved with 80% of episodes of CAP in children under 2 years old and over 40% of older children [6] [7] [8] [9] [10] [11] . Studies of CAP have traditionally focused little on viral causes [2] . So for, very few studies have included an extensive and appropriate evaluation of the role of viruses in the aetiology of CAP in developing countries, including China. In recent years, the introduction of better-quality diagnostic tests has markedly improved the ability to detect multiple viral pathogens [11] [12] [13] , shifting attention to the important role of viruses as a cause of CAP [6] [7] [8] [9] [10] [11] . According to previous studies, up to two-thirds of childhood pneumonia cases are associated with a viral infection [3] [4] [5] [6] [7] [8] [9] [10] [11] . Respiratory syncytial virus (RSV), influenza virus (IFV), rhinovirus (RV), human metapneumovirus (HMPV) and parainfluenza viruses (PIVs) are the most common viruses associated with pneumonia [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] . In addition, the roles of cytomegalovirus (CMV), other herpes viruses (HHVs), recently identified human coronaviruses (HCoV-NL63 and -HKU1) and human bocavirus (HBoV) as causes of CAP in infants and children remain controversial [3, [19] [20] [21] [22] [23] [24] [25] . So far, pathogenic profiles of HHV and its role in CAP among infants and young children from rural areas have not been well characterized. The present study was undertaken to describe the profiles of HHVs and other respiratory viruses associated with hospital-based CAP and non-CAP among infants and young children in a rural area of China using comprehensive and sensitive molecular diagnostic techniques.@story_separate@All aspects of this study were performed in accordance with national ethics regulations and approved by the Institutional Review Boards of the Centre for Disease Control and Prevention of China and the Ethics Committee of Wenzhou Medical College. The participants received written information regarding the purpose of the study and of their right to confidentiality. Individual written informed consent was obtained from the parents or guardians of all participants. Wenling is located in a rural area on the southeast coast of China with a sub tropical monsoon climate. It has a population of approximately 1,000,000. According to World Health Organisation clinical criteria [3, 8, 11] , CAP was defined as the presence of pneumonic infiltrates (alveolar or parenchymal) on chest radiography with simultaneous signs and/or symptoms of acute infection in which the reading of X-ray films by specialist were blinded to the clinical results. All CAP patients were also selected according to a set of necessary criteria based on respiratory symptoms (i.e., dyspnea or respiratory distress, cough, tachypnea) or evidence of parenchymal infiltrates on chest radiography. A total of 354 highquality induced sputum (IS) samples (,25 squamous epithelial cells and .25 leukocytes per low-power field) were obtained from 948 hospitalised infants and young children with respiratory illness in Wenling Hospital from September of 2007 to April of 2008. Two hundred and seventy-three samples were preselected from hospitalised children patients who diagnosed as non typical bacterial CAP within 48 hrs of admission, while 81 samples from hospitalized children patients were set as a control group, whom were clinical diagnosis as non-CAP patients based on chest X-ray and other respiratory signs (asthma, chronic bronchitis or cystic fibrosis) at admission. Typical bacterial CAP based on microbiologic tests, treatment algorithms and an elevated leukocyte count ($10 10 /L) were excluded. In addition, all patients were selected as immunocompetent at baseline and negative for HIV-1 and TB test. All the immunosuppressed or typical bacterial CAP patients were excluded. The children with presumed nosocomical CAP and lower-quality induced sputum (IS) samples were also excluded. Sputum production was induced by the inhalation of a 5.0% hypertonic saline solution; the sputum was sampled during the 1 st week after hospital admission by aspiration through the nostrils. Our sputum collection method was described in detail elsewhere [14] [15] [16] . Nucleic acid was extracted from 200 mL of the virus transport medium (VTM) using a QIAamp MinElute Virus Spin Kit (Qiagen, Germany) according to the manufacturer's instructions. Polymerase chain reaction (PCR) or multiplex PCR was performed as described previously [26] [27] [28] [29] [30] for HHVs, including HSV-1 and -2, varicella zoster virus (VZV), CMV, Epstein Barr virus (EBV), HHV-6 and -7. Adenoviruses (ADVs), IFV types A and B, PIV types 1-3, RSV, Picornaviruses (PIC, including enteroviruses and rhinoviruses) using multiple RT-PCR assays [26, 27] (Table S1 ); And for human coronavirus (HCoV)-OC43, -229E, -NL63 and -HKU1, human metapneumovirus (hMPV) using RT-PCR or and HBoV using nested-PCR assays [27] [28] [29] (Table S1). A positive (virus stock or DNA) and negative control (VTM only) in each set PCR assay was included to survey the possibility of laboratory contamination. All the methods were reported previously and validation in our lab [26] [27] [28] [29] [30] . The amplicons of positive for PIC were gel-purified for DNA sequencing using a QIAquick Gel Extraction (Qiagen, Germany), according to the manufacturer's instructions. DNA sequencing was performed with specific primers using an ABI PRISM BigDye Terminator Cycle Sequencing Reaction kit (version 3.1) on an ABI PRISM 3130 DNA sequencer (Applied Biosystems, Foster City, CA), following the manufacturer's instructions. Enteroviruses (EV) or rhinoviruses were identified based on sequence alignment of amplicons. Eligibility and classification of the clinical syndromes of pneumonia were determined from the original record of each item on the medical history and examination in the database. The frequency distribution of viral pathogens between CAP and non-CAP were analysed by the x 2 test and Fisher exact test. All statistical analyses were performed with the Statistical Package for the Social Sciences (SPSS, Version17, SPSS Inc., Chicago, IL). Statistical significance was assessed by Tukey's test and P-values ,0.05 were considered to be statistically significant. All IS samples were collected from hospitalised patients with severe CAP (n = 273) and non-CAP (n = 81) in Wenling area between September 2007 and April 2008. The age and sex distributions are shown in In addition, we found that the prevalence of several viral agents (rhinovirus, HBoV, ADV and CMV) among IS samples of CAP were significantly higher than that of non-CAP control group (P,0.05), while the prevalence of INF B (5,6.2%) among IS samples of non-CAP were significantly higher than that of CAP group (P = 0.001). A total of 271 CAP cases were positive for HHVs, accounting for about 99.3% of the hospitalised infants and young children with CAP included in this study. 73 of 81 non-CAP cases, however, were also identified as positive (90.1%) for HHVs. Among other 15 respiratory viruses, RSV was the most dominant for both CAP and non-CAP groups, which was present significantly less frequent than HHVs. To further study the epidemiological profiles of virus infections, the distribution of viruses by age and season in this study were characterised (Figure 1 and 2) . No significant difference was found for FluA, Piconavirus (enterovirus/rhinovirus), PIV and hMPV among various age groups of CAP cases ( Figure 1A) . However, the infection rate of HBoV and ADV showed a peak among CAP patients aged 6 months to 3 years (P,0.05). In contrast, RSV detection peaked in the infant group (0-12 months) of CAP and decreased significantly with advancing age. In addition, no significant differences for HSV and CMV were observed among various age groups of CAP cases ( Figure 1B) . However, the rate of infection with EBV, HHV-6 and HHV-7 increased with age among CAP cases (P,0.05). The infection rate was more than 73.7% for CMV, EBV, HHV-6 and HHV-7 among children older than 3 years. The distribution of viruses by age among the control group with non-CAP was also investigated ( Figure 1C and 1D) . No significant differences for RSV, EBV, HHV-6 and CMV were shown among various age groups of non-CAP cases. However, the rate of infection with HHV-7 increased with age, which is similar to that of CAP group.  Interestingly, co-infections were found in 241 (88.28%) of the CAP cases and 65 (80.25%) of the non-CAP cases (Table 1) . Single virus infection were detected in 31 IS samples of CAP cases (25 for CMV only, 5 for HHV-6 only and 1 for HBoV only). In this study of co-infection, 77 patients were found to be infected with 2 viruses, 76 with 3 viruses, 48 with 4 viruses, 36 with 5 viruses, 3 with 6 viruses and 1 with 7 viruses. In addition, HHVs were the most detected co-infection agent with other respiratory viruses. Among 102 RSV infections of CAP cases, HHV (102 cases, 100%) and HBoV (23 cases, 22.54%) were the most common concomitantly detected viruses, which were significantly higher than that of coinfection among non-CAP group. The clinical manifestation of CAP patients included cough, fever ($38uC), asthma and sputum. A few cases also showed signs of diarrhoea, rhinorrhoea, dyspnea and rale (data not shown). Since the high virus detection rate (more than 98%) and coinfection rate (more than 80%) were among IS samples from both CAP and non-CAP groups in this study (Table 1) , it was difficult to associate the clinical symptoms of patients with CAP with individual virus infection. However, the prevalence of several viral agents (rhinovirus, HBoV, ADV and CMV) among IS samples of CAP were drastically higher that of non-CAP control group (P,0.05). In addition, the prevalence of RSV coinfection with HHVs (102/102, 100%) and HBoV (23/102,22.54%) among CAP group was significantly higher than that among non-CAP controls (P,0.05).These data indicated that several viral agents (such as HBoV and CMV) may contribute to the occurrence of CAP. CAP is more common and severe in the developing areas than developed areas [1] [2] [3] , and is a major cause of death among infants and children in rural areas [3] . Previous investigations of paediatric CAP in US and Europe emphasised the importance of infections with common respiratory viruses (RSV, INF, PIV and ADV) [3, 4, 6] . The roles of HHVs and more recently identified viruses (HBoV, HCoV-NL63 and HCoV-HKU1) as causes of CAP remain controversial [2, [5] [6] [7] 12, 14] . In this study, the viral prevalence in sputum specimens of childhood with non typical bacterial CAP was investigated using sensitive molecular diagnostic methods for HHVs and 15 respiratory viruses, and viruses were detected in 99.6% of the children. This is not surprising considering that the samples included were highly selected for the discovery of viral etiology and addition HHVs detection in this study. To our knowledge, this is the first comprehensive study of the prevalence of HHVs in sputum samples among infants and young children with CAP [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] . A few reports have described the detection of DNA from several HHVs in respiratory samples, with most of them focusing on immunosuppressed individuals or adults with CAP [2, [19] [20] [21] [22] 31, 32] . In this study, we screened for DNA of HHVs in IS samples among infants and young children with CAP using a sensitive multiple PCR assay; of the HHVs considered, only VZV was not detected. The highest positive rate was found for CMV infection (91.6%). CMV infection, which is usually congenital, showed no significant difference among various age groups in this study. These data are consistent with those of previous reports [2, 22, 31] . In addition, it was reported here that CMV and HHV-6 were the only detected viral agent among 25 CAP cases and 5 CAP cases, respectively. Furthermore, the prevalence of CMV among IS samples of CAP were significantly higher than that of non-CAP control group. The prevalence of RSV coinfection with HHVs among CAP group was drastically higher than that among non-CAP control (P,0.05). These data suggest an association between infection with HHVs (especially CMV) and CAP in infants and children. Few comprehensive studies have searched for viruses in IS samples among infants and children with CAP in rural areas [8, 10, 11] . In this study, 15 common and recently identified viruses associated with acute respiratory infection were screened using molecular methods. Our results are consistent with previous studies conducted in China or other areas [8, 10, 11, 33] , which showed that the most-detected agent was RSV, followed by HBoV, RV, HMPV, ADV and PIV3 in IS samples from infants and children with CAP [3, 11, [14] [15] [16] . RSV and HBoV were also the dominant viruses detected in IS samples from non-CAP group. Moreover, our data show a higher HBoV detection rate (28.2%) compared with previous reports [23, 24] . The prevalence of HBoV among IS samples of CAP were significantly higher that of non-CAP control group. Similar trends were also observed in the prevalence of rhinovirus and ADV among IS samples of CAP when compared with non-CAP control group. Unlike previous data [34] , the prevalence of HCoVs among IS samples was significantly lower in present study. These differences might primarily due to the specimens [11, 15, 16] -IS vs. a nasopharyngeal aspirate or nasopharyngeal wash. In the meantime, the impact of other factors, such as area and the duration of the study period on infection, could not be ruled out. One interesting finding of present study was that HHV coinfections were found in 70% of the CAP cases, compared with rates between 15 and 45% in previous etiological studies of childhood CAP [7, [35] [36] [37] . The clinical consequences of mixed infections have not been fully understood yet. Evidence suggests that mixed viral infections can lead to more severe condition than individual viral infections [2, 7, [35] [36] [37] [38] . In this study, it was unable to determine whether the HHVs were reactivated from a latent reservoir after another respiratory virus infection, or if an immunosuppressed condition caused by HHV infection increases the potential risk of other respiratory virus infections. Consequently, it is difficult to estimate the true association between the clinical manifestations and virus infection. At the same time, we understand that the detection of viruses in an IS sample by PCR does not necessarily mean that they are the causative agents of the concomitant CAP. The IS samples included in this study may only represent part of hospitalized infants and children with CAP in this hospital. To evaluate the real pathogenic role played by virus in hospitalized children with CAP in this study, non-CAP hospitalized children with chronic respiratory illness were set as control group. However, this study still has two major limitations. One limitation of this study is that viral detection from non-hospitalised children (due to limitation of ethics) and patients with bacterial CAP, which would have provided a control group for this study, were not included. Therefore, some viral agents detected in this study may represent asymptomatic persistence, prolonged shedding, or other situations. It is also not possible to evaluate the exact importance of each virus responsible for CAP in most cases. Nevertheless, it is believed that overall this study highlights the importance of HHVs (mainly CMV) and respiratory viruses in Children with CAP. Another limitation of this study is that no samples were collected during summer, which could lead to the missing of some viral agents such as parainfluenza viruses and some enteroviruses.@story_separate@In summary, our study on the prevalence of HHVs and other respiratory viruses in infants and young children with CAP identified a detectable virus in more than 99.6% of case participants, in which CMV, HHV-6, EBV, RSV and HBoV were clearly predominant (.25%) and contributed significantly to the spectrum of CAP in a rural area of China. Although the HHVs were the most commonly identified pathogens in this study, which were not previously thought of as typical causes of CAP in immunocopetent individuals [3] [4] [5] [6] [7] [8] 20, [38] [39] [40] [41] , further studies are required to determine the relationship of the presence of HHVs and severity of disease, thus the clinical significance of HHV infections or co-infections should receive greater attention in future treatment and prevention studies of CAP in infants and children.","OBJECTIVE: Few comprehensive studies have searched for viruses in infants and young children with community-acquired pneumonia (CAP) in China. The aim of this study was to investigate the roles of human herpes viruses (HHVs) and other respiratory viruses in CAP not caused by typical bacterial infection and to determine their prevalence and clinical significance. METHODS: Induced sputum (IS) samples were collected from 354 hospitalised patients (infants, n = 205; children, n = 149) with respiratory illness (CAP or non-CAP) admitted to Wenling Hospital of China. We tested for HHVs and respiratory viruses using PCR-based assays. The epidemiological profiles were also analysed. RESULTS: High rate of virus detection (more than 98%) and co-infection (more than 80%) were found among IS samples from 354 hospitalised infants and children with respiratory illness in this study. Of 273 CAP samples tested, CMV (91.6%), HHV-6 (50.9%), RSV (37.4%), EBV (35.5%), HBoV (28.2%), HHV-7 (18.3%) and rhinovirus (17.2%) were the most commonly detected viruses. Of 81 non- CAP samples tested, CMV (63%), RSV (49.4%), HHV-6 (42%), EBV (24.7%), HHV-7 (13.6%) and HBoV (8.6%) were the dominant viruses detected. The prevalence of several viral agents (rhinovirus, bocavirus, adenovirus and CMV) among IS samples of CAP were significantly higher than that of non-CAP control group. We also found the prevalence of RSV coinfection with HHVs was also higher among CAP group than that of non-CAP control. CONCLUSIONS: With sensitive molecular detection techniques and IS samples, high rates of viral identification were achieved in infants and young children with respiratory illness in a rural area of China. The clinical significance of rhinovirus, bocavirus, adenovirus and HHV (especially CMV) infections should receive greater attention in future treatment and prevention studies of CAP in infants and children."
"In these testing times of a global pandemic caused due to severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection, the practice of dentistry and orthodontics has come to a standstill. The coronavirus disease (COVID-19) was declared as a pandemic by the World Health Organization on 30th January 2020. In this situation, all governing and professional bodies have advised to handle only dental patients in emergency situations, also taking a great amount of precaution and preparation.@story_separate@The coronavirus disease (COVID-19) is believed to have originated from the city of Wuhan, in the Hubei province of China, and is caused due to infection by the now-called severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The SARS-CoV-2 virus is a single-stranded RNA virus that belongs to a family called Coronaviridae, which includes the known Severe Acute Respiratory Syndrome coronavirus (SARS-CoV) of 2002, and even the Middle East respiratory syndrome coronavirus (MERS-CoV) that was seen in 2012. 1, 2, 3 The virus genome has been sequenced and it was found to share 79.5% of the genomic sequence with the SARS-CoV. On average, it takes 5 to 6 days for symptoms to develop from the time a person is exposed to the virus. Occasionally, it can take up to 14 days and rarely, even longer 1, 4, 5 . The COVID-19 affects different people in different ways. The most common symptoms resemble very much to that of seasonal flu. Patients experience dry cough, rising fever and tiredness or shortness of breath. Some patients have even been documented having joint pains, headache, loss of taste or smell, sore throat, rashes and/or diarrhea. On the other side, there are asymptomatic patients who can act as ""carriers"" and act as a pool of infection. Chest radiography study reveal ground-glass opacities in patients with advanced infections. Most of the patients with good immunity and no comorbidities brush away these symptoms in course of time, by developing the necessary antibodies. Others who have a compromised state develop complications like Severe Respiratory Distress situation or Pneumonia, and the downward spiral into the disease begins 2,6 . SARS-CoV-2 binds to human angiotensin-converting enzyme 2 receptors. The salivary glands of humans are rich in these receptors and thus there is a high potential for transmission of COVID-19 via respiratory droplets in the air, which spread easily to a radius of no further than 6 feet, and then can enter the body directly through eyes, nose, ears and mouth, this would later infect the clinician, who may get critical or, worse, can become a carrier. Faces have also shown a certain titer level of this virus. An average person touches his face 23 times an hour, and then some of the other inanimate objects around them. Spread of virus can also happen in this way, as the virus can survive for up to three days on such objects and surfaces. Incubation period is known to last for one to two weeks 7 . Facing such a difficult and highly contagious disease, the government also recommends to handle only emergency patients or patients that will require minimal intervention. 7 There are two ways in which you can handle them: 1. Remotely guiding and helping them, with help of telecommunication. 2. You can prepare your clinic by following all sanitization protocols and then keep the clinic open only for such patients. Remote handling of the patient requires the orthodontist to have patience and understanding of the patient's psyche. Conversation content should be well planned and thought of. Patients are not aware of the dental terminology, so more colloquial terms should be used. Much more of a listening attitude should be inculcated while they convey about their troubles. Use of calm tone and positive words is most important while the government-mandated restrictions are on. More than the orthodontist, it's the patient who is suffering, as their appliance is still there and treatment will surely be prolonged. Since all this is being done on virtual platforms, encrypted end to end applications should be used, so that the patient also feels secure while this is being done, and the data should also be stored by the clinician. Orthodontic treatment requires meticulous and pragmatic approach from the clinician's aspect, so that proper improvisations can be done for the treatment. Lastly, all these new protocols have to be done after confirmation from the Regional Dental associations, since these things rely on the interpretation of information given by the doctor and are also confidential. Orthodontists should follow Alexander's principle of ""Let It Cook"" more religiously, now that the wire sequence duration is prolonged, instead of getting anxious. • Since most of the patients are in the adolescent category, with the school and colleges closed, unvaried calls should be made regarding the food types to be avoided to prevent breakages. Patients in the adult category will obviously be more understanding and will not be disobedient regarding the instructions. • Regarding bonded molar tubes or brackets, patients can be asked to use a toothpick to get the loose appliances out, following instructions provided via video call. • Use of elastics can be taught to the patient by either sending an on-line video or explaining them with help of a model, via a video call. • With the public transport closed, an impinging wire can easily be cut with help of a nail cutter, cleaned with an alcohol-based sanitizer or by boiling it in water at 100ºC for 20 minutes. This can be done if the archwire is of lower gauge. In case of rigid rectangular wire, a heavy-duty cutter will be needed, which can easily be ordered on-line. Guiding the patient through a video is suggested at all times. Patient should be informed to hold the distal end of the wire secure, so as to prevent the risk of swallowing. Alternatively, a ball of wet cotton can provide temporary relief from the end of a poking wire, in case the patient has run out of relief wax. • Regarding the expansion screws, patients can be reminded about it and instructed again, with help of a phone call. The expansion should be monitored via video call or by assessing photos of teeth, sent by the patient, and the expansion discontinued at the right time. In such situations, it is safer to err on the side of caution, and avoid over-expansion. Internet links on guidance for the patient to take dental photos should be sent to them in advance. • Consideration should be given to terminate the procedures that are likely to cause problems if there is another wave of COVID-19, such as: 1. Activation of slow/rapid expansion screw. • Patients using removable functional appliances should be reminded to wear it, and also instructed regarding cleaning it. All patients, in general, should receive video explaining the hand hygiene protocol. • In case of aphthous or traumatic ulcers, routine topical anesthetic ointments, which are available over the counter, should be recommended. A photographic examination should be performed, with regard to the size and severity of the ulcer, keeping in mind differential diagnosis of ulcers. • Retention plates can easily be delivered with contactless delivery technique, and hoping it fits well. Use of the plate and instructions can, again, be done remotely. • Since the use of ultrasonic scalers will be next to none, use of mouthrinse and a minimum of twice daily brushing protocol has to be more strictly followed and reminded multiple times. • In case of aligner patients, their next aligner can be easily delivered without contact, and patients' treatment progresses unhindered. If they feel their current aligner is incorrectly adjusted or any other issue, they can be asked to wear the previous aligner. Again, monitoring via photos taken by the patient is helpful, and the internet links for guidance to take correct dental photos should be sent to the patient in advance. • In case patient does experience serious pain, 500-mg Paracetamol tablets can be prescripted. 8, 9 Once a list of urgent attention-needing cases is made, they can be called to the clinic after conducting a session on the phone, asking the necessary questions to establish a baseline regarding the condition of the patient. Any risk factor for COVID-19 disease and virus exposure history (contact history) has to be ruled out in the telephonic conversation. Before the patient visits the clinic, the following measures should be undertaken: 1. The clinic should be sanitized with Environmental Protection Agent (EPA). 10 Various techniques to decrease chairtime, interval between appointments and overall treatment duration can be thought of, as follows: 1. A shift from fixed appliances to a self-ligating bracket system should be thought of, as there is reduced number of wires changes, the interval between appointments is minimum of six weeks, and with the better bracket manufacturing technique the rate of breakages may also be smaller. 8 2. Treatment planning should be well chosen, and appliances or techniques that deliver maximum results with minimum chairside activation should be employed. 3. Attempts should be made to decrease the patient visits during the retraction process. 4 . A shift to 0.018-in slot can be thought of in mild cases that do not require a lot of control, as the wire sequence to reach a 0.016 x 0.022-in stainless steel working wire is shorter. • Aligner technology can employ a digital scan instead of impressions, thereby decreasing chairtime and reducing contact with patient saliva. • To further reduce patient contact, digital treatment plans can be made without use of attachments, so that it reduces patient chairtime. For difficult movements where attachments are imperative, the placement can be delayed by a few weeks or months, to reduce current risk of exposure. • Space gaining in aligners can be achieved mostly via expansion and interproximal reduction (IPR). IPR should be done in the most non invasive way. • Aligners can be delivered to a patient with contactless delivery. • Instructions and maintenance protocol videos or internet links can be sent to the patient. For all patient, we should use all autoclaved instruments. Handling and giving the elastics, NiTi coil springs, elastomeric chains and other auxiliaries can be performed by the assistant, to prevent contamination as much as possible. 6. Impression procedure should be bare minimum and if done, the impression should be disinfected with 2% Glutaraldehyde. 7. Fresh bondings and start-ups should be delayed for now, as the chairside time is to be minimized. 8 . LED or UV curing light guns should be sanitized after every use. 9 . Use of high strength composite as bite blocks can be thought of, so that they can be easily removed when not needed. A two-dose regimen of BNT162b2 vaccine conferred 95% protection against Covid-19 in persons 16 years of age or older. Safety over a median of two months was similar to that of other viral vaccines. 18 Although the vaccine has been proven effective, questions have been raised about the longevity of the formed antibodies, since in orthodontic treatment, the treatment duration is longer than a year. So a patient who was vaccinated before, may not have antibodies by the end of treatment. Thus, safety measures need to be followed all time.@story_separate@The field of Orthodontics is ever-changing. There is a wide range of parameters and variables, all combined together in many permutations and combinations. Therefore, we are used to continuous evolution of the subject and practice. Change is the only permanent state, so we should face the current crisis with utmost precaution and attention. Treatment modalities will change, patient expectations will change, COVID-19 is an uninvited guest, but it will not leave soon, because the disease is new, its study is still not complete, and the situation is changing day by day. Therefore, innovative thinking and small tweaks will go a long way to help us. Health of our staff and our helping associates should not be compromised at any cost. Difficult times also call for difficult measures, and those should be taken keeping in mind the cost/risk-benefit ratio for the patient and the doctor. Current approach should be to minimize direct patient contact and provide maximum remote assistance and management.","INTRODUCTION: A pandemic was declared by the World Health Organization on 30th January 2020, the coronavirus disease (COVID-19) emerged, and led to standstill of Dentistry and Orthodontics. DESCRIPTION: The COVID-19 is a very multivariant disease. It affects in many different ways; the most reported symptoms resemble very much to that of a seasonal flu. Patients feel rising fever, dry cough and shortness of breath. There are two ways to handle them, the first being remotely guiding and helping them with aid of telecommunication, and second you can prepare the clinic by following all sanitization protocols and keep the clinic open only for such patients. Usage of Environment Protection agents, N95 masks, PPE kits and HEPA filters are some of the basic things to go about. CONCLUSION: With the non-stop change of scenario of the COVID-19, meticulous monitoring of the local situation and one eye on the latest instructions given by the WHO and Health ministry should be followed."
"Acute limb ischemia (ALI) is defined as the sudden decrease in limb perfusion that can compromise limb function and can even result in life-threatening complications [1] . Studies report ALI incidence to be 1.5 cases out of 10,000 people every year [2] . The estimated mortality rate is 15%-20% from the acute onset due to underlying conditions as cardiovascular, cerebrovascular, and ischemia-reperfusion injury [2] . The primary causes of ALI include atrial fibrillation, arterial aneurysms, hypercoagulable states, and iatrogenic thromboembolism [1] . The typical presentation of ALI symptoms is the ""six P's"": pain, pulse deficit, paralysis, pallor, poikilothermia, and paresthesia [1] . The diagnostic tools include duplex ultrasound (DUS), computed tomography angiography (CTA), and magnetic resonance angiography (MRA) [3] . ALI has a relatively poor prognosis, with the sudden loss of limb function resulting in the amputation of the affected limb [1] . Vascular medicine, vascular surgery, and interventional therapy are the key to prompt revascularization in ALI [3] . Treatment begins with intravenous (IV) unfractionated heparin infusion to prevent thrombus progression within the rest of the limb [3] . The signs of cyanosis, paralysis, and stiffness indicate irreversible ischemia, and urgent amputation is needed in such cases [3] . Treatments include a surgical approach or endovascular management. Surgical approaches include thromboembolectomy and bypass, while endovascular approaches include catheter-directed thrombolysis (CDT) and stent placement. Sometimes a combination of the two methods is used [1] . Heparin-induced thrombocytopenia (HIT) is a hypercoagulable state that can develop immune-mediated reactions against any form of heparin products [4] . It can be characterized into type one HIT (non-immune mediated) and type two HIT (immune-mediated) [5] . Type two HIT is a more common condition due to heparin's antibody-mediated reaction to platelet factor four (PF4), leading to thromboembolic complications such as deep venous thrombosis and pulmonary embolism [4] . The most apparent outcome is thrombocytopenia caused by consumption of IgG-coated platelets by macrophages and the reticuloendothelial system [4] . HIT management involves immediate discontinuation of heparin and switching to argatroban, bivalirudin, danaparoid, fondaparinux, or a direct oral anticoagulant (DOAC) [5] . Coronavirus disease 2019 (COVID-19) is the global pandemic known mainly for acute respiratory distress syndrome [6] . However, studies have reported that COVID-19 has severely impacted various integrated body systems, including the coagulation parameters [6] [7] [8] . The deranged coagulation parameters create a hypercoagulable state, increasing the risk for a thromboembolic event [6] [7] [8] [9] [10] . Recent studies of peripheral arterial involvement have also been published that correlate COVID-19 to incidences of ALI [7] [8] [9] [10] . We present a case of a patient with an asymptomatic COVID-19 infection who suddenly suffered from ALI, which was further complicated by HIT and other clinical implications.@story_separate@This report involves a 49-year-old Caucasian male with no significant past medical history who presented to the emergency department (ED) complaining of pain and coldness in the right foot with some tingling for the past few hours. The pain was described as vague and had a progressive onset. The patient has a history of smoking one pack per day for the last 30 years, and he works as a general contractor. At the time of presentation, the patient was able to move his toes and foot without much difficulty. The right foot examination revealed diminished dorsalis pedis pulse, mild sensory loss, and no muscle weakness. The right foot was cold and displayed pallor with no distinct demarcation. The patient had a CTA done, which revealed an acute occlusion involving the proximal anterior tibial artery and the tibioperoneal trunk with reconstitution distally. Given the poor reconstitution, no evidence of atherosclerotic disease in either extremity and no evidence of vasculitis the occlusions were likely acute and embolic in etiology. The patient was admitted to the intensive care unit (ICU), a tissue plasminogen activator (TPA) was infused directly into the affected peripheral vessel, and a heparin drip was started. The patient did not have any history of cardiac arrhythmias or myocardial infarction. An echocardiogram revealed a patent foramen ovale which was only evident by a bubble study. Due to the foramen ovale not being large enough to explain the current arterial occlusion, a transesophageal echocardiogram and a closure device were not recommended. Interventional radiology was consulted, and the patient underwent four attempts of thrombolysis, resulting in improved clot burden by the end of each procedure. However, the patient continued to have repeated episodes of thrombosis. Angioplasty of the anterior tibial and posterior tibial arteries was also performed. Unfortunately, recanalization of these vessels was unsuccessful. Despite four days of TPA thrombolysis therapy and multiple attempts at angioplasty and thrombectomy of all three tibial vessels, they remained occluded. The patient's right lower extremity angiogram demonstrated persistent occlusion of all three tibial vessels below the knee in concurrent images ( Figure 1 ). There was also rethrombosis of the peroneal artery and anterior tibial artery. Hypercoagulable workup was negative for factor V Leiden, lupus, antiphospholipid syndrome, and vasculitis. Furthermore, the activity of protein C, protein S, and anti-thrombin III was normal. Seven days after the patient's initial presentation, he had worsening discoloration, advancing pain, and a cold avascular foot, ankle, and calf. The patient's foot was insensate, with the inability to move toes, severe mottling, and darkening of the skin below the ankle. There was also mottling of the distal third of the leg. A right belowknee amputation was planned to prevent infectious gangrene. At the time of amputation, the patient was noted to have avascular gangrene of the distal half of his right lower extremity, especially lateral and anterior compartments, with non-contractile muscle. Complete occlusion of all arterial portions of the vascular tree was found during amputation, with a gelatinous clot. Pathology reports stated findings of an embolic clot with some atherosclerotic changes in the posterior tibial vessels. Postoperative D-dimer was elevated at 12,021 ng/mL FEU and platelets dropped from 253,002 to 26,000 in two days. HIT was suspected which is a clinicopathologic diagnosis that requires combined evaluation of clinical examination and laboratory test results. The 4Ts scoring system was used to support the need for laboratory testing ( Table 1) . This case resulted in a score of at least 6 which is correlated with a high probability of HIT. Heparin was held, and HIT testing with a serotonin release assay was positive. Therefore, he was started on an argatroban drip and coumadin. COVID-19 IgG and IgM antibody tests were positive even though testing at the time of admission via nasal swab, reverse transcription-polymerase chain reaction, and nucleic acid amplification were negative. This raised a concern that the clotting was possibly a complication of a previous COVID-19 infection, although the patient denied any history of COVID-19 infection and showed no other symptoms. Once stabilized, the patient was discharged on 6 milligrams of warfarin and low-dose aspirin daily. After discharge, the patient was lost to follow up and was brought to the ED 13 days later by ambulance complaining of severe headache and altered mental status. When the patient arrived at the ED, he was minimally responsive and appeared lethargic with no apparent trauma. The patient was not responding to painful stimuli, no posturing was noted, and his pupils were reactive to light and measured at 4 millimeters. CT of his head showed massive intraparenchymal and intraventricular hemorrhages with extension into the third ventricle and a rightward shift consistent with subfalcian herniation as well as downward herniation ( Figure 2 ). The patient decompensated, his respiratory efforts became closer to agonal, and the patient was intubated. The patient's INR was 7.2. He was given fresh frozen plasma, vitamin K, and Kcentra. The patient was transferred to another hospital better equipped to handle critical patients but could not survive. ALI presents with sudden and severe symptoms within two weeks. This is due to the lack of development of collateral circulation, which is in contrast with chronic ischemic conditions [3] . The severity of ALI is categorized using the Rutherford classifications. It is based on the clinical presentation, including sensory and motor findings and both arterial and venous Doppler signals ( Table 2 ) [11] . Based on these classifications, the diagnosis and treatment method is determined (Figure 3 ) [12] .  Based on the patient's presentation of acute onset pain, tingling, and coldness of the right foot, the patient's ischemia of the lower extremity was likely classified into Rutherford category two, known as threatened. Hence, instead of doppler, the patient underwent a CTA, which was consistent with ALI findings. Despite appropriate treatment, the patient's right lower extremity ischemia worsened within four days, progressing from Rutherford classification two to classification three consistent with irreversible ischemia. Subsequently, the extremity had to be amputated to prevent infectious gangrene. Moreover, the platelet count dropped significantly within two days making the diagnosis consistent with HIT. Thrombosis due to HIT occurs via platelet activation and endothelial cell injury. Both venous and arterial thrombi are associated with HIT, with venous thrombi much more common. Venous thrombotic complications include limb gangrene and pulmonary embolism [13] , whereas arterial thrombosis can lead to stroke, myocardial infarction, ALI, and organ infarction [14] . Typically, HIT develops five to ten days after the initiation of heparin [15] . Nevertheless, early onset may be seen in patients who already have circulating HIT antibodies due to previous heparin exposure [16] . The common hemostasis abnormalities related to COVID-19 infection are thrombocytopenia and elevated D-dimer, as seen in our patient [17] . This abnormal hemostasis increases the risk of thromboembolic disease, respiratory failure, or death [17, 18] . The disease severity is associated with prolonged prothrombin time (PT), INR, and thrombin time (TT), and decreased activated partial thromboplastin time (aPTT) [17] . A recent study found that a higher D-dimer, fibrin degradation products, and prolonged PT were seen in patients with COVID-19 infection who died compared to those who survived [6] . However, it is still unknown if these hemostatic changes are caused explicitly by COVID-19 infection or precipitated by cytokine release from systemic inflammatory response syndrome [17] . Hospitalized patients with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), especially patients with comorbid conditions, should receive prophylactic anticoagulation to prevent thromboembolic disease and further complications [6, [17] [18] . The recommended prophylaxis by the World Health Organization (WHO) is daily low-molecular-weight heparins, or twice-daily subcutaneous unfractionated heparin (UFH) [17] . Although our patient was on IV heparin for more than one week, his clinical deterioration was owing to concurrent HIT. This case highlights the importance of diagnoses and treatment of ALI promptly. The patient does not have a history of significant cardiovascular disease and did not present any symptoms of COVID-19 infection. Regardless of the patient's past medical history and current health condition, prophylactic anticoagulation should be started immediately. It is also crucial to perform appropriate lab testing regularly. If the patient does not have clinical improvement within 24-48 hours, physicians should suspect potential HIT and confirm the diagnosis. This will prevent complications such as loss of complete blood supply and infectious gangrene requiring amputation. Additionally, physicians should be aware of life-threatening hemorrhage when a patient is on any anticoagulant medication. Regular follow-up and prompt management are the keys to patient survival. Human subjects: Consent was obtained or waived by all participants in this study. Conflicts of interest: In compliance with the ICMJE uniform disclosure form, all authors declare the following: Payment/services info: All authors have declared that no financial support was received from any organization for the submitted work. Financial relationships: All authors have declared that they have no financial relationships at present or within the previous three years with any organizations that might have an interest in the submitted work. Other relationships: All authors have declared that there are no other relationships or activities that could appear to have influenced the submitted work.@story_separate@This case reports an asymptomatic COVID-19 patient with no significant comorbidities who suffered from ALI complicated by HIT. Vascular emergencies such as sudden loss or marked decrease in limb perfusions consistent with ALI need to be diagnosed and treated promptly. The key to prompt revascularization in ALI is vascular medicine, vascular surgery, and interventional therapy. Prophylactic anticoagulation should be initiated immediately, as long as the patient is not currently bleeding. Monitoring regular lab tests while the patient is on anticoagulation should be done to detect complications such as HIT early. Patients should be educated on the risks of anticoagulation therapy as life-threatening complications such as hemorrhage can occur. Therefore, patient compliance is a significant factor in the appropriate management of the disease. Finally, when individual patient needs are addressed, a multidisciplinary method will provide a stronger outcome and quality of life.","Acute limb ischemia (ALI) is the sudden decrease in limb perfusion caused by embolism secondary to many blood stasis conditions. Treatment commences with intravenous (IV) unfractionated heparin infusion. Individuals can have an immune-mediated reaction to heparin products which results in heparin-induced thrombocytopenia (HIT). Coronavirus disease 2019 (COVID-19) has added to the difficulty of treating patients with ALI due to increasing the likelihood of HIT via the virus's ability to manipulate the coagulation parameters. We present a case of ALI complicated by HIT in a 49-year-old male with a confirmed asymptomatic COVID-19. The patient initially presented with progressive pain, coldness, and tingling in the right foot. He was treated with a tissue plasminogen activator (TPA) and a heparin drip. The occlusion persisted despite medical intervention leading to right below-knee amputation. The patient returned to the emergency department (ED) 13 days later with massive intracranial hemorrhage and subsequently expired. This case study demonstrates the significance of COVID-19 diagnostic testing due to the possibility of developing blood clots and potential complications, including HIT."
"During the COVID-19 outbreak throughout the world, traditional Chinese medicine (TCM) has been proven to stop mild to severe symptoms of COVID-19 in China, 1,2 and there is lab evidence that TCM can be used safely to fight the epidemic. 1, 2 Many traditional foods and traditional Chinese medicines are made from fermentation, such as wine, sauce, and Massa Medicata Fermentata (MMF). During the fermentation process of the foods or drugs, the influence of microorganisms is an important step in the production; for example, senna glycoside is degraded into diarrhea-causing emodin under the influence of microorganisms in our human bacterial gut system. 3 For use as a purgative drug, the activity of microbial degradation of Scutellariae Radix is higher than that of the root. 4 Since the beginning of the third century, it has been wellknown that MMF is a fermented drug used in China, and now it is very popular in research on the gut microbiota in the world as the intestinal microenvironment impacts the lungs by the gut−lung axis and the brain by the gut−brain axis. We already understand that the gut microbiota are responsible for the health of individuals starting from birth and during early life, adulthood, and aging. MMF is used as a digestive agent where it functions in strengthening the gut and spleen and in balancing the digestive system. In addition, Massa Medicata Fermentata is used for gastroenteritis and dyspepsia with low gastric acidity. 5 MMF is a fermented drug that has been widely used since the beginning of the third century. MMF is used as a digestive agent clinically, and it has the functions of strengthening the spleen and gut and balancing the digestion system. 6 MMF is used for dyspepsia and gastroenteritis with low gastric acidity. MMF is a traditional Chinese medicine with natural fermentation, and MMF is made by Artemisia annua, Polygonum hydropiper, Xanthium sibiricum, red bean, bitter almond, flour, and wheat bran 7 (National Pharmacopoeia Commission. Pharmacopoeia of the People's Republic of China (3 Part) [S], 2012). Modern studies have shown that the fermented MMF can improve the disorder of the bacterial system in the gut, and the unfermented MMF does not have these pharmacological activities. According to ""The People's Republic of China Pharmacopoeia 2010"", in a set prescription of fermented herbal medicine, MMF can account for up to 47%. Although MMF has been used for a long time by the Chinese and there is also a huge domestic market today, there are few studies about the fermentation and metabolic processes, and its medicinal ingredients have not been determined. This is resulting in poor controllability of the production and the market. 8 To ensure the safety and effectiveness of MMF for clinical use, we have to study the MMF fermented process and finally to explore the active medicinal ingredients of MMF. We know that MMF is made by Artemisia annua, Polygonum hydropiper, Xanthium sibiricum, red bean, bitter almond, flour, and wheat bran (National Pharmacopoeia Commission. Pharmacopoeia of the People's Republic of China (3 Part) [S], 2012) (shown in Figure 1 ). As shown in Table 1 , MMF raw materials contain various ingredients, including cellulose, hemicellulose, starch, protein, volatile oil, fat, and other ingredients. Xanthium sibiricum and other volatile oils disappeared during the production process. 9, 10 Artemisinin of Artemisia annua is a common medicinal ingredient. 11 It has been found that artemisinin is degraded, and octadecenoic acid of the organic acid substances is detected during the fermentation of MMF. 12 MMF is clinically used as a digestive aid and may show acidity. This study explores the change in acidity during the fermentation process of MMF. Bitter almond has protein ingredients such as Amygdalin and Prunase. 13−15 As shown in Figure 1 , Amygdalin is one of the main medicinal ingredients in bitter almond, and it would be degraded to produce benzaldehyde to undergo enzymatics in the presence of water. Benzaldehyde and amygdalin are two kinds of medicinal ingredients in bitter almond, and these two ingredients are representative medicinal ingredient for almonds. This study observed changes in the content of amygdalin and benzaldehyde during fermentation. As shown in Figure 1 , AAS contains amygdalase, prunase, and other protein ingredients 7,8 as the main pharmacological ingredients. For laetrile, when it is in water, enzyme degradation occurs to produce benzaldehyde. Thus, laetrile and benzaldehyde are two kinds of major ingredients in AAS. Our study observed the changes of content for laetrile and benzaldehyde during the MMF fermentation process. PHH contains volatile oils and flavonoids, and the main pharmacological ingredient is rutin (Figure 3 ) in PHH. In the biostudy, we observed the changes of rutin's content during the MMF fermentation process. In the experiments, we observed the changes of the HPLC fingerprint for MMF during the fermentation process, so we could explore the changes of ingredients and the ratio of ingredients for MMF. Recently, researchers isolated a large amount of yeast and other bacteria and a small amount of lactic acid bacteria from MMF. 16, 17 Some researchers suggest that enzyme activities can be used as quality standards. 18, 19 MMF uses the process of stir- frying until yellow and stir-baking to brown. Stir-frying until yellow can keep up to 60% efficacy of crude materials, while stir-baking to brown causes total loss of enzyme efficacy. Some studies have shown that fry-processed MMF loses almost all the activities of amylase and proteinase. 20 Some researchers have already suggested that unfermented MMF could be used. 21 In these cases, we observed changes of amylase activity during its fermented process. In the biostudy, we systematically analyzed the main chemical ingredients of crude drugs from MMF including the amylase activities and acidity. We to explore the new ingredients with conducive for the digestion and to provide the scientific data for the safety used of clinical drug. ■ RESULTS AND DISCUSSION HPLC Fingerprint. High-performance liquid chromatography is a technique used in China Pharmacopoeia to separate, identify, and quantify each component for our MMF. The software has been used in processing, and the results are shown in Figure 2a and Table 2 . We observed a variety of components in traditional Chinese medicine (TCM) 9,21 at the same time. 20−23 We studied the HPLC fingerprint of the MMF of 0∼7 days fermentation samples and obtained HPLC fingerprint study data (according to the national pharmacopoeia committee ""Chinese medicine chromatographic fingerprint similarity evaluation system"" 2015 software for processing), and the results are shown in Figure 2a and Table 2 . As shown in Figure 2a and Table 2 , MMF extracts were analyzed by HPLC. The fingerprint similarity was 0.943 between day 0 and day 1; 0.103 between day 1 and day 2; 0.525 between day 2 and day 3; 0.715 between day 3 and day 4; 0.487 between day 4 and day 5; 0.387 between day 5 and day 6; and 0.204 between day 6 and day 7. The HPLC fingerprints showed dynamic changes during fermentation, which means that the components and the ratio between components were changing as well. The most significant changes happened during day 1 to day 2. Next, significant changes happened from day 6 to day 7. The fingerprint similarity was only 0.122 between day 0 and day 7. In Figure  2a , peak 1 was rutin; peak 2 was laetrile; and peak 3 was benzaldehyde, and these components were degraded to small molecules by micro-organisms during fermentation. In this study, we found that changes of components of the crude drugs from MMF are significant; therefore, the main components of crude drugs are not the pharmacodynamic components of MMF. In Figure 2a and Table 2 , Massa Medicata Fermentata extracts were analyzed by HPLC. 22, 23 MMF Impacts Propulsion in the Small Intestine. Recent advances in microbiota explorations have led to improved knowledge of the communities of commensal microorganisms within the human body. 24 , 25 We aimed to analyze how MMF influences the propulsion in the small intestine and used the review-manager software 5.3 to analyze the propulsion in the small intestine of MMF using Chinese published literature about MMF, 26−28 and there is a significant difference in the propulsion in the small intestine between used MMF mice and unused MMF mice (heterogeneity: Chi 2 = 7.61; df = 3 (P = 0.05); I 2 = 61%; test for overall effect: Z = 7.51 (P < 0.00001), Figure 2b ). When the I 2 value exceeds 25%, 50%, and 75%, it indicates that our study has low, moderate, and high heterogeneity. It is generally believed that I 2 > 50 has substantial heterogeneity. For the Cochrane Q test, the essence is the chi-square test, and the method of qualitative analysis of heterogeneity, P > 0.1, means no statistical heterogeneity between our studies; on the contrary, P < 0.1 means there is heterogeneity between used MMF and unused MMF (Figure 2b ). Used MMF digestive liquid catalyzes the breakdown of food into many small molecules which can be absorbed and utilized by our gut and which can be further absorbed into our body for lung respiration. 29, 30 According to the gut−lung axis, used MMF treatments can impact the intestinal microenvironment and impact metabolic functions as well as immune responses in our body. 29−32 The gut−lung axis has emerged as a specific axis with intensive dialogues between the gut and lungs, involving each compartment in a two-way manner, with both microbial and immune interactions. 31, 32 The metabolites produced by used MMF treatments not only modulate gastrointestinal immunity but also impact distal organs like the lungs and brain. 29−32 Benzaldehyde and Laetrile. Benzaldehyde (C 6 H 5 CHO) is an organic compound consisting of a benzene ring with a formyl substituent, and it is the simplest aromatic aldehyde. We analyzed benzaldehyde and laetrile content by our employed HPLC. The analysis showed laetrile, and benzaldehyde levels decreased sharply from day one (Figure 3a ). Laetrile is a compound that has been used as a treatment for people with cancer, and laetrile is another name for amygdalin. Amygdalin is a bitter substance found in fruit pits, such as apricots, raw nuts, lima beans, clover, and sorghum. The method to analyze laetrile and benzaldehyde was established by HPLC, and the content of laetrile and benzaldehyde was measured. As shown in Figure 3a , the analysis showed that laetrile and benzaldehyde content decreased sharply from day 1. Laetrile was not detectable from day 2. Benzaldehyde was undetectable from day 7. Part of laetrile was degraded by amygdalase and prunase. Some laetrile and benzaldehyde were degraded by other microbials during the fermentation process since laetrile and benzaldehyde are unstable and degraded easily. Laetrile and benzaldehyde are not the pharmacodynamic ingredients of MMF. Rutin. Rutin is a bioflavonoid, or plant pigment, that is found in certain vegetables and fruits. Our sample rutin standard mixture was added to flour and fermented, and this increased the initial rutin content so that the rutin became easy to detect. Standard rutin mixed with flour was fermented. This increased the initial rutin content so that rutin is easy to detect. As shown in Figure 3b , rutin content gradually decreased with fermentation time. The content had fallen significantly since days 2−3 and then decreased gradually. Rutin might be degraded by microbes in flour or other materials. We concluded that rutin is not one of the pharmacodynamic components of MMF. Amylase Activity. Amylase is an enzyme that catalyzes the hydrolysis of starch into sugars, and amylase is present in the saliva of humans and some other mammals, where it begins the chemical process of digestion. We tested the amylase activity of Massa Medicata Fermentata (Figure 3c ) in different fermenting times and showed that there was no difference between day 0 and day 1, but it was significantly different between day 0 and other days. Amylase activity in the second fermenting day also differed significantly from the third day to the seventh day. However, there was no significant difference in the amylase activity between samples of 3 and 7 days. Amylase activity was increased slowly and gradually reached a plateau region after the third day. Amylase activity which was increased during the fermentation process not only degraded components of crude drugs from MMF but also could impact the digestion of foods in the human gut. Acidity. As shown in Figure 3d , the acidity of MMF in different fermenting times showed that there was a significant difference between day 0 and the third day, and for the acidity change, there was no significant difference between days 4 and 7. There was a plateau as the time passed, and then the acidity of MMF increased. This is because it produces abundant organic acid materials during fermentation. For example, aliphatic from AAS was degraded to 95% content of unsaturated fatty acid. 24, 25 Acidic materials could reduce the pH of the human gut and impact the secretion of the pancreas, and then it could be used as a digestive. 35, 36 In the fermentation process of MMF, it has two tendencies: first is that the main components of crude drugs from MMF degraded to small molecules by some enzyme, and the acidity became higher; second is that the amylase activity increased. The fermentation process of MMF includes the interaction between components of crude drugs and micro-organisms, and in this process it produced some materials which are digestive. As shown in Table 3 , wheat bran content in MMF is the highest and reaches 42%. Wheat bran contains about 62% hemicellulose, 24% cellulose, and 11% lignin. These indigestible wheat bran fibers could absorb water to promote intestinal peristalsis and make it easy to defecate by intenerating excrements. Vitamin B1, which is part of the digestive product of wheat bran, could regulate carbohydrate metabolism and promote digestion. 34−36 Flour and PS contain proteins, 37, 38 and they could be degraded to some essential amino acids for the human body and provide nutrients that are easy to absorb in the human body. These pharmacological effects are in accord with the clinical effect of traditional Chinese medicine, which is digestive and not suitable for hyperacidity indigestion. In this study, we showed that the original medical components were not pharmacodynamic components, and amylase activity could explain some pharmacological activity of MMF to some extent but could not explain it completely. Frequently, MMF uses the process of stir-frying until yellow or stir-baking to brown, which causes total loss of enzyme efficacy. 20 The digestive contents diluted hydrochloric acid and pepsase, pancreatin, amylase, etc.; 33 likewise, MMF as a digestive contents abundant microbial enzymes and a certain acidity and wheat bran fiber witch promote intestines peristalsis. MMF has been widely used in China for a long time, but there are no studies on its chemical components and mechanism. This study started to make the exploration of the system.@story_separate@Materials. Acetonitrile (HPLC grade), distilled water, flour, methanol (analytical grade), laetrile, benzaldehyde, and rutin were purchased from China National Institutes for food and drug. AAS, PS, AH, PHH, SC, and wheat bran were purchased from Changan Angguo Pharmacy Company, China. Methods. Preparation of the Test Sample of Flour and Fermentated AAS Product. According to the National Chinese medicine preparation, samples were prepared by using 2500 g of flour and 100 g of AAS. AAS was smashed and filtered through a 20-mesh filter and mixed with flour. About 2000 mL of warm water was added to leaven gradually. The mixture was rubbed to a round shape. The standard is that the 1.3% volatile oil was volatilized mixture will be chunky when grabbed in the hand, and it will disperse when thrown at the table. The mixture was finally put in a mold and fermented for 7 days in a constant temperature and constant humidity oven. One small chunk was taken out every day and dried in an air-dry oven at 40°C. Preparation of the Test Sample of Flour and Rutin Fermentated Product. According to the National Chinese medicine preparation, samples were first prepared by dissolving 64.6 mg of rutin standard in about 150 mL of warm water. The solution was added into 400 g of flour gradually and mixed well. The mixture was rubbed to a round shape. The standard is that the mixture will be chunky when grabbed in the hand, and it will disperse when thrown at the table. The mixture was finally put in a mold and fermented for 7 days in a constant temperature and constant humidity oven. One small chunk of leaven was taken out every day and dried in an air-dry oven at 40°C. Preparation of the Test Sample of MMF Fermented Product. According to the National Chinese medicine preparation, 500 g of wheat bran, 10 g of AAS, and 10 g of PS were smashed and mesh screened individually, followed by mixing with 250 g of flour. Amounts of 50 g of AH, 50 g of PHH, and 50 g of SC were mixed with 1800 mL of distilled water and boiled for 1 h, filtered, and concentrated to 400 mL. The hot extract was added to the above well-mixed powder and rubbed to a chunky shape. The mixture was placed in molds in a 30°C, 85% humidity constant temperature and constant humidity oven. One small chunk of MMF was taken out every day for a consecutive 7 days and dried in a 40°C airdrying oven (Figure 4) . Preparation of the HPLC Test Sample. AAS and Flour Sample. An amount of 30 g of AAS and a flour sample were taken out every day, mixed with 100 mL of methanol, sealed, and extracted by an ultrasound. The extract was filtered and used for laetrile and benzaldehyde detection by HPLC. Each sample was repeated three times. Laetrile control sample: weight of 6.05 mg of laetrile and put into a 10 mL volumetric flask, add methanol, and dissolve laetrile by ultrasound to make 0.605 mg/mL of a control mother liquid, which was filtered through a 0.45 μm filter and used as a control sample. Benzaldehyde control sample: weight of 103.08 mg of benzaldehyde and put into a 100 mL volumetric flask and add methanol to make 1.0308 mg/mL of control mother liquid. The control sample was filtered by a 0.45 μm filter and used as a control solution. Rutin and Flour Sample. An amount of 2.00 g of rutin and a flour sample were taken out every day, mixed with 50 mL of methanol, sealed, and extracted by an ultrasound for 30 min. The extract was filtered, and 10 mL of filtered extract was dried by evaporation and dissolved in 5 mL of methanol in a volumetric flask and then used for the HPLC test sample. Each sample was repeated three times. Rutin control sample: 2.29 mg of rutin was weighed and put into a 10 mL volumetric flask and dissolved by methanol in an ultrasound to make 229 μg/ mL of control mother liquid. An amount of 1 mL of mother liquid was brought to 10 mL by adding methanol and then the concentration was 22.9 μg/mL. It was filtered through a 0.45 μm filter and used as a control sample. MMF HPLC Fingerprint Test Sample. Taking MMF samples from days 0−7, respectively, each 15 g, precisely add 100 mL of methanol. The bottle was sealed and weighed at 25°. The extraction lasted for a half hour, and then it was cooled and weighed again. The weight loss was made up by adding methanol. The mixture was mixed well and filtered. An amount of 20 mL of filtrate was taken and evaporated to dry and transferred to a 5 mL volumetric flask. The extract was mixed well and filtered through a 0.22 μm filter, and then it was ready for HPLC assay. Each sample was repeated three times. Detection Method of HPLC. AAS and Flour Sample. A Waters 1525 HPLC and a Diamonsil C18 chromatographic column were used. The mobile phase was A: acetonitrile, B: water. Acetonitrile−water gradient elution: 0∼5 min, 5%:95%; 5∼15 min, 5% → 10%:95% → 90%; 15∼25 min, 10% → 25%:90% → 75%; 25∼45 min, 45% → 55%:55% → 45%. Detection wavelength: 0∼30 min: 207 nm, 30−45 min: 249 nm. Flow velocity: 1 mL/min. Column temperature: 30°C. Injection volume: 10 μL. Laetrile standard curve: y = 1000000x + 140309, R = 0.9995, linear range: Rutin and Flour Sample. A Diamonsil C18 chromatographic column was used. The mobile phase was A: acetonitrile, B: water. Acetonitrile−water gradient elution: 0∼10 min, 20% → 30%:80% → 70%; 10∼15 min, 30% → 100%:70% → 0%; 15∼25 min, 100%:0%; 25∼30 min, 100% → 20%:0% → 80%. Detection wavelength: 360 nm. Flow velocity: 1 mL/min. Column temperature was 30°C. Injection volume was 10 μL. Rutin standard curve: y = 1000000x − 3144.3, R = 0.9999, linear range: 0.01145 ∼0.1374 μg. Detection procession, stability, recovery, and repeatability all satisfy the requirements. MMF HPLC Fingerprint. We used a Diamonsil C18 chromatographic column. The mobile phase: A: acetonitrile, B: water. Acetonitrile−water gradient elution: 0∼10 min 2%:98%; 10∼12 min, 2%:98%; 12∼15 min, 2% → 5%:98% → 95%; 15∼30 min, 5% → 24%:95% → 76%; 30∼40 min, 24% → 60%:76% → 40%; 40∼55 min, 60% → 75%:40% → 25%; 55∼70 min, 75% → 94%:25% → 6%; 70∼84 min, 94%:6%; 84∼85 min, 94% → 100%:6% → 0%; 85∼105 min 100%:0%. Detection wavelength was 280 nm. Flow velocity: 0.5 mL/min 0∼10 min, 1 mL/min 10∼115 min. Column temperature was 30°C. Injection volume was 10 μL. This assay, the methodology test precision, repeatability, and stability are good, and the RSD is less than 3%. The sample recovery rate of the detection range between 95%∼105% meets the requirements of test accuracy. Amylase Detection Enzyme Substrate Buffer Preparation. Amounts of 9.0 g of sodium choloride, 22.6 g of anhydrous disodium hydrogen phosphate, and 12.5 g of anhydrous potassium dihydrogen phosphate were dissolved in approximately 500 mL of distilled water by boiling. An amount of 0.4 g of soluble starch was mixed with 10 mL of distilled water, and the suspension was transferred to the above boiling solution. The mixture was cooled to room temperature. An amount of 5 mL of 37% formaldehyde solution was added to the mixture, and the volume was brought to 1000 mL by distilled water. This was the buffer solution of pH 7.0 and 0.4 g/L of enzyme substrate. Iodine storage solution (0.1 mol/L): 1.7835 g of potassium iodate and 22.5 g of potassium iodide were dissolved in distilled water. An amount of 4.5 mL of hydrochloric acid was added, and the volume was brought up to 500 mL. After thorough incorporation, the final solution was stored in a brown bottle at 4°C. Diluted iodine solution (0.1 mol/L): Iodine storage solution was diluted ten times and kept in a brown bottle and used fresh. Enzyme solution extraction: 5.0 g of MMF after 0∼7 days fermentation was smashed and filtered by a 20-mesh filter. An amount of 50 mL of distilled water was added and stirred for 30 min in a 40°C water bath. Fully dissolve the enzyme protein by filtration, and put the filtrate aside. The reaction was prepared by mixing 1.0 mL of substrate buffer and 0.2 mL of enzyme extract mixed in 40°C water for 7.5 min, and 1.0 mL of diluted iodine solution was added to 6.0 mL of distilled water. The spectrophotometer was blanked using distilled water, and the absorbance was read at 660 nm. Each sample was repeated three times. At the same time, we did not add the enzyme-controlled experiment. Activity = (AB − AU)/AB × 800. AB: blank absorbance; AU test tube absorbance. Unit Definition: One unit is defined as the amount of enzyme required to hydrolyze 10 mg of starch in 30 min at 40°C in a total reaction volume of 100 mL. pH Detection. We weighed 1.0 g of MMF after 0∼7 days fermentation, smashed and filtered by a 20-mesh filter, and dissolved it in 10 mL of water in a volumetric flask and stirred it for 30 min. We used it for a pH test sample and used a pH meter (Shanghai Sanxin instrument and meter plant) testing solution to get the pH value. We repeated it 3 times.@story_separate@This biostudy has provided initial knowledge of Massa Medicata Fermentata, and the results imply that deep exploration of this popular traditional medicine should be done to further focus on outbreaks of new human diseases worldwide. Massa Medicata Fermentata acts as a digestive and relies on abundant microbial enzymes, particularly acidities, and wheat bran fiber, which promotea intestinal peristalsis. The present digestive contents in Massa Medicata Fermentata include diluted hydrochloric acid, pepsin, pancreatic, and amylase. The process of stir-frying and -baking Massa Medicata Fermentata results in a total loss of enzyme efficacy. Although Massa Medicata Fermentata is widely used in China, there is a lack of studies regarding its chemical components and fermentation mechanisms. Our biostudy determined that the initial components of Massa Medicata Fermentata are not identical to the pharmacodynamic components. We also conclude that amylase activity explains the pharmacological activity of Massa Medicata Fermentata to a certain extent, but it is likely not the only factor.","[Image: see text] Massa Medicata Fermentata (MMF) has been used for a long time by the Chinese. MMF is used widely in feed additives and human medicinal applications throughout the world; however, there have only been a few reports about the biostudy of its fermentation mechanism and medicinal ingredients. To safely use MMF, we observed the changes in the ingredients and amylase activity for several raw materials during the fermentation process of MMF. We are going to explore the basis of pharmacodynamic substances and the purpose of MMF to provide support for safe use in clinics. This biostudy data demonstrated that the ingredients such as amygdalin, benzaldehyde, and rutin were gradually degraded during the process of fermentation, and the fermented MMF did not contain amygdalin and benzaldehyde. The HPLC fingerprint of fermented MMF for 7 days is similar to the chemical composition of the original unfermented MMF with a similarity of only 0.106. Meanwhile, the activities of amylase in fermented MMF had gradually increased, and the content of organic acids also had increased. According to our biostudy, we found that the raw material chemical composition of MMF in the process of fermentation was affected by microorganisms and various substances. The conclusions of our study determined that the initial components of MMF are not identical to the pharmacodynamic components. We also conclude that amylase activity explains the pharmacological activity of MMF to a certain extent, but it is likely not the only factor. The implication not only provides the initial knowledge of MMF but also implies the further exploration of this popular traditional medicine."
"The COVID-19 disease, caused by the SARS-Cov-2 virus, is presently causing the most important crisis of world society and governance in the XXI century. The International Monetary Fund predicts a decrease of world's product in the order of 3% in 2020, [1] While this is a dire forecast for all countries it is especially difficult for developing countries like most of those of the Southern Hemisphere, where the economy weak before the outbreak. The World Health Organization declares COVID-19 a pandemic 13 of March. [2] However, at present number of deaths is of ca. 150.000 [3] , while grave or critical cases are in the order of 60.000 [3] . The number of reported cases is in the order of 2,2 million.[3] Those numbers represent a small amount (0,03%) of the world's population and are smaller than other viral pandemics/endemics. It is estimated that up to 44.0 million people globally were living with HIV in 2018, with up to 1,1 million deaths. [4] Seasonal influenza caused 5 million cases worldwide, with 650000 deaths. However, COVID-19 pandemic is at early stages and the number of cases and deaths could grow considerably. Therefore, the capability of forecasting relevant parameters (death, critical or grave cases) is critical. At the same time, the global response to this pandemic has been swift and harsh with shutdown of all international travel and several countries in different degrees of lockdown. The socioeconomic consequences of such response are catastrophic, such as high unemployment, businesses bankruptcies, etc. Obviously is the response, based mainly on non-pharmacological interventions(NPI),[5] the cause of the economic crisis, not the disease itself. It is reasonable to ponder why such harsh measures has been taken in response to COVID-19 and not before upon seasonal influenza, HIV, H1N1 influenza,[6] etc. The usual answer is that COVID-19 is radically different and requires such measures. Besides, there is no vaccine for COVID-19 available. However, specifically in the case of influenza H1N1, the vaccine was produced only 5-6 months after the declaration of pandemic (June 2009) and 7 months after the outbreak (April 2009). [7] In the meantime, especially in the southern hemisphere, which was in autumnwinter where influenza strains are specially active, some kind of social distancing and some antivirals were the only way to fight the disease. [8] Before the H1N1 pandemic, declared by WHO in June 2009, [9] WHO predicted 2-7 million deaths in the 'best case' scenario. [10] . Other expert predictions, based on the death toll pandemic influenza in 1918-1920 range from 62 million deaths, [11] to 180-360 million deaths. [12] The final death toll was below 20.000. [9] The point is relevant because the same analogies are used today to predict the outcome of COVID-19 pandemic. In the best of my knowledge, such dire predictions do not motivate the governments at the time to enact full lockdown or even complete international travel shutdown. There were targeted flight bans and in some countries school shutdown or phase out to springtime. Obviously, the social and economic consequences were small. It is interesting that the CDC guidelines, [13] suggest social distancing measures (school closing, banning public gatherings, isolation of infected, etc.) but no lockdown. The rationale behind social isolation is grounded on the studies of the effect of such interventions on the mortality of the 1918-1919 influenza pandemic. [14, 15] The community NPIs recommended by the CDC, [13] involve: School Closures and Dismissals and Social Distancing Measures for Schools, Workplaces, and Mass Gatherings. Those are made with together with personal NPI: voluntary home isolation (i.e., staying home when ill or self-isolation, respiratory etiquette and hand hygiene. As it can be seen, social distancing but short of lockdown or stay at home orders. The evidence supporting the applications of such NPIs is the studies of the effect of NPIs on the mortality outcomes of different US cities during the outbreak of pandemic influenza (1918) (1919) (1920) . [14, 15] Again, the NPIs were short of lockdown or stay at home order. Moreover, it is explicitly stated, [15] that an experimental study on the effect (and collateral effect) of NPI has not been performed because:""the trend away from such traditional public health measures for disease control during the past 50 years,(stated in 2007) and ethical limitations of using population-wide nonpharmaceutical interventions in the absence of a serious threat"". [15] It seems that COVID-19 is such a big threat that even harsher NPIs are considered adequate today. A key factor is to be able to predict the importance of the threat, related with the number of cases or deaths. Plenty of models have been set-up to model the number of cases and deaths of COVID-19. Most rely on SIR (Susceptible-Infected-Removed) simulation using systems of differential equations. [16] A more complex kind of models involves the so called agents, where the movements, transmission and infection of individuals are randomly produced and the infection rate calculated. Both kinds of models requires to know several parameters (e.g. number of persons infected by one infected individual) which can be estimated from earlier cases (e.g. Wuhan in China) but likely change from case to case, as it is shown in Europe. A well-known calibrated SRI simulation was made by the Imperial College Group, [16] whom inform policy in the UK, US and the world (including southern hemisphere countries (SHC)). They predict a maximum of deaths of 2.6M and 200K for USA and UK, respectively if ""suppression"" was not enacted. Mitigation measures which include isolation of cases and contacts, social distancing, ban of public gatherings and schools were considered insufficient. [18] Such dire forecast prompts both governments to apply social isolation. In that situation, the model predicts only 200K and 50K for the USA and UK, respectively. Most of other countries, including Argentina, followed suit and apply lockdown. In all cases was a quite informed decision because the ICG predicts 3.2M deaths for Latin America & Caribbean in the case no measures were taken, 729K if the ""suppression"" is made after 1.6 deaths/week/100K inhabitants has reached and 158K in case the ""suppression"" is enacted before 0.2 deaths/week/100 K has been reached. It should be mentioned that the last threshold means ca. 12 deaths per day in the whole Argentina. Such threshold have not been reached when total lockdown was enacted (23 rd of March 2020), was not reached since and the forecast presented here suggest that will never be reached. On the other hand, the Institute for Health Metrics and Evaluation (IHME) of Washington University,[18] uses a fitting method to obtain a parametric equation which allows forecasting the number of deaths during time using the data of the ongoing outbreak. The equation that describes the number of deaths per day is the Gaussian distribution equation. The total number of deaths per day is the integral form of the equation. The equation represents a bell curve which is the shape found out empirically by Farr (Farr's law) which have found to fit most of epidemic outbreaks of diseases. While IMHE models several countries of the world, it does not apply the methodology to the southern hemisphere or the world, where Argentina is located. For informing health policy in our country, both our data and that of our neighbors is relevant. Therefore, programs were set to fit the integral of the Gaussian equation. The fitting and forecasting capabilities of the programs were tested with advanced cases (in the northern hemisphere) where can be compared with IHME data. Then, were applied to southern hemisphere countries and also to the whole world. The forecast for countries in the southern hemisphere show relatively low excess deaths. The calculation of different scenarios for infection rates also shows a relatively low infection rates. Possible causes are discussed.@story_separate@The program was developed in Python 3.76 (https://www.google.com/search?client=firefox-b-d&q=python) in the IDE Spyder (https://www.spyder-ide.org/) launched by Anaconda (https://www.google.com/search?client=firefox-b-d&q=anaconda+python) on a Dell Latitude 3460 laptop (i3, 4 Gb of memory and 600 Gb of disk). The Gaussian equation (Farr's law) was symbolically integrated with Euler (http://euler.rene-grothmann.de/index.html) by adding integration constant. Method: fit with routines in Python (scipy.optimize, https://www.scipy.org/) in our own Python programs (available at https://github.com/cesarbarbero/programas-para-predecir-COVID-19/). The test suite was from Italy that contains more than 2/3 of the peak (deaths per day)-We also fit China that contains the whole forward peak. However, it does not contain the full data before the peak since the first reports are 17 deaths (in Wuhan). Moreover, recently (17/04/2020), they have incorporated 50% more deaths without information on the day of death. Therefore, the dataset of China is not usable. The program predicts the same parameters using total data from Italy (53 days) or 35 days (non zero deaths for most SHC), showing that it is able to adequately predict the evolution of deaths over time. Initially, the data from Argentina was obtained from the Ministry of Health of the Nation (MSN) by manual recording from daily reports (https://www.argentina.gob.ar/coronavirus/informe-diario). Then, the data from most southern hemisphere countries were obtained from worldometer (https://www.worldometers.info/coronavirus/#countries) by reading the graphs in the webpage (see acknowledgements for the help in data collection). However, the final runs were made with the data produced by John Hopkins University and stored in a github repository (https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv #L17). In that way, the database is public and its quality is independently verified. A special program: ""Graphical fit"" was used to obtain roughly correct parameters (a,b,c,norm) to be used as seed and as central points for the constraint of the curve fitting routine. By trial and error, guided by the understading of each parameter on the shape of the curve, the simulated data is graphed along the experimental data. When a reasonable fit is obtained, the parameters are copied in the curve fitting program as seed. The constraints of the curve fit are set around those values. The curve fitting program is run until the parameters are different to the constraints. The numerical and graphical output is directly written in the manuscript, without any data manipulation. The results of the fit (numerical data and plots) for each country are provided in the supplementary information and in github. To test the ability of the program to forecast the evolution we used the dataset from Italy which has already cover ca. 2/3 of the peak. In Figure 1 it is shown the sum of deaths during time from the 22 nd of January (first reported death in the world). Along it, it is shown the calculated fitted points, which closely follow the actual data. Using the . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 26, 2020. . The dashed blue line represents the worst case scenario (WCE) with 50% uncertainty. In that way a total number of deaths of 22978 (29871-22978). The estimation of uncertainty is up to the 30% of the predicted data. Accordingly, in Figure 1 it is shown the worst case scenario (WCE) which correspond to the upper limit of the error. It should be noticed that the use of this uncertainty region in the graph of deaths per day allow to include the 95% of the scattered data (see below). The best case scenario (BCE) is not plotted in Figure 1 since it will show an unreal case of lower than actual deaths before the last real data point. It is likely for the deaths to be under-reported, * but it is unlikely to be over-reported. Accordingly, the BCE for the total deaths (16804) is not shown because it is lower than the deaths already reported (22170 al 17-04-2020).The projected number of deaths agree (taken into account the uncertainty range) with the total number of deaths projected by the IHME of 25007 (31056-23589).[ https://covid19.healthdata.org/italy accessed 18/04/2020)]. Using the parameters of the PIGE, it is possible to calculate the evolution of the number of deaths per day (parametric Gaussian equation, PGE) and compare with the reported data. In Figure 2 it is shown the graph of the number of deaths reported for Italy for each day. While the total number of deaths at each given day shows a smooth curve (Figure 1) , the data of number of deaths per day show a large scattering. This is reasonable since the local reporting reach the health authorities at different rates, depending on distance of local governance. However, the predicted curve follow well the data and the uncertainty range (shown by dashed blue lines) of the forecast includes more than 95% of the reported data. In this case, the low range includes actual reported data. From the PGE it is possible to obtain other parameters of interest. First, it can be predicted the maximum of the peak, when the outbreak is at maximum which was de 1 st (+/-3) of April. As it can be seen in Figure 2 the reported deaths data show a clear maxima in that region. More interesting is to predict the end of the outbreak. 100% of deaths will occur before the 16 th (+/-3) of May 2020. Using the 3 criterion (99.748 %), the outbreak will be the finished by 1 st (+/-3) of May. Note that the curve in Italy has already passed the  point (68.27%) which happened the 5 th (+/-3) of April. Therefore, it is a convenient test suite for the fitting program. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 26, 2020. . The good fitting with Gaussian equation allows calculating a parameter which is relevant and has acquired growing epidemiological importance that is the true start of the outbreak. While in well-known diseases (e.g. measles) the cause of death is clearly assigned, with COVID-19 requires testing for the virus. In China the initial reports (22 nd of January) are of 17 cases. Applying the program to China show that there should be deaths due to COVID-19 before but there were not tests available. In other countries where the outbreak began later, the situation should be better. However, if the outbreak was not detected, deaths by COVID-19 could be assigned to other pathologies. Since the period between contagion an deaths is ca. 6 days [Updated understanding of the outbreak of 2019 novel coronavirus (2019nCoV) in Wuhan, China -Journal of Medical Virology, Jan. 29, 2020], it allow to find out the true beginning of the outbreak. In the case of Italy, the program calculates the 28 th (+/-3) of December 2019 as the date when 0% deaths has happened. Therefore, contagion in Italy should have been occurring in December 2019. To test the capacity of the program to predict the evolution, the test was performed using data well before the peak (only till 21 st of March). The forecast shows similar outcomes predicting a total number of deaths of 25456 (33092 -254569). The times of different events is even closer, with peak of death the 1 st (+/-3) of April, 100 % deaths the 20 th of May, day the 4 of April and beginning of the outbreak the 24 th of December 2019. Another test case used was Spain. The relevant parameters are depicted in Table 1 . The detailed data with plots, similar to Fig. 1 and Dig. 2, are presented in the supplementary information. The most personally relevant case for this study is Argentina. Moreover, the 23 rd of March was applied a total lockdown which is strongly affecting the economy and life in the country. Forecasting the magnitude of the problem is critical to advise policy. The fitting of the reported total deaths data is shown in Figure 3 . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 26, 2020. . Other important parameters are the day of maximum death since it is related to the day of maximum usage of the health system. To find out, the Gaussian equation is plotted along with the data of deaths per day. (Figure 2 ). . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 26, 2020. . However, already the 1 st (+/-3) of May, 95.45% (2 ) of the deaths have occurred. It is reasonable to think that at that date, the outbreak is over. Moreover, the parametrc equation allows to calculate the beginning of mortality due to COVID-9 which is the 9 th (+/-3) of March 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 26, 2020. . Table 2 . Relevant parameters of different countries in the Southern Hemisphere (SH) obtained by fitting the sums of daily death data. † The countries are ordered in descending order, taking into account the projected total deaths. The dates are in the format dd/mm/yy. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 26, 2020. . As it can be seen, the PIGE predicts a relatively low number of deaths. The number for the Southern Hemisphere (last but one row at the left in Table 2 ) is significantly lower (10 to 15 times) than the projected best scenario (for Latin America & Caribbean only) in the ICG modeling (shown in the last row at the left of Table 2 ). The suppression imply 75% lockdown before the death rate has reached 0.2 deths/per week/100.000 inhabitants. [17] . Not all the countries studied decide to apply a full lockdown (Chile for example apply a mitigation protocol in areas with few cases and good health coverage) and others have difficulties to enforce total lockdown (e.g. Brazil) but the outcomes are everywhere dramatically better than the IGC estimation. Therefore it is reasonable to assume that the IGC model overestimate the number of deaths. The parametric equation allows detecting the maximum of deaths per day peak. Several countries have already passed the peak (including Argentina) meaning that the outbreak is subsiding. Since the number of deaths have to be related with the number of new infections (with a delay), it also means that number of new cases is decreasing. In any epidemiological model, this means that the number of infections caused by an infected individual is decreasing in time. This could be to the fact that the number of susceptible contacts is decreasing (because all are already infected or recovered) or that the number of contacts is decreasing with time. A way to calculate the number of persons infected involves dividing by the rate of mortality (Rm = deaths/infected). However, Rm is not easily known because it would require to know exactly the number of persons infected in all the countries involved, and such number depends on the testing capabilities and testing protocol. In Argentina, only individuals who show symptoms are tested, therefore asymptomatic infected individuals are not counted. Since different Rm values have been reported, the Rm reported by South Korea (0.5 %) was used to produce the high limit number and that of Italy (8 %) to calculate the lower limit. The results are shown in the last two columns of Table 2 . The numbers for the whole SH are shown in the last but one row (right) of Table 2 . In the worst case scenario ca. 2M individuals will be infected, which is quite low since the population of the SH is of more than 664M. Obviously, if the rate of mortality of COVID-19 is as low of the seasonal influenza (0.1%), the number of cases will be higher (ca. 10 M) but such scenario means that the COVID-19 is not a grave menace for general population, as the seasonal influenza, and the generalized lockdown is unjustified. In the last row (right), it is shown the predicted number of cases by ICG. [17] The number is more than 45M, which is more than 20 times larger than the calculated here. Even if the rate of mortality is as low as that of seasonal influenza, the number of cases predicted by IGC is 4-5 times off. One of the more important concerns in this pandemic outbreak is the ability of different health systems to cope with the number of cases. Therefore, it is relevant to know the number of cases per day. In that way, it is possible to calculate the needs (hospital beds and intensive care unit (ICU) beds for each country (Table 3) . To do that, we assume that 20% of the cases require hospitalization and 5% of the cases require ICU beds. Using the population data and following the ICG report, [17] it is possible to calculate the number of hospital beds (and ICU beds) available. To do that we use the worst case scenario that all SH countries are Low Middle Income Countries (LMIC), which gives 1.5 beds/1000 inhabitants. Then, the some category of LMIC gives 1.75 ICU beds/100 beds. The Lower Income Countries (e.g. Bolivia) in the list This work was funded by Universidad Nacional de Rio Cuarto (UNRC, Argentina) and the Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET, Argentina) whom paid my salary while I am socially isolated at home. Special thanks to members of my research group: A. Cuello, D.Acevedo, E. Yslas, R. Bellingieri, R. Gramaglia, G. Morales, J. Balach and M.A. Molina whom helped with the initial data collection. Helpful virtual discussions with J. Balach and E. Quinteros about the program are also discussed. The laptop used was purchased with funds from a Secretaria de Politicas Universitarias -. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 26, 2020. . https://doi.org/10.1101/2020.04.20.20072488 doi: medRxiv preprint Minsterio de Educacion (Argentina). The author appreciates the use of open source programs (Python, Anaconda, Spyder, Matplotlib, Scipy, Numpy, Euler Math Toolbox, Vseuz graphics software). Finally, special thanks to Dr. L. Sereno whom teach me how to visually find out good seed/constraints for nonlinear fitting of complex equations. A set of document files with the results of all the countries described and representative datasets. The Programs could not be loaded in medaRXiv. Are available at https://github.com/cesarbarbero/programas-para-predecir-COVID-19/).@story_separate@The fitting with a parametric integrated Gaussian equation (PIGE) seems to be a good method to obtain parameters of both descriptive and predictive value. Using open software libraries in Python (3.7) it is possible to produce programs which fit the experimental data (reported cumulative deaths). The programs are tested with advanced outbreaks (Italy and Spain) and give results comparable with those produced, using similar methods, by the IHME (Washington University, USA). The application to the reported data from Argentina allows forecasting a relatively small number of deaths (277-182). It also allows calculating: i) the day of the peak, the day of the begining and iii) the day of the end of the outbreak. The application of the program to the data from the most important countries of the Southern Hemisphere shows a similar trend. While countries like Brazil and Mexico show more deaths it scales with a much larger population. In fact, relatively small countries (e.g. Uruguay) show so little number of deaths that makes the fitting difficult. The sum of deaths predicted for all the countries (even with an uncertainty of 50%) are significantly lower than those predicted by the Imperial College Group(ICG). Using the parameterized death data and the mortality ratio (Rm), it is possible to calculate the number of COVID-19 cases, assuming two scenarios: a low Rm (South Korea) and a high Rm (Italy). These assumptions translate into a worst case scenario and best case scenario, respectively, for the number of infected individuals. These data are also much smaller than those predicted by the ICG. Using the maximum deaths per day, calculated by the parameterized Gaussian equation (PGE) with the parameters obtained from the fit of PIGE, it is possible to forecast the maximum need of hospital and ICU beds. Using the assumptions of ICG, we can calculate the hospital and ICU beds available in each country. The comparison allows to state that all countries have enough hospital beds but Peru, Ecuador and Panama should have not enough ICU beds to cope with grave COVID-19 patients. One possible reason of low mortality involves the fact that the outbreaks begun during late summer in the SH, instead or late winter as in the Northern Hemisphere. Therefore, a new harsher outbreak could occur after June (winter in the SH). If that is the case, the harsh lockdown measures implemented in late March would be a hard cure for a mild disease but it would made more difficult for SH countries to reapply such hard measures during winter when the new, potentially harder, outbreak develops.","A set of open source programs in Python is devised to fit a parametric integrated Gaussian equation to cumulative deaths due to COVID-19 in Southern Hemisphere countries. The programs were successfully tested using data from advanced outbreak trajectories (Italy and Spain). The procedure was applied to data reported by Argentina. The projected total death toll will be 182 (277-182) with a peak of deaths (6(+/-2)) the 14 of April. The outbreak begins the 9th of March and end completely the 20th of May. However, already on 1st of May, 2 s (95.45%) of the deaths have occurred. The death toll arises from a number of infected individuals between 36412 and 2275. Then, they were to use to process data from several Southern Hemisphere countries: Argentina, Brazil, Mexico, Peru, Colombia, Ecuador, Cuba, Chile, Panama, Australia, Bolivia, Honduras, New Zealand, Paraguay, Guatemala, Venezuela, Uruguay, El Salvador, Jamaica, Haiti, Costa Rica and Nicaragua. The trend is to show low number of total deaths compared with other disease outbreaks. A total projected number of deaths between 15148 and 9939 deaths for a total population of ca. 664 M inhabitants. The projected death toll is much lower (5-10 times) than those forecasted by the Imperial College Group (ICG) even considering the best scenario of total suppression of virus transmission. Using actual mortality rates it is possible to back calculate which number of infected individuals would produce such mortality. The calculated number of infected individuals (worst case scenario) is below 2.5 million. This is significantly lower than that calculated by ICG (> 45 millions). In most countries the outbreak will end in May or early June. The dynamics of the outbreaks seems to do not saturate the health services (hospital beds) but only Peru, Ecuador and Panama should have not enough ICU beds for grave COVID-19 patients"
"Our understanding of the mechanisms by which enveloped viruses enter cells has made an enormous leap forward in the past few years, primarily through the solution of atomic structures of virion surface proteins (or fragments thereof) that mediate the fusion of the viral membrane with cellular membranes. Fusion proteins from several different virus families including Orthomyxoviridae (Wilson et al., 1981; Bullough et al., 1994; Chen et al., 1998; Rosenthal et al., 1998) , Paramyxoviridae (Baker et al., 1999) , Retroviridae (Fass et al., 1996; Tan et al., 1997; Weissenhorn et al., 1997; Chanet al., 1997; Caffrey et al, 1998; Malashkevich et al., 1998; Kobe et al., 1999) , and Filoviridae (Weissenhorn et al., 1998; Malashkevich et al., 1999) have been shown to exhibit striking structural similarities, suggesting that they all use a common mechanism for inducing membrane fusion, and that the same general model applies to all of these cases (Hughson, 1997; Skehel and Wiley, 1998; Weissenhorn et al., 1999) . The envelope glycoprotein E of the flavivirus tick-borne encephalitis (TBE) virus (Rey et al., 1995) is a notable exception. It mediates membrane fusion, but it does not share the salient features of the previously mentioned viral fusion proteins, suggesting that the structures and mechanisms used by flaviviruses might be significantly different. In this review we focus primarily on the work carried out with TBE virus, the structurally best characterized of the flaviviruses. We attempt to relate these data to those obtained with other flaviviruses, which are assumed to have a conserved structural organization, and compare the characteristics of flavivirus fusion to those of other enveloped viruses.@story_separate@The genus Flavivirus of the family Flaviviridae includes about 70 distinct viruses, all of which are serologically related and, in the majority of cases, maintained in nature by transmission from hematophagous arthropod vectors (mosquitoes or ticks) to vertebrate hosts [reviewed by Monath and Heinz, (1996) ]. More than 50% of the flaviviruses have been associated with human disease, and of those, the most important in terms of disease incidence are dengue (DEN) virus (types 1 to 4), yellow fever (YF) virus, Japanese encephalitis (JE) virus, and TBE virus. Flaviviruses are distributed worldwide, but individual species are restricted to certain geographic areas that provide the ecological conditions required to maintain the natural cycles of these viruses (e.g., DEN virus in tropical and subtropical areas around the world; YF virus in tropical and subtropical regions of Africa and South America; JE virus in Southeast Asia; TBE virus in Europe and Northern Asia). The flavivirus genome is a positive-stranded RNA molecule consisting of a single long open reading frame (ORF) of more than 10,000 nucleotides flanked by noncoding regions at the 5"" and 3' ends. The genomic RNA is the only mRNA found in infected cells, and its translation gives rise to a polyprotein that is cotranslationally and posttranslationally processed into the viral structural proteins and a set of nonstructural proteins required for virus replication [for more details of the molecular biology of virus replication, see Rice (1996) ]. The virion is spherical, with a diameter of approximately 50 nm and contains an isometric nucleocapsid surrounded by a lipid envelope. Mature flaviviruses have three proteins: a capsid protein (C) and two integral membrane proteins designated E (envelope) and M (membrane) (Fig. 5.1) . The E protein is glycosylated in most, but not all, flaviviruses and, at least in TBE virus, is a homodimer. It is believed to mediate both receptor-binding and fusion activity and is the major target of neutralizing antibodies. Immature virions, which are present in infected cells, contain heterodimers consisting of the E protein and a second glycoprotein (prM), the precursor of the M protein. The prM protein is cleaved by a cellular protease (presumably furin) during virus maturation. The entry of enveloped viruses into cells and the release of the nucleocapsid require the fusion of the viral membrane with a cellular membrane (reviewed by White, 1992; Hernandez et al., 1996) This may occur either at the plasma membrane (e.g., in the case of many retroviruses and paramyxoviruses) or at endosomal membranes after the virus is taken up by receptor-mediated endocytosis (e.g., in the case of orthomyxoviruses, rhabdoviruses, togaviruses, and flaviviruses). The envelope glycoproteins responsible for viral fusion often have a dual function, with receptor binding and fusion activity residing in the same protein (e.g., the influenza virus HA protein), but in some cases Mature virion p~ T FIG 5.1, Schematic of the composition of immature and mature flaviviruses. Limited trypsin digestion of TBE virus yielded a soluble dimeric ectodomain fragment of the E protein, which was used for structure determination (Rey et al., 1995) . these functions are mediated by different proteins, such as the HN and F proteins of paramyxoviruses. Several of these proteins are synthesized in a precursor form that requires cleavage by a cellular protease (reviewed by Klenk and Garten, 1994) . The cleavage event primes the molecule for a subsequent conformational change that is crucial for the fusion process. The activating cleavage can occur either in the fusion protein itself (e.g., in the case of the influenza virus HA protein) or in an accessory protein that forms a stable complex with the fusion protein during biosynthesis (e.g., in the case of the alphavirus spike glycoproteins). In either case it leaves the fusion protein in a metastable conformation, which, when the appropriate trigger is applied (receptor binding or low pH, depending on the virus), is converted to a lower energy state. For influenza virus HA and structurally related fusion proteins the transition involves the release and extension of part of the protein as an a-helical coiled coil, and the metastable state therefore is said to be ""spring-loaded"" (Carr and Kim, 1993; Carr et al., 1997; Qiao et al., 1998) . The conformational changes triggered at the plasma membrane by receptor binding or in the endosome by acidic pH lead to the exposure of a structural element, the fusion peptide, which interacts with the target membrane and thus initiates the fusion event. Detailed structural information on the conversion from the metastable native conformation to the stable final conformation is available only for the influenza HA, because it is the only viral fusion protein for which the atomic structures of both forms are known (Wilson et al., 1981; Bullough et al., 1994) . However, from the partial structures of the presumed final stable conformation of several other viral fusion proteins (Fass et al., 1996; Tan et al., 1997; Weissenhorn et al., 1997; Chan et al., 1997; Weissenhorn et al., 1998; Malashkevich et al., 1998; Malashkevich et al., 1999; Baker et al., 1999; Kobe et al., 1999) , it has become apparent that they all share a similar structural basis for their functions, which is also mechanistically related to that of the cellular fusion machinery (v-SNARES and t-SNARES) Hughson, 1999) . They have in common that they undergo conformational changes in which specific protein segments are recruited into rod-shaped helical bundles, bringing together the fusion peptide and the membrane anchor, and with them presumably also the viral and cellular membranes. Among the viral fusion proteins of this structural class, the vaccinia virus 14-kDa protein is the only one that does not have its own membrane anchor but is indirectly attached to the membrane via a second protein (Vazquez et al., 1998) . The structural changes leading to viral fusion in many cases are irreversible and can occur only once because they lead to the inactiva-tion of the virus. Therefore, these molecules are also vulnerable to premature triggering during assembly and release, either by interaction with receptor molecules or by exposure to acidic pH in the trans-Golgi network (TGN)o Viruses have evolved different strategies to cope with this problem, including the use of accessory proteins to stabilize the labile fusion protein (Salminen et al., 1992; Guirakhoo et al., 1992; Heinz et al., 1994) and the use of proton channel-forming proteins to increase the pH in the TGN (Steinhauer et al., 1991; Hay, 1992) . The flavivirus life cycle as it relates to fusion is shown schematically in Fig. 5 .2. Available data indicate that viruses enter cells by receptormediated endocytosis and that low pH-triggered fusion of the viral m e m b r a n e with the endosomal membrane leads to the release of the The life cycle of flaviviruses, highlighting the processes of entry by receptormediated endocytosis, fusion of the viral membrane with the endosomal membrane, assembly of immature virions in the endoplasmic reticulum (ER), transport of immature virions through the exocytic pathway, proteolytic cleavage of prM in the trans-Golgi (TGN) network, and release of mature virions. A subviral particle (slowly sedimenting hemagglutinin, SHA) is secreted as a by-product of flavivirus replication. Acidic compartments are shaded gray. nucleocapsid into the cytoplasm, where translation and RNA replication occur (Rice, 1996) . Based on ultrastructural and biochemical evidence, immature (prM-containing) virions appear to be assembled at intracellular compartments, presumably by budding into the endoplasmic reticulum (ER) and are then transported through the cellular exocytic pathway, where modifications such as the trimming and terminal addition of carbohydrate side chains occur. The maturation cleavage of prM is believed to be mediated in the TGN by furin shortly before release of the virus. Flavivirus-infected cells also secrete subviral particles with hemagglutination activity, called slowly sedimenting hemagglutinin (SHA). These particles, which are apparently a byproduct of virus assembly, contain the envelope proteins but not the capsid protein. Similar particles can also be generated in recombinant form by the expression of the E protein together with the prM protein and, as discussed next, have played an important role in several areas of flavivirus research, including the investigation of fusion. It is a characteristic property of flaviviruses that the coexpression of the prM and E proteins in the absence of the C protein leads to the formation and secretion of a capsidless subviral particle . Recombinant subviral particles (RSPs) have been generated for several different flaviviruses Konishi et al., 1991; Pincus et al., 1992; Konishi et al., 1992a; Konishi et al., 1992b; Yamshchikov and Compans, 1993; Sato et al., 1993; Konishi et al., 1994; Fonseca et al., 1994; Pugachev et al., 1995; Allison et al., 1995b) , but they have been the most extensively characterized in the TBE virus system (Schalich et al., 1996) . The TBE virus RSPs are smaller than virions (approximate diameter 30 vs. 50 nm), but their assembly pathway is quite similar to that of the virus. Like whole virions, they are first assembled in an immature form that contains prM and E. The mechanisms of intracellular transport, processing of carbohydrate side chains, and cleavage of prM by a cellular protease before release from the cells occur in the same manner, and presumably by the same mechanisms used by the virus itself. Consistent with their smaller size, they exhibit a slower sedimentation rate than virions, and because of the lack of a nucleocapsid their buoyant density is lower (1.13 vs. 1.19 g/cm 3 in sucrose). The following evidence suggests that TBE virus RSPs possess a lipid membrane (Allison et al., 1995b; Schalich et al., 1996; Corver et al., 2000) : (1) They have been shown in metabolic labeling experiments to incorporate [14C]choline and fluorescently labeled fatty acids, (2) they are readily disrupted by treatment with nonionic detergent, (3) they fuse with liposomes at low pH, and (4) they are capable of inducing cell-cell fusion when applied externally to cells and acidified. The structure and oligomeric arrangement of the E protein on the surface of TBE virus RSPs appear to be very similar to that on the snrface of virions. This conclusion is supported by a variety of different experimental data (Schalich et al., 1996) . RSPs and virions are indistinguishable in their reactivity pattern with a panel of E protein-specific monoclonal antibodies, several of which are neutralizing and conformation-specific. They are also similar in their specific HA activities and fusion properties, both of which are mediated by the E protein. Their particulate nature and native antigenic structure make RSPs excellent vaccine candidates, as has been shown in a number of immunization studies in the TBE virus and other flavivirus systems using purified RSPs (Konishi et al., 1992b; Konishi et al., 1994; Heinz et al., 1995; Konishi et al., 1997b) , as well as plasmid constructs (Phillpotts et al., 1996; Schmaljohn et al., 1997; Colombage et al., 1998; Konishi et al., 1998b; Aberle et al., 1999) and recombinant viruses Konishi et al., 1991; Pincus et al., 1992; Konishi et al., 1992a; Konishi et al., 1994; Fonseca et al., 1994; Konishi et al., 1997a; Colombage et al., 1998; Konishi et al., 1998a ) that lead to the synthesis of RSPs after administration. Because their envelope glycoproteins have a native structure and are functionally active, RSPs are also an extremely valuable model for studying flavivirus envelope structure and function (see Sections VII.B, VII.F, and VII.G). The fusion properties of flaviviruses have been investigated using several different assay systems, including virus-induced cell-cell fusion and virus-liposome fusion (Ueba and Kimura, 1977; Gollins and Porterfield, 1986b; Summers et al., 1989; Randolph and Stollar, 1990a; Guirakhoo et al., 1991; Vorovitch et al., 1991; Despres et al., 1993; Guirakhoo et al., 1993; Corver et al., 1999) . All of these studies indicate that flaviviruses require an acidic pH for fusion, consistent with their proposed mode of entry. This is further supported by electron microscopy studies that show that they are taken up by receptormediated endocytosis (Gollins and Porterfield, 1985; Kimura et al., 1986; Gollins and Porterfield, 1986c) as well as the observation that infection of cells by various different flaviviruses can be inhibited by raising the pH in endocytic compartments (Gollins and Porterfield, 1984; Brandriss and Schlesinger, 1984; Randolph and Stellar, 1990a; Heinz et al., 1994) . A detailed analysis of flavivirus fusion was carried out by Gollins and Porterfield (1986b) using [3H] uridine-labeled West Nile virus and liposomes containing ribonuclease. Fusion was measured by quantitating the degradation of the viral RNA to trichloroacetic acid-soluble material, and this technique allowed a number of important parameters relevant for fusion to be investigated. Using liposomes containing phosphatidylcholine (PC), phosphatidylethanolamine (PE), sphingomyelin (Sph), and cholesterol (Cho) at molar ratios of 1:1:1:1.5, maximum fusion activity was demonstrated at pH 6.7 and below. It was shown to be complete after 2 minutes at 37°C and to be independent of the presence of divalent cations. Fusion was strongly dependent on temperature, and no fusion activity was detectable at 0°C. Surprisingly, fusion could also be induced at pH 8.0 by raising the temperature to 45°C, suggesting that under certain circumstances increased temperature can substitute for the effect of an acidic pH. The fusion characteristics were also shown to be significantly influenced by changing the lipid composition of the liposomes, which affected both the optimum pH and the extent of fusion. The elimination of PC, PE, or Cho reduced the extent of fusion by one-fourth to one-third, whereas the elimination of Sph produced a small increase. Cho, although not essential, appears to have special fusion-promoting properties, because liposomes composed only of PC and Cho exhibited the same maximum level of fusion as liposomes consisting of PC + PE + Cho + Sph, whereas no fusion was observed with PC + PE or PC + Sph liposomes. Although these studies have revealed a number of important parameters of flavivirus-induced fusion, the types of assay systems used did not allow detailed kinetic analysis to be carried out. This has since been made possible in the TBE virus system by the establishment of fluorescence-based fusion assays, allowing on-line measurements of fusion kinetics and the investigation of the effects of a variety of factors such as pH, temperature, and lipid composition (Corver et al., 1999) . Most of the experiments have been carried out using an assay in which a virus that had been metabolically labeled by the addition of 1pyrenehexadecanoic acid (Cz6-pyrene) to the cell culture medium fuses with a liposomal target membrane. This leads to a change in the fluorescence spectrum due to the dilution of the fluorophore, thus allowing precise quantitative measurements (Pal et al., 1988; Stegmann et al., 1993) . Corver et al. (2000) studied TBE virus fusion with target liposomes containing PC, PE, Sph, and Cho (molar ratios 1:1:1:1.5); and their most important findings can be summarized as follows: 1. Consistent with previous flavivirus fusion studies, TBE virusinduced fusion at 37°C was absolutely dependent on acidic pH, with a relatively high threshold (pH 6.8 to 6.6) and a broad optimal range (pH 5.0 to 6.2). 2. Fusion was extraordinarily fast and efficient. At optimal pH, fusion occurred at the unprecedented rate of about 40% per second, and was more than 50% complete within the first 2 to 3 seconds. 3. In contrast to many other viruses, lowering the temperature had relatively little influence on the rate and extent of the TBE virus fusion reaction. No measurable lag phase was observed when the temperature was lowered to 15°C, and the initial fusion rate was only three times lower at 15°C than at 37°C. Even at 4°C, fusion was still relatively efficient, although at this temperature a brief lag phase of 4.5 seconds was observed. This differs from the lack of measurable fusion activity at 0°C observed in the West Nile virus study (Gollins and Porterfield, 1986b) . The apparent discrepancy could be due to the effect of temperature on the detection system itself in the ribonuclease assay. 4. As with West Nile virus (Gollins and Porterfield, 1986b) , the composition of the target liposomes had a significant influence on the fusion kinetics of TBE virus. Both studies showed that Sph is apparently not required, but that omission of cholesterol results in a strong decrease in fusion efficiency. The consistent conclusion of both of these studies is that the presence of cholesterol in the target membrane facilitates fusion, but, unlike with the alphaviruses, it is not absolutely required (Kielian, 1995; Lu et al., 1999; Smitet al., 1999) . A comparison of these kinetic data with those of other enveloped viruses reveals that TBE virus (and probably other flaviviruses as well) possess the most efficient and fastest fusion machinery described to date for any enveloped virus. Up to now, the fastest rates have been observed for the alphavirus Semliki Forest virus (SFV). As depicted in Fig. 5 .3A, the rate of fusion with SFV at 37°C (25%/sec) Nieva et al., 1994; Moesby et al., 1995) is not only slower than that of TBE virus (40%/sec), but it is also more strongly influenced by lowering the temperature. The same also holds true for influenza virus (Stegmann et al., 1990) , which, under optimal conditions (using erythrocyte ghosts), has a fusion rate of about 6%/sec at 37°C when calculated in the same way as for TBE virus. In comparable fusion assays (i.e., with liposomes as target membranes) influenza virus fusion is even slower. Stegmann et al. (1990) observed an initial rate of not more than 0.2%/sec at 37°C, which dropped to about 0.01%/sec at 0°C. Thus, at lower temperatures the differences between TBE virus and the other viruses are even more pronounced. Probably more significant than the high fusion rate is the lack of a lag phase in the TBE virus fusion reaction, even at 15°C. This is quite different from what has been observed with SFV (Justman et al., 1993; Bron et al., 1993) and contrasts even more with influenza virus, which, at 0°C, has a lag phase of 4 to 8 minutes (Stegmann et al., 1990) (Fig. 5.3B) . Viruses that fuse at the plasma membrane, for example, paramyxoviruses (Hoekstra et al., 1985) and retroviruses (Sinangil et al., 1988) , also exhibit relatively slow rates of fusion under optimal conditions, which become very slow or even undetectable at lower temperatures. TBE virus does not require the presence of a receptor for fusion, indicating that receptor binding and fusion activity are unlinked properties, as is the case with other viruses that fuse at low pH. For influenza virus, however, it has been shown that the presence of its receptor (sialic acid) in the target membrane increases the rate and extent of fusion (de Lima et al., 1995) . In this case the binding to the sialic acid receptor may help to orient the HA molecule at the site of fusion in a way that facilitates the formation of the fusion pore (Ramalho-Santos and de Lima, 1998). With flaviviruses it is still not known whether a receptor might play a role in a postbinding event. The atomic structure of the ectodomain of the TBE virus E protein has been determined by X-ray crystallography to a resolution of 2.0 (Rey et al., 1995) . This was made possible by the isolation of a soluble and crystallizable dimeric fragment of the E protein (sE) by limited trypsin digestion of purified TBE virus . The sE fragment lacks the C-terminal membrane anchor and a ""stem structure"" of approximately 40 amino acids located between the membrane and the crystallized ectodomain. The most striking and distinguishing features of the structure (Fig 5.4 ., see also color insert) are that the subunits of the homodimer are arranged in a head-to-tail, rather than parallel orientation and that the dimer is apparently oriented parallel rather than perpendicular to the membrane, as would be expected of a viral glycoprotein spike. The orientation of the dimer has been inferred from the observations that the dimer has a slight curvature, correo sponding to the curvature of the surface of a virion with a diameter of about 50 nm, and that its external face carries the carbohydrate side chain, antibody binding sites involved in neutralization, and structural elements that vary in sequence and size among different flaviviruses. This structure is therefore fundamentally different from that of all of the other viral envelope glycoproteins for which structural information is currently available. Each of the protein monomers is composed of three distinct domains, designated domains I, II, and III ( Fig. 5.4) . Domain I is in the center of the monomer and consists of an 8-stranded up-and-down ~ barrel, the axis of which is oriented parallel to the membrane. It contains the N terminus and two disulfide bridges, and also carries the single carbohydrate side chain. Domain II is an extended finger-like structure with a short antiparallel ~ sheet at its base and an elongated part that is also mostly composed of ~ strands but includes two short stretches of helices. This domain can also be regarded as a subdomain of domain I, because it is composed of two large insertions extending from loops of the central domain, one of which is a 3-stranded [~ sheet cross-linked by three disulfide bridges. The dimer is stabilized by interactions between domain II and each of the three domains of the other subunit. The side of domain II makes an extended contact with its counterpart in the dimer, and its tip (the cd loop) extends far into a pocket created by domains I and III of the other subunit. Domain III has the typical fold of an immunoglobulin constant (IgC) domain. It is separated from domain I by a stretch of 15 amino acids, which is also linked to domain III by a disulfide bridge. The axis of the IgC barrel is perpendicular to the virus surface, and so far, this is the only example of an Ig-like domain in a viral envelope glycoprotein. However, a similar domain has been found in the structure of a nonenveloped insect virus (N-omega virus) (Munshi et al., 1996) , and due to its exposure on the virion surface, this domain is believed to be involved in receptor binding. It appears justified to assume that the overall structural organization of the E proteins of other flaviviruses is the same as that of TBE virus, based on the fact that all flavivirus E proteins share at least 40% identical amino acids and that all of the 12 cysteines present in the TBE structure, which have been assigned experimentally to six disulfide bridges in the West Nile virus E protein , are absolutely conserved. The TBE virus E protein structure therefore has also been used to map and interpret data obtained using other flaviviruses (McMinn, 1997; Chen et al., 1997; Ni et al., 1997; Roehrig et al., 1998) . There is still little direct experimental data regarding the involvement of different structural elements in the receptor-binding and fusion functions of the E protein. Domain III has been proposed to contain a receptor-binding site (Rey et al., 1995, Stuart and Gouet, 1995) , in part because there are many examples of the involvement of Ig-like domains in cellular protein-protein interactions, including those of cellular adhesion molecules. It is noteworthy therefore that the lateral surface of domain III differs significantly between mosquito-borne and tick-borne flaviviruses. Specifically, the FG-loop in the TBE structure, which contains a tight turn, is extended in all mosquito-borne flaviviruses by a 4 amino acid insertion. In several cases, this includes an RGD sequence, which is a characteristic motif of ligands for members of the integrin family of cell surface receptors. Other sites on the protein have also been implicated in receptor binding. In studies with dengue 2 virus, two putative glycosaminoglycan (GAG) binding motifs on domains III and I were identified, and experimental data support the involvement of GAG binding for DEN entry (Chen et al., 1997) . Consistent with a possible role in receptor binding, a number of studies have shown that mutations in the lateral surface of domain III can have a strong influence on the virulence characteristics of several different flaviviruses [reviewed in McMinn (1997) ]. The fusion function of the E protein requires an extensive structural rearrangement, probably involving each of the three domains. Based on sequence similarities with other viral fusion peptides, the cd loop at the tip of domain II has been proposed to function as an internal fusion peptide for flaviviruses (Roehrig et al., 1989; Roehrig et al., 1990) . These structural aspects of flavivirus fusion are discussed more extensively later. The fusion of viral and cellular membranes is apparently not mediated by individual protein molecules but requires cooperativity between fusion protein oligomers. It has been proposed that the lag phase observed in the fusion process of enveloped viruses represents the time needed for a specific clustering and arrangement of fusion proteins at the site of fusion pore formation (Ellens et al., 1990; Danieli et al., 1996) . The flavivirus envelope, as shown with TBE virus, has a highly ordered structural organization, which may facilitate the rapid formation of the necessary oligomeric assemblies during fusion. A detailed understanding ofvirion architecture, especially the oligomeric organization of the E proteins in the virion envelope, is therefore important for understanding the molecular mechanisms of flavivirus fusion. E protein dimers on the virion surface are not spatially isolated and, in fact, appear to be densely packed. Treatment of intact TBE virus with bifunctional cross-linkers yields a series of oligomeric bands, including dimers, trimers, tetramers, pentamers, and higher molecular weight structures that can be identified by electrophoresis (Heinz and Kunz, 1980; Allison et al., 1995a) . Solubilization with nonionic detergents, such as Triton X-100, results in the loss of the lateral contacts between the E dimers, yielding a homogeneous population of isolated dimers. More detailed structural information on the arrangement of the E dimers is emerging from ongoing cryoelectron microscopy and image reconstruction studies with the TBE virus system, conducted by Stephen Fuller and his coworkers at the EMBL in Heidelberg, using mature virions, immature virions, and capsidless RSPs. Because the most progress so far has been made with RSPs, we will first describe their structural charac-teristics before discussing the possible implications of these data for the understanding of the structure of the whole virion. The structure of the TBE virus RSP was determined to a resolution of 19 A by cryoelectron microscopy and image reconstruction (Ferlenghi et al., in preparation) . The most striking result of this work is the finding that RSPs are icosahedral with 30 dimers arranged in a T=I lattice. Each of the dimers is centered on an icosahedral twofold axis, but rotated to form a closed shell with a diameter of 315 A (shown schematically in Fig. 5.5B ). Lateral dimer-dimer interactions appear to involve contacts between a loop in domain II on one side and a groove in domains I and III on the other. The formation of capsidless subviral particles by interactions of membrane proteins alone has also been observed with other viruses, for example, coronaviruses (Vennema et al., 1996) and hepatitis B virus (Simon et al., 1988; Bruss and Ganem, 1991) , but so far no evidence for icosahedral symmetry has been presented in these cases. Preliminary cryo EM data indicate that TBE virus particles are also icosahedral (D. Thomas and S.D. Fuller, unpublished) . Their larger size (520 A), however, would preclude them from having the same T=I arrangement as the RSPs. Based on the assumption that the lateral contacts between E proteins are similar, the larger surface area of the virions would accommodate a hypothetical T=3 organization with 90 dimers (Fig. 5.5C ). High-resolution data from image reconstructions are necessary to assess whether this model is correct. Icosahedral envelope arrangements have also been observed in the alphaviruses Semliki Forest virus (Vogel et al., 1986; Venien and Fuller, 1994) , Ross River virus (Cheng et al., 1995) , and Sindbis virus (Fuller, 1987; Paredes et al., 1993) . These viruses are somewhat larger than flaviviruses and have a T=4 organization. Their envelopes, however, like those of flaviviruses, are composed of a network of threefold envelope protein assemblies situated at local threefold symmetry axes. One of the alphavirus envelope proteins (E2) interacts specifically with the proteins of the nucleocapsid (Garoff et al., 1998) , which, like the viral envelope, has a T=4 icosahedral arrangement. For flaviviruses it is still not known what role interactions between the nucleocapsid and the membrane proteins might play in the ordering of the virus structure. Flaviviruses are similar to other enveloped viruses in that their fusion activity apparently depends on triggered conformational changes in the fusion protein. Evidence for such structural changes was first provided by protease digestion experiments (Kimura and Ohyama, 1988; Guirakhoo et al., 1989) and by the demonstration that the reactivity with conformation-specific monoclonal antibodies changes after preincubation of viruses at low pH Roehrig et al., 1990; Guirakhoo et al., 1992; Heinz et al., 1994) . When the specific location of these epitopes in the three-dimensional structure of the TBE virus E protein was established (Rey et al., 1995) , it became clear that these alterations affect the entire molecule, with changes occurring in each of the three domains Heinz et al., 1994; Schalich et al., 1996) . The loss or reduction of the reactivity of several conformational epitopes involved in neutralization and the increased reactivity of others suggest an extensive change in the E protein structure after low pH treatment. These changes are not restricted to the individual protein subunits. In fact, they lead to a complete oligomeric rearrangement of the E protein molecules in the viral membrane. Cross-linking and sedimentation analysis (Allison et al., 1995a) revealed that the exposure of the virus to low pH converts the E dimers to a homotrimeric form. This transition is irreversible and complete within a few seconds. How an assembly of dimeric proteins can be rapidly and quantitatively converted into trimers can be envisioned in the context of an icosahedral structure (Fig. 5.5) . With the dimers centered on icosahedral twofold axes, each of the monomeric subunits makes contact with two neighboring ones at threefold symmetry axes in RSPs or pseudo-threefold symmetry axes in virions. Therefore, when lateral interactions are considered, the entire viral envelope can be thought of as an assembly of either 90 dimers or 60 trimers. It is likely that the conformational changes induced by low pH have the effect of strengthening the neighboring trimeric contacts at the expense of the dimeric ones. The nature and stability of the dimer and trimer interactions, however, may not be identical in all flaviviruses. In studies with West Nile virus, Wengler (1989) and Wengler et al. (1987) isolated trimeric forms of the E protein from protease-treated virions at pH 8.0 using octylglucoside solubilization. The isolated trimers were 7 nm in diameter and had a ring-shaped appearance in electron micrographs. On removal of the detergent, they formed higher-order aggregated structures. Therefore, even without exposure to acidic pH, the contacts at 3-fold axes might be strong enough (and those at the 2-fold axes weak enough) to allow the isolation of trimers under certain experimental conditions. In the TBE virus system, however, there is clearly a quantitative oligomeric switch from Triton X-100-stable dimers at neutral pH to trimers at acidic pH, and in all the experiments carried out so far, this change was irreversible (Allison et al., 1995a; Stiasny et al., 1996; Schalich et al., 1996; Stadler et al., 1997) . The pH threshold for triggering the low pH-induced structural changes in TBE virus correlates with that of the induction of fusion activity, suggesting that these processes are closely linked. A threshold around pH 6.6 was found for both the changes in monoclonal antibody (MAb) reactivity and the dimer-trimer transition (Allison et al., 1995a) , and this corresponds to the threshold for the induction of fusion in cell-cell fusion assays (Guirakhoo et al., 1991) and for virus fusion with artificial liposomal membranes (Vorovitch et al., 1991; Corver et al., 2000) . Somewhat higher pH thresholds for both the conformational change and fusion have been reported for other flaviviruses (Gollins and Porterfield, 1986b; Kimura and Ohyama, 1988; Summers et al., 1989; Guirakhoo et al., 1993) . Although incubation times of 30s (Allison et al., 1995a) or less (unpublished observation) are sufficient for conversion of dimers to trimers, precise kinetic measurements of the time course of events occurring within the first seconds or milliseconds after acidification have not yet been carried out and may require similar technical approaches as those applied for studying related events in SFV (Fuller et al., 1995) . The switch from dimers to trimers requires that the dimers dissociate and form new contact sites that stabilize the trimer. Although these steps are not separable when whole virions are analyzed, studies using different forms of soluble E protein dimers from TBE virus have provided evidence that they occur sequentially and are not necessarily linked Allison et al., 1999) . Based on these experiments it has been proposed that acidic pH first induces a reversible dissociation of the head domains, followed by an irreversible trimerization step that, at least in solution, requires structural elements in the stem-anchor region. The three-dimensional structure of the stem-anchor region is not known, but sequence-based predictions provide evidence for the presence of potentially important structural elements, as depicted in Fig.  5 .6. This includes two potential ¢z helices flanking a highly conserved sequence element and two transmembrane regions constituting the Cterminal membrane anchor. The importance of each of these elements for different functions of the E protein, including the dimer-trimer switch in solution, was investigated using a set of deletion mutants yielding recombinant E protein dimers with progressive C-terminal truncations at the boundaries of each of the predicted structural elements . These studies revealed that the low pHinduced irreversible switch from dimers to trimers was dependent on the presence of at least the first of the two predicted amphipathic a helices in the stem region (HlP red, Fig. 5.6) , suggesting an involvement of this helix in trimer contacts. However, recent data on the trimerization of E protein in the presence of liposomes (see Section VII.D) sug- (Rey et al., 1995) and the ""stem-anchor"" region for which only secondary structure predictions are available (reproduced from Allison et al. 1999, with permission) , The viral membrane is indicated by parallel lines. HlP red and H2Pred: Predicted amphipathic a helices. CS: Conserved sequence element. TM1 and TM2: Predicted membrane-spanning segments. As depicted in the figure, it is not known whether TM2 actually remains in the membrane after polyprotein processing. gest that this structure may serve only as a facilitator of trimerization under the experimental conditions used rather than being essential for the maintenance of a stable trimeric structure. Although the structure of the low pH-induced trimeric form of the E protein is not yet known, it can be presumed that it is significantly different from the putative fusogenic or postfusion forms of the other viral fusion proteins for which atomic structures are currently available, including those of influenza virus (Bullough et al., 1994) , retroviruses (Fass et al., 1996; Tan et al., 1997; Weissenhorn et al., 1997; Chan et al., 1997; Malashkevich et al., 1998; Kobe et al., 1999) , filoviruses (Weissenhorn et al., 1998; Malashkevich et al., 1999) , and paramyxoviruses (Baker et al., 1999) . In contrast to the flavivirus E protein, these proteins contain long ~-helical elements that make up a considerable portion of their secondary structure. They also do not exhibit an oligomeric switch during fusion; they exist as trimers in their native conformation and remain trimeric after their triggered conformational change. On the other hand, significant similarities exist between flaviviruses and alphaviruses, in which the viral glycoproteins (El and E2) also form an icosahedral network (in this case composed of 80 trimers of El-E2 heterodimers). Biochemical studies (Wahlberg et al., 1992; Wahlberg and Garoff, 1992) , as well as timeresolved cryo-EM in combination with image reconstruction (Fuller et al., 1995) , indicate that the low-pH-induced fusion process of these viruses also involves oligomeric rearrangements similar to those occurring in flaviviruses. Specifically, acidic pH induces a series of events first leading to the dissociation of the El-E2 heterodimer and then to the irreversible formation of a stable trimer of the fusion-active E1 protein with an altered structure. Flaviviruses and alphaviruses therefore have in common an oligomerization-controlled mechanism of low pH-triggered fusion activity based on an icosahedral arrangement of their envelope proteins. Little is known about how the interaction of viruses and their fusion proteins with the lipids of the target membrane influences the structural changes required for fusion. Most of the structural studies carried out so far have been done in the absence of membranes, and even in their presence, only a small percentage of the fusion proteins on the virion surface would be expected to participate directly in membrane interactions. We have recently begun to study TBE virus-membrane interactions using a liposome coflotation assay (Stiasny et al., in preparation) . In these studies, binding and coflotation were observed only when the virus was acidified in the presence of liposomes, whereas preexposure to acidic pH led to the irreversible loss of the capacity to bind to liposomes. Consistent with earlier data on acid pHinduced inactivation of fusion activity, HA activity, and infectivity (Heinz et al., 1994) , this clearly shows that the final trimeric form is biologically inactive and suggests that the initial interactions with the target membrane are made by a transient intermediate form. Coflotation experiments carried out with sE dimers (ectodomain fragment), which dissociate at low pH in solution but are unable to trimerize, have shown that the monomeric subunit of the E protein ectodomain is capable of binding to liposomal membranes, suggesting that the dissociation of the E dimer is the main prerequisite for membrane binding activity (Stiasny et al., in preparation) . Analysis of the bound proteins, however, revealed that they were no longer monomeric but had acquired a trimeric structure that appears to be similar to that obtained with the whole protein. This was surprising because the sE protein lacks HlP red (Fig. 5.6 ), the potential a-helical element in the stem that had been shown to be required for trimerization in solution in the absence of membranes Allison et al., 1999) . It can be concluded, therefore, that (1) binding of the monomers to target membranes facilitates their trimerization, (2) interactions involving only the ectodomains are sufficient for maintaining the trimer structure once it is formed, and (3) elements in the stem probably also contribute to trimer formation, but are not absolutely needed if the protein is already bound to a membrane. Although it would appear from these studies that lipid-and stem-mediated trimerizations are functionally equivalent for obtaining trimers in this in vitro system, it is likely that each plays a separate but important role in the more complex process of lipid bilayer fusion. Similar results have also been reported recently with the ectodomain of the SFV fusion protein E 1 isolated from purified virions by digestion with proteinase K (Klimjack et al., 1994) . In contrast to TBE virus, this C-terminally truncated form of E1 is monomeric at neutral pH, but at acidic pH it was also shown to bind to liposomes and to be converted into a stable oligomer (presumably a trimer), which was resistant to SDS treatment. This transition was dependent on the presence of cholesterol and sphingomyelin in the liposomal membrane, consistent with the unique dependence of SFV fusion on these lipids. Nevertheless, the lipid-induced oligomeric switch appears to be yet another detail that points to a similarity between the fusion machineries of flaviviruses and alphaviruses. The irreversibility of the dimer-to-trimer transition and the stability of the E trimers after back-neutralization are consistent with the notion that the native E dimer of TBE virus is metastable and that its conversion to the fusogenic state, like that of influenza virus HA, is kinetically controlled (Baker and Agard, 1994) . This is consistent with the observation that flavivirus fusion with liposomes can be artificially induced by heating (Gollins and Porterfield 1986b) . It is therefore likely that the function of acidic pH is to lower the energy barrier between the metastable native state and a more stable final conformation rather than affecting the thermodynamic stability of these conformations. In the case of influenza virus, the final stable state and fusion can also be attained by heating or the addition of chemical denaturants (Haywood and Boyer, 1986; Ruigrok et al., 1986; Carr et al., 1997) . The relatively low temperature dependence, the high initial fusion rates, and the lack of a lag phase (at least between 15 ° and 37°C) suggest that TBE virus fusion requires a low activation energy at acidic pH. In the case of influenza and Sendai viruses, fusion has been described as a two-step process (White, 1990) , consisting of a rate-limiting second-order aggregation step followed by a first-order fusion step. For influenza virus the lag phase is believed to represent the time required for several HA trimers (at least three or four) to come together before fusion can occur (Danieli et al., 1996) . Owing to the length and extended nature of the spikes, however, the viral and cellular membranes would be expected to be quite far apart when the fusion process is initiated. Flaviviruses are the only viruses for which the fusion protein is known to lie flat on the membrane rather than forming a spike, and it is likely that this difference is the structural basis for the extremely fast fusion rates observed with TBE virus. The flat orientation of the flavivirus E proteins would presumably allow the two membranes to be much closer from the beginning, and for this reason less energy might be required to make them fuse. In addition, it is possible that the icosahedral organization of E proteins on the virion surface already provides a geometrical arrangement that facilitates fusion pore formation and therefore obviates the need for the kind of specific structural rearrangements that are required by other viruses and are believed to be responsible for the longer lag phases. The structural and functional properties of TBE virus RSPs make them excellent tools for studying the involvement of specific structural elements in the functional activities of the E protein. Because they can be produced by transfection with plasmids, it is possible to make RSPs with specific mutations in functionally important regions of the E protein that would be lethal in a whole infectious virus system. In a detailed investigation of the fusion properties of RSPs in a liposome fusion assay system, Corver et al. (2000) demonstrated that the fusion characteristics of RSPs are very similar to those of the virus. This includes the low pH-dependence, the rate and extent of fusion, the effect of the lipid composition of the target membrane, and the kinetics of fusion inactivation at acidic pH. Furthermore, Schalich et al. (1996) demonstrated that the structural rearrangements induced in the virion envelope at low pH also occur in RSPs. The conversion from dimers to trimers and the accompanying changes in the reactivity pattern with monoclonal antibodies were found to be similar in RSPs and whole virions, as was the pH threshold for these changes. All of these observations strongly suggest that RSPs and virions use the same fusion mechanism, and that mechanistic insights gained from model studies with RSPs are directly relevant and applicable to the whole virus. Fusion peptides are the structural elements within viral envelope glycoproteins that interact with the cellular target membrane and thus initiate the fusion process (reviewed by Hernandez et al., 1996) . From the analysis of such structures in several different families of enveloped viruses, it has become clear that many fusion peptides are located at the N terminus of the fusion-active subunit (e.g., in the fusion proteins of orthomyxo-, paramyxo-, and certain retroviruses), or proximal to its N terminus, as in the avian leukosis and sarcoma virus subgroup A of retroviruses (Hernandez and White, 1998) . Fusion peptides at internal sites have been identified in the fusion proteins of alphaviruses (Levy and Kielian, 1991; Durrer et al., 1995) and rhabdoviruses (Whitt et al., 1990; Zhang and Ghosh, 1994) . In flaviviruses, the N termini of the E and M proteins are not conserved, and their sequences are not similar to those of other known fusion peptides. However, the sequence element at the tip of domain II, the cd loop ( Fig.  5.4) , has been hypothesized to represent an internal fusion peptide (Roehrig et al., 1989) for the following reasons: (1) It resides within the most highly conserved stretch of amino acids in the flavivirus E protein (amino acids 98 to 111), (2) it contains the tetrapeptide GLFG, which is identical to the N terminus of the fusion peptide of influenza A virus HA and is similar to sequences found in other viral fusion peptides, and (3) it becomes more exposed in virions on low pH treatment (Roehrig et al., 1990) . Allison et al. (2000, submitted) used site-directed mutagenesis to make mutant RSPs in which Leu-107, which is part of the GLFG tetrapeptide, was replaced by Asp and Phe, the latter of which occurs as a natural variant in Powassan virus (Mandl et al., 1993) and certain strains of JE virus (Nitayaphan et al., 1990; Aihara et al., 1991) and DEN virus (Blok et al., 1989) . As predicted from their location in the structure, these mutations did not appear to affect the formation of dimers or the synthesis and secretion of RSPs, but pyrene-labeled RSPs containing the Leul07Asp mutation no longer had the ability to fuse with liposomes. Reduced but significant fusion activity, however, was observed with the Phe mutant, consistent with its rare but natural occurrence in infectious viruses. A careful analysis of other properties of the mutant RSPs, including reactivity profiles with monoclonal antibodies and low pH-induced conformational changes allowed the conclusion that the mutations at position 107 indeed had a direct effect on fusion. Liposome coflotation assays showed that the Asp mutant had lost its capacity to bind target membranes at low pH, consistent with the role of the cd loop as an internal fusion peptide. Although internal fusion peptides have been identified in several other viral fusion proteins (Whitt et al., 1990; Levy and Kielian, 1991; Zhang and Ghosh, 1994; Durrer et al., 1995; Hernandez and White, 1998) , the TBE virus fusion peptide is the only one so far for which its native three-dimensional structure is known. It is a highly constrained structure that is held in place by a disulfide bridge. It will be interesting therefore, to see whether the specific structure of the cd loop is functionally important and whether any structural conservation is found in the internal fusion peptides of other viruses. Despite the high degree of conservation of Leu-107 among flaviviruses, Phe is found at this position in several variants, including an attenuated strain of JE virus SA-14-14-2, which is being used as a live vaccine in China (Tsai and Yu, 1995) . It is possible that the mutation in the internal fusion peptide is at least partially responsible for the attenuated phenotype observed, a hypothesis that could be tested by engineering it into an infectious clone and comparing the virulence properties of the wildtype and mutant viruses. E protein mutants of several different flaviviruses have been described that differ from the corresponding wild types in their low pH-sensitivity and/or fusion activity. Mutations affecting these properties have been found in each of the three domains, providing support for the assumption that the structural transitions required for fusion are complex and involve the whole E protein molecule. Not surprisingly, such mutations can also have profound effects on other biological properties of the virus, such as neurovirulence or neuroinvasiveness [reviewed by McMinn (1997) ]. Our understanding of the structural and mechanistic implications of these mutations is limited because the structure of the low-pH form of E has not yet been determined, and therefore the changes that occur within the protein at low pH are not known. Nevertheless, we will summarize the most significant of these mutations (ordered by the domains to which they map) based on the current knowledge of the neutral pH structure and the functional and structural changes induced by low pH. Domain I: Guirakhoo et al. (1993) selected two different DEN 2 virus mutants with a significantly elevated pH threshold of fusion (at least 0.65 pH units), one by repeated exposure to acidic pH and the other by the addition of ammonium chloride. These mutants had in common the loss of a potential glycosylation site (Asn 153) corresponding to the TBE virus glycosylation site at position 154 (Fig. 5.4 ). This portion of the protein has been shown to participate in interactions between the subunits of the dimer, which also involve the carbohydrate moiety itself (Rey et al., 1995) . Although this site has since been reported not to be glycosylated in DEN 2 virus (Johnson et al., 1994) , it is possible that the elevated pH threshold of fusion in this case was due to a loss of protein interactions contributing to dimer stability. Another mutation in domain I of TBE virus (Lysl71Glu) appeared to have the opposite effect, resulting in stabilization, because its pH threshold of fusion was lower (by 0.4 pH units) than that of the wild type (Guirakhoo et al., 1991) . Domain II: The tip of this domain constitutes the fusion peptide and, as discussed previously, mutations in this region have direct consequences for target membrane binding. Mutations in other parts of this domain, however, were also shown to have significant, but probably more indirect effects on fusion and/or hemagglutination activity (a property of flaviviruses that requires acidic pH and--in contrast to influenza virus--is therefore probably related to fusion activity rather than receptor binding). With both Murray Valley encephalitis (MVE) and TBE virus, the most significant effects on fusion and HA activity were observed with mutations located at the base of domain II, which has hinge-like characteristics (Rey et al., 1995) and may therefore play an important role in domain movements during the fusion process ( Fig. 5.4) . McMinn et al. (1995 McMinn et al. ( , 1996 isolated a neutralization-escape mutant of MVE virus (Ser 277 He) that had lost HA activity and not only exhibited a lower pH threshold for fusion, but also a lower rate and extent of fusion. As with a related mutant of JE virus (Ile270Ser) (Cecilia and Gould, 1991) , HA activity was also impaired. A mutation spatially close to this site (Glu207Gly) in a TBE virus neutralization-escape mutant caused a similar severe impairment of HA activity (Holzmann et al., 1989) and fusion activity (unpublished). The mutant protein was extremely labile, and structural changes occurred even above pH 7.0. The location of this mutation at the dimer interface could cause a weakening of the dimer contacts and thus lower the activation energy required for the dimer-trimer transition. Domain III: The lateral surface of this domain (Fig. 5.4) has been implicated in receptor binding, but it is apparently also at least indirectly involved in fusion activity. The possible structural basis for this is completely unknown at present, but two mutations causing significantly altered fusion properties have been identified in this domain (unpublished) . The replacement of Thr-310 by Lys in TBE virus results in an almost complete loss of in vitro liposome fusion, even though the pH threshold of structural changes (as measured with a domain IIspecific antibody) was unchanged. Another mutation (Gly368Arg) apparently facilitates the low-pH transition by elevating the pH threshold but nevertheless exhibits a reduced rate of fusion. The scattered distribution of mutations affecting flavivirus fusion is reminiscent of that found in the influenza virus HA, in which four separate groups of fusion mutations mapped to distinct structural entities of the protein [summarized in Bullough et al. (1994) ]. These mutations influence the structural transitions from the neutral to the low pH form, and the availability of the atomic structures of both forms of the influenza virus HA has made mechanistic interpretations possible. For TBE virus, we still have only half of the picture (the neutral-pH structure), and so a more in-depth treatment of these issues in the flavivirus system will have to wait until the low-pH structure of the E protein is solved. Studies on the inhibition of in vitro fusion activity by MAbs whose epitopes have been mapped on the three-dimensional structure of the E protein have provided valuable additional information on the involvement of specific structural elements in the fusion process and have also yielded new insights into the mechanisms of antibody-mediated neutralization. Most of the data related to structure have been obtained with TBE virus, MVE virus, and DEN 2 virus. These can be summarized as follows. Efficient inhibition of fusion was achieved with MAbs recognizing epitopes in domain II of TBE virus (Guirakhoo et al., 1991) (Schalich et al., in preparation) , DEN 2 virus (Roehrig et al., 1998), and MVE virus (McMinn et al., 1996) as well as domain I of TBE virus. However, partial inhibition has been observed with other antibodies against each of the three domains (Guirakhoo et al., 1991) (Schalich et al., in preparation) . These data are consistent with the evidence already discussed that the low pH-induced rearrangements are extensive and involve several different regions of the E protein. The inhibitory effect of antibody binding on fusion can be direct (e.g., by blocking the necessary interaction of the fusion peptide with the target membrane) or indirect (e.g., by impairing the structural changes required for fusion). There is evidence that the TBE virus MAbs A1 and A2 inhibit fusion by the first of these mechanisms. Their epitopes have been mapped to the fusion peptide (cd loop) of the E protein (Allison et al. submitted) based on the selective loss of reactivity of these MAbs with the mutant RSPs described in Section VII.G, and in coflotation experiments with the sE protein they were shown to completely inhibit the binding of monomeric E to liposomes at low pH (Stiasny et al., in preparation) . In another recent study with TBE virus, Volkova et al. (1999) demonstrated that the fusion of TBE virus with artificial membranes could be blocked by a MAb that specifically reacts with a synthetic peptide (amino acids 98 to 113) corresponding to the cd loop and containing the fusion peptide. Antibodies that inhibit fusion would also be expected to have a significant inhibitory effect on virus infectivity. Indeed, inhibition of fusion in the endosome as a mechanism of virus neutralization has been demonstrated with West Nile virus (Gollins and Porterfield, 1986a) . There is now extensive evidence in the literature that fusion inhibition may be one of the principal mechanisms of antibody-mediated neutralization [reviewed by Dimmock (1995) ]. With flaviviruses there appears, in some instances, to be a good correlation between fusion inhibition and neutralization, most notably in the case of the domain II-specific neutralizing antibodies A3 and A4 for TBE virus (Guirakhoo et al., 1991) (Schalich et al., in preparation) and 4E5 and 1B7 for DEN 2 virus (Roehrig et al., 1998) . The TBE virus MAbs A1, A2, , 14D2 (Volkova et al., 1999) , and Gll (Vorovitch et al., 1991) , however, are nonneutralizing, although they can completely inhibit fusion in vitro. The most likely explanation for these seemingly paradoxical results is that these MAbs do not bind well to the native infectious virus as it exists outside the cell, but instead recognize cryptic epitopes that become accessible only after the virus has entered the endosome and the low pH-induced structural changes have occurred. The fusion-inhibiting antibodies therefore would not be present with the virus in the compartment where fusion actually takes place. Recent observations with the TBE virus MAbs A1 and A2 support this hypothesis. These antibodies recognize a cryptic epitope involving the cd loop, but do not bind native virus at neutral pH (Schalich et al., in preparation) . A similar phenomenon was recently described for influenza virus. In this case a MAb inhibited the low pH-induced conformational change of HA and fusion activity but did not neutralize the virus (Vanlandschoot et al., 1998) . This may be different with viruses that fuse at the plasma membrane, because in these cases the intermediate structures required for fusion are generated by receptor binding when the virus is still outside the cell and therefore might be accessible to fusion-inhibiting antibodies, even if their epitopes are cryptic in native virions. Indeed, a recently described approach for generating immunogens that induce broadly neutralizing antibodies against human immunodeficiency virus (HIV) is based precisely on this principle (LaCasse et al., 1999) . The fusion proteins of many enveloped viruses (e.g., orthomyxoviruses, retroviruses, and paramyxoviruses) are synthesized as inactive precursors, and proteolytic cleavage by a cellular protease is required to convert them to a state that is responsive to the fusion trigger (low pH or receptor binding) [reviewed by Klenk and Garten (1994) ]. In other viruses the fusion proteins are initially held in an inactive state by their association with a second protein, and the activation step requires the proteolytic cleavage of this second protein and not of the fusion protein itself. Such a mechanism has been demonstrated for alphaviruses (Lobigs and Garoff, 1990; Watson et al., 1991; Salminen et al., 1992) , and there is now evidence that flaviviruses use a similar mechanism based on the interaction between prM and E to switch from a fusion-inactive form during assembly to the fusion-competent form required for entry. Immature virions containing uncleaved prM proteins can be isolated from infected cells by cell lysis (Wengler, 1989) , but they can also be obtained in a secreted form from the supernatants of cells treated after infection with acidotropic agents, apparently because increasing the acidic pH in the TGN prevents the cleavage of prM (Shapiro et al., 1973; Randolph et al., 1990b; Guirakhoo et al., 1992; Heinz et al., 1994) . prM-containing particles of several different flaviviruses have been characterized (Wengler, 1989; Randolph et al., 1990b; Guirakhoo et al., 1991; Guirakhoo et al., 1992; Heinz et al., 1994; Stadler et al., 1997) , and their properties differ from those of mature virions in several important aspects. They exhibit significantly lower specific infectivity, HA activity, and fusion activity; and, in contrast to mature virions, acidic pH does not induce a change in the epitope reactivity pattern or in the oligomeric structure, suggesting that these changes are prevented by the presence of prM in immature virions. The existence of a heterodimeric complex between the E and prM proteins in immature virions has been demonstrated by chemical cross-linking analysis (Wengler, 1989; Heinz et al., 1994) , and studies with E-specific MAbs revealed that the association of E with prM primarily affects epitopes located in domain II (Guirakhoo et al., 1992; Heinz et al., 1994; Rey et al., 1995) (Fig. 5.4) . It is not clear at present whether prM binds domain II and therefore physically shields these epitopes or whether domain II has an altered structure in the prM-E complex. Further sites of prM-E interactions have been mapped to the stem-anchor region of the E protein in coexpression studies using Cterminal deletion mutants and in protease digestion experiments with immature virions (Wang et al., 1999) . Both the second of the predicted amphipathic ~ helices (H2pred) and the first of the two membrane-spanning regions (TM1) (Fig. 5.6 ) were shown to be important for the stability of the heterodimer. The maturation cleavage results in the removal of slightly more than half of the N-terminal end of prM and occurs at a site corresponding to the consensus sequence for furin and related proteases (RXRIKR), which is also found in many other viral glycoproteins that require proteolytic cleavage for activation (reviewed by Klenk and Garten, 1994) . The mechanism of cleavage has been investigated in some detail in vitro using immature TBE virus (secreted from cells treated with ammonium chloride to raise the pH in the TGN) and recombinant bovine furin (Stadler et al., 1997) . These experiments confirmed the requirement for a slightly acidic pH (6.7 or lower) for cleavage and further showed that the exposure of immature virions to low pH apparently induced an irreversible conformational change to make the cleavage site accessible to the enzyme. Consistent with the presumed stabilizing function of prM, the in vitro cleavage of immature virions resulted in a 100-fold increase in infectivity, the acquisition of fusion activity and HA activity, and the ability of the E protein to undergo the low-pH-induced structural rearrangements characteristic of mature virions. Both fusion activity itself and its activation are thus controlled by conformational changes induced by acidic pH, albeit in different cellular compartments and in different phases of the viral life cycle. The information available suggests that the function of prM in immature virions is to hold the E protein in a stable conformation and thus protect it during passage through the acidic TGN from undergoing the irreversible conformational changes that are required for fusion activity and that would otherwise lead to premature inactivation. It is not clear why these changes are not triggered once prM is cleaved in the TGN. It is possible that the high molar concentration of the proteins and/or the acidic pH in the TGN favor the maintenance of a stable complex between E and the cleavage products of prM and thereby allow the cleaved N-terminal part of prM to continue to protect the E protein until the virion has left the cell. Alternatively, it is possible that the generation of the mature conformation of E is also pH-dependent and occurs only after the virus has left the acidic environment of the TGN. All of the viruses that require a low pH-triggered structural change for fusion activity are presumably confronted with the problem of avoiding these changes and associated activities during biosynthesis and passage of the fusion proteins through the acidic TGN. Different viruses have apparently evolved completely different strategies to cope with this problem. Influenza virus makes use of the proton channel activity of its M2 protein, which, by inserting into the TGN membrane, raises its pH and thus allows HA molecules that are cleaved in the TGN to maintain their native conformation even though the cleavage has made them pH sensitive (Steinhauer et al., 1991; Hay, 1992) . In the case of the rhabdoviruses the fusion protein G can adopt different conformational states in a reversible manner. This protein is believed to be transported to the plasma membrane in an inactive conformation (desensitized state), thereby avoiding inappropriate fusion events Pak et al., 1997) . Flaviviruses, like alphaviruses, use an oligomerization-controlled mechanism in which the fusion protein is held in a low pH-resistant and fusion-inactive conformation in a complex with a second protein.@story_separate@Detailed studies on the structural organization and fusion properties of the TBE virus E protein have revealed that the same function that is carried out by trimeric spikes with a-helical coiled coils in many other viruses is mediated in flaviviruses by an icosahedral network of flat, head-to-tail dimers of mostly ~-sheet proteins. Moreover, this unusual viral fusion machinery is the fastest and most efficient one known so far. Nevertheless, there are a number of recognizable similarities in the strategies used by flaviviruses and members of other virus families. The use of the acidic pH in the endosome to trigger fusion, the synthesis and transport of the envelope proteins through the TGN in an acidresistant form, the conversion of the fusion protein to a kinetically trapped metastable state by a proteolytic cleavage event, and the use of protein oligomerization as a mechanism for controlling these steps are all principles used by other enveloped viruses, although many of the details differ. There are, however, a number of strikingly similar fea-tures shared by flaviviruses and alphaviruses that distinguish them from other enveloped viruses, including an icosahedral envelope organization, an oligomeric switch occurring at the pH of fusion, and a heterodimer-regulated control of the fusion protein, which is activated by proteolytic cleavage of the second protein in the complex. For a more complete picture of the structural changes related to flavivirus fusion and its control, it will be necessary to solve the structure of the low pH (postfusion) form of the E protein and that of the prM-E heterodimer. These are major challenges for the future that will eventually lead to a more precise understanding not only of the mechanism of cell entry by these important human pathogens, but also of how completely different structures are used to accomplish the same task--the fusion of viral and cellular membranes.","This chapter focuses on the work carried out with tick-borne encephalitis (TBE) virus, the structurally best characterized of the flaviviruses. The data is related to those obtained with other flaviviruses, which are assumed to have a conserved structural organization, and compare the characteristics of flavivirus fusion to those of other enveloped viruses. Fusion proteins from several different virus families, including Orthomyxoviridae, Paramyxoviridae, Retroviridae, and Filoviridae have been shown to exhibit striking structural similarities; they all use a common mechanism for inducing membrane fusion, and the same general model applies to all of these cases. The flavivirus genome is a positive-stranded RNA molecule consisting of a single, long open reading frame of more than 10,000 nucleotides flanked by noncoding regions at the 5′ and 3′ ends. The fusion properties of flaviviruses have been investigated using several different assay systems, including virus-induced cell–cell fusion and virus–liposome fusion. All of these studies indicate that flaviviruses require an acidic pH for fusion, consistent with their proposed mode of entry."
"In the current scenario, CNTs are one of the forefronts in a diverse field of medicine, which are continuously being explored by researchers, scientists and academicians for the development of new, safe and effective nanomedicine. The CNTs are promising quasi one-dimensional nanomaterial with well ordered flat networks of fused benzene rings or hollow graphitic cylindrical tubular structure consisting of hexagonal arrangement with sp 2 hybridized carbon atoms [1] [2] [3] [4] . CNTs are mainly classified into four types, based upon the structure and diameters including single-, double-, triple-, and multi-walled carbon nanotubes. The length of the tubes can be extended depending on the type of production method [5] [6] [7] [8] . CNTs are one of the attractive tools in nanotechnology with surface engineered carbon nanotubes (f-CNTs), emerging as a new family of carbon nanovectors that enabled numerous biomedical applications. Functionalization plays a pivotal role in the design of CNTs-based nanomaterials by rendering them more biocompatible and less toxic with increased dispersibility in comparison to pristine CNTs. The methodology of functionalization of CNTs can be classified broadly into two categories: (a) covalent attachment of active biochemical moieties through chemical reactions onto CNTs skeleton, and (b) non-covalent adsorption or wrapping of different functional molecules [7, 9] . The various types of nanocomposites have been summarized in Fig. 1 .@story_separate@The study of cellular uptake mechanism of the surface engineered CNTs has been intensely addressed in the last two decades [10, 11] . Lacerda et al. have demonstrated that the surface engineered CNTs have propensity to enter the cells via an energy-dependent, endosomally-mediated cellular internalization approach and direct cytoplasmic translocation through insertion or passive diffusion in a non-invasive manner (tiny nanoneedle mechanism) [11] [12] [13] . The f-CNTs have been easily cross the blood brain barriers (BBB) without requirement of any external transporter device owing to nano-dimension and tiny nano-needle tubular structure morphology ( Fig. 2A) . The main pathways speculated by scientists for cellular uptakes of f-CNTs are: (i) phagocytosis, (ii) CNTs piercing into membrane by passive diffusion, (iii) caveolae-mediated endocytosis, (iv) clathrin-mediated endocytosis, and (v) caveolaeclathrin mediated endocytosis. The intracellular uptake mechanisms of CNTs are crucial for the controlled uptake and devising new strategies in the field of novel drug delivery [12, 13] . Reports have shown that the nanotubes may enter cells rapidly with free trafficking into the cytoplasm in the first hour of internalization. This penetration of surface engineered CNTs into phagocytic and non-phagocytic cells is mediated by three alternative pathways: i) via membrane wrapping as individual tubes; ii) via direct membrane translocation of individual nanotubes; and iii) in bundles within vesicular compartments (Fig. 2B) [13] . These exciting facts about intracellular trafficking of CNTs have opened a new door for the development of a promising delivery system for therapeutic and diagnostic agents [11] . The potential of surface engineered CNTs and possible biomedical applications are discussed below and various CNTs conjugates employed in bioactive delivery shown in Fig. 3 . Transdermal drug delivery system (TDDS) represents a convincing as well as promising alternative to oral or injectable delivery of drugs. Recently, CNTs have been investigated as TDDS due to their tiny nano-needle shape structure and superior adsorption capacity. Im and co-workers prepared an electro-sensitive TDDS of CNTs using electrospinning method to control drug release with polyethylene oxide and pentaerythritol triacrylate polymers. In this TDDS, CNTs facilitated the electro-sensitive-transdermal drug delivery [14] . The advantages of CNTs in TDDS include high loading efficiency and enhanced transdermal penetration of drugs by application of a small electrical bias to create a programmable drug delivery system. The future explorations of f-CNTs in TDDS present a feasible solution to limitation of current smoking cessation and opioid withdrawal symptom treatments [15, 16] . Several approaches have been exploited in the development of safe, biocompatible and comfortable nanovehicle for controlled ophthalmic drug delivery with enhanced patient compliance and reduced toxicity. Ophthalmic drugs have a short residence time (<5 min) and only 1-5% of applied therapy may penetrate the cornea and enter into the intraocular tissues. The CNTs-based ocular drug delivery has been found to enhance the bioavailability of few ophthalmic medications overcoming the limitation of traditional ophthalmic drug delivery methods [17] . CNTs could also be used for ocular targeting of different therapeutic agents to the different ocular sites. Unfortunately only very few reports are available in this area [18] . Application of 'Kajal' (also known as kohl or surma) is a common practice in Indian families. Kajal has been claimed for prevention and treatment of various eye diseases (blepharitis, cataract and conjunctivitis etc.) and also said to ward off an 'evil eye'. Cosmetic application of CNTs is well documented in various literatures [19, 20, 21 ]. Surface engineered CNTs based delivery systems have been explored as a new platform to repair the damaged CNS tissue/cells in the field of neuroscience. The CNTs have been claimed to be able to cross the blood brain barrier (BBB) by different targeting mechanisms and act as safe and effective targeted drug delivery system [22, 23] . Since the last one-decade researchers have continuously explored and assessed the CNTs as substrate for neuronal tissue growth, regeneration and its application in neuroscience research. CNTs have numerous salient features with a simple and inert molecular tubular nanoneedle structure and porosity beneficial to neural interface for trafficking of cells, sensing of microenvironments, delivery of transfection agents, and scaffolding for incorporating within host body, to provide the support for adhesion, proliferation and migration of cells. Ren and co-workers developed a dual targeted delivery system based on the oxidized PEGylated MWCNTs modified with Angipep-2 (a targeting ligand of lowdensity lipoprotein receptor related-protein (LRP) receptors) loaded with Doxorubicin (DOX) and systematically evaluated their in vitro and in vivo anti-glioma effect by C6 cytotoxicity and median survival time (MST) of intracranial C6 glioma bearing Balb/c mice. The combination of O-MWCNTs-PEG with angiopep-2 as targeting ligand was claimed to play a role of active dual-targeting and combination of O-MWCNTs-PEG and angiopep-2 constituted an ideal dual-targeting drug delivery to brain glioma [22] . Photodynamic therapy (PDT) is an effective, alternative, noninvasive, non-toxic therapy used in oncology [24] . Till date only few numbers of reports are available on the applications of surface engineered CNTs in PDT. Photosensitizer [5-aminolevulinic acid (5-ALA)] loaded PAMAM dendrimers modified MWCNTs (dMNTs) showed good biocompatibility with significant increase in the accumulation of 5-ALA in MGC-803 tumor cells leading to a potential photodynamic anti-tumor effect [25] . Chitosan wrapped Chlorine6 (Ce6), which is a photosensitizer, loaded SWCNTs revealed high cellular uptake (high anticancer effects) and low toxicity against HeLa cancer cells than free Ce6 [26] . CNTs hold promise in photothermal therapy (PTT) due to extraordinary photon-to-thermal energy conversion efficiency with high absorption in the near infra-red (NIR) light [27] [28] [29] . The SWCNTs have the ability to absorb 700-1100 nm NIR radiation and convert it into heat, which kills cancer cells [29] . Moon and co-workers demonstrated the photothermal effect of PEGylated SWCNTs upon NIR irradiation on KB tumor bearing nude mice and observed that sufficiently high thermal energy was generated from optically excited PEG-SWCNTs to destroy tumor in a non-invasive manner. The mice treated with PEG-SWCNTs and NIR irradiation CNTs conjugates employed in bioactives delivery. www.drugdiscoverytoday.com 753 Reviews POST SCREEN Folic acid (FA)-chitosan (CHI)/alginate (ALG)-SWCNTs. HeLa cell line Doxorubicin through p-p stacking. Fluorescence Cell viability and cell uptake studies CNTs complex found to be more selective and effective than free DOX due to targeting based on FA and release of DOX at lysosomal pH. [45] mAB-BSA adsorbed-SWCNTs. WPDr colon cancer cell line Doxorubicin through p-p stacking. Electron microscopy (SEM, HRTEM) Raman spectroscopy Uptake study revealed that delivery efficiency was 100%. All cells could take up the SWCNT complexes. [46] Diaminotriethylene glycol-MWCNTs. 10-Hydroxycamptothecin (HCPT) through p-p stacking. In vitro single photon emission computed tomography (SPECT showed the complete eradication of solid malignant tumor devoid of any toxicity or abnormal behavior 20 days post treatment. The issue concerned with residual SWCNTs accumulation inside the body after the treatment was resolved as nanotubes were excreted from mice's body in about 2 months through the biliary or urinary pathway in biodistribution study [27] . Hashida and co-workers reported the photothermal ablation activity of a novel SWCNTspeptide composite with a designed peptide having a repeated structure of H-(-Lys-Phe-Lys-Ala-) 7 -OH[(KFKA) 7 ] against tumor cells. The obtained results suggest the remarkable suppression of tumor growth compared with only SWCNT-(KFKA)7 injection alone or NIR irradiation alone [28] . Currently viral vector system based gene delivery is most widely used to achieve high efficiency of gene expression, which concerns the safety, as viral vector can be immunogenic, oncogenic, and may be responsible for inflammation. Further, gene therapy may suffer rapid degradation of exogenous nucleic acid. Now-a-days some effective multiple non-viral delivery systems like polymeric nanoparticles, liposomes, cell penetrating peptides, cationic lipids, dendrimers and f-CNTs are being employed to efficiently deliver nucleic acids including siRNA with reduced immunogenicity. The efficiency of gene expression mediated by these nanovectors is lower as compared with the viral vector but they provide the advantages of easy up-scaling, flexibility and reduced immunogenicity. The applications of CNTs as new vectors for delivery of nucleic acids is another area of research and development which could offer several advantages for nucleic acid, siRNA, gene and protein delivery owing to their thin and long architecture that offers a large surface area to which siRNA can be bound and delivered to target site. Further, CNTs may have protective capacity, which stabilize and lead to more efficient cellular transfection and prevent the lysosomal degradation of encapsulated nucleic acids [30] . Kawaguchi and co-workers synthesized DNA-functionalized SWCNTs to improve the dispersibility as compared to acid treated SWCNTs. The binding ratio of the acid-treated SWCNTs and DNA was calculated to be 3:1 (DNA/SWCNTs) from the phosphorous content in DNA-SWCNTs [31] . In context of the enhanced gene delivery Sanz and co-workers were first to develop and demonstrate the enhanced gene delivery using lysosomotropic anti-malarial drug chloroquine loaded polyethyleneimine (PEI)-coated DWCNTs to enhance the cell transfection efficiency [32] . Infectious diseases such as tuberculosis, leishmaniasis, severe acute respiratory syndrome (SARS), flu (swine, bird and avian) and anthrax infection indicate that infectious diseases have emerged as a critical public health issue with global concerns. Surface engineered CNTs have been used in the treatment of infectious diseases due to their ability to easily conjugate drugs like amphotericin B (AmB) and dapsone. Leishmaniasis is a microbial disease in which macrophages and other cells of reticuloendothelial system (RES) serve as host as well as replication site for the parasite [33] . Conjugation of amphotericin B (AmB) to f-CNTs can modify its properties in terms of toxicity and anti-mycotic efficiency [34, 35] . Drug Discovery Today Volume 20, Number 6 June 2015 cell sorter analysis The f-SWCNTs-COS-GTX-p53 was found to be most effective delivery vehicle with a controlled release and enhanced cytotoxicity rendered through apoptosis in HeLa cells. [54] GL-MWCNTs-DOX Wu and co-workers explored the toxicity and antifungal activity of AmB loaded CNTs (AmB-CNTs) functionalized with fluorescein isothiocynate (FITC) for efficient nuclear localization in human Jurkat lymphoma T cells and observed that AmB-CNTs could be easily taken up by mammalian cells precluding any specific toxic effect but preserving antifungal activity [34] . CNTs surface engineered with mannose showed promising targeted delivery of AmB to J774 macrophages cells [36] . Cancer is one of the leading causes of death worldwide. More than 99% cases of chemotherapy destroy cancer cells along-with the normal healthy cells, with serious side effects and hence strategies based on nanotechnology are being explored as 'safe and effective' strategy to achieve selective uptake of chemotherapeutic agent by target cancer cells [7] . A significant decrease in toxicity with preferential killing of cancer cells was achieved with dual targeted nanocarrier combining MWCNTs and iron oxide magnetic nanoparticles (MNs) conjugated with FA for antineoplastic agent, DOX [37] . Jain and coworkers observed tumor targeted delivery of DOX and reduced toxicity with DOX loaded dexamethasone mesylate anchored MWCNTs to A-549 lung epithelial cancer cells [38] . Further, CNTs surface engineered with folic acid and D-alpha tocopheryl polyethylene glycol 1000 succinate (TPGS) showed tumor targeted delivery of DOX with improved cytotoxicity toward cancer cells and enhanced cellular uptake speculated to be mediated by endocytosis and tiny nano-needle mechanism [2, 8] . Fig. 3 presents the different conjugates based on CNTs employed in the delivery of anticancer bioactives varying from pristine CNTs to drug loaded CNTs. From the aforesaid account it may be concluded that the surface engineered CNTs could have promising potential in cancer therapy. Reports showed that CNTs may emerge as promising nanocarrier in targeting of macrophages owing to their exceptional physicochemical characteristics. AmB conjugated CNTs showed improved antileishmanial activity as compared to free AmB in J774A.1 macrophage cells [39] . Later, AmB loaded mannose conjugated CNTs showed efficient macrophage targeting in J774 macrophage cell lines with significantly reduced toxicity toward RBCs and kidney cells showing considerable reduction in the nephro-and hemolytic-toxicity, which are the major constraints in clinical use of AmB [36] . A brief summary of various bioactives delivered through surface engineered CNTs is shown in Table 1 [10, 13, 22, 34, 36, [40] [41] [42] [43] [44] [45] [46] [47] [48] [49] [50] [51] [52] [53] [54] [55] . CNTs alone as well as in combination with other nanocarriers like dendrimers, nanoparticles and quantum dots are emerging as promising novel drug delivery and diagnostic nano-vector tool with minimal toxicity and immunogenicity. Delogu and co-workers assessed the echogenic property of nanotubes in vitro and found that the ultrasound signal of f-MWCNTs is higher than the pristine MWCNTs, graphene oxide and f-SWCNTs. The authors found that the MWCNTs are highly echogenic in liver and heart as examined on pig as an experimental animal model. Thus the nanotubes could show enormous potential as ultrasound contrast agents and theragnostics moiety combining diagnostic and therapeutic modalities [56] . The smart/intelligent surface engineered carbon nanotubes are still having controversy about their biodegradable/non-biodegradable nature. Previous literature suggested non-biodegradable nature of CNTs and excretion through biliary pathway, especially via urine and feces. However, few investigations observed that CNTs are degraded in specific environments via natural, enzymatic catalysis, natural horseradish peroxidase (HRP) with low concentration of H 2 O 2 (approximately 40 mM) at 4 8C over 12 weeks or in the presence of human neutrophil enzyme, myeloperoxidase. Importantly biodegraded nanotubes did not produce any inflammatory response when aspirated in to the lungs of mice [57] [58] [59] . Bianco and co-workers investigated the biodegradation of SWCNTs and MWCNTs under different conditions and concluded that the oxidized MWCNTs were highly degrading in nature as compared to SWCNTs [59] . These few recent literature reports support the biodegradable nature of CNTs, otherwise previously, CNTs were considered non-biodegradable and excreted out as examined by electron microscopic studies. Additionally biocompatible nanotubes could be prepared via conjugation of phospholipids (PL) and polyethylene glycol (PEG) chains on to them, which may be a promising alternative candidate in biomedical applications [58] [59] [60] . The toxicities associated with the CNTs are yet unclear. Several research studies demonstrated the toxicity of pristine CNTs, which could fortunately be minimized via surface engineering that renders them more biocompatible and non-immunogenic. The specific structural properties of CNTs like needle-shape, long and thin and biopersistent nature (insoluble) may produce adverse pulmonary effect but this potential risk could be avoided by use of surface engineering of CNTs. However, till date CNTs' eco-toxicological data are limited and controversial and also lack reliable information of exposure as per Occupational Health and Safety regulations. In contrast to ecotoxic point of view, surface of CNTs can often be modified with the different chemical reactions or by 'grafting to' and 'grafting from' make CNTs more biocompatible with better stability. Additionally, there is a significant need for research and development in the field of analytical and detection methods. Strict norms and regulations are needed in the development of new drug products for being safe, effective and economic in generally regarded as safe (GRAS) prominence.@story_separate@CNTs' potentials as novel carriers in bioactives delivery make them promising candidate for the development of new pharmaceutical products in clinical relevance. Before the clinical use of CNTs based products; their pharmacological and toxicological parameters must be proved to be safe and effective. Surface of CNTs could be easily engineered with targeting and imaging agents, peptides, proteins, siRNA, nucleic acids, antibodies and chemotherapeutic drugs for aforementioned pharmaceutical and biomedical applications. These surface engineered CNTs are considered promising nanomaterial for use in many biomedical applications, including biocompatible modules for the delivery of bioactives. In conclusion, before realizing the full potential of CNTs, it is very important to generate data on their safety, efficacy, and feasibility. Although the scientists are optimistic about the possible application of CNTs yet learning the lesson from past (like thalidomide tragedy), the safety and efficacy of CNTs/CNTs based products/devices etc. must be established beyond doubt. We have witnessed the emergence of several materials/devices/products, which could not make their way to market but then that's the research. Let's keep our fingers crossed and wait for the conclusive proof regarding the possible application of CNTs, particularly in biomedical arena. No conclusion should be drawn either in haste or without conclusive evidence of safety.","Surface engineered carbon nanotubes (CNTs) are attracting recent attention of scientists owing to their vivid biomedical and pharmaceutical applications. The focus of this review is to highlight the important role of surface engineered CNTs in the highly challenging but rewarding area of nanotechnology. The major strength of this review lies in highlighting the exciting applications of CNTs to boost the research efforts, which unfortunately are otherwise scattered in the literature making the reading non-coherent and non-homogeneous."
"1. Manual. 2. Could be any vector tool like CorelDraw, AutoCAD. 3. Semi-automatic. 4 . Making some preprocessing before the user could fix things manually. Have a bunch of drawbacks cause some complicated cases could probably save not so much time rather than Manual methods. 5. Automatic. 6 . Methods that consume only the image and returning the vector output file. Nothing must be done manually. Mostly all automatic solutions use only deep learning or only statistical methods applicate to specific cases or datasets with known image conditions and structure. The primary purpose of this paper is to describe an approach that uses the combination of methods like computer vision, computational geometry, statistical analysis, and deep learning to enhance the general result metrics and make an approach independent on which type of plan used and what image conditions were to predict. Our main contributions are summarized as follows: -We proposed the approach that allows us to recognize and vectorize floor plans of different topology and different image conditions with a better IoU indicator than presented in other papers. -We have shown an approach of enlarging small dataset using back perspective transform with physical photography. This approach has shown an increase in 1.5% in the IoU indicator and allowed us to build the solution robust to shadows.@story_separate@The introduction part of this paper has denoted that there are three general types of vectorization methods: manual, semi-automatic, and automatic. The manual methods are usually general vector graphics software for developing the floor plan itself, for example, AutoCAD, CorelDraw, etc. The investigated semi-automatic methods have many different approaches implementing the idea of the vectoring plan. Some methods used just for the preprocessing based on thresholding [1] . A bit more advanced methods starting from the thresholding and after this, switching to the edit mode, where the preserved object could be placed over the source image [2] . The essential type of methods in the context of this paper -is an automatic approach. One of the first published solutions for floor plan vectoring is based on statistical methods (blurred shape model, k-means, A*) [3] ; the example result of vectoring depicted in Fig. 1 . Convolutional neural networks (CNNs) have been successfully applied in many fields, so as in the field of plan recognition. The wall segmentation approach [4] using the Fully-Convolutional Networks (FCN) shown the result of 89.9% by mean IoU metric. The example results presented in Fig. 2 . As it could be observed, the best results have been achieved with FCN-2s. The approach in this paper is also based on CNN, and the UNet [5] has been chosen for this problem. It has a higher number of parameters than FCN, but, shows better accuracy. The comparison between architectures on different datasets is presented in Table 3 . Since the real-time solution of this problem is not the main goal, the performance of the neural network was not considered. The UNet architecture is used in [6] for door and wall recognition, but modified version U-Net+DCL, where the baseline UNet's deconvolution layers were replaced with a simplified version of pixel deconvolution layers for segmentation. The best result in the wall recognition task in this paper is 0.799 by mean IoU metric. The object detection approach for filtering floor plan using Faster R-CNN [7] was applied in paper [8] . In this work, Faster R-CNN was chosen for object detection too since it shows high scores with fast convergence. They have achieved a mean average precision of 0.86, and a mean average recall of 0.92 on a dataset including 12 classes of objects. The work has been performed for the specific type of plan named BTI (Bureau of Technical Inventarization), so 700 floor plan images have been collected from public real estate websites. The dataset consists mainly of scans, but private testing revealed that user input is usually a photo with different lighting conditions. An example of the user input is shown in Fig. 3 . An approach based on inverse perspective transformation [9] was applied to build a model capable of recognizing floor plans in images with different lighting conditions, as well as to increase the number of images in the dataset. Some of the labeled plans were printed with ArUco markers from the OpenCV library [10] at a fixed distance from them. Each of the printed photos was captured 10 times in different viewpoints; an example of a photo is shown in Fig. 4 (b). Markers are accurately detected by OpenCV function, so based on their coordinates, the perspective transformation matrix to the vertical plane is calculated. The layout of the original floor plan ( Fig. 4(a) ) is converted to the layout of the printed using an inverse matrix of the perspective transform. Then the image is cropped, and the markers are erased using the bilinear interpolation algorithm. An example of the result is presented in Fig. 4(c) . Thereby, the dataset was increased to 2000 images. Training on this expanded dataset made it possible to increase the accuracy of the IoU indicator by 3%, and to train a model resistant to shadows. 3 Architecture 2 neural networks were used for solving the problem: UNet for semantic segmentation. The U-Net architecture is built upon the Fully Convolutional Network (FCN), and the two main differences comparing to FCN are that UNet is symmetric and the skip connections between the downsampling path and the upsampling path apply a concatenation operator instead of a sum. These skip connections intend to provide local information to the global information while upsampling. The UNet architecture is used in this paper since it has been successfully applied to many image segmentation tasks, and it does not require a dataset of a dozen thousands of images to achieve high results. Pre-trained on ImageNet dataset ResNet backbone is used. In addition to the UNet, the DeepLab3+ [11] model was tested as one of the state-of-the-art models for image segmentation, but results turned out to be worse than the UNet ones. The results were compared using the Intersection over Union (1) . As a model for object detection, pre-trained on ImageNet dataset Faster R-CNN was chosen as one of the most widely used state-of-the-art architecture, which shows high accuracy even when training on a small dataset. It uses Region Proposal Network (RPN) to reduce computational time and make a good accuracy as their predecessor method. Faster R-CNN spread out in many pieces of research in object detection [12] [13] [14] . The pipeline for image processing consists of several steps was developed. The main requirement for the pipeline was to add new steps easily or modifying existing ones. A scheme of the pipeline is presented in Fig. 5 . The trained neural network consumes 512 × 512 RGB images as an input. In the first step, the image is resized from the original shape to the desired one. If the image is larger than required, compression is performed so that the bigger side has a length of 512. After that, the image is supplemented to shape 512 × 512. To avoid the appearance of image borders, next algorithm to blur the edges was applied to each of the smaller sides: Inputs: source I -image size m, n Outputs: image 512x512 free of noize near the border 1: I scaled(I,512 / max(m,n)) #scaling 2: w (max(m,n)-min(m,n)) / 2 #width of strip This method avoids the appearance of artifacts near the border in segmentation results, as shown in Fig. 6 . If the original image is smaller than required, the same algorithm is applied but using upsampling. The scaling result is processed by two neural networks. An example of the segmentation result can be seen in Fig. 7(b) . It is noticeable that the result contains noise and little gaps in the walls. The morphological operations of erosion, dilatation, and closure with a 3 × 3 core and connectivity of 4th are used for eliminating this noise as well as inaccuracies. Figure 7 (c) depicts the result of neural network pixel noise removal. Based on the previous step, the connected components of the image are built and semantically representing the rooms. Morphological operations as above are applied to get rid of small defects at the border, such as part of a door segmented as a wall, but using scalable empirical constants depending on the size of the door, since it is standard and varies in small intervals of 600-1000 mm. Further, component filtration is used to remove connectivity components that are not rooms Fig. 7(d) . Based on the room components, an approximation of the components by the contours is used. Since the approximation is rough due to the pixelated source border, there is a need to simplify contours. So, Ramer -Douglas -Peucker algorithm is used [15] with the parameter ε = 1.0 (the parameter was selected empirically, with any increase contours are distorted on most images, with any decrease there are no changes in contours). The algorithm reduces the number of points in the contour, thereby removes steps at non-parallel walls and also rectifying the corners of rooms, as shown in Fig. 8 . Using the obtained contours of the rooms (internal walls borders), as well as the borders of the external walls obtained at the segmentation stage, the 1px-wide middle line is found using the Thinning Algorithm [16] . Hereupon, the wall thickness could be found. The result of simplified contours in a row with the result of object detection is used to arrange doors, windows, and other objects. Doors and windows are placed by the method of intersecting segments, so they become part of the wall. A K-D tree [17] is constructed for reducing the enumeration of segments when searching for intersections. The developed approach has shown the ability to process user input that does not correlate with the training data. The group of methods from start to result works for 2-3 s using the following configuration: Intel Core i5, GeForce GTX 1080Ti, and 16 GB RAM, which allows recognizing incoming plans in production environments without long delays. The test set contains 300 different plans, both scans and photos. There were deep learning tasks: semantic segmentation and object detection. Table 1 shows the mean average precision (mAP) score [18] for object detection using Faster R-CNN. Intersection over Union (IoU) with threshold = 0.7 was chosen as the main metric for the validation of the segmentation model. The IoU of a predicted set of wall pixels and a set of true wall pixels is calculated as: where TP are the true positives, FP false positives, and FN false negatives. As aforementioned, the UNet model is used for semantic segmentation. Different backbones were tried: ResNet-34, ResNet-50, ResNet-101. They all showed approximately the same accuracy, but ResNet-50 turned out to be the best. Table 2 shows a comparison of the results for these backbones. Model weights are updated using binary cross-entropy soft-dice loss (2) with dice weight (dw) = 0.7, where P -predicted, T -target: Also were tried Lovasz loss [19] and a sum of losses (3), but unfortunately, it did not improve the results. The IoU metric obtained on the test set of source data presented in our dataset is presented in Table 3 . The results of training on the public floor plan dataset [20] are also presented. The public dataset contains 5000 images with labels for segmentation; 1000 of them were used for training, 200 for validation, and 3800 for testing. Examples of the recognition results of test images are presented in Fig. 9 , while results from private testing are shown in Fig. 10 . @story_separate@The developed approach allows recognizing and building vector representation for the floor plan using the combined methods of deep learning (semantic segmentation with UNet, object detection with Faster R-CNN) in a row with statistical methods (morphology, component filtration, and Ramer -Douglas -Peucker algorithm). The segmentation has shown an accuracy of about 99% by the IoU metric, while object detection has shown 86% by the mAP metric. Also, the dataset enlargement approach using a backperspective transform was tested. This way of augmenting the dataset introduces natural spatial noise to the image that reduces risks of overfitting and allows make the processing algorithm more robust to shadows. The method developed performs the whole data processing for one input for about 2 s. It allows using this approach for cloud-based recognition systems or any other productive deployment.","The floor plan recognition and vectorization problem from the image has a high market response due to the ability to be applied in such domains as design, automatic furniture fitting, property cost estimation, etc. Several approaches already exist on the market. Many of them are using just statistical or deep machine learning methods capable of recognizing a limited set of floor plan types or providing a semi-automatic tool for recognition. This paper introduces the approach based on the combination of statistical image processing methods in a row of machine learning techniques that allow training robust model for the different floor plan topologies. Faster R-CNN for the floor object detection with a mean average precision of 86% and UNet for the wall segmentation has shown the IoU metric results of about 99%. Both methods, combined with functional and component filtration, made it possible to implement the new approach for vectoring the floor plans."
"Background and rationale COVID-19 is a respiratory illness caused by the novel coronavirus, SARS-CoV-2. In March 2020, it was designated a pandemic by WHO; at the time of writing there have been more than 20 million cases worldwide and 750 000 deaths associated with COVID-19. 1 2 Within Europe, the UK has experienced a high burden of COVID-19 with more than 300 000 cases, the second highest number of total cases in the region and more than 46 000 deaths. 1 During the first surge of the pandemic, London was particularly affected, with the highest age-standardised mortality rate from COVID-19 in the UK (85.7 deaths per 100 000 individuals). 3 Barking, Havering and Redbridge University National Health Service (NHS) Hospitals Trust (BHRUT) serves one of the largest catchment areas in London for a single NHS trust; the area has been severely affected by COVID-19. The population served is ethnically diverse, with a large Asian cohort, and includes boroughs with high indices of multiple deprivation. 4 5 Many groups have described risk factors for severe disease and mortality from COVID-19, with non-white ethnicity emerging as a key risk factor, even after adjusting for geographic, socioeconomic, 6 cardiometabolic and behavioural factors. 7 The longerterm implications of severe disease remain unclear, however, there is significant concern Key messages ► What were the demographics, clinical characteristics and sequelae for patients admitted to hospital with coronavirus disease 2019 (COVID-19) during the first peak of the pandemic, in a large, urban East London population with high indices of deprivation? ► In our population, increasing age, male sex and Asian ethnicity are associated with increased risk of death, as previously described. Radiological abnormalities and symptoms persist 6 weeks after discharge in over 50% of patients. Over a third of all currently employed patients who had follow-up had been unable to return to work by their first review. ► This study describes the inpatient experience together with early outpatient outcomes for patients admitted to hospital with COVID-19 during the first wave of the pandemic. It is one of the largest cohorts of patients from two large district general hospitals in London from a deprived urban area, including outcomes from a respiratory clinician-led continuous positive airway pressure unit. Open access about the potential for prolonged respiratory disability, in part based on data from the previous SARS outbreak. 8 So-called 'long COVID-19' may however have more wide-ranging consequences, including thromboembolic, neurological and psychological sequelae. 9 Objectives Our first objective was to describe the local cohort of individuals hospitalised with COVID-19 during the first surge (1 March 2020 and 8 June 2020) including inpatient mortality and risk factors for poor outcome. This is in the form of a whole hospital cohort, and nested cohort of patients admitted to respiratory units (RU), for who more detailed data were available. This provides the context in which we established an outpatient follow-up pathway for patients with severe COVID-19. Our second objective was to describe outcomes for these individuals at six to twelve weeks after discharge.@story_separate@This retrospective cohort study included adult patients (age ≥18 years old) admitted across two hospitals that comprise a large NHS Trust in London, UK with a clinical or laboratory diagnosis of COVID-19, from 1 March 2020 to 8 June 2020. The reporting of this study is in accordance with the guidelines set out in the STrengthening the Reporting of OBservational studies in Epidemiology statement. We present an additional analysis of a nested cohort of patients admitted to the RU. The RUs comprise a total of 90 beds across two sites and admitted the first patients with COVID-19, before rapidly evolving to preferentially admit patients with more severe disease including those requiring non-invasive ventilation (NIV), which was delivered on the unit. Additional data were collected for patients admitted to the RUs between 10 March 2020 (the date of admission of the first patient with COVID-19) and 26 April 2020. We describe the demographic, clinical, laboratory and radiological findings and disease course and clinical outcomes of these patients. As part of development of a local follow-up pathway for COVID-19, we established a prospective cohort of patients invited for postdischarge review, with the primary aim of informing service development. All patients discharged from BHRUT after severe COVID-19 (defined as requiring NIV and/or admission to higherdependency care) are being followed up by this clinic. The first patient invited, and those described here, were those admitted to the RU. Definitions COVID-19 cases were defined as either a laboratory confirmed or clinically suspected diagnosis of COVID-19. Patients who tested positive via real-time PCR for SARS-CoV-2 in a respiratory tract sample were classed as laboratory confirmed. A clinically suspected case was defined as a patient who tested negative for COVID-19, but where the attending physician determined that COVID-19 infection was the likely underlying diagnosis, taking into account all clinical, laboratory and radiological data available during the patient's admission, with reference to definitions from Public Health England. 10 Treatment escalation definitions are defined as: level 1 is for maximal therapy delivered in a medical ward environment; level 2 is for single organ support in a higher dependency area including the RU and level 3 for multiorgan support including invasive mechanical ventilation in an intensive care setting. Ethnicity definitions were those defined by the UK Office for National Statistics. 4 Obesity is defined as a recorded body mass index of ≥30 kg/m². Frailty was recorded as the Rockwood Clinical Frailty Score (CFS). An NIV trial is defined as any time on either continuous positive airway pressure (CPAP) or bilevel positive airway pressure. Chest radiograph (CXR) classification and severity was assessed by a member of the respiratory team according to the British Society of Thoracic Imaging (BSTI) classification. 11 Data collection Data were collected from a combination of electronic health records databases, linked using personal identifiers. Data extracted included age, sex, ethnicity, length of stay and discharge outcome. During the period of the study, 'COVID-19 status', as one of 'not clinically suspected', 'suspected COVID-19' or 'confirmed COVID-19', were recorded daily as part of the patient flow pathway, which included input from multidisciplinary clinical ward teams during 'board rounds'. For this analysis, the last COVID-19 status prior to discharge was used. We included individuals with 'suspected COVID-19' and 'confirmed COVID-19', defined as above. Additionally, for the nested RU dataset only, these electronic datasets were combined with data collected from manual review of electronic and paper-based patient records. Additional data collected included clinical symptoms and signs, progress during admission including time-updated requirements for organ support and outcome. After record linkage, data were anonymised for analysis. Follow-up data were collected prospectively for patients attending for follow-up at approximately 6 weeks from their discharge using locally adapted British Thoracic Society guidelines. 12 Data collected included patient demographics, Medical Research Council (MRC) breathlessness scales at baseline (evaluated retrospectively) and present; results of screening tools for anxiety (Generalised Anxiety Disorder scale-2 (GAD-2)) and depression (Patient Health Questionnaire-2 (PHQ-2)); functional impairment and return to work status. CXRs were reviewed from admission and post-discharge. Patients were informed about clinic appointments prior to discharge. Appointment letters were sent via post and patient pathway coordinators Open access attempted to contact all patients by telephone to confirm their appointment. For telephone clinics, two attempts were made to contact patients (one at a scheduled clinic appointment time, and one other in the same half-day clinic). Where patients did not attend face-to-face appointments, clinicians attempted to contact them via phone. Electronic health records were reviewed to determine if the patient had been readmitted to hospital as a reason for non-attendance. If a patient remained out of contact after this, they were offered one further appointment via post, with telephone confirmation. Analysis was performed using the R statistical computing environment V.4.0.1. 13 14 We described the study population stratified by inpatient outcome. For continuous variables, analysis of variance tests was used. For categorical variables, Pearson's χ 2 tests or Fischer's exact tests were used. Univariable, and then multivariable Cox proportional hazard models were used for survival analyses, with age, gender and ethnicity included as a priori likely confounders. Proportional hazard assumptions were checked using Schoenfeld residuals. For retrospective data, complete case records analysis was used, with missing exposure data assumed to be so at random (there were no missing outcome data). For follow-up data, an intention-to-treat analysis was used, with missing data included in the final analysis. At the suggestion of a reviewer, we performed a sensitivity analysis to evaluate the impact of our use of a clinical, rather than laboratory confirmed, diagnosis of COVID-19 for our case definition. For this, we repeated the analysis restricting the study population to PCRconfirmed COVID-19 cases only. These analyses were completed as part of ongoing service evaluation in order to facilitate future planning and ongoing service requirements for patients with COVID-19, in collaboration with the Trust Clinical Audit and Research and Development Team. The Caldicott Guardian was consulted for approval for the use of anonymised patient data. Due to the retrospective nature of the study, patients and the public were not involved prior to the collection of data, study design or recruitment to the study. Follow-up data fields were adapted from BTS guidelines, which has patient and public involvement in the form of Lay Trustees. We intend to disseminate the main results of the study using the Trusts' public engagement channels. Demographics and outcomes Data were available for 2091 admissions, representing 1946 patients, with a coded diagnosis of suspected or confirmed COVID-19, admitted from 1 March 2020 to 8 June 2020. Median age was 73 years (IQR 57-84 years); 42.1% patients were female. Of 1781 patients with ethnicity data available, 1250 (70.2%) were of white ethnicity, 23 (1.3%) mixed, 313 (17.6%) Asian, 154 (8.6%) black, 41 (2.3%) other. (table 1) There were 594 deaths over 99 days (overall mortality 30.5%; 11.4 deaths per person-year at risk (PY)). There were 414 deaths (12.5 deaths/PY) among admissions to general medical wards and 83 deaths (8.05 deaths/ PY) among admissions to RU. Two hundred and sixteen (10%) admissions included a spell in the critical care unit (CCU), with 98 recorded deaths (8.83 deaths/PY). One hundred and seventy-seven patients (8.5%) were admitted to CCU without having been transferred from or subsequently to an RU. The median length of stay was 5 days (IQR 2-11) for all inpatients irrespective of ward. Length of stay was longer where admissions included a spell in CCU (median 13 days (IQR 6-23])) or RU (9 days (IQR 5-15), p<0.001). A considerable tail of individuals had prolonged admissions over 30 days (4% in general wards, 5% in the RUs and 19% in CCU; figure 1). Two hundred and ninetythree admissions included a spell in one of the RUs, of which 248 (84.6%) are included in the subgroup analysis. Age, gender and ethnicity were included as covariates in the Cox proportional hazards model (table 1) . Increasing age was associated with decreased survival probability: compared with patients younger than 60, patients aged 60-80 had 2.95 times higher rate of death, increasing to 4.44 times in those older than 80 (95% CI 2.12 to 4.11 and 3.19 to 6.19, respectively). Men appeared to have a higher mortality rate than women (HR 1.30, 95% CI 1.09 to 1.56), as did those of Asian ethnicity compared with White (HR 1.40, 95% CI 1.08 to 1.81). No difference in survival probability was seen with Black, Mixed or other ethnicity compared with white. Restricting the study population to PCR-confirmed COVID-19 as a sensitivity analysis, resulted in 1189 admissions, representing 1117 patients. There were 355 deaths over 99 days (overall mortality 31.8%; 9.3 deaths/PY). There were 257 deaths among admissions to general medical wards (10.5 deaths/PY), 67 deaths among admission to the RU (10.0 deaths/PY), and 75 deaths among admissions to ITU (7.2 deaths/PY). In the Cox proportional hazards model (online supplemental table 1), age, gender and ethnicity were included as covariates. Similar associations to those in the overall population were observed, with increasing age associated with decreased survival probability: patients aged 60-80 had a 2.7 higher risk of death, rising to 3.9 times higher with patients Open access older than 80 years old, compared with those younger than 60. Men had a higher hazard of death, compared with women (HR 1.4, 95% CI 1.1 to 1.8); as did people of Asian ethnicity (HR 1.5, 95% CI 1.1 to 2.1). RUs and ward-based NIV Data were collected from 248 admissions, representing 235 individual patients. One patient was excluded due to highly missing data, and analysis is on 234 patients. Among 28 patients (12%) with more than one admission recorded, the mean number of admissions was 2.31. In this nested cohort, the median age was 65 years (IQR 54-80). Most patients admitted to the RU with COVID-19 were men (66%). Seventy-six patients died during the data collection period (9.5 deaths/PY) and 20 patients remained inpatient. Patient ethnicity was: 135 (58%) white, 46 (20%) Asian, 31 (13%) black, 4 (2%) mixed and 18 (8%) other (table 2) . Pre-existing diabetes was present in 69 patients (33%), and 32 patients were obese (14%). Among 122 patients who were admitted to the RUs above the age of 65 years, median CFS was 5 (IQR 3-6). Seventy-nine per cent (186 people) had a treatment escalation plan from a senior clinician. Of those, fifty per cent had a documented clinical decision that treatment escalation to level 3 care was medically appropriate; of Open access those for whom this was not felt appropriate, 17% were for NIV (level 2 care) and 33% for level 1 care. Fortyeight patients had RU-based NIV; this consisted of CPAP in 88%. Mortality was higher in patients who received NIV than those who did not (13.1 vs 8.6 deaths/PY, p=0.1). Of the 27 patients who received NIV, and were considered for admission to the CCU, or did not have a decision that admission to CCU was not medically appropriate, 20 ultimately required admission of which 7 were ultimately intubated. Forty-six per cent (N=18/35) patients receiving NIV in the RU had a trial of awake prone positioning. Awake prone positioning in patients using NIV appeared to be associated with lower mortality (8.2 vs 16.5 deaths/PY, p=0.1) however numbers were small. Among patients who required NIV, mortality rate was higher among those for maximal level 2 care compared with those considered appropriate for level 3 care or without a decision for maximal treatment ceiling (34.7 vs 3.0 deaths/PY, p<0.0001) (figure 2). Admission CXRs were classified as normal in 38 (17%), classical for COVID-19 in 121 (53%), demonstrating In univariable analyses, there was weak evidence for lower maximum recorded C-reactive protein (CRP) level during admission, lower maximum serum creatinine and lower maximum serum alanine aminotransferase (ALT) among patients who survived to discharge compared with those who died (survivors vs non-survivors, CRP: 189 mg/L vs 267 mg/L (p=0.06), creatinine: 137 μmol/L vs 174 μmol/L [p=0.09] and ALT: 77 IU/L vs 146 IU/L ((p=0.06)). Analysis of LDH, D-dimer, creatine kinase and ferritin were excluded due to a high degree (>50%) of missingness. Eighty-four studies were performed on 66 patients to evaluate for suspected thromboembolic events, including CT pulmonary angiograms (CTPA), CT head and leg Doppler ultrasound scans. Thirteen studies were positive for thrombosis in 11 patients, representing 4.6% of RU patients. Five patients were diagnosed with pulmonary emboli (2.1%), with 5 of 25 CTPAs performed being positive for embolism. Four patients were diagnosed with ischaemic strokes (1.7%) and three with lower limb deep vein thromboses (DVT, 1.3%). One patient had a confirmed lower limb DVT and positive CTPA. A total of 139 patients discharged from the RU have been offered follow-up at the end of the data collection period. Eight patients (6%) required readmission prior to 12-week review (three with pneumonitis, two with pulmonary embolism, two with myocardial infarction and one with stroke). Of the remaining 131, 113 (86%) attended for review at 6-12 weeks after discharge. Nine patients did not attend despite having two confirmed appointments, one declined due to bereavement, one declined due to existing community COPD follow-up and seven patients did not respond to both appointment letters and telephone calls. All 113 patients who attended for follow-up had imaging performed; CXR appearances were persistently abnormal in 66 patients (58%). Ongoing symptoms were reported in 79 patients (70%), with fatigue being the most common (69 patients; 61%); the median fatigue score was 5 (out of 10; IQR 3.5-7.0). The mean (retrospectively assessed) preadmission MRC breathlessness score was 1.6 (SD 1.05); postdischarge, the mean score was 2.2 (SD 1.2). Forty-one patients (36%) had an MRC breathlessness score above their pre-admission baseline at follow-up; this proportion was higher in patients without pre-existing breathlessness (45% vs 22%, p=0.03). Other symptoms included cough (17%), memory impairment (6%) speech and language issues (7%) and hair-loss (6%). Of those who attended for follow-up, 15% had PHQ-2 scores of >3% and 6% of patients had GAD-2 scores of >3 (6%), representing a positive screen for depression and anxiety respectively. Of the 69 patients who worked prior to admission, 27 had not yet returned to work at 6 to 12 week review due to their symptoms (27/69=39%).  The overall mortality rate in our population was 11.4 deaths/PY, with 22.9% of admissions requiring a higher level of support than that which could be provided on a general medical ward. Increasing age, male sex and Asian ethnicity identified individuals with higher inpatient mortality rate in adjusted analyses. This is broadly consistent with inpatient cohorts in central London teaching hospitals, national and international data. [15] [16] [17] Increasing CXR severity also trends with mortality. Our RU nested cohort was, on average, younger than the overall study population, reflecting a selection bias towards patients clinically identified as likely to benefit from more intensive therapy. Men and people of Asian ethnicity are also over-represented, which likely reflects more severe disease among these individuals, necessitating additional support. In the RU cohort, 11 patients (4.6%) had positive studies for thrombosis. The proportion escalated from CPAP/NIV to invasive mechanical ventilation, as well as the mortality thereafter, are comparable to data elsewhere. 18 Few published data exist to describe individual centres' experience of ward based NIV for COVID-19, particularly its use in District General Hospitals with high patient flow. We report some of the first early follow-up data for patients with severe COVID-19 in the UK. A high proportion of patients remain symptomatic at 6-12 weeks after discharge, particularly with fatigue and breathlessness. These findings are similar to a recently reported central London cohort, 9 and to a Belgian study, 19 where a restrictive pattern of lung function was common (38%, N=84/101). This finding was associated with longer, or critical care admission. It remains unclear to what extent these features reflect COVID-19 specific complications, rather than deconditioning. Our study additionally found that features of mood disorders were common, with elevated anxiety and depression screening scores. Over half of those previously working had not yet returned to work and did not feel ready to do so, concordant with the increasing care needs seen in a significant amount of patients after discharge in other reports. 20 These findings highlight the importance of holistic assessment and ongoing support following COVID-19 and have led to the inclusion of a clinical psychologist, physiotherapist and occupational therapist within our post-COVID clinic. The data presented for the whole hospital cohort used electronic databases and record linkage. While coded diagnoses of 'confirmed COVID-19' were checked against laboratory results, there is potential for incorrect coding of 'suspected' cases, resulting in both missed cases, and inclusion of individuals who did not in fact have COVID-19. The local process by which these codes were generated (ie, with the clinical team for each individual patient) and use of the last status coded during the admission (when the decision takes into account all available data and the patient's clinical course during the admission) is likely to increase the accuracy of these codes. Additional reassurance may be provided by our sensitivity analysis, which suggests the findings are similar when restricted to PCRconfirmed cases, and the consistency of our results with other cohorts, which used only PCR-confirmed COVID-19. Coded diagnoses are usually based on initial diagnosis, and rarely with input from the attending physician, thus the method applied locally provides a rare opportunity to understand the mortality experience of people who were clinically felt to have COVID-19 but who did not have a positive laboratory test. These analyses were developed as an approach to understand our local experience in the first wave of COVID-19 and inform service requirements for future. The RU cohort represents most unwell COVID-19 patients in our hospitals, outside of critical care and therefore can inform the necessary decisions about optimal resource utilisation during surges of SARS-CoV-2 infection, or other future epidemics. This cohort in fact includes the vast majority of all patients admitted to critical care during the period of the study, however, 8.5% patients were admitted to critical care but not the RU and are not included. This cohort may not, therefore, be fully representative of all patients needing higher level of care. For our adjusted estimates of risk factors for mortality, there is potential for unmeasured confounding, given the limited number of variables available from routine data. For example, pre-existing comorbidities are well recognised as risk factors for poorer outcomes from COVID-19, however, these data were not available. Despite an approach which includes several attempts to contact individuals after discharge, 16 (12%) patients did not attend and had not been readmitted to hospital; their status at 6-12 weeks is unknown. This is similar to the proportion who did not attend face-to-face follow-up in a clinical trial cohort from Bristol. However, in that study, 48% of those not attending did so due to ongoing shielding. Given the use of telephone appointments, this may be a less common reason in our study; we might suggest therefore that these individuals had fully recovered and felt an appointment was unnecessary or were unable to attend as they had returned to work or care provision. 21 If so, the missing data for these individuals may, in a complete case records approach, may have led to overestimation of the prevalence of ongoing symptoms and functional impairment. However, we cannot exclude the converse, that patients who did not attend were unable to do so because of breathlessness or other symptoms impacting mobility. As a result, we did not consider it appropriate to assume that non-attenders were asymptomatic. Finally, COVID-19 is a rapidly evolving situation, both from a public health and clinical perspective with regular new insights into pathogenesis and treatments. In addition, the development of effective vaccines is of Open access great promise. These data, from the first wave of the UK pandemic may therefore not be generalisable to the current situation, or that in future. These analyses complement the existing literature describing the clinical course and outcomes of hospitalised individuals with COVID-19 in the UK. These data draw from two district general hospitals in a deprived urban location with a large catchment area, very high emergency department demand, and without specialist clinical infectious diseases units. 22 As a result our study population is larger than previously published individual cohorts 23 and may be considered more representative of other district general hospitals compared with cohorts from central London. The high deprivation scores among our population should be considered: Barking and Dagenham has the highest index of multiple deprivation (IMD) in London. Other analyses have identified the impact of deprivation on age-standardised mortality rates from COVID-19 in the UK, with a 118% increase in death rate comparing the least deprived to the most deprived areas, a larger effect than deprivation has on all-cause mortality. 3 In this context, similar risk factors for mortality were observed. Increased mortality in individuals of Asian ethnicity has been reported in multiple settings. 24 We do not find an association between black ethnicity and survival in our cohort, as is reported elsewhere. This difference may reflect low power to detect a difference, given relatively fewer individuals of Black ethnicity compared with white or Asian in our population, or the effect of unmeasured and unadjusted confounding, for example by deprivation indices. During the COVID-19 pandemic response hospitals have had to undergo rapid review and service redesign in order to manage healthcare demand, particularly ITU capacity. Locally these factors led to an early decision being taken to adapt two existing general medical/ respiratory wards to offer CPAP with high flow oxygen, increased nursing ratios and 24-hour on-site respiratory cover. These analyses were first developed to understand the impact of this service, and we believe they are highly relevant to other clinicians and service managers facing similar decisions. We found that almost 80% of patients had a documented treatment escalation decision, however there was further improvement possible. NIV/ CPAP was only used for 20% of admitted patients, with early evidence during the first wave of the UK pandemic demonstrating its effectiveness in reducing mortality. 25 Three-quarters of individuals receiving NIV and for whom IMV was considered potentially beneficially were ultimately admitted to higher-dependency care, however a minority (15%) required intubation. We did not capture the reasons for admission to higher-dependency care, which may include need for renal-replacement therapy and inotropic support as well as deteriorating oxygenation. However, we did also have issues with achieving high-oxygen flow rates through some NIV devices, which anecdotally could also have been a factor. While evaluation of awake prone positioning was not an objective of this study, it was in common use at the time of the study. Given the small numbers and high likelihood of confounding (eg, patients able to tolerate awake prone positioning may be less unwell, be less overweight or have fewer comorbidities than those who are not) it is difficult to draw conclusions from the apparent 50% reduction in mortality observed with this intervention. Early reports from Italy and China suggested a high rate of venous thromboembolism in patients with severe COVID-19 pneumonias. 26 27 Data from intensive care units show higher rates of thrombotic complications compared with our respiratory ward cohort. 28 However, without a non-COVID-19 comparator group it is difficult to interpret whether our data represents a higher rate of thrombosis than would be expected in hospitalised individuals with other viral pneumonias. Our finding that CXR severity according to BSTI criteria trends with mortality agrees with similar data from the UK 29 and CXR scoring systems such as the Italian Brixia score. 30 Together with studies which correlate semiquantitative CT scores with mortality, 31 this adds support to the importance of radiological scores in risk stratifying outcome with COVID-19. The need for more data on recovery from COVID-19 is well recognised. 32 We report some of the first data on early follow-up outcomes, including describing ongoing symptoms and CXR abnormalities in the majority of patients, with fatigue the most common symptom. The considerable proportion of patients who screened positive for mood disorders, is an important reminder of the need for multidisciplinary input in development of services for individuals recovering from COVID-19, which should include mental health and rehabilitation support. So-called 'long COVID-19' is increasingly recognised, including in patients with milder disease who would not be included in our data. Our findings provide evidence to support development of guidelines for management of postacute COVID-19. 33 That almost half of patients who had been working prior to their illness felt unable to return to work 6 weeks after discharge also highlights the potential economic impact of COVID-19 for individuals, particularly the more severely affected Black and Minority Ethnic (BAME) and and economically deprived populations. Daryl Cheng http:// orcid. org/ 0000-0001-9906-4298@story_separate@The UK, and countries around the world, are currently experiencing high numbers of COVID-19 cases, with significant pressure on hospitals and, particularly, intensive care units. While advent of vaccines offers hope, significant time and resource will be required before population coverage is sufficient to impact communitylevel transmission. We describe the inpatient outcomes Open access of a large cohort of hospitalised patients with COVID-19, the potential use of ward-based high flow oxygen and CPAP in the management of severe cases, and a large burden of residual symptoms 6-12 weeks after discharge. These data are contributing to local resource planning and have wider applicability for development of inpatient and outpatient services and evidence-based national guidelines for COVID-19. We again highlight the need for detailed investigation to understand underlying causes of excess mortality in BAME individuals. Contributors All authors contributed to the study design and concept. DC, CC, ES and a wider team in the acknowledgements contributed to data extraction. Data analysis was performed by DC and CC. The manuscript was drafted, revised and reviewed by all authors. Funding The authors have not declared a specific grant for this research from any funding agency in the public, commercial or not-for-profit sectors. Competing interests None declared. Patient consent for publication Not required. Ethics approval The data collected during this study were reviewed by the Trust Research & Development and Clinical Audit department review panel and approval was granted without the need for ethical approval as per the NHS Health Research Authority and National Institute for Health Research guidance. Provenance and peer review Not commissioned; externally peer reviewed. Data availability statement Data are available on reasonable request. Individual deidentified participant data (including data dictionaries) will be shared. Data that underlie the results reported in this article, after deidentification (text, tables, figures and appendices). Imaging data will not be available to view. Other documents which will be available include study protocol, statistical analysis plan, analytical code. Data will be available beginning from publication and ending five years following article publication. Data will be made available to all researchers who provide a methodologically sound proposal, for their stated aims. Proposals should be directed to daryl. cheng@ nhs. net. Supplemental material This content has been supplied by the author(s). It has not been vetted by BMJ Publishing Group Limited (BMJ) and may not have been peer-reviewed. Any opinions or recommendations discussed are solely those of the author(s) and are not endorsed by BMJ. BMJ disclaims all liability and responsibility arising from any reliance placed on the content. Where the content includes any translated material, BMJ does not warrant the accuracy and reliability of the translations (including but not limited to local regulations, clinical guidelines, terminology, drug names and drug dosages), and is not responsible for any error and/or omissions arising from translation and adaptation or otherwise. Open access This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http:// creativecommons. org/ licenses/ by-nc/ 4. 0/.","BACKGROUND: Descriptions of clinical characteristics of patients hospitalised withCOVID-19, their clinical course and short-term inpatient and outpatient outcomes in deprived urban populations in the UK are still relatively sparse. We describe the epidemiology, clinical course, experience of non-invasive ventilation and intensive care, mortality and short-term sequelae of patients admitted to two large District General Hospitals across a large East London National Health Service Trust during the first wave of the pandemic. METHODS: A retrospective analysis was carried out on a cohort of 1946 patients with a clinical or laboratory diagnosis of COVID-19, including descriptive statistics and survival analysis. A more detailed analysis was undertaken of a subset of patients admitted across three respiratory units in the trust. RESULTS: Increasing age, male sex and Asian ethnicity were associated with worse outcomes. Increasing severity of chest X-ray abnormalities trended with mortality. Radiological changes persisted in over 50% of cases at early follow-up (6 weeks). Ongoing symptoms including hair loss, memory impairment, breathlessness, cough and fatigue were reported in 70% of survivors, with 39% of patients unable to return to work due to ongoing symptoms. CONCLUSIONS: Understanding the acute clinical features, course of illness and outcomes of COVID-19 will be crucial in understanding the effect of differences in risk, as well as the effectiveness of new interventions and vaccination between the successive waves of the pandemic."
"Since the outbreak of COVID-19 (formally known as 2019-nCoV) in December 2019 in Wuhan, Hubei Province, China (Shen et al., 2020) , the pandemic has become a major threat to the whole world. By May 30, 2021, the virus had affected more than 169 million people and caused the deaths of 3.5 million in more than 190 countries and regions worldwide (JHU, 2021) . Although many measures have been taken to cope with the health emergency of national concern, such as social distancing measures, locking down measures, imposing quarantines, universities, and business closures (Tison et al., 2020) , monitoring the dynamics of the epidemic and preventing its spread poses a huge challenge in practice due to the limited capacity of conventional disease surveillance systems. Studies have shown that publicly available data can play a crucial role in tracking the spread of epidemic disease as complements for conventional public health surveillance (Gundecha and Liu, 2012; Samaras et al., 2020) . Non-medical data generated from various sources (Aiello et al., 2020; Kirian and Weintraub, 2010; Ram et al., 2015) , has been widely used to estimate disease incidences and to detect disease outbreaks before clinically confirmed data is available (Charles-Smith et al., 2015; Dai et al., 2021; Lu et al., 2021) . Social media data collected from Facebook (Gittelman et al., 2015; Strekalova, 2016) , YouTube (Basch et al., 2015; Nerghes et al., 2018) , Instagram (Guidry et al., 2017; Seltzer et al., 2017) , and Internet search queries (Ginsberg et al., 2009; Zhao et al., 2018) are also used to predict diseases for public health concerns. For example, Twitter data is widely used for early warning and outbreak detection, such as to predict syphilis (Young et al., 2018) , swine flu (Kostkova et al., 2014) , flu (Chen et al., 2014) , and Ebola (Yom-Tov, 2015) . The representative work was made by the Google research and development team, who developed the Google Flu Trends (GFT) algorithm based on the high correlation between the number of certain queries in the Google search platform and influenza-like activity level (Ginsberg et al., 2009 ). They accurately estimated the level of influenza activity in near-real time without knowing the development stage and transmission mechanism of the disease. Since then, many researchers are inspired to track epidemics with social media data (Araujo et al., 2017; Huang et al., 2013; Signorini et al., 2011) . As for the unprecedented pandemic COVID-19, some researchers also applied social media and Internet data to monitor and estimate the development of the epidemic (Ayyoubzadeh et al., 2020; Li et al., 2020; Qin et al., 2020) . However, many of these studies used only sampled, incomplete data, so the integrity of the dataset and the accuracy of the prediction models are both difficult to guarantee, and there is still a lack of a general prediction framework that can accurately predict the course of COVID-19 using social media data. To detect and predict the development of COVID-19 using publicly available social media data, this paper applied the daily new confirmed COVID-19 case counts in Wuhan reported by its Health Commission, and a complete dataset of user posts from Sina Weibo (Weibo, 2020) , the Twitter-like microblog platform in China, to propose a new confirmed case prediction algorithm named Weibo COVID-19 Trends (WCT) based on the GFT algorithm. WCT can effectively predict the daily new confirmed case counts before the official report is released. This paper also provided a general prediction framework that can be easily extended to predict other diseases or public emergencies using accessible third-party data. This study provides a promising approach for forecasting newly emerging infectious diseases at an early stage when most epidemiological characteristics are unknown. Table 1 shows the nomenclatures used in each processing of this paper. The main contributions of this paper are summarized as follows: 1. A new confirmed case prediction algorithm is developed based on GFT to predict the development of COVID-19. 2. A genetic algorithm is designed to select a keyword set to filter Weibo posts related to COVID-19. 3. A highly adaptive framework for feature engineering which allows third parties to utilize the data for epidemic predictions is proposed. The rest of the paper is organized as follows. Section 2 reviews the GFT algorithm and its updated versions. Section 3 mainly describes the framework for the proposed COVID-19 prediction algorithm (i.e., WCT), in which a genetic algorithm is implemented to improve related keyword set selection. Section 4 presents the estimated results of WCT with a comparison with other algorithms including GFT. Finally, Section 5 summarizes the findings and limitations of this study. Since the outbreak of COVID-19 (formally known as 2019-nCoV) in December 2019 in Wuhan, Hubei Province, China (Cuihua et al., 2020) , the pandemic has become a major threat to the whole world. By May 30, 2021, the virus had affected more than 169 million people and caused the deaths of 3.5 million in more than 190 countries and regions worldwide (JHU, 2021) . Although many measures have been taken to cope with the health emergency of national concern, such as social distancing measures, locking down measures, imposing quarantines, universities, and business closures (Tison et al., 2020) , monitoring the dynamics of the epidemic and preventing its spread poses a huge challenge in practice due to the limited capacity of conventional disease surveillance systems. Studies have shown that publicly available data can play a crucial role in tracking the spread of epidemic disease as complements for conventional public health surveillance (Samaras et al., 2020; Gundecha and Liu, 2012) . Non-medical data generated from various sources (Aiello et al., 2020; Kirian and Weintraub, 2010; Ram et al., 2015) , has been widely used to estimate disease incidences and to detect disease outbreaks before clinically confirmed data is available (Charles-Smith et al., 2015) . Social media data collected from Facebook (Gittelman et al., 2015; Strekalova, 2016) , YouTube (Basch et al., 2015; Nerghes et al., 2018) , Instagram (Guidry et al., 2017; Seltzer et al., 2017) , and Internet search queries (Ginsberg et al., 2009; Zhao et al., 2018) are also used to predict diseases for public health concerns. For example, Twitter data is widely used for early warning and outbreak detection, such as to predict syphilis (Young et al., 2018) , swine flu (Kostkova et al., 2014) , flu (Chen et al., 2014) , and Ebola (Yom-Tov, 2015) . The representative work was made by the Google research and development team, who developed the Google Flu Trends (GFT) algorithm based on the high correlation between the number of certain queries in the Google search platform and influenza-like activity level (Ginsberg et al., 2009 ). They accurately estimated the level of influenza activity in near-real time without knowing the development stage and transmission mechanism of the disease. Since then, many researchers are inspired to track epidemics with social media data (Signorini et al., 2011; Araujo et al., 2017; Huang et al., 2013) . As for the unprecedented pandemic COVID-19, some researchers also applied social media and Internet data to monitor and estimate the development of the epidemic (Qin et al., 2020; Li et al., 2020; Ayyoubzadeh et al., 2020) . However, many of these studies used only sampled, incomplete data, so the integrity of the dataset and the accuracy of the prediction models are both difficult to guarantee, and there is still a lack of a general prediction framework that can accurately predict the course of COVID-19 using social media data. To detect and predict the development of COVID-19 using publicly available social media data, this paper applied the daily new confirmed COVID-19 case counts in Wuhan reported by its Health Commission, and a complete dataset of user posts from Sina Weibo (Weibo, 2020) , the Twitter-like microblog platform in China, to propose a new confirmed case prediction algorithm named Trends (WCT) based on the GFT algorithm. WCT can effectively predict the daily new confirmed case counts before the official report is released. This paper also provided a general prediction framework that can be easily extended to predict other diseases or public emergencies using accessible third-party data. This study provides a promising approach for forecasting newly emerging infectious diseases at an early stage when most epidemiological characteristics are unknown. Table 1 shows the nomenclatures used in each processing of this paper. The main contributions of this paper are summarized as follows: 1. A new confirmed case prediction algorithm is developed based on GFT to predict the development of COVID-19. 2. A genetic algorithm is designed to select a keyword set to filter Weibo posts related to COVID-19. 3. A highly adaptive framework for feature engineering which allows third parties to utilize the data for epidemic predictions is proposed. The rest of the paper is organized as follows. Section 2 reviews the GFT algorithm and its updated versions. Section 3 mainly describes the framework for the proposed COVID-19 prediction algorithm (i.e., WCT), in which a genetic algorithm is implemented to improve related keyword set selection. Section 4 presents the estimated results of WCT with a comparison with other algorithms including GFT. Finally, Section 5 summarizes the findings and limitations of this study.@story_separate@Google Flu Trends (GFT) is a short-term forecasting tool for weekly influenza activity as an auxiliary method of influenza surveillance (CDC, 2020) . It was launched in 2008 with satisfying forecast precision at that time and was further applied to influenza surveillance and early warning systems in many countries (Butler, 2013) . Although Google had improved the details of the algorithm many times in the process of GFT application, due to the impact of a sudden increase in influenza-like illness (ILI) related queries and other factors (Kandula and Shaman, 2019; Lazer et al., 2014b) . The problem of inaccurate prediction of the algorithm has never been solved completely. Finally, Google shut down the GFT flu prediction function in 2015 (GFT, 2015) . The most well-known GFT algorithm is its initial version. With input on the fraction of certain ILI-related search queries from Google and the percentages of ILI physician visits from the US Centers for Disease Control and Prevention (CDC), the GFT algorithm trains a log-odds linear regression model (LR) to estimate ILI incidence. LR uses the log-odds of an ILI physician visit and the log-odds of an ILI-related search query to realizes regression prediction: where logitðpÞ ¼ lnðp =ð1 À pÞÞ, IðtÞ is the percentage of ILI physician visits, QðtÞ is the ILI-related query fraction at time t (i.e., the sum of each query fraction in the selected ILI-related search queries set), α is the multiplicative coefficient, and ε is the error term. Firstly, the model is trained by each of the 50 million candidate common queries separately. It outputs the prediction result of ILI physician visits and the Pearson correlation score between the estimates and the CDC ILI data. Then the aggregated top-scoring queries are used to train the model and the best fit (when the number of keywords n ¼ 45) is selected automatically. The selection of queries from the best fit is called ""the greedy combination algorithm"" (GCA). Finally, the selected queries are used to train the model and predict the ILI physician visits. This approach has successfully estimated the level of weekly influenza activity in the United States from 2007 to 2008 with a mean correlation score of 0.97 and 1-2 weeks ahead of the reports published by CDC. It offers the opportunity to use search queries to detect influenza epidemics and inspires researchers to explore the application of social media data in public health surveillance (Cui et al., 2015; Schmidt, 2012) . Google officially launched GFT (GFT 1.0) in November 2008, and subsequently gained a wide range of popularity. However, in the first wave of influenza A (H1N1) epidemic, that is, from April to August 2009, the predicted incidence of H1N1 was badly lower than the ILI activity reported by CDC (Butler, 2013) . Therefore, Google upgraded GFT for the first time and developed the second version GFT 2.0 (Cook et al., 2011) . GFT 2.0 adjusted the number and category of selected search queries, referring to the ILI monitoring data during the first wave of H1N1 epidemic (March 29 to September 13, 2009). It increased the search Table 1 The nomenclatures used in this paper. query terms and deleted search queries that were not directly related to influenza, which significantly improved the performance of GFT 2.0. Since its launch in September 2009, its prediction result had been very similar to the ILI activity in the United States until 2012. In the influenza epidemic season of 2012-2013, GFT 2.0 greatly overestimated the influenza epidemic with almost twice the result of CDC monitoring (Butler, 2013) . This overestimation led to the second upgrade of GFT (Copeland et al., 2013) . GFT 3.0 was officially launched in October 2013, it made two changes based on GFT 2.0, that is, weakening the impact of abnormal media hot spots and using elastic net to predict ILI (previously based on linear regression). Compared with GFT 2.0, GFT 3.0 significantly reduced the peak amount of its predicted ILI in the 2012-2013 flu season. However, its predicted result was still slightly higher than that of CDC in the United States, and in the 31 weeks after the implementation of GFT 3.0, the prediction result was higher in 23 weeks (Lazer et al., 2014a) . The last upgrade of GFT took place in August 2014 (Lampos et al., 2015) . GFT 4.0 expanded the GFT 3.0 model by incorporating the queries selected by the Elastic Net into a non-linear regression framework, based on a composite Gaussian Process. It also injected the ILI activity data as prior knowledge about the disease into the model. The bias of GFT prediction was significantly reduced. GFT 4.0 was used until August 2015, when Google shut down the GFT prediction service. Because of the important role of ILI surveillance in public health, many researchers are still committed to improving the predictive performance of ILI. Such as correcting the limitations of the GFT algorithm process, updating or adding the training data source of the prediction model, and proposing new prediction algorithms based on GFT. Kandula et al. proposed a corrected GFT algorithm, which uses the estimated value of the original GFT algorithm as new data for training the ILI prediction model, reducing the total prediction error by 44% (Kandula and Shaman, 2019) . This algorithm considers the problem that the ILI data provided by CDC is not timely and incomplete when the GFT algorithm is proposed. It uses complete ILI data and GFT estimates to train the prediction model and replaces LR with an autoregressive integrated moving average (ARIMA) model. The algorithm greatly improves the prediction accuracy and proves the validity and practicability of the GFT prediction results. Similarly, other studies (Dugas et al., 2013; Preis and Moat, 2014; Santillana et al., 2015; Wagner et al., 2018) also found that replacing LR with other non-linear regression models and combining new data sources, including search queries, social media, and traditional data sources, into the prediction model can significantly improve the accuracy of ILI prediction. Sina Weibo is a popular Chinese microblog platform with millions of users voluntarily sharing their lives and thoughts (Weibo, 2020) . The considerable amount of post-data generated by so many users offers the possibility of monitoring and predicting the development of emerging infectious diseases. In this study, all posts made by Weibo users in Wuhan from December 1, 2019, to March 20, 2020, were collected. The dataset spans 111 days and contains the period before the COVID-19 outbreak and its evolution. The dataset contains 38,182,972 posts published publicly by 2,239,450 unique users. Each record of post data contains the post's content, type (whether the post was original or forwarded), time, user nickname, and corresponding encryption ID. If the post was forwarded, the post data contained the original post content (otherwise, it was blank), original time posted, original user nickname, and ID. During the data collection period, the mean number of daily unique users was over 117,000, and they generated more than 343,000 posts every day. On average, each user generated 2.9 posts per day. average of 25,395 posts. The number of posts is highly correlated with the number of daily active users (see Fig. 1c ), and the Pearson correlation score is 0.89 (p < 0.01). Inspired by the high correlation score between the relative frequency of the certain keyword in Weibo posts and daily new confirmed case counts of COVID-19 (see Fig. 4a in Section 4), a new confirmed case prediction algorithm named Weibo COVID-19 Trends (WCT) based on GFT is proposed. The basic algorithm process of WCT and its comparison with GFT are shown in Fig. 2 . Both of the two algorithms are trying to train a regression model to predict the case counts in which the evaluation indicator is the Pearson correlation score (R) between the prediction results and the real case counts. In WCT, GCA is replaced by the genetic algorithm (GA) (Mitchell, 1998) when selecting the keyword set for the best fit of the prediction model. After comparing the performance of different prediction models, the LR model in GFT is selected as the prediction model in WCT. A prior list of 41 keywords (see Appendix Table A ) is compiled firstly to select all posts that contain COVID-19 information, including the pneumonialike epidemic's medical terminology, symptom, and epidemic control measures and organizations. There are 4,761,010 related posts from a total of 38,182, 972 posts from all users (12.47%). Next, the keywords from each post related to the pneumonia-like epidemic were extracted, and a list of 118,572 most commonly used keywords (see Appendix Table B ) were produced. The most frequent 2,000 keywords were chosen based on the absolute frequency for the next analysis. The ""absolute frequency"" of a keyword is the total number of posts containing that keyword since the beginning of the statistical period. Next, the time series of the relative frequency of each commonly used keyword was obtained. The ""relative frequency"" of a keyword on a certain day refers to the number of all posts containing the keyword on that day divided by the number of unique users on that day. The relative frequency of a keyword set (KS), i.e., the sum of the relative frequency of each keyword in the selected KS, was used to train the case counts prediction model and then predict the development of the epidemic. The purpose of KS combination and selection is to find the most epidemic relevant keyword set (MKS) from the list of most commonly used keywords in Weibo posts. This paper is aimed to design a selection algorithm to seek the MKS which could obtain the highest R between the prediction results and the real case counts. Viewing the composition of a KS as analogous to an arrangement of chromosomes, GA is used to select the MKS. The fitness function of GA is to maximize R between the prediction results, yielded from the prediction model, and the real case counts. The process of GA is presented as follows: Step 1 KS initialization. The initial KS group is formed by M KSs, with each KS containing N keywords. Each KS is scored according to the fitness function to maximize R. Step 2 KS update. The new KS is formed through crossover, mutation, and combination of keywords in KS. Each iteration of the algorithm will choose M better KSs based on R for the next generation and the iteration repeats. Step 3 Stop criteria. When the maximum iteration time MG is reached or R is high enough, the algorithm will stop and the program will output the MKS. The flow chart of GA is shown in Fig. 3a . In the implementation process, parameters were set as M ¼ 25 and MG ¼ 100. Then the respect MKS was obtained with N varying from 1 to 50 while fixing the length of MKS (N ¼ 1 to 50), separately. To avoid over-fitting, the training period was set as from December 1, 2019, to January 29, 2020, and the test period was set from January 29, 2020, to February 22, 2020. To evaluate the advantages of GA, the MKS obtained by GCA in GFT was also analyzed. The detailed MKS selection results are presented in Section 4.2. In this section, LR model was applied to predict the number of new confirmed cases using the relative frequency of MKS obtained by GA and a historical case count sequence. The analysis period covers the complete development stage of COVID-19 in Wuhan except February 12 and 13, 2020, due to a change in the criteria for counting diagnoses of the virus. During that period, the number of new confirmed cases increased abnormally. The starting and ending times of the training set and the predicting set are December 1, 2019, to February 21, 2020, and from February 22, 2020, to March 20, 2020, respectively. The case counts series were manually smoothed with a 3-day window length and then used as input data for prediction. There are also two parameters in the fitting process, the duration (D) of the training data and the lag (g) for prediction. For example, a prediction model trained with D ¼ 6, g ¼ 1 is shown in Fig. 3b . In this study, D ¼ 3 was set to ensure adequate training data in the training process, and g ¼ 1 was set to predict the next day's case counts using all information up to date. All training processes apply three-fold cross validation to reduce overfitting. The training and predicting processes are introduced as follows. Training process Model trained ¼ FIT m ðC t ; C tÀg ; C tÀgÀ1 ; :::; C tÀgÀDþ1 ; P tÀg ; P tÀgÀ1 ; :::; P tÀgÀDþ1 Þ where Model trained is the trained model, C t and P t are the case count and number of relative frequency of MKS at time t during the training period, FIT m is the fitting process by inputting training data {C t ; C tÀg ; C tÀgÀ1 ; :::; C tÀgÀDþ1 ; P tÀg ; P tÀgÀ1 ; :::; P tÀgÀDþ1 } to train Model trained . The length of the training window is D and the dimensions of training data is 2D þ 1. The whole training set is {C t ;C tÀg ;C tÀgÀ1 ;:::;C tÀgÀDþ1 ;P tÀg ;P tÀgÀ1 ;:::;P tÀgÀDþ1 } (t increases from 1). Predicting process C t ¼ Model trained ðC tÀgÀ1 ; C tÀgÀ2 ; :::; C tÀgÀDþ1 ; P tÀgÀ1 ; P tÀgÀ2 ; :::; P tÀgÀDþ1 Þ (3) where C t is the case count at time t during the predicting period. Historical data is input as {C tÀgÀ1 ; C tÀgÀ2 ; :::; C tÀgÀDþ1 ; P tÀgÀ1 ; P tÀgÀ2 ; :::; P tÀgÀDþ1 } into the trained model Model trained . Then the prediction result of the case count at time t is output. The length of the predicting window is D and the dimensions of predicting data is 2D. The whole predicting set is {C tÀgÀ1 ; C tÀgÀ2 ; :::; C tÀgÀDþ1 ; P tÀgÀ1 ; P tÀgÀ2 ; :::; P tÀgÀDþ1 } (t increases from 1). Previous research has demonstrated that non-linear regression models, such as the Gaussian Processes, Long Short-Term Memory (LSTM), and so on, can achieve great performance in COVID-19 tracking and prediction (Alakus and Turkoglu, 2020; Lampos et al., 2021) . The performance of LSTM model was also calculated to be compared with LR model. A 4-layer LSTM model was designed with a dropout rate of 0.15. The loss function was mean square error (MSE) and the optimizer was Adam. The number of training epoch ¼ 100 and batch size ¼ 10. The detailed estimated results are provided in Section 4.3. To investigate the relationship between the frequency of COVID-19 related keywords and the number of new confirmed cases per day, the temporal evolution of the keywords with the number of new confirmed COVID-19 cases in Wuhan was analyzed in this section. The direct correlation Pearson score R between the relative frequency of the top 2000 commonly used keywords in Weibo posts and the number of new confirmed cases each day during the whole statistical period was calculated. Most of the correlated keywords are related to the treatment of COVID-19 ('hospitalization', 'physical examination', 'patient', and so on), and a few are used to describe symptoms or conditions (such as 'breathing difficulties', 'cough'). The most correlated keywords are 'hospital beds' (R ¼ 0.84, p < 0.01) and 'Shu Hongbing' (R ¼ 0.78, p < 0.01). Shu Hongbing is the vice president of Wuhan University and husband of the director of the Wuhan Institute of Virology. The latter was involved in a massive discussion and criticism that it stated that the Chinese herbal remedy Shuanghuanglian can suppress COVID-19. The R value, as well as the absolute frequency of the top ten most correlated and uncorrelated keywords, are listed in Appendix Table C . The evolution of the number of confirmed cases of COVID-19 and the relative frequency of the five most relevant keywords are shown in Fig. 4 . It can be seen that the relative frequency of each keyword is very similar to the trend of the number of new confirmed cases, supporting the motivation of tracking COVID-19 with Weibo data. In contrast, the 10 keywords with the weakest correlation ('article', 'new product', '##', 'grandpa Li', 'concert', 'Trump', '19', 'Hubei Economy TV', '2019') were also analyzed. These keywords with low correlation scores have little to do with the symptoms or treatment of COVID-19. GA and GCA algorithm were both used to select MKS. By setting the length of MKS (N) to vary from 1 to 50 and applying LR and LSTM prediction model (D ¼ 3, g ¼ 1) into GA and GCA algorithm, the changes in the indicator R between the prediction results and the real case counts were compared to evaluate the performance of the MKS selection algorithm. Each prediction model adopted three-fold cross validation and then output the average test scores of the training set as R. The MKSs (1 N 50) with the highest R selected by each algorithm are presented in Table 2 . The original Chinese text for keywords in each MKS are provided in Appendix Table D . Most keywords in MKS obtained by GA or GCA algorithm are medical terms directly related to 'isolation', 'CT', 'coronavirus') . It also contains keywords which are not directly related to COVID-19, such as numbers ('14', '17') and personal pronouns ('you'). GA has the feature of retaining the most relevant keywords and automatically outputting MKS with the best performance. The keywords in MKS can be repeated if duplication can make the MKS perform better. It can be found that there are some duplicated keywords in the MKS of GA-related algorithms (see Table 2 ). This is because the KS with duplicated keywords performs best in the iteration process of GA and becomes MKS. Judging from the correlation between the relative frequency of MKS and the daily case count of COVID-19, the performance of GA and GCA is close, but from the R value of the MKS obtained by the two algorithms, GA is better than GCA. The highest test score is obtained by the GA&LR algorithm (WCT) with R ¼ 0.66 (p < 0.01), which is higher than the test score of GFT (i.e., GCA&LR) of R ¼ 0.62 (p < 0.01). In the four combination algorithms, GA&LR (WCT) has the best performance with the average test score R ¼ 0.65 (p < 0.01), while the average test score of GCA&LSTM is the smallest at R ¼ 0.43 (p < 0.01). The variation of R for MKS with different N is shown in Fig. 5a . Notably, GA-based predictions are much more stable than GCA. For GA&LR and GA&LSTM, the correlation scores vary in a very limited range, 0.60 to 0.66 and 0.55 to 0.62, respectively. However, for GCA-based predictions, the correlation scores experienced unexpected large variations. With GCA&LSTM generating the poorest prediction results, the correlation score of GCA&LR can drop to 0.21 when N ¼ 50. In a word, the MKS filtered by GA in terms of predicting daily new confirmed cases is with high agreements to the real data. In addition, the performances of MKSs filtered by GA and GCA (N from 1 to 50) were compared when the fitness function was to maximize the direct R between the relative frequency of the MKS and daily new confirmed case counts. The experimental results further evidenced the superiority of GA in selecting more relevant keyword sets, and it is not sensitive to the length of keywords N (see Figure D8 in Appendix). In this section, the relative frequency of the selected MKS and daily new confirmed case counts were applied to train prediction models and predict the case counts in the whole analysis period with D ¼ 3, g ¼ 1. For each prediction result, R values between the prediction results and the real case counts in the whole analysis period, the training set, and the predicting set, were calculated as the indicators of performance. Note that different from the three-fold cross validation technique used in the previous analysis, the whole data in the training set were used to construct all models in this section. The MKSs with the highest R selected by GA and GCA were used to train the LR and LSTM model, where the lengths of MKS in GCA&LR, GCA&LSTM, GA&LR, and GA&LSTM are N ¼ 35, 37, 44 and 25, respectively (see Table 2 ). The prediction results show that WCT (referred to GA&LR in Fig. 5b ) has a higher prediction accuracy than GFT (referred to GCA&LR in Fig. 5b) . The performance of WCT is R ¼ 0.97 (p < 0.01) during the whole analysis period, all of which are the best among contrast models. While the performance of GFT is R ¼ 0.96 (p < Table 2 The keyword combination and performance of MKS selected by four algorithms. 0.01). The performance in training set (R ¼ 0.98 (p < 0.01)) and predicting set (R ¼ 0.87 (p < 0.01)) of WCT are also the best among the four algorithms. Compared with GFT, which excessively estimated the daily new confirmed cases during the outbreak period (February 4 to February 5, 2020) over 6-8%, WCT breaks through this limitation and the prediction error is constrained with less than 100 cases (0-3%) (Fig. 6a) . The combination of GA and LR effectively overcomes the GFT's shortcoming of over-estimating the epidemic peak value. Besides, in either the training or testing process, WCT constantly outperforms the other algorithms. In contrast, the LSTM model does not perform well in this special task. In both GA&LSTM or GCA&LSTM, the peak number of cases was underestimated by 80% maximumly, and in the late stage of the epidemic, LSTM models overestimated the number of new cases by 10-60% from March 1 to March 22, 2020. In this section, the performances of the WCT algorithm under different parameter combinations were tested to evaluate the effect of duration of the training data (D) as well as the lag for prediction (g). The parameter D is set to change from 1 to 7, implying that the length of the training window increased from one day to a week before the days to be predicted. The parameter g is set to change from 1 to 15, implying that the algorithm attempts to predict the number of daily new confirmed cases on the gth day in the future. The length of MKS when it produces the best performance in the three-fold cross validation for each algorithm is used in this analysis (see Table 2 ). Fig. 7 shows the performance of the four algorithms. The four algorithms all show robustness to the parameter D, especially when g is set in the range of 1-3. When the number of days of historical data used for prediction (D) increases from 1 to 7, the performances of the four algorithms are rather robust, in comparison to the large variation of R in terms of the lag parameter g. Overall, there is a weak tendency of increased performance with larger D, i.e., the prediction model works better when more historical data is included in the training process. When g is small for more recent predictions, the WCT model continues to produce the best result given D is in the range of 2-5. For example, when the algorithm extends the prediction from the next day (g ¼ 1) to the second day (g ¼ 2) with D ¼ 3, the performance of WCT reaches R ¼ 0.97 to R ¼ 0.96, while the R values of GFT are only 0.96 and 0.93, respectively. When g increases from 10 to 12 with a week's historical data being trained (D ¼ 7), the R value of WCT varies in the range of 0.71 to 0.59. On the other hand, GFT only has the R value of 0.59 to 0.51. The four algorithms all show sensitivity to the parameter g. As the number of days to predict cases in advance increases, it becomes more difficult for the model to predict the future based on existing data. Compared to the GCA-based algorithms (GFT and GCA&LSTM), GA-based algorithms (WCT and GA&LSTM) show less sensitivity to changes in the g parameter. For example, WCT can still has a great performance as R ¼ 0.88 (D ¼ 6) when g ¼ 7, while the maximum R of GFT is only 0.78 (D ¼ 7). From the comparison of the prediction effect based on the LR model and the LSTM model, the LSTM model is less sensitive to the g parameter and can still maintain a good performance when g increases. WCT remains to produce the best prediction results among other algorithms when the number of forecast days increases from one to eight days with the highest correlation score from 0.98 (p < 0.01) to 0.86 (p < 0.01). However when g increases to 15, GA&LSTM model can maintain high R as 0.67 Some studies have applied social media dataset to predict new confirmed cases of COVID-19. Qin et al. (2020) used the Baidu search index to predict new confirmed case counts with the performance of R ¼ 0.99 for g ¼ 1. However, this model is of limited practical value as it was not tested for longer term predictions, on the other hand, the WCT can predict case counts in 1-8 days' future with a high R ¼ 0.86-0.98. Lampos et al. designed an unsupervised prediction model using Google Trends data, which can predict newly confirmed case counts with R ¼ 0.83-0.85, ahead of official reports in more than 16 days (Lampos et al., 2021) . However, this model relies on manual construction of keyword set of Google Trends, which is highly subjective. While WCT utilizes GA to select MKS automatically and heuristically, with little human intervention in the MKS selection process. Ayyoubzadeh et al. (2020) also used Google Trends data to predict newly confirmed case counts in Iran. Comparing linear model and LSTM model, they found that the performance of linear model is better than the LSTM model, which is consistent with the conclusion of this study. From the above comparison results of sensitivity analysis, it is clear that the WCT method exhibits relatively stronger robustness to the parameters D and g. It produces the highest correlation scores with short future predictions and can maintain relatively more stable performance for longer future estimates. The authors declare that there are no conflicts of interest. Google Flu Trends (GFT) is a short-term forecasting tool for weekly influenza activity as an auxiliary method of influenza surveillance (CDC, 2020) . It was launched in 2008 with satisfying forecast precision at that time and was further applied to influenza surveillance and early warning systems in many countries (Butler, 2013) . Although Google had improved the details of the algorithm many times in the process of GFT application, due to the impact of a sudden increase in influenza-like illness (ILI) related queries and other factors (Kandula and Shaman, 2019; Lazer et al., 2014b) . The problem of inaccurate prediction of the algorithm has never been solved completely. Finally, Google shut down the GFT flu prediction function in 2015 (GFT, 2015) . The most well-known GFT algorithm is its initial version. With input on the fraction of certain ILI-related search queries from Google and the percentages of ILI physician visits from the US Centers for Disease Control and Prevention (CDC), the GFT algorithm trains a log-odds linear regression model (LR) to estimate ILI incidence. LR uses the log-odds of an ILI physician visit and the log-odds of an ILI-related search query to realizes regression prediction: ILI-related query fraction at time t (i.e., the sum of each query fraction in the selected ILI-related search queries set), α is the multiplicative coefficient, and ε is the error term. Firstly, the model is trained by each of the 50 million candidate common queries separately. It outputs the prediction result of ILI physician visits and the Pearson correlation score between the estimates and the CDC ILI data. Then the aggregated top-scoring queries are used to train the model and the best fit (when the number of keywords n = 45) is selected automatically. The selection of queries from the best fit is called ""the greedy combination algorithm"" (GCA). Finally, the selected queries are used to train the model and predict the ILI physician visits. This approach has successfully estimated the level of weekly influenza activity in the United States from 2007 to 2008 with a mean correlation score of 0.97 and 1-2 weeks ahead of the reports published by CDC. It offers the opportunity to use search queries to detect influenza epidemics and inspires researchers to explore the application of social media data in public health surveillance (Cui et al., 2015; Schmidt, 2012) . Google officially launched GFT (GFT 1.0) in November 2008, and subsequently gained a wide range of popularity. However, in the first wave of influenza A (H1N1) epidemic, that is, from April to August 2009, the predicted incidence of H1N1 was badly lower than the ILI activity reported by CDC (Butler, 2013) . Therefore, Google upgraded GFT for the first time and developed the second version GFT 2.0 (Cook et al., 2011) . GFT 2.0 adjusted the number and category of selected search queries, referring to the ILI monitoring data during the first wave of H1N1 epidemic (March 29 to September 13, 2009). It increased the search query terms and deleted search queries that were not directly related to influenza, which significantly improved the performance of GFT 2.0. Since its launch in September 2009, its prediction result had been very similar to the ILI activity in the United States until 2012. In the influenza epidemic season of 2012-2013, GFT 2.0 greatly overestimated the influenza epidemic with almost twice the result of CDC monitoring (Butler, 2013) . This overestimation led to the second upgrade of GFT (Copeland et al., 2013) . GFT 3.0 was officially launched in October 2013, it made two changes based on GFT 2.0, that is, weakening the impact of abnormal media hot spots and using elastic net to predict ILI (previously based on linear regression). Compared with GFT 2.0, GFT 3.0 significantly reduced the peak amount of its predicted ILI in the 2012-13 flu season. However, its predicted result was still slightly higher than that of CDC in the United States, and in the 31 weeks after the implementation of GFT 3.0, the prediction result was higher in 23 weeks (Lazer et al., 2014a) . The last upgrade of GFT took place in August 2014 (Lampos et al., 2015) . GFT 4.0 expanded the GFT 3.0 model by incorporating the queries selected by the Elastic Net into a nonlinear regression framework, based on a composite Gaussian Process. It also injected the ILI activity data as prior knowledge about the disease into the model. The bias of GFT prediction was significantly reduced. GFT 4.0 was used until August 2015, when Google shut down the GFT prediction service. Because of the important role of ILI surveillance in public health, many researchers are still committed to improving the predictive performance of ILI. Such as correcting the limitations of the GFT algorithm process, updating or adding the training data source of the prediction model, and proposing new prediction algorithms based on GFT. Kandula et al. proposed a corrected GFT algorithm, which uses the estimated value of the original GFT algorithm as new data for training the ILI prediction model, reducing the total prediction error by 44% (Kandula and Shaman, 2019) . This algorithm considers the problem that the ILI data provided by CDC is not timely and incomplete when the GFT algorithm is proposed. It uses complete ILI data and GFT estimates to train the prediction model and replaces LR with an autoregressive integrated moving average (ARIMA) model. The algorithm greatly improves the prediction accuracy and proves the validity and practicability of the GFT prediction results. Similarly, other studies (Preis and Moat, 2014; Wagner et al., 2018; Dugas et al., 2013; Santillana et al., 2015) also found that replacing LR with other nonlinear regression models and combining new data sources, including search queries, social media, and traditional data sources, into the prediction model can significantly improve the accuracy of ILI prediction. Sina Weibo is a popular Chinese microblog platform with millions of users voluntarily sharing their lives and thoughts (Weibo, 2020) . The considerable amount of post-data generated by so many users offers the possibility of monitoring and predicting the development of emerging infectious diseases. In this study, all posts made by Weibo users in Wuhan from December 1, 2019, to March 20, 2020, were collected. The dataset spans 111 days and contains the period before the COVID-19 outbreak and its evolution. The dataset contains 38,182,972 posts published publicly by 2,239,450 unique users. Each record of post data contains the post's content, type (whether the post was original or forwarded), time, user nickname, and corresponding encryption ID. If the post was forwarded, the post data contained the original post content (otherwise, it was blank), original time posted, original user nickname, and ID. During the data collection period, the mean number of daily unique users was over 117 thousand, and they generated more than 343 thousand posts every day. On average, each user generated 2.9 posts per day. Figure 1A summarizes the series of daily quantity of statistical indicators. The number of posts fluctuated greatly, with a peak of 486,073 posts on March 1, 2020, and the fewest posts (119,886) occurring on December 29, 2019. The number of unique daily users and posts per user remains relatively stable around 117 million and 2.93, respectively. Figure 1B shows the number of posts from hour 0 to hour 23 of each day. It is obvious that the number of posts decreases first and then increases from hour 0 to hour 23. The minimum value appears at about hour 5, with an average of 2,085 posts, and the maximum value appears near hour 22, with an average of 25,395 posts. The number of posts is highly correlated with the number of daily active users (see Figure  1C ), and the Pearson correlation score is 0.89 (p < 0.01).  Inspired by the high correlation score between the relative frequency of the certain keyword in Weibo posts and daily new confirmed case counts of COVID-19 (see Figure 4A in Section 4), a new confirmed case prediction algorithm named Weibo COVID-19 Trends (WCT) based on GFT is proposed. The basic algorithm process of WCT and its comparison with GFT are shown in Figure 2 . Both of the two algorithms are trying to train a regression model to predict the case counts in which the evaluation indicator is the Pearson correlation score (R) between the prediction results and the real case counts. In WCT, GCA is replaced by the genetic algorithm (GA) (Mitchell, 1998) when selecting the keyword set for the best fit of the prediction model. After comparing the performance of different prediction models, the LR model in GFT is selected as the J o u r n a l P r e -p r o o f prediction model in WCT. A prior list of 41 keywords (see Appendix Table A) is compiled firstly to select all posts that contain COVID-19 information, including the pneumonialike epidemic's medical terminology, symptom, and epidemic control measures and organizations. There are 4,761,010 related posts from a total of 38,182,972 posts from all users (12.47%). Next, the keywords from each post related to the pneumonia-like epidemic were extracted, and a list of 118,572 most commonly used keywords (see Appendix Table B ) were produced. The most frequent 2,000 keywords were chosen based on the absolute frequency for the next analysis. The ""absolute frequency"" of a keyword is the total number of posts containing that keyword since the beginning of the statistical period. Next, the time series of the relative frequency of each commonly used keyword was obtained. The ""relative frequency"" of a keyword on a certain day refers to the number of all posts containing the keyword on that day divided by the number of unique users on that day. The relative frequency of a keyword set (KS), i.e., the sum of the relative frequency of each keyword in the selected KS, was used to train the case counts prediction model and then predict the development of the epidemic. The purpose of KS combination and selection is to find the most epidemic relevant keyword set (MKS) from the list of most commonly used keywords in Weibo posts. This paper is aimed to design a selection algorithm to seek the MKS which could obtain the highest R between the prediction results and the real case counts. Viewing the composition of a KS as analogous to an arrangement of chromosomes, GA is used to select the MKS. The fitness function of GA is to maximize R between the prediction results, yielded from the prediction model, and the real case counts. The process of GA is presented as follows: Step 1 KS initialization. The initial KS group is formed by M KSs, with each KS containing N keywords. Each KS is scored according to the fitness function to maximize R. Step 2 KS update. The new KS is formed through crossover, mutation, and combination of keywords in KS. Each iteration of the algorithm will choose M better KSs based on R for the next generation and the iteration repeats. Step 3 Stop criteria. When the maximum iteration time MG is reached or R is high enough, the algorithm will stop and the program will output the MKS. The flow chart of GA is shown in Figure 3A . In the implementation process, parameters were set as M = 25 and MG = 100. Then the respect MKS was obtained with N varying from 1 to 50 while fixing the length of MKS (N = 1 to 50), separately. To avoid over-fitting, the training period was set as from December 1, 2019, to January 29, 2020, and the test period was set from January 29, 2020, to February 22, 2020. To evaluate the advantages of GA, the MKS obtained by GCA in GFT was also analyzed. The detailed MKS selection results are presented in Section 4.2.  In this section, LR model was applied to predict the number of new confirmed cases using the relative frequency of MKS obtained by GA and a historical case count sequence. The analysis period covers the complete development stage of COVID-19 in Wuhan except February 12 and 13, due to a change in the criteria for counting diagnoses of the virus. During that period, the number of new confirmed cases increased abnormally. The starting and ending times of the training set and the predicting set are December 1, 2019, to February 21, 2020, and from February 22, 2020, to March 20, 2020, respectively. The case counts series were manually smoothed with a 3-day window length and then used as input data for prediction. There are also two parameters in the fitting process, the duration (D) of the training data and the lag (g) for prediction. For example, a prediction model trained with D = 6, g = 1 is shown in Figure 3B . In this study, D = 3 was set to ensure adequate training data in the training process, and g = 1 was set to predict the next day's case counts using all information up to date. All training processes apply three-fold cross validation to reduce overfitting. The training and predicting processes are introduced as follows. Training process: ,..., ,..., − − + } ( t increases from 1). Predicting process: where t C is the case count at time t during the predicting period. Historical data is input as  To investigate the relationship between the frequency of COVID-19 related keywords and the number of new confirmed cases per day, the temporal evolution of the keywords with the number of new confirmed COVID-19 cases in Wuhan was analyzed in this section. The direct correlation Pearson score R between the relative frequency of the top 2,000 commonly used keywords in Weibo posts and the number of new confirmed cases each day during the whole statistical period was calculated. Most of the correlated keywords are related to the treatment of COVID-19 ('hospitalization', 'physical examination', 'patient', and so on), and a few are used to describe symptoms or conditions (such as 'breathing difficulties', 'cough'). The most correlated keywords are 'hospital beds' (R = 0.84, p < 0.01) and 'Shu Hongbing' (R = 0.78, p < 0.01). Shu Hongbing is the vice president of Wuhan University and husband of the director of the Wuhan Institute of Virology. The latter was involved in a massive discussion and criticism that it stated that the Chinese herbal remedy Shuanghuanglian can suppress COVID-19. The R value, as well as the absolute frequency of the top ten most correlated and uncorrelated keywords, are listed in Appendix Table C . The evolution of the number of confirmed cases of COVID-19 and the relative frequency of the five most relevant keywords are shown in Figure 4 . It can be seen that the relative frequency of each keyword is very similar to the trend of the number of new confirmed cases, supporting the motivation of tracking COVID-19 with Weibo data. In contrast, the 10 keywords with the weakest correlation ('article', 'new product', '##', 'grandpa Li', 'concert', 'Trump', '19', 'Hubei Economy TV', '2019') were also analyzed. These keywords with low correlation scores have little to do with the symptoms or treatment of COVID-19. GA and GCA algorithm were both used to select MKS. By setting the length of MKS (N ) to vary from 1 to 50 and applying LR and LSTM prediction model (D = 3, g = 1) into GA and GCA algorithm, the changes in the indicator R between the prediction results and the real case counts were compared to evaluate the performance of the MKS selection algorithm. Each prediction model adopted three-fold cross validation and then output the average test scores of the training set as R. The MKSs (1≤N≤50) with the highest R selected by each algorithm are presented in Table 2 . The original Chinese text for keywords in each MKS are provided in Appendix Table D . Most keywords in MKS obtained by GA or GCA algorithm are medical terms directly related to 'isolation', 'CT', 'coronavirus') . It also contains keywords which are not directly related to COVID-19, such as numbers ('14', '17') and personal pronouns ('you'). GA has the feature of retaining the most relavant keywords and automatically outputting MKS with the best performance. The keywords in MKS can be repeated if duplication can make the MKS perform better. It can be found that there are some duplicated keywords in the MKS of GA-related algorithms (see Table 2 ). This is because the KS with duplicated keywords performs best in the iteration process of GA and becomes MKS. Judging from the correlation between the relative frequency of MKS and the daily case count of COVID-19, the performance of GA and GCA is close, but from the R value of the MKS obtained by the two algorithms, GA is better than GCA. The highest test score is obtained by the GA&LR algorithm (WCT) with R = 0.66 (p < 0.01), which is higher than the test score of GFT (i.e., GCA&LR) of R = 0.62 (p < 0.01). In the four combination algorithms, GA&LR (WCT) has the best performance with the average test score R = 0.65 (p < 0.01), while the average test score of GCA&LSTM is the smallest at R = 0.43 (p < 0.01). The variation of R for MKS with different N is shown in Figure  5A . Notably, GA-based predictions are much more stable than GCA. For GA&LR and GA&LSTM, the correlation scores vary in a very limited range, 0.60 to 0.66 and 0.55 to 0.62, respectively. However, for GCA-based predictions, the correlation scores experienced unexpected large variations. With GCA&LSTM generating the poorest prediction results, the correlation score of GCA&LR can drop to 0.21 when N = 50. In a word, the MKS filtered by GA in terms of predicting daily new confirmed cases is with high agreements to the real data. In addition, the performances of MKSs filtered by GA and GCA (N from 1 to 50) were compared when the fitness function was to maximize the direct R between the relative frequency of the MKS and daily new confirmed case counts. The experimental results further evidenced the superiority of GA in selecting more relevant keyword sets, and it is not sensitive to the length of keywords N (see Figure D8 in Appendix).  In this section, the relative frequency of the selected MKS and daily new confirmed case counts were applied to train prediction models and predict the case counts in the whole analysis period with D = 3, g = 1. For each prediction result, R values between the prediction results and the real case counts in the whole analysis period, the training set, and the predicting set, were calculated as the indicators of performance. Note that different from the three-fold cross validation technique used in the previous analysis, the whole data in the training set were used to construct all models in this section. The MKSs with the highest R selected by GA and GCA were used to train the LR and LSTM model, where the lengths of MKS in GCA&LR, GCA&LSTM, GA&LR, and GA&LSTM are N = 35, 37, 44 and 25 , respectively (see Table 2 ). The prediction results show that WCT (referred to GA&LR in Figure 5B ) has a higher prediction accuracy than GFT (referred to GCA&LR in Figure  5B ). The performance of WCT is R = 0.97 (p < 0.01) during the whole analysis period, all of which are the best among contrast models. While the performance of GFT is R = 0.96 (p < 0.01). The performance in training set (R = 0.98 (p < 0.01)) and predicting set (R = 0.87 (p < 0.01)) of WCT are also the best among the four algorithms. Compared with GFT, which excessively estimated the daily new confirmed cases during the outbreak period (February 4 to February 5) over 6-8%, WCT breaks through this limitation and the prediction error is constrained with less than 100 cases (0-3%) ( Figure 6A ). The combination of GA and LR effectively overcomes the GFT's shortcoming of over-estimating the epidemic peak value. Besides, in either the training or testing process, WCT constantly outperforms the other algorithms. In contrast, the LSTM model does not perform well in this special task. In both GA&LSTM or GCA&LSTM, the peak number of cases was underestimated by 80% maximumly, and in the late stage of the epidemic, LSTM models overestimated the number of new cases by 10-60% from March 1 to March 22.  In this section, the performances of the WCT algorithm under different parameter combinations were tested to evaluate the effect of duration of the training data (D) as well as the lag for prediction (g). The parameter D is set to change from 1 to 7, implying that the length of the training window increased from one day to a week before the days to be predicted. The parameter g is set to change from 1 to 15, implying that the algorithm attempts to predict the number of daily new confirmed cases on the g th day in the future. The length of MKS when it produces the best performance in the three-fold cross validation for each algorithm is used in this analysis (see Table  2 ). Figure 7 shows the performance of the four algorithms. The four algorithms all show robustness to the parameter D, especially when g is set in the range of 1 to 3. When the number of days of historical data used for prediction (D) increases from 1 to 7, the performances of the four algorithms are rather robust, in comparison to the large variation of R in terms of the lag parameter g. Overall, there is a weak tendency of increased performance with larger D, i.e., the prediction model works better when more historical data is included in the training process. When g is small for more recent predictions, the WCT model continues to produce the best result given D is in the range of 2 to 5. For example, when the algorithm extends the prediction from the next day (g = 1) to the second day (g = 2) with D = 3, the performance of WCT reaches R = 0.97 to R = 0.96, while the R values of GFT are only 0.96 and 0.93, respectively. When g increases from 10 to 12 with a week's historical data being trained (D = 7), the R value of WCT varies in the range of 0.71 to 0.59. On the other hand, GFT only has the R value of 0.59 to 0.51. The four algorithms all show sensitivity to the parameter g. As the number of days to predict cases in advance increases, it becomes more difficult for the model to predict the future based on existing data. Compared to the GCA-based algorithms (GFT and GCA&LSTM), GA-based algorithms (WCT and GA&LSTM) show less sensitivity to changes in the g parameter. For example, WCT can still has a great performance as R = 0.88 (D = 6) when g = 7, while the maximum R of GFT is only 0.78 (D = 7). From the comparison of the prediction effect based on the LR model and the LSTM model, the LSTM model is less sensitive to the g parameter and can still maintain a good performance when g increases. WCT remains to produce the best prediction results among other algorithms when the number of forecast days increases from one to eight days with the highest correlation score from 0.98 (p < 0.01) to 0.86 (p < 0.01). However when g increases to 15, GA&LSTM model can maintain high R as 0.67 (D = 7), while WCT is R = 0.49, D = 7. J o u r n a l P r e -p r o o f Some studies have applied social media dataset to predict new confirmed cases of COVID-19. Qin et al. used the Baidu search index to predict new confirmed case counts with the performance of R = 0.99 for g = 1 (Qin et al., 2020) . However, this model is of limited practical value as it was not tested for longer term predictions, on the other hand, the WCT can predict case counts in 1-8 days' future with a high R = 0.86-0.98. Lampos et al. designed an unsupervised prediction model using Google Trends data, which can predict newly confirmed case counts with R = 0.83-0.85, ahead of official reports in more than 16 days (Lampos et al., 2021) . However, this model relies on manual construction of keyword set of Google Trends, which is highly subjective. While WCT utilizes GA to select MKS automatically and heuristically, with little human intervention in the MKS selection process. Ayyoubzadeh et al. also used Google Trends data to predict newly confirmed case counts in Iran. Comparing linear model and LSTM model, they found that the performance of linear model is better than the LSTM model, which is consistent with the conclusion of this study (Ayyoubzadeh et al., 2020) . From the above comparison results of sensitivity analysis, it is clear that the WCT method exhibits relatively stronger robustness to the parameters D and g. It produces the highest correlation scores with short future predictions and can maintain relatively more stable performance for longer future estimates.@story_separate@In this study, an algorithm called WCT is proposed to predict new confirmed cases of COVID-19. Inputting the number of historical case counts and a comprehensive dataset of Sina Weibo posts by Wuhan users, the number of daily new confirmed cases can be accurately predicted by WCT. This paper applied a genetic algorithm to automatically construct the keyword set and it can consistently outperform the maximum average test score in the training set, higher than that obtained by GCA (0.66 vs. 0.62). The genetic algorithm is more relevant and more stable than GCA in terms of the Pearson correlation score between the prediction results and the real case counts. The relative frequency of related posts filtered by the selected keyword set is then applied to the LR algorithm and obtained the estimates with a high correlation score of 0.97 (p < 0.01) in the whole analysis period one day ahead of the official reports. WCT can accurately predict the development of COVID-19 using only the historical number of cases combined with Weibo post data. Compared with GFT, WCT overcomes the GFT's shortcoming of over-estimating the epidemic peak value. However, since the development of public emergencies on social media is dynamic, one limitation of the WCT model is that it may need to continuously update the keyword set for future situations with the development of public emergencies, to ensure accurate prediction in the later stage of epidemic or other public emergencies, which makes the application of the method challenging. Compared with the prediction results of the classical GFT model, considering the influence of noise and other factors, the prediction accuracy of the WCT model in short-term estimates needs to be further improved. This study offers a promising approach of using Sina Weibo data or other social media data to realize syndromic surveillance-based disease prediction and to increase global awareness of events. It provides a process for mining epidemic development trends from large-scale social media data without too many manual parameters. In the future, the use of WCT can be extended to monitor and track other diseases or public emergencies by inputting social media data. In this study, an algorithm called WCT is proposed to predict new confirmed cases of COVID-19. Inputting the number of historical case counts and a comprehensive dataset of Sina Weibo posts by Wuhan users, the number of daily new confirmed cases can be accurately predicted by WCT. This paper applied a genetic algorithm to automatically construct the keyword set and it can consistently outperform the maximum average test score in the training set, higher than that obtained by GCA (0.66 vs. 0.62). The genetic algorithm is more relevant and more stable than GCA in terms of the Pearson correlation score between the prediction results and the real case counts. The relative frequency of related posts filtered by the selected keyword set is then applied to the LR algorithm and obtained the estimates with a high correlation score of 0.97 (p < 0.01) in the whole analysis period one day ahead of the official reports. WCT can accurately predict the development of COVID-19 using only the historical number of cases combined with Weibo post data. Compared with GFT, WCT overcomes the GFT's shortcoming of over-estimating the epidemic peak value. However, since the development of public emergencies on social media is dynamic, one limitation of the WCT model is that it may need to continuously update the keyword set for future situations with the development of public emergencies, to ensure accurate prediction in the later stage of epidemic or other public emergencies, which makes the application of the method challenging. Compared with the prediction results of the classical GFT model, considering the influence of noise and other factors, the prediction accuracy of the WCT model in short-term estimates needs to be further improved. This study offers a promising approach of using Sina Weibo data or other social media data to realize syndromic surveillance-based disease prediction and to increase global awareness of events. It provides a process for mining epidemic development trends from large-scale social media data without too many manual parameters. In the future, the use of WCT can be extended to monitor and track other diseases or public emergencies by inputting social media data. Appendix C. R and absolute frequency of part of keywords","While incomplete non-medical data has been integrated into prediction models for epidemics, the accuracy and the generalizability of the data are difficult to guarantee. To comprehensively evaluate the ability and applicability of using social media data to predict the development of COVID-19, a new confirmed case prediction algorithm improving the Google Flu Trends algorithm is established, called Weibo COVID-19 Trends (WCT), based on the post dataset generated by all users in Wuhan on Sina Weibo. A genetic algorithm is designed to select the keyword set for filtering COVID-19 related posts. WCT can constantly outperform the highest average test score in the training set between daily new confirmed case counts and the prediction results. It remains to produce the best prediction results among other algorithms when the number of forecast days increases from one to eight days with the highest correlation score from 0.98 (p < 0.01) to 0.86 (p < 0.01) during all analysis period. Additionally, WCT effectively improves the Google Flu Trends algorithm's shortcoming of overestimating the epidemic peak value. This study offers a highly adaptive approach for feature engineering of third-party data in epidemic prediction, providing useful insights for the prediction of newly emerging infectious diseases at an early stage."
"In over one year, approximately 200 million people worldwide were infected with COVID-19, of which 4.3 million have died [1] . The COVID-19 pandemic had a significant negative impact on people's socio-economic lives [2] [3] [4] [5] [6] . Various non-therapeutic measures were adopted to contain COVID-19; however, vaccines were required to control the pandemic and save lives [7] . Vaccination is the most effective method of preventing the spread of an infectious disease [8] [9] [10] . The development of a safe and effective vaccine requires time; however, researchers developed several vaccine candidates against COVID-19 in a short time [11] . By December 2020, 57 COVID-19 vaccine candidates were in clinical trials, with some candidates demonstrating efficacy of as high as 95% in preventing symptomatic COVID-19 infections [12] . Many countries started administering the vaccine in 2021. Successful immunization should reduce the global burden of illness and death, as long as the majority of people receive vaccines [6, 13] . It was recommended that 70% of the population be vaccinated in order to achieve herd immunity against COVID-19 [14] . Xiao and Wong [15] identified several factors responsible for wider vaccine acceptance, including the safety and efficacy of the vaccine, adverse health outcomes, misconceptions about the need for vaccination, lack of trust in the health system, and lack of knowledge among the community on vaccine-preventable diseases. In many countries and regions of the world, large variability in the acceptance of COVID-19 vaccines was reported [16, 17] . Peoples' distrust and unwillingness to receive the vaccine could hinder the management and outcomes of COVID-19 inoculation [18] . In addition to peoples' acceptance, several management-related issues could affect smooth immunization against COVID-19. For instance, Pfizer-BioNtech vaccine must be stored at a temperature of -70-degrees Celsius, which is challenging for technologically poor countries [19] . Other challenges may include the availability of staff to oversee the vaccines, equipment, and vaccinators, data systems to track advancement, and methods of informing people regarding the second dose [7, 20] . Moreover, prioritizing a particular group for vaccination and equitable distribution of vaccine could be further obstacles [21] . Bangladesh reported its first positive COVID-19 case on March 8, 2020 and the total number of positive cases rose to 1249,484 as of August 3, 2021, including 20,685 deaths [22] . The Government of Bangladesh signed the Memorandum of Understanding with the Serum Institute of India to receive 30 million doses of the Oxford-AstraZeneca (Covishield) vaccine. In addition, Bangladesh would receive 11 million doses of the COVID-19 vaccine from the Global Alliance for Vaccines and Immunization (GAVI) under the COVID-19 Vaccines Global Access (COVAX), an initiative of the World Health Organization [23] . Peoples' knowledge about COVID-19 vaccines, level of acceptance, and perception of immunization management issues is likely to affect smooth inoculation and achieving herd immunity. However, previous research on this topic is currently lacking. Therefore, the objectives of this study were to explore the understanding and acceptance of COVID-19 vaccines, and perceptions regarding immunization challenges among people in Bangladesh. This study hypothesized that knowledge of COVID-19 vaccines and acceptance is influenced by respondents' gender, education and residence, such as urban versus rural. The findings of this study provide useful information, which health officials may consider for achieving the expected level of COVID-19 immunization in the country.@story_separate@a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 A cross-sectional design was adopted to explore knowledge and acceptance of COVID-19 vaccines, and perception on challenges of vaccination among Bangladeshi people aged 18 years and above. Both quantitative and qualitative data were collected through an online survey, face-to-face interviews, and in-depth interviews. As questionnaires appropriate for this study, particularly the Bangladesh context, were not available, an original questionnaire was developed for quantitative data collection. A questionnaire was drafted based on the authors' prior research experience and mass media information, which was reviewed by two experts and underwent a preliminary evaluation (pre-test) with 70 respondents. Based on experts' comments and pre-test feedback, some questions were eliminated or rephrased for clarity. The final structured questionnaire consisted of 21 multiple choice questions in four categories: (1) socio-demographic information, including four questions, (2) knowledge of COVID-19 vaccines, including nine questions, (3) acceptance of COVID-19 vaccines, including five questions, and (4) COVID-19 vaccine management, including three questions (S1 Table) . The questionnaire was prepared in English and translated into Bengali, the national language of Bangladesh. In order to validate the questionnaire, six relevant experts were asked to assess its relevance for this study. The relevance of a questionnaire has been widely used to measure content validity [24] [25] [26] [27] . All experts reported that the items (questions) and responses were relevant to achieve the objectives of this study. Study population of this research was Bangladeshi nationals living in the country during the study period. The inclusion criteria were being a Bangladeshi resident aged 18 years or over and living in Bangladesh at the time of the survey. A Google form link was shared through social media, including Facebook, Messenger, and WhatsApp, and respondents were asked to share the link with friends and relatives. In addition, the form was shared through emails with different groups. The form was available from January 24 to February 6, 2021. A total of 1975 responses were collected. Face-to-face interviews were conducted by research assistants using the same questionnaire and following standard operation procedures, such as wearing masks, safe distancing, and maintaining proper hygiene. Interviews targeted respondents with limited Internet access. Following a convenience sampling strategy [28] , respondents were selected in an ad-hoc fashion based on accessibility, following the same inclusion criteria as above. A total of 2200 respondents were interviewed. The response rate was approximately 75%. Each interview took approximately 10 minutes and was conducted at road sides, small bazars, urban slums, agrifarms, and tea stalls. Following COREQ guidelines [29] , seven in-depth telephone interviews were conducted with officials of health administration of Bangladesh (civil surgeons, divisional health directors, medical college hospital directors, and public health experts) to collect qualitative data. One of the authors, who had social medicine expertise, conducted the interviews. Interviews were guided by a check-list consisting of open-ended questions related to the challenges, acceptance, confidence in vaccine management, and the government's future plans regarding vaccine safety. Interviewees were selected deliberately based on their engagement in the public health sector. This study was approved by the ethical review committee of Chittagong Medical College, Bangladesh (Memo No. CMC/PG/2021/130). Participation was voluntary and anonymous, and respondents were informed that they could withdraw from the survey at any time. Informed consent was obtained electronically through the form prior to beginning the questionnaire. For face-to-face interviews, verbal consent was obtained after the aims of the study were explained, and for in-depth interviews, informed verbal consent to participate in this study was obtained before each interview. A total of 4175 responses (1975 online and 2200 face-to-face) were obtained, which was satisfactory at the 95% confidence level with a ±5% margin of error [30] . Israel [31] suggested a sample size of 400 at a 95% confidence level with a ±5% precision level. For α = 0.05 and a hypothesized proportion of 0.5, the power of a sample size of 4175 is 1.0 (calculated using the SigmaXL statistical tool). It was assumed that a sample size of 4175 for this study is adequate to generalize the study findings. This study examined two major outcome measures. First one was knowledge of COVID-19 vaccination of respondents (five dependent variables namely heard about the COVID-19 vaccine, believe that vaccine control COVID-19, dose, side effects, and type of side effects) using gender, age, resident and education as explanatory variables among the respondents. Second outcome measure was opinion of acceptance of COVID-19 vaccine of respondents (five dependent variables namely like to take COVID-19 vaccine; reason-protected from COVID-19; reason-take and control transmission; Bangladesh produces the COVID-19 vaccine, would you take it; and possible side effects and temporary protection) using gender, age, resident, education, believe that vaccination can control COVID-19, dose and type of side effects as explanatory variables. Descriptive statistics (frequency and percentage) of responses were estimated. Binary logistic regression analyses were conducted to assess the association between explanatory and dependent variables. There were few assumptions of running logistic regression. First, logistic regression does not require a linear relationship between the dependent and explanatory variables. Second, the error terms (residuals) do not need to be normally distributed and homoscedasticity is not required. Finally, the dependent variable in logistic regression is not measured on an interval or ratio scale. Odds ratio (OR) with a 95% confidence interval (CI) was used to assess the strength of association, and p-values of less than 0.05 were considered statistically significant. Following Chinn [32] , effect size (expressed as ""Cohen's d"") was estimated to understand the magnitude of relationship between two variables. Explanatory variables with more than two categories were grouped into two ""yes"" and ""no"" categories (S2 Table) . To check model fitness, the omnibus chi-square test was used and all models were found to be highly significant (S3 Table) . The significance value of less than 0.05 indicated that the current model outperformed the null model. In all models, significant chi-square values indicated that the fitted model was better than the null model. In order to report and describe qualitative data, COREQ guidelines were followed. Statistical analyses were conducted using the Statistical Package for the Social Sciences (SPSS) version 16 (SPSS for Windows, Version 16.0. Chicago, SPSS Inc.). Due to the sampling methods, gender balance could not be ensured. Of 4175 respondents, there were more men (n = 2723; 65.2%) than women ( Table 1 ). The distribution of respondents in five age classes was consistent to the age structure of Bangladesh [33] . There was a predominant number of university students (n = 1185; 28.4%), likely due to internet and social media access. As expected, most respondents (n = 2404; 57.6%) were from urban areas, possibly due to higher education and internet access. The results indicated that approximately 93% of the respondents heard or knew about COVID-19 vaccines, largely from television news (68.7%) and social media (38.7%; Table 2 ). The government of Bangladesh took extensive measures to ensure awareness through The results indicated that only 60.5% of respondents were interested in receiving a COVID-19 vaccine (Table 3) , with the majority of them (74.6%) stating that COVID-19 vaccines would protect them from infection and 36.8% opined that the vaccine would reduce or control virus transmission. Respondents who indicated that they did not wish to receive a COVID-19 vaccine reported several reasons, including belief that the vaccine is ""not necessary, I am fine and naturally protected"" (57.4% respondents), ""possible side effects and temporary protection"" (39.9%), and ""religious reasons"" (18.5%). Those interested in receiving a COVID-19 vaccine preferred the Pfizer-BioNTech vaccine (24.4%), while 50.5% did not know about vaccine options. However, 88.8% of the respondents wanted to receive a Bangladeshi COVID-19 vaccine, if available.  The majority of the respondents (53%) believed that security personnel (e.g. Army) would execute immunization properly, while 24.6% believed it would be administered by government hospitals (Table 6 ). During the interviews, a divisional director of health commented that: The health ministry will distribute the vaccine to the public across the country through government hospitals and clinics. We have no plan to include the security personnel in its distribution. Bangladesh has a positive reputation for vaccine management in the world. We hope the Ministry of Health will successfully manage the vaccination program, such as the Expanded Program on Immunization (EPI). We have sufficient vaccine points throughout the country; however, if needed, the government will increase registration and vaccination points. Only 35.4% of respondents perceived that Bangladesh authority would manage the distribution of vaccines properly. However, many of the respondents were concerned with challenges of COVID-19 immunization. For instance, 36.7% of respondents reported that motivating the public to receive vaccine would be a major challenge, followed by cost (35.4%), coordination between ministries and field level centers (26.5%), and storage and transport of vaccines at a low temperature (16.5%). A health ministry official stated that: Until now, educated and high-and middle-income people and various professionals have shown greater interest in receiving vaccines. But Bangladesh faces some challenges: first, ensuring uninterrupted vaccine supply from the source point, as the government planned, for 130 million people to be vaccinated gradually; second: keeping online registration systems active for this mass immunization program in the whole country; third, in order to encourage the public to get vaccinated, the government needs to create various awareness-building plans and programs; fourth, the country needs a good example of co-ordination between the state mechanisms and other agencies for a successful ending. Vaccination against COVID-19 is considered the most effective method to control the COVID-19 pandemic. Successful vaccination and herd immunity among the public depends on peoples' knowledge of COVID-19 vaccines, which may influence vaccine acceptance and proper management. This study attempted to understand Bangladeshi peoples' perceptions of these factors. The results revealed that over 90% of respondents heard about COVID-19 vaccines, although only a small fraction of them knew about the effectiveness, side-effects, and correct doses of the vaccines. This indicated that respondents lacked correct information regarding COVID-19 vaccines, which suggests the need for awareness-building and correct information dissemination programs. An official of the Ministry of Health mentioned: We know many people do not have the correct information regarding COVID-19 vaccines and are confused about whether or not to receive the vaccine. The government has already started a campaign through mass media to eliminate false impressions and hesitancy toward vaccination among the public. Approximately 46.2% of respondents reported believing that COVID-19 vaccines have several side-effects. Previous studies reported COVID-19 vaccine side-effects, such as pain or discomfort, allergic reactions, swelling, fever, chills, tiredness, and headache within 1-3 days after the vaccine is administered [34, 35] . Among vaccine recipients globally, few people were reported to experience severe allergic reactions after receiving the COVID-19 vaccine [36] . A higher official of the Ministry of Health stated: We do not have many records or complains about side-effects after vaccination. A few people may face some problems, such as pain, fever, or allergic reactions after receiving the vaccine. We request vaccine recipients to stay at our observation centers for at least 30 minutes after getting the vaccine. We have every preparation to deal with probable side-effects. Men demonstrated better knowledge of COVID-19 vaccines than women. This is in line with previous studies [18, [37] [38] [39] [40] . Age and level of education had a significant influence on knowledge of COVID-19 vaccines, suggesting that the government should provide extensive motivational programs through various channels, such as mass media and community engagement, to encourage these groups of people to receive the COVID-19 vaccine. Results indicated that only 60.5% of respondents were likely to receive the COVID-19 vaccine. The real rate of vaccination could be lower due to misinformation regarding COVID-19 vaccines and their side-effects on social media, religious beliefs, beliefs in temporary protection, and confidence in self-immunity. Spread of misinformation through multiple channels could considerably affect the acceptance of the COVID-19 vaccine [41] . Therefore, mass awareness programs are crucial in order to create confidence among the public and achieve a 70% vaccination rate to reach herd immunity. Eliminating misconceptions through transparent communication with proper knowledge among people is necessary [38, 42] to reduce the skepticism about vaccination [43] . Higher acceptance rates were reported in India (86.3%), China (89.5%), Malaysia (94.3%), and Indonesia (93.3%) [37, 44, 45] . Countries such as Kuwait (23.6%), Jordan (28.4%), Italy (53.7), Russia (54.9%), Poland (56.3%), the US (56.9%), and France (58.9%) reported lower rates of COVID-19 vaccine acceptance [45] . COVID-19 vaccines acceptance rates below 60% pose a severe problem for controlling the pandemic [45] . Women and rural residents were more interested in receiving the COVID-19 vaccine despite limited knowledge of vaccines. Therefore, the government should provide extensive programs, such as easy vaccination registration and vaccination centers in rural areas, targeting women and rural residents. On the other hand, respondents who believed that vaccine could prevent COVID-19 were approximately 12 times more likely to get vaccinated, confirming that correct information on vaccines is of utmost importance to higher acceptance. Along with socio-demographic characteristics, COVID-19 vaccination may have several challenges, including procurement, distribution, and implementation. The government of Bangladesh drafted a national deployment and vaccination plan to vaccinate 80% of the population in four stages, including ensuring procurement and proper coordination and launching awareness campaigns to address vaccine hesitancy [23] . Bangladesh procured COVID-19 vaccines from several sources and approximately 3.6% population received at least one dose of vaccine and 2.6% population were fully vaccinated by July 4, 2021 [46] . Distribution of vaccines through appropriate organization, setting up priority groups, motivating people, and appropriate infrastructure are important for vaccine management [45] . The results of this study indicated that motivating people to receive the vaccine and coordination among agencies were some of the major challenges to smooth vaccination. Islam and Hossain [47] suggested creating a monitoring team to oversee proper vaccine transportation and storage at the right temperature. An uninterrupted supply chain of vaccines across the country needs to be ensured, with storage methods following the EPI framework. This can be assumed that the quality of the vaccine degrades if it is not properly preserved, transported, distributed, and administered. This study had some limitations. First, respondents were mainly educated people, likely due to access to information and past experience as research participants. People with lower levels of education may feel less confident acting as research participants. Second, respondents participated in this study voluntarily and only those who were interested took part in the survey. As such, gender balance could not be achieved. Third, the participation of rural and urban respondents was unequal, possibly due to urban residents having better access to the Internet. However, these limitations were believed to have no effect on the findings of this study.@story_separate@COVID-19 is a deadly disease that requires therapeutic and non-therapeutic solutions. World leaders face challenges in containing COVID-19 through non-therapeutic solutions, with mass vaccination remaining as the primary solution. Knowledge, beliefs, availability, and distribution of the vaccine pose challenges to mass vaccination. This study found mixed responses regarding level of knowledge and acceptance of the COVID-19 vaccine. Raising public awareness and demonstrating positive aspects of vaccination to the public appears to be most effective in increasing the vaccine acceptance rate. Governments, public health officials, and advocacy groups should address hesitancy and build vaccine literacy to encourage the public to accept immunization. COVID-19 immunization program should be implemented across the country to give rural and urban populations equal opportunity to receive the vaccine. Supporting information S1","In order to eliminate COVID-19, many countries provided vaccinations. However, success depends on peoples’ knowledge levels and rates of acceptance. But, previous research on this topic is currently lacking in Bangladesh. This cross-sectional study aimed at to investigate Bangladeshi peoples’ knowledge, acceptance, and perception of challenges regarding COVID-19 vaccines. Quantitative data were collected using an online survey (n = 1975) and face-to-face interviews (n = 2200) with a pre-tested structured questionnaire. In addition, seven open-ended interviews were conducted with health experts regarding challenges of vaccination. Binary logistic regression analyses were conducted to assess the association between explanatory and dependent variables. Effect size was estimated to understand the magnitude of relationship between two variables. Of 4175 respondents, 92.6% knew about COVID-19 vaccines, while only 37.4% believed vaccines to be effective in controlling COVID-19. Nearly 46% of respondents believed that COVID-19 vaccines have side-effects, and 16.4% of respondents believed that side-effects could be life-threatening. Only 60.5% of respondents indicated that they would receive the COVID-19 vaccine. Out of 1650 respondents (39.5%) who did not intend to receive the vaccine, 948 (57.4%) believed that they would be naturally protected. Regressions results indicated that men had higher rates of knowledge regarding the vaccine. In addition, rural respondents demonstrated lower knowledge regarding the vaccine. Furthermore, education had a significant association with knowledge of COVID-19 vaccines. Respondents with university education had more knowledge regarding the vaccine (Odds ratio, OR = 29.99; 95% confidence interval, CI 11.40–78.90, effect size 1.88; p = 0.01) and correct dosage (OR 27.34; 95% CI 15.25–49.00, effect size 1.83; p = 0.01). However, women (OR 1.16; 95% CI 0.96–1.40, effect size 0.08) and rural (OR 1.24; 95% CI 1.07–1.44, effect size 0.12; p = 0.01) respondents were more enthusiastic regarding receiving the COVID-19 vaccine. Higher educated respondents showed higher probability of receiving the vaccine. Those who believed in the effectiveness of the COVID-19 vaccine were 11.57 times more interested (OR 11.57; 95% CI 8.92–15.01, effect size 1.35; p = 0.01) in receiving the vaccine. Open-ended interviews identified several challenges toward successful COVID-19 vaccination. Mass awareness creation, uninterrupted supply, equitable distribution, and sectoral coordination were suggested to achieve at least 70% immunization across the country."
"The 2019 Coronavirus Disease (COVID-19) is a pandemic that continues to spread and pose an international public health emergency since it was first identified in December 2019. 1, 2 With every passing day, the scientific community continues to learn more about the disease and, in fact, COVID-19-related symptoms continue to be recognized and described. While was initially characterized by symptoms of fever, cough, muscle aches and/or fatigue, dyspnea, headache, sore throat, and gastrointestinal symptoms, 3 olfactory dysfunction (OD) has been reported to be a common symptom of COVID-19. 4, 5 In fact, at this time, OD is well-accepted as a symptom of COVID-19, occurring in approximately 50% of COVID-19 positive individuals. 4, 5 OD has been highlighted as an early symptom of COVID-19, 6 reportedly to occurring at a mean of 3-4 days into the COVID-19 disease course. 7, 8 OD may be the first symptom of COVID-19 in up to a quarter of COVID-19 patients. 9 , 10 As such, OD has been viewed as an early marker of COVID-19 that may be helpful in the early diagnosis of COVID-19, which may consequently reduce spread of the disease. 9, [11] [12] [13] OD has also been proposed to be a prognostic indicator of COVID-19 disease severity. However, there have conflicting reports as to whether OD portends a milder or more severe COVID-19 disease course. 7, 14 The identification of prognostic indicators for the COVID-19 disease course may be important for several reasons. Perhaps most importantly, patients anticipated to have the greatest disease severity could be identified early and treated aggressively. The recent discovery of remdesivir as an antiviral medication for COVID-19 has been an exciting development in the treatment of COVID-19. 15 Other potential antiviral medications for COVID-19 are in clinical trials as well. 16 However, because of the likely scarcity in available doses-which has already . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint been observed for remdesivir-and the likely need to initiate antiviral treatment early in the disease course, predictors of a severe COVID-19 disease course are needed. Herein, we report the results of a multicenter study of COVID-19 patients who presented to 13 hospitals across the Kurdistan province of Iran. The objective of our study was to determine the association of OD with disease severity in COVID-19 patients, with hospitalization used as the metric for severe disease. . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted July 28, 2020. The inclusion criteria for our study included laboratory-confirmed COVID-19 infection (reverse transcription-polymerase chain reaction [RT-PCR] from nasopharyngeal swabs), age greater than 18 years, and the ability to complete the study questionnaire. Exclusion criteria included patients who had a history of OD for more than 1 month before presentation. Patient were directly recruited from hospitals which were specially designated for treatment of COVID-19 patients in Kurdistan province, Iran. Once the patients visited the emergency department of one of these hospitals, they were evaluated and managed based on the contemporary COVID-19 protocol of Iran. 17 At that point, they were also tested for COVID-19 by RT-PCR. Patients were deemed to require hospitalization if they presented with severe shortness of breath, were prescribe to receive non-invasive oxygen therapy, had SpO2<93% or respiratory rate>30. 17 Patients were followed through the end of their COVID-19 course for admission to an intensive care unit (ICU), re-hospitalization, death, or symptomatic resolution of the disease. . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint@story_separate@The questionnaire consisted of three parts: demographic information, medical history, and COVID-19-related symptomatology. Demographic information collected included age, gender, and history of active smoking. Medical history that was assessed included a history of chronic rhinosinusitis and allergic rhinitis. A general medical history was taken specifically to assess for a history of diabetes mellitus, hypertension, heart disease (coronary artery disease or congestive heart failure), cancer, and respiratory disease (asthma or chronic obstructive pulmonary disease). The COVID-19 symptoms that were assessed included the presence of cough, fever, shortness of breath, sore throat, rhinorrhea and headaches at the time of presentation (as a binary variable: yes/no). OD at the time of presentation was assessed as a binary variable (yes/no) and its severity on an 11-point Likert scale ranging from 0 (no OD) to 10 (complete anosmia). The total number of days with symptoms attributable to COVID-19 was also assessed at the time of presentation. We used Statistical Package for the Social Sciences for Windows (SPSS version 25,0; IBM Corp, Armonk, NY, USA) to perform the statistical analyses. The potential associations between epidemiological, clinical and olfactory outcomes have been assessed through cross-tab generation between two variables (binary or categorical variables) and Chi-square test. We used logistic and linear regression to fit a model for anosmia outcomes. Incomplete responses were excluded from the analysis. A level of p<0.05 was used to determine statistical significance. . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint A total of 203 individuals participated in this study. The mean age of the participants was The demographic, clinical, and COVID-19-related characteristics of all participants, and participants stratified by hospitalization status are shown in Table 1 . There was significantly higher prevalence of allergic rhinitis in hospitalized patients (p=0.007). Although the differences in prevalence did not reach statistical significance, there were more patients in the hospitalized group who were active smokers (p=0.059) and a history of heart disease (p=0.061). With respect to COVID-19 symptoms assessed, the cohort of hospitalized more frequently reported all symptoms-OD, cough, fever, shortness of breath, headache, sore throat and rhinorrhea-(p<0.05 in all cases). . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint The prevalence of OD at the time of presentation for the entire cohort (which was at a mean of 6.4 days after onset of COVID-19 symptoms) was 12.3%. OD was reported at the time of presentation in 15.2% of patients who were hospitalized vs. 6.2% of patients who were not hospitalized (p=0.049). Amongst patients who had OD, the mean severity of OD in hospitalized patients was 6.9 (SD: 2.6) while the mean severity of OD in non-hospitalized patients was 8.3 (SD: 5.78), which was not a statistically significant difference (p=0.508). On univariate logistic regression, OD was associated with hospitalization (odds ratio [OR] = 2.47, 95%CI: 1.085 -6.911, p = 0.049). We considered the possibility that this finding was due to differences in the length of time of COVID-19 symptoms before presentation. However, we found no significant difference in the days of COVID-19 symptoms at the time of presentation between the hospitalized group (mean: 6.7 days, SD: 4.3 days) and the nonhospitalized group (mean: 5.1 days, SD: 4.0 days) (p=0.159). We next used a multivariable logistic regression model to check for association between hospitalization (as dependent variable) and OD (as independent variable) while controlling for age, gender, active tobacco smoking, allergic rhinitis, comorbid heart disease, comorbid respiratory disease and comorbid diabetes mellitus. We found that hospitalization was still positively associated with OD (OR=3.22, 95% CI: 0.57-18.31, p=0.188) but while the point estimate for association suggested a possible association on multivariable analysis, this was not statistically significant. We next evaluated the utility of OD as a symptom predictive of hospitalization. In our cohort, the presence of OD had 84.0% sensitivity (95%CI: 63.9% -95.5%) but only 34.3% (95%CI: 63.9% -41.7%) specificity for identifying patients requiring . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint hospitalization. We also evaluated severity of OD at presentation as a predictor of hospitalization and found that severity of OD was not a statistically significant predictor of hospitalization for COVID-19 (AUC = 0.462, 95%CI: 0.251 -0.673, p = 0.834) . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint Although initially underappreciated, OD is now a recognized symptom of COVID-19. 13, 18 In fact, OD has proven to be a clinically informative symptom of COVID-19 in several ways. The presence of OD has been identified as a predictor of COVID-19, both in patients with flulike symptoms as well as those who are otherwise asymptomatic. [19] [20] [21] [22] OD has been shown to be a typically early symptom of COVID-19, occurring in most patients within a few days of the onset of COVID-19. 7, 8 Moreover, OD may be the sole presenting symptom of COVID-19 in up to a quarter of patients. 9 Consequently, OD has been recognized as an important and informative characteristic of COVID-19 with public health utility in identifying otherwise asymptomatic or pre-symptomatic COVID-19 patients who may unknowingly transmit the disease to others. 23 Studies of OD in COVID- 19 have also suggested that OD may have prognostic significance with respect to the subsequent COVID-19 disease course. 7, 14, 24 However, studies reporting the significance of OD as a prognostic indicator of the subsequent COVID-19 disease course have so far been conflicting and therefore data from more centers are needed in this regard. Herein we report the results of a multicenter center study of OD as a predictor of hospitalization for COVID-19 in patients presenting to the emergency departments of thirteen different hospitals in the Kurdistan province of Iran. In our cohort of patients, patients who were hospitalized had a greater prevalence of OD and that OD was a sensitive (84.0%) but not specific (34.3%) predictor of hospitalization for COVID-19. Several studies have reported that OD may be a prognostic indicator of the severity of the COVID-19 disease course. In a retrospective review of 169 patients who tested positive for COVID-19 at their institution, Yan et al reported that hospital admission was associated with an . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint intact sense of smell while OD was associated with outpatient care. 14 In a different study, however, Speth et al performed a cross-sectional study of patients testing positive for COVID-19 at their institution and found that the severity of OD experienced was positively correlated with the severity of shortness of breath experienced by patients, suggesting that OD was associated with a more severe COVID-19 disease course. 7 Consistent with this finding, Benezit et al used a mobile application to study COVID-19 symptoms and found that OD was associated with hospitalization for COVID-19. 24 Given the present dearth of evidence and conflicting reports that exist, we sought to determine whether in our patient population, OD was a predictor of hospitalization for COVID-19. In our cohort of patients, prospectively recruited and evaluated for OD during presentation for COVID-19 at the emergency departments of 13 hospitals in the Kurdistan province of Iran, we also found a higher prevalence of OD in COVID-19 patients needing to be hospitalized compared to those who underwent outpatient management. These patients presented to these emergency departments at a mean of 6 days after the onset of COVID-19 symptoms, with no difference between those who were hospitalized compared to those who were not hospitalized for COVID-19. In our entire cohort, we found the prevalence of subjectively reported OD to be 12.3, which is a lower prevalence than the general 50 -60% prevalence of OD that has been reported in systematic reviews of COVID-19 patients. 4 but closer the 29% prevalence of subjectively reported OD in Iranian COVID-19 patients by Moein et al. 20 Moreover, it is important to note that our cohort of hospitalized COVID-19 patients had a higher prevalence of all COVID-19 symptoms that we assessed than COVID-19 patients who were not hospitalized for COVID-19. Using regression analysis, we found that OD was associated with hospitalization using univariate association. However, while the point estimate for association . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . between hospitalization and OD suggested a positive association on multivariable association, this association was not statistically significant after controlling for confounding demographic and clinical characteristics. Our study results are consistent with the previous studies by Speth et al and Benezit et al who found OD to be associated with more severe 24 In our cohort of patients, those who were hospitalized also had a greater prevalence of all symptoms of COVID-19, not just OD. This is similar to findings by Speth et al who found that OD was associated with more severe COVID-19 symptoms in a Swiss cohort. 7 However, our results-including the finding that the statistically significant association between hospitalization and OD disappears after controlling for comorbidities-also suggest that negatively-prognostic OD (i.e. associating with more hospitalization) occurs in the setting of a greater prevalence of other COVID-19 symptoms and other risk factors for severe disease such as cardiovascular and respiratory comorbidities. Thus while OD as a single variable may be associated with COVID-19 disease severity, other underlying patient characteristics may be more directly responsible for modification of the COVID-19 disease course, which may explain why previous studies have been conflicting. Our study should be interpreted within the constraints of its limitations. First, although this was a multicenter study, all participants were from the Kurdistan province of Iran and subjective OD may be differentially reported than in other parts of the world. All of the patients who participated in our study also were presenting to an emergency department, which suggests that these patients were experiencing more severe symptoms in general, in contrast to other studies that have reported findings for COVID-19 patients with mild to moderate symptoms. Finally, we did not use objective assessment of OD due to limitations of practicality in the setting of emergency department treatment. As reported by Moein et al, who also studied Iranian . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint COVID-19 patients, the subjectively reported prevalence of OD may be significantly lower than OD determined by objective testing. 20@story_separate@Amongst patients presenting to emergency departments for COVID-19, patient-reported OD was more prevalent in those needing hospitalization for COVID-19. However, patientreported OD was a component of a generally higher prevalence of COVID-19 symptomsincluding a greater prevalence of symptoms such as cough, fever, shortness of breath, headache, rhinorrhea and sore throat-as well as other high-risk comorbidities. Patient-reported OD in isolation may be a predictor of more severe COVID-19 and the need for hospitalization, but this association may be driven by other underlying risk factors for more severe disease. . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted July 28, 2020. . is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted July 28, 2020. . https://doi.org/10.1101/2020.07.26.20158550 doi: medRxiv preprint","Objective: To evaluate the association of olfactory dysfunction (OD) with hospitalization for COVID-19. Study Design: Multi-center cohort study. Setting: Emergency departments of thirteen COVID-19-designed hospitals in Kurdistan province, Iran. Subjects and Methods: Patients presenting with flu-like symptoms who tested positive by RT-PCR for COVID-19 between May 1st and 31st, 2020. At the time of presentation and enrollment, patients were asked about the presence of OD, fever, cough, shortness of breath, headache, rhinorrhea and sore throat. The severity of OD was assessed on an 11-point scale from 0 (none) to 10 (anosmia). Patients were either hospitalized or sent home for outpatient care based on standardized criteria. Results: Of 203 patients, who presented at a mean of 6 days into the COVID-19 disease course, 25 patients (12.3%) had new OD and 138 patients (68.0%) were admitted for their COVID-19. Patients admitted for COVID-19 had a higher prevalence of all symptoms assessed, including OD (p<0.05 in all cases), and OD identified admitted patients with 84.0% sensitivity and 34.3% specificity. On univariate logistic regression, hospitalization was associated with OD (odds ratio [OR] = 2.47, 95%CI: 1.085-6.911, p=0.049). However, hospitalization for COVID-19 was not associated with OD (OR=3.22, 95% CI: 0.57-18.31, p=0.188) after controlling for confounding demographics and comorbidities. Conclusion: OD may be associated with hospitalization for (and therefore more severe) COVID-19. However, this association between OD and COVID-19 severity is more likely driven by patient characteristics linked to OD, such as greater numbers of COVID-19 symptoms experienced or high-risk comorbidities."
"Drawing on theories of humanism and structural and cultural ecology, Gesler (1992) introduced the concept of therapeutic landscapes and uncovered the healing and recovery coordination between place and environment (Gesler, 2003) . Therapeutic landscapes are referred to (1) facilities that offer conventional western medical treatments and alternative health treatments, such as naturopathy, cupping therapy, art therapy, mud therapy, etc. (Williams, 1998; Smith, 2015; Majeed et al., 2017a Majeed et al., , 2019a , (2) built attractions, e.g., spa hotels, hospitals, community gardens, etc. (Oster et al., 2011; Adongo et al., 2017; Majeed et al., 2018; Townsend et al., 2018; Ramkissoon, 2020) , and (3) travel destinations with natural features (Palka, 1999) which provide restorative experiences alongside the feeling of comfort and gratitude to individuals seeking health and wellbeing (Hansen et al., 2017) . Research on therapeutic landscapes continues to attract the attention of scholars across different fields including urban planning for landscape development (Rodiek and Fried, 2005) , health geography (Smyth, 2005) , nursing (Kennedy et al., 2004) , psychology (Coghlan, 2015) , holistic medicine (Williams, 1998) , traditional and complementary medicine (Majeed et al., 2017a) , medical tourism (Buzinde and Yarnal, 2012; Majeed and Lu, 2017; Majeed et al., 2018) , public health (Love et al., 2012; Williams, 2014) , and religion (Agyekum and Newbold, 2016) . Therapeutic landscapes are a combination of physical and built environments with human perceptions and social interactions that interact with each other to produce a sense of healing (Gesler, 2003; English et al., 2008) which generates happiness and contributes to the overall quality of life. Life satisfaction, happiness, and quality of life notions are noted as the core constructs of health and well-being (Smith, 2015; Ramkissoon, 2020) or sometimes just well-being. Researchers also examine the contribution of healing places to human health and well-being, which are noted in terms of connections of mind, body, and soul (Townsend et al., 2018; Majeed et al., 2019a) . Wellness and spa tourism is becoming increasingly popular with destination marketers offering a range of products including therapeutic landscapes (Wakefield and McMullan, 2005; Zhou et al., 2017) . These retreats often have state-ofthe-art environmental settings and are well equipped with staff ranging from nutritionists, sports physiologists, and naturopaths whose combined expertise assist in co-creating healing and wellness experiences with customers (Ramkissoon, 2014) . Meeting individuals' expectations and perceptions give a feeling of satisfaction and happiness which are orthogonal to quality of life Majeed et al., 2020a,b) . Researchers have examined the traveling trends of people across the globe with hopes and expectations to find different health and well-being treatments (Smith, 2015; Majeed et al., 2017a Majeed et al., , 2018 Majeed et al., , 2019a . Individuals perceive that traveling to destinations with abundant therapeutic landscapes, such as health resorts, gardens, meadows, lakes, and wellness retreat centers, improves their health and wellbeing. Scholars note the increasing trends in health (medical) and wellness tourism that allow tourists to rest and relax or spend time at therapeutic landscapes after surgery for recuperation (Ramkissoon et al., 2013a; Majeed et al., 2018; Kaspar et al., 2019) . People in the Baltic States report they search to improve their health and well-being by enjoying the spa, being at the beach, and exploring forests (Smith, 2015) . Some scholars mention the healing properties of the sea, trees, and fossil-based treatments at destinations (Dryglas and Salamaga, 2018) . Therapeutic landscapes have attracted significant attention from scholars and practitioners. However, research examining the interplay of relationships between visits to therapeutic landscapes, place attachment, and re-visit intentions to health and wellness tourism destinations is still at an infancy stage. The premise of this scoping review is to explore the associations between these constructs. We further explore how the global health crisis COVID-19 may influence health tourism and wellness tourism. The scoping review aims to examine, first, how do people's perceived goodness of therapeutic landscapes influence their decisions to visit a destination's therapeutic landscapes? Second, what are the associations between people's visits to wellness and health tourism destinations and place attachment? Third, how does a global health crisis impact on visitors' revisitation to health and wellness tourism destinations? We use the present global pandemic COVID-19 as the context. Our objective is to develop and propose a conceptual framework and hypotheses to present the associations between perceived goodness of therapeutic landscapes, health and wellness tourism consumption, place attachment, and re-visitation to therapeutic landscapes and the potential influence of COVID-19 perceived risk on these relationships. This has important implications for future research and practice across different disciplines. We examine the varying concepts of therapeutic landscapes into an integrated research framework that may provide insights to scholars and practitioners in the service industries and assist in the effective management of therapeutic landscapes and in their marketing efforts to attract more national and global visitors. We followed the scoping review technique (Arksey and O'Malley, 2005) to achieve scoping review objectives. Our scoping review of the published literature between 2000 and 2020 addresses the woven connections of sub-constructs of therapeutic landscapes that influence people's perceptions of therapeutic landscapes to improve their health and well-being that may further impact on their place attachment.@story_separate@An initial search was conducted using relevant keywords, such as therapeutic landscapes, health and place, visits to therapeutic landscape, landscapes, health and well-being, and therapeutic landscapes and disasters, in three electronic databases (Google Scholar, Scopus, and Web of Science). To expand the literature searching strategy in a focused way, the reference mining technique was adopted. Reference mining refers to analyzing the references of already searched literature. It allows researchers to find more relevant literature sources quickly from already searched literature in the context of the review (Majeed et al., 2017a) . Relevant keywords were searched in nine databases, including Google Scholar, PubMed, Web of Science, MDPI, Taylor and Francis, Scopus, Springer Nature, Elsevier, and Sage, to search articles and books published between 2000 and 2020. The title, abstract, and keywords of all identified literature were reviewed by the researchers. The difference of opinions on whether to conduct a full or partial review at the initial stage was resolved within the weekly team meetings of the researchers. An in-depth review of the literature was conducted based on the initial findings of the title, abstract, and keywords. We organized, charted, and collated the extracted data of 124 literature sources in a commonly accessible online spreadsheet (see Appendix 1 for full literature spreadsheet). Researchers recorded the emerging themes from the reviewed sources, i.e., title, research approach, and conclusions in brief on the online spreadsheet accessible by the researchers. A total of 124 literature sources were retained after screening and determining the eligibility of the gathered literature (see Figure 1) . A list of searched literature with main notes and extracted themes is presented in Appendix 2. Table 1 shows that searched literature sources belong to different research domains. The majority of searched literature belongs to the field of geography (30.65%) followed by health and wellness tourism (25.81%). Table 2 shows that the majority of searched literature was journal articles (86.29%) followed by book chapters (8.06%) and books (5.65%). Findings of the scoping review are summarized in the next sections. Perceived goodness of therapeutic landscapes involves multidimensional concepts in its breadth and depth (Pitt, 2014; Adongo et al., 2017) calling for more research into the operationalization of the term. Our scoping review sheds further light on the operationalization of perceived goodness of therapeutic landscapes. The notion of individuals' feelings of health, healing, and recovery in tandem with attitudes toward therapeutic landscapes is interpreted as perceived goodness of therapeutic landscapes (Völker and Kistemann, 2011) . The resources of a destination's therapeutic landscapes, whether natural or built, shape visitors' perceptions of feeling well and living well (Bolten and Barbiero, 2020) . Environmental pollution is a pressing concern for people's health as it threatens the ecological infrastructure of a destination (Wang X. et al., 2018) . Our analysis reflects that landscape resources, such as clean water, blue sky, and pollution-free environment, favorably influences people's perceived goodness of therapeutic landscapes that may contribute to their optimal health and well-being (Steinwender et al., 2008) . The quality of the environment determines the quality of human health and the healing process. Scholars across disciplines including geography, public health, and tourism present the concept of therapeutic landscapes in terms of places offering hygienic food, clean hospitals, necessary medical interventions, wellness treatment, clean accommodation, beaches, fresh air, and natural landscapes to boost the anatomical connection of the mind, body, and soul Ramkissoon and Sowamber, 2018; Townsend et al., 2018) . Natural resources, however, may also pose potential threats to individuals' health and well-being because of the length of time consumed in therapeutic landscapes (Adongo et al., 2017) . Therapeutic landscapes are categorized as blue space (Britton et al., 2020) , e.g., beach, river, lake, and spa, and green space, e.g., gardens and groves (Foley and Kistemann, 2015; Bell et al., 2017; Zhou et al., 2017) . People travel to therapeutic landscapes to find blue and green space in warm climates in search of peaceful and distinctive environments suitable to their mind and body (Zhou et al., 2017) . Green space often gives a sense of meaningful purpose in life (Ramkissoon et al., 2013c) and enhances mood and energy (Hansen et al., 2017) . Evidence shows that people travel to parks to find healing, recovery, and confidence; for some, these places provide spectacular landscapes and experiences (Hall and Page, 2002; Ramkissoon et al., 2012) . For example, people express they could feel the healing and recovery in the Denali National Park of Alaska and considers it as an extraordinary therapeutic landscape (Palka, 1999) . Blue and green spaces involve the phenomenon of exposure to natural stimuli; researchers argue it is part of nature therapy due to their preventive medical effects on people's psychological and physical health (Hassan and Ramkissoon, 2020) , such as reducing the risk of stress and mood disorders, hypertension, and heart attack and increasing the feeling of comfort and gratitude (Hansen et al., 2017) . Despite blue space and green space notions, people also travel to deserts and consider the yellow space as an important natural therapeutic landscape promoting their health and well-being. Turpan city desert in China is an interesting destination for seekers of health and wellness; they engage in sand bathing to seek a cure for their respective illness (Wang K. et al., 2018) . Drawing on the above, natural landscape with blue, green, and yellow space may influence individuals' perceived goodness of therapeutic landscapes. People attempt to travel to destinations with a variety of therapeutic landscapes to promote their health and well-being. People travel to community places such as community gardens and hospitals (if needed) to promote their well-being and quality of life (Milligan et al., 2004; English et al., 2008; Love et al., 2012) . Traditional and complementary medicine also supports the healing and recovery impacts of built therapeutic landscapes, such as spiritual retreats and spa town (Oster et al., 2011; Majeed et al., 2017a) . Spa hotels in Estonia are known for the best healing and recovery treatments with medical spa, diet, and rehabilitation (Smith, 2015) . Holy wells, mosques, and churches are also known as built landscapes for healing and recovery of the mind, body, and soul combined with spirituality (Foley, 2010; Agyekum and Newbold, 2016) . Many recovery programs, such as alcohol prevention and recovery, are developed at built landscapes with gardens, medical assistance, and physical exercises to improve the health and well-being of people (Wilton and DeVerteuil, 2006; Love et al., 2012) . Built landscapes may provide physical settings allowing people to interact with nature being brought to them, contributing to their wellness and enhancing their overall life satisfaction. Built landscapes at wellness destinations may influence individuals' perceived goodness of therapeutic landscapes providing satisfaction, happiness, feeling of comfort, a sense of achievement, healing, and recovery, thus promoting visitors' health and well-being (English et al., 2008; Zhou et al., 2017) . Literature on therapeutic landscape shows that landscape design is an important element of perceived goodness of therapeutic landscapes. Water holds special importance in the concept of landscape design (Asakawa et al., 2004) . Natural scenery, such as calm aquatic scenes and gently curving banks, positively influences human feelings of healing and recovery (Asakawa et al., 2004; Steinwender et al., 2008; White et al., 2010) . Landscape design with waterscapes integrates aesthetic and ecological characteristics to amuse and relax humans for their health and well-being in urban areas (Karmanov and Hamel, 2008) . The Spa Town in Buxton in the peak district in the United Kingdom is known to attract visitors to its water festivals (Maxfield and Wiltshier, 2019) . Landscape design helps to satisfy individuals with cheerfulness and promote health and well-being (Myers, 2020) . The structural biodiversity of therapeutic landscapes, such as trees, vegetation, architecture, history, symbols, wildlife, and water, gives the feeling of healing, recovery to individuals traveling for health, and well-being (Yamashita, 2002; Townsend et al., 2018) . Landscape design with distinctive features fuels individuals' perceived goodness of therapeutic landscapes which can enhance place attachment. Therapeutic networks are external supporting factors to ensure individuals' health and well-being at healing and recovery places. Therapeutic networks sometimes function at a microlevel, including doctors, paramedical staff, and practitioners of traditional and complementary medicine (Smyth, 2005; Majeed and Lu, 2017; Majeed et al., 2018) . Therapeutic networks also function at a macro-level, including hospitals, asylums, gardens, towns, regions (Andrews, 2004; Andrews et al., 2005; English et al., 2008; Majeed et al., 2017a) , and supporting service providers, such as the hospitality industry. For instance, the accommodation, food and beverage suppliers, and shopping stores provide the necessities to assist health and wellness visitors (Smyth, 2005; Majeed and Lu, 2017; Majeed et al., 2018) . Scholars discuss the concept of therapeutic mobilities in terms of supporting therapeutic factors, such as pharmaceuticals, gifts, paramedical staff, information, and narratives, which unfold through the network of regions and markets to develop an infrastructure to improve the therapeutic capacities of a destination's landscape (Kaspar et al., 2019) . Such human and non-human elements exist at the therapeutic landscapes to assist individuals seeking health and well-being benefits. Religious centers, resorts, spa towns, caves, hot springs, bath houses (Dryglas and Salamaga, 2018) , drug-treatment centers, alcohol prevention facilities, neighborhood treatment settings, and home-alike health centers (Love et al., 2012) coordinate together to deliver healing and recovery services to individuals. These healing and recovery service providers and therapeutic service actors (see Kaspar et al., 2019) further extend the understanding of a broader infrastructure of therapeutic networks that may influence individuals' perceived goodness of therapeutic landscapes. Evidence suggests that individuals' health and well-being are linked to the environment, both natural and built, for healing and recovery (Hall and Page, 2002; Steinwender et al., 2008; Adongo et al., 2017; Majeed et al., 2018) . Perceived goodness of therapeutic landscapes encapsulates the enduring healing of physical and mental health with a combination of treatment of illness and landscape (Gesler, 1992 (Gesler, , 2003 . The associated combination of place and treatment for illness is documented in health geography, medical tourism, and wellness tourism literature (Majeed et al., 2017a) . The notion of holistic medicine involves place-based treatments with traditional and complementary medicine, such as naturopathy, homeopathy, spa, cupping therapy, art therapy, touch therapy, and mud therapy, in botanical gardens and beaches (Williams, 1998; Majeed et al., 2017a Majeed et al., , 2019a . Therapeutic landscapes often help to maintain health with the healing effects of place, including blue and green environmental settings (Adongo et al., 2017) . Activities at therapeutic places help to balance the biodiversity of the mind, body, and soul (Smith and Puczkó, 2014) . Placebased wellness treatments, such as mud therapy (especially with sea mud), Ayurveda, and acupuncture, may positively influence wellness (e.g., treatment for beauty enhancement) and health (e.g., treatment of underlying health conditions) (Smith, 2015) and in turn promote place attachment. Individuals' preferences for travel and optimal well-being are noted in terms of lifestyle treatments, such as cosmetic surgery or plastic and reconstructive surgery, to perform better in their everyday matters (Majeed et al., 2019b) . Soft environments in healing places, e.g., hospitals with polite medics and facilities to accommodate patients' family and friends, are considered conducive to individuals' healing and recovery (Williams, 1998) . Singapore General Hospital and Mount Elizabeth Hospital are examples of adopting a holistic medicine approach showcasing a soft environment to patients for them to relax and bring a feeling of good health for quick recovery. Associations between human feelings, expectations, and perceptions of therapeutic landscapes play an important role in physical and mental health which is referred to as 'mind landscape.' This is because the cohesion of human psychological filters with the surrounding environment and visualization produces imagery to sketch the mind landscape (Williams, 1998) . Holistic medicine offers treatments which are place-based. Williams (1998) and Cremers (2020) documents that sense of place points to the feelings of family life, aesthetics, identity, and security which transcends over a passage of time with a longer stay at a particular place. Ramkissoon et al. (2013c) investigate place attachment with sub-dimensions of place dependence, place identity, place affect, and place social bonding in a national park setting in Australia. Individuals with high place affect experience a sense of psychological well-being (Ramkissoon et al., 2013b) . Place attachment in nature-based settings also positively influences visitors' quality-of-life (Brown and Raymond, 2007; . A strong sense of attachment to the place may lead to enduring therapeutic effects on individuals' health and well-being. Such concepts are deeply linked to therapeutic landscapes with natural and built environments (Gatrell, 2013) . For example, temples, mosques, churches, and asylums belong to different religious beliefs; people visiting religious places may assign positive meanings to the place leading to healing and recovery. The association of a place with the health and well-being enhancement is referred to as psychological rootedness (Gesler, 1992) in literature. Some evidence suggests individuals travel to remote reputable therapeutic places for optimal health and well-being (English et al., 2008) . Ancient sites, e.g., Epidaurus in Greece, the hot springs of South Dakota, and spiritual retreats in Lourdes, France, are some examples to illustrate the links between visitors' health and wellness and place attachment (English et al., 2008) . Improvement in individuals' physical and mental health may ensure life satisfaction, happiness, and quality of life (Gatrell, 2013; Majeed et al., 2019a) . Studies on human perceptions and behaviors note individuals' may experience positive feelings due to favorable trade-offs between their expectations and perceptions (Liamputtong and Suwankhong, 2015; Majeed and Lu, 2016; Majeed et al., 2020a,b; Saqib et al., 2020; Xue et al., 2020) . Health and well-being are determined by the psychological interplay of individuals' expectations and perceptions of blue and green spaces (e.g., Völker and Kistemann, 2011; Ramkissoon, 2020) , which further impact their travel decisions (Ramkissoon and Mavondo, 2015; Smith, 2015; Majeed et al., 2020b) . Attention restoration theory presents that individuals' directed and fascinated attention determines their actions to overcome complex impressions of everyday life (Stigsdotter et al., 2010) . Individuals' attention exhausts quickly in the absence of appropriate recovery opportunities. People recover well in a comfortable environment. Restorative environments include traveling to places where the feeling of connectedness (humanenvironment bond) (Ramkissoon et al., 2013b) , compatibility (human needs and supporting resources at the host place) (Nunkoo and Ramkissoon, 2016) , and fascination (attraction and uniqueness of host place) (Jiang et al., 2017) are fulfilled (Stigsdotter et al., 2010) . The aesthetic-affective theory presents that natural environments contain the stimulus that restores individuals' more positive views of himself/herself and his/her capacities with decreased stress (Stigsdotter et al., 2010) . Individuals' visits to destinations' therapeutic landscapes are determined by their intrinsic motivations which originate through the interplay of perceptual filters to find health and well-being benefits (Jeuring and Becken, 2013; Liamputtong and Suwankhong, 2015) . The theory of therapeutic landscapes suggests that human health and well-being is a place-based concept (Gesler, 1992) , suggesting people find healing benefits in connection to place (e.g., land, sea, forest, and cities) and develop an emotional bond with these environmental settings (Ramkissoon et al., 2013a; Ramkissoon et al., 2013c) . Emotions have a strong influence on human behaviors and develop an emotional attachment with a person, object, and environment (Majeed et al., 2017b) . This emotional bond between people and place is commonly known as place attachment. Place attachment originates from attachment theory (Bowlby, 1982) depicting the mother-infant bond. This relationship expands to include other relationships with social, natural, and built environments, including therapeutic landscapes. Ramkissoon et al. (2013a,b) argue that individuals develop a sense of place dependence, place identity, place affect, and place social bonding as their relationships expand. Individuals may be place-dependent on therapeutic landscapes as these settings serve their functional purpose (Stokols and Shumaker, 1982) , and the visitors might not want to substitute this place for another. People may also feel a sense of identity with therapeutic landscapes due to their distinctive features (Proshansky, 1978; Ramkissoon and Mavondo, 2015) . Individuals may form social connections at therapeutic landscapes which can assist greatly in their mental well-being. People coming together may collectively create meanings (Nye and Hargreaves, 2010) at the therapeutic landscapes which promote relaxation and other mental and physical health benefits (Ramkissoon et al., 2013b) . Some evidence show associations of natural and built therapeutic landscapes help to alleviate individuals' stress and promote a sense of health and well-being. This may in turn promote place attachment to therapeutic settings . The combined philosophies of the attention restorative theory and the aesthetic-affective theory, therapeutic landscape theory, and place attachment theory provide theoretical support for our proposed theoretical model. People's feelings of the likelihood of being a victim of COVID-19 have fueled perceived risk in travel which may impact negatively future travel decision-making. Health and wellness tourism destinations are likely to be highly impacted. Despite the healthenhancement attractions of visits to therapeutic landscapes, perceived risk of the likelihood of a health-related crisis, such as COVID-19, can disrupt the balance of individuals' favorable perceptions, visit/re-visit intentions (Novelli et al., 2018) . The Greek word ""krisis"" coined the term ""crisis"" which means decision, choice, or judgment. Different research contexts interpret ""crisis"" differently. Scholars note ""crisis"" in terms of ambiguous cause and effect that threatens organizational viability, reputation, and individuals' lives with the belief of quick resolution (Pearson and Clair, 1998) . Destination crisis is also noted in terms of events that lead to adverse situations (Seymour and Moore, 2000) . Improper understanding of destination crisis may undermine consumers' confidence in the service provider's competence for business and society (Laws and Prideaux, 2005) . COVID-19 pandemic may impact individuals' visits to health and wellness destinations. Scholars note that health crises in the past, such as Middle East respiratory syndrome coronavirus (MERs-Cov) in the Middle East, severe acute respiratory syndrome (SARs) in South East Asia, EBOLA in Africa, foot and mouth disease in the United Kingdom, and influenza pandemic in Mexico, increased tourists' doubts on the credibility of epidemichit destinations and discouraged them to visit or re-visit such destinations for health and well-being benefits (Pine and McKercher, 2004; Wilder-Smith, 2006; Mao et al., 2010; Pavli et al., 2014; Baker, 2015; Novelli et al., 2018) . Risk is noted as an important factor which shapes human decision making (Rittichainuwat and Chakraborty, 2012; Ramkissoon, 2018) . Different people perceive traveling risks differently (Aro et al., 2009) . Individuals' visits to destinations' therapeutic landscapes are tightly linked to health, healing, recovery, and longevity. Scholars note that health crises exert long-lasting negative impacts on re-visits to destination's therapeutic landscapes (Tse, 2006) . Overall life satisfaction is important for the health and well-being of our people (Townsend et al., 2018; Majeed et al., 2019a Majeed et al., , 2020b . Individuals' visits to destination's therapeutic landscapes and resultant health and well-being benefits are associated with experiences derived from healthy places; epidemic-hit places may discourage re-visitation. COVID-19 is likely to have a huge impact on the health and wellness tourism consumers and providers. Previous research examined different aspects of therapeutic landscapes across different research contexts (Smyth, 2005; Love et al., 2012; Coghlan, 2015; Majeed et al., 2017a Majeed et al., , 2018 . Our review of individuals' perceived goodness of therapeutic landscapes reflects the core constituents of therapeutic landscapes which may impact health and well-being tourist consumption which may in turn influence place attachment. We further explore perceived risk of COVID-19 and its associations with the interacting phenomena of therapeutic landscapes promoting health and wellness tourism. Perceived goodness of therapeutic landscapes involves different service platforms in its breadth and depth to ensure individuals' health tourism, wellness tourism, place attachment, and re-visits to destinations' therapeutic landscapes. Individuals seek natural landscapes, built landscapes, good landscape designs, and therapeutic networks for managing and improving their health and well-being. They may get emotionally attached to such places encouraging re-visits. However, this is likely to be disrupted by the current COVID-19 public health crisis. COVID-19 pandemic perceived health risk may exert its negative influence on the respective relationships between perceived goodness of therapeutic landscapes and health tourism, wellness tourism, place attachment, and re-visit to destination's therapeutic landscapes. Based on our scoping review of extant literature, we develop an integrative theoretical framework (Figure 2) . Figure 2 presents that visitors' perceived goodness of therapeutic landscapes positively impacts health and wellness tourism consumption and place attachment. Further, our model posits that visitors' place attachment positively influences their re-visit to the destination. The relationship between perceived goodness of therapeutic landscapes, health and wellness tourism consumption, place attachment, and re-visit to destination's therapeutic landscapes is negatively impacted by COVID-19 pandemic perceived health and wellness risk. A total of 40 items are borrowed from extant literature to measure the proposed constructs in this scoping review (see Table 3 ), i.e., perceived goodness of therapeutic landscapes (six items), wellness tourism (eight items), health tourism (six items), place attachment (nine items), re-visit to destination (five items), and COVID-19 pandemic perceived health risk (six items). Hinkin et al. (1997) present a seven-step process for scale construction. We developed scale items for each construct as presented in Table 3 , which were needed to support idea generation and to start the process of developing a new scale for therapeutic landscapes and health and wellness tourism consumption in the context of health pandemics, such as COVID-19. We note that the content adequacy assessment with factor analytical technique alongside a comparison of mean scores is needed (Hinkin et al., 1997) . It is suggested to pretest this new scale with an adequate sample of health and wellness tourism consumers. A minimum sample size of 100 is suggested on a seven-point Likert scale to examine discriminant, convergent, and criterion-related validity (Hinkin et al., 1997) . We suggest researchers employ an exploratory factor analysis for the scale measurement. Our review is the first to develop and propose a single integrative model exploring associations between perceived goodness of therapeutic landscapes, health and wellness tourism consumption, place attachment, and re-visitation to therapeutic landscapes and the potential influence of perceived risk of the global health pandemic COVID-19 on these relationships. An understanding of therapeutic landscapes from the broader spectrum of healing and recovery elements to promote individuals' health and well-being, place attachment, and revisitation to health and wellness tourism destinations remains scant in the literature. Our scoping review shows that the literature on therapeutic landscapes examined different perspectives of healing and recovery places where the focus of research is on one or more aspects of the therapeutic landscape. With a focus on individuals' perceptions of the goodness of therapeutic landscapes, our review attempts to propose the concept of therapeutic landscapes that is not confined within a particular research domain. The proposed integrated theoretical framework may serve as a roadmap to develop new theoretical understandings across different disciplines including geography; tourism; marketing and management; psychology; sociology; conventional medical, traditional, and complementary medicine; and public health. The present review makes important contributions to landscape management, public health, place attachment and health tourism, and wellness tourism literature. Our review further contributes to the body of knowledge in understanding the perceived health impacts of COVID-19 on visitors' travel decision making to health and wellness tourism destinations  Therapeutic landscapes with natural resources will help to find better mental and physical health. Asakawa et al., 2004; Smith, 2015 Therapeutic landscapes will provide better caring environment than expected. Smith, 2015 Therapeutic landscapes will help to strengthen immune system of the body. Kennedy et al., 2004 The environment of therapeutic landscapes will be good for rest, sleep, and rehabilitation. Kennedy et al., 2004 Therapeutic landscapes with a supporting network of people and services will help in quick healing and recovery. Kennedy et al., 2004; Rodiek and Fried, 2005; Zhou et al., 2017 Therapeutic landscapes will provide aesthetic services (e.g., alternative treatments, diet and exercise plan, etc.). Wellness tourism Visiting and staying at a destination's therapeutic landscapes helps me perform well in my daily life activities. Kennedy et al., 2004; Rodiek and Fried, 2005 Visiting and staying at a destination's therapeutic landscapes allows me to spend happy time with other people. Kennedy et al., 2004; Rodiek and Fried, 2005 Visiting and staying at a destination's therapeutic landscapes helps me to feel refreshing. Kennedy et al., 2004 Time spent at a destination's therapeutic landscapes makes my life enjoyable. Kennedy et al., 2004; Rodiek and Fried, 2005 Visiting and staying at a destination's therapeutic landscapes helps me to feel positive energy. Kennedy et al., 2004 Visiting a destination's therapeutic landscapes helps me to find peace of mind, body, and soul. Rodiek and Fried, 2005 Staying at a destination's therapeutic landscapes helps me to maintain a good mood. Kennedy et al., 2004; Rodiek and Fried, 2005 Visiting and staying at a destination's therapeutic landscapes helps me to feel the renewal, restoration, and rejuvenation. Health tourism Visiting and staying at a destination's therapeutic landscapes helps me to live longer. Kennedy et al., 2004; Rodiek and Fried, 2005 Visiting and staying at a destination's therapeutic landscapes helps me to improve my physical health. Kennedy et al., 2004; Larsen et al., 2009 Visiting and staying at a destination's therapeutic landscapes helps me to improve my mental health. Larsen et al., 2009 Staying at a destination's therapeutic landscapes allows me to relax mentally and physically. Smith, 2015 Visiting and staying at a destination's therapeutic landscape helps me to find desired health treatments. Majeed et al., 2018 Visiting and staying at a destination's therapeutic landscape helps me to find valuable healthcare than the care available in other health facilities/destinations. Majeed et al., 2018 Place attachment For the activities that I enjoy most, the settings and facilities provided by this place are the best. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 For what I like to do, I could not imagine anything better than the settings and facilities provided by this place. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 I identify strongly with this place. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 I feel a strong sense of belonging to this place and its settings/facilities. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 This place means a lot to me. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 This place says a lot about who I am. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 I am very attached to this place. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 My friends/family would be disappointed if I were to start visiting other settings and facilities. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 If I were to stop visiting this place, I would lose contact with a number of friends. Ramkissoon et al., 2013a,b,c; Ramkissoon and Mavondo, 2015 (Continued) Frontiers in Psychology | www.frontiersin.org I worry that I might be exposed to the risk of contagious diseases. Dolnicar, 2007 I do not worry about the happening of epidemics at the host destination. Larsen et al., 2009 During traveling to a destination, I constantly worry that something may go wrong. Larsen et al., 2009 A thermometer to measure fever will help to monitor my health and protect myself from disease (if any). Revisitation to destination's therapeutic landscapes I will re-visit a destination's therapeutic landscapes to find healing places. English et al., 2008 I will re-visit a destination's therapeutic landscapes to find refuge for health optimization. English et al., 2008 I will re-visit a destination's therapeutic landscape to find like-minded people for exercise and fun. English et al., 2008; Zhou et al., 2017 I will re-visit a destination's therapeutic landscapes for healing and recovery than stand-alone facilities. I will re-visit a destination's therapeutic landscapes to feel healing power of nature. English et al., 2008; Larsen et al., 2009 during and post the COVID-19 global health crisis. Another contribution is the proposed scale measurement items to test the proposed framework. Our review shows that individuals travel to therapeutic landscapes offering a combination of natural and built landscapes, landscape design, holistic medicine, and therapeutic network to promote their health and well-being. Visitors expect to improve their well-being and quality of life Ramkissoon, 2011a,b, 2012) with health and wellness tourist offerings (Beirman, 2003; Smith, 2015) . Policymakers may draw from our conceptual framework (Figure 2 ) for the development of therapeutic landscapes with health and wellness attractions matching travelers' expectations. Bringing nature to people will promote quality of life and healthy nations, hence contributing to the sustainable development goals (Ramkissoon, 2016 (Ramkissoon, , 2020 . While people's place attachment to health and wellness tourism destinations may have possibly encouraged re-visitations in a pre-COVID-19 context, the global health crisis is likely to influence visitors' health risk perceptions and may impact negatively on tourist demand (Pine and McKercher, 2004) . Destination marketers and policymakers will need to invest further efforts and resources in promoting destination image and place attachment during and after COVID-19. The health of people depends on environmental health demanding urgent actions on the protection of our biodiversity Ramkissoon, 2020) . While COVID-19 has threatened human health, failure to address calls to protect therapeutic landscapes will continue to jeopardize both human and environmental health. Stakeholder engagement (Nunkoo and Ramkissoon, 2013; Ramkissoon and Sowamber, 2020) is essential in managing therapeutic landscapes and promoting health and wellness tourism. DMOs, therapeutic service providers, and governments need to collaborate (Hristov and Ramkissoon, 2016; Hristov et al., 2018; Naumov et al., 2020) to develop and implement effective measures to deal with health crises such as COVID-19 and other crises and disasters at the pre-crisis stage, during, and post-crisis stage. This is important to sustain the health and environment sectors, tourism and hospitality businesses, and other niche industries to meet people's health and well-being needs, hence promoting place attachment and re-visitation. Therapeutic landscapes and more inbound visits may show visitors' trust in the destination's therapeutic landscapes and contribute to sustainable economic growth. We recommend that future researchers test and validate our proposed framework. Scale items presented to measure the constructs under investigation are subject to content adequacy assessment, pre-test questionnaire administration, factor analysis, internal consistency assessment, and construct validity to conclude a final set of scale items for future empirical research. We identified different underlying concepts of therapeutic landscapes and developed an integrative conceptual framework in the ongoing scenario of COVID-19 global health pandemic. Future research may extend the scope of the proposed framework with additional constructs. Literature on COVID-19 presenting its impacts on health and wellness tourism consumption is at a development stage. Although our research provides significant support to develop the literature on the role of COVID-19 in the promotion of health and wellness tourism, we encourage future research to consider other literature on COVID-19, health and wellness tourism, and place attachment, which have been published as of the date of this review, to build on our initial conceptual model in this emerging field. This review introduces the concept of built landscapes which is related to the holistic medicine approach involving exercises, medical treatments, service providers' caring attitudes at hospitals, and ambient environmental settings to address health and wellness tourists' preferences. However, cultural landscapes, such as museums, or places with architecture goods might also impact on visitors' well-being (good moods and happiness). We encourage future research to analyze the impact of cultural landscapes on health and wellness tourism consumption. Due to the language proficiency of the researchers of this review, relevant literature was searched in English databases. There might be relevant and important literature on therapeutic landscapes in non-English databases. Future research may attempt to find relevant literature from non-English databases and may interpret them into English to fertile the grounds of theory and practice discussed in this review. SM and HR: conceptualization, literature gathering, literature analysis, development, revisions, and proofreading of the manuscript. Both authors: contributed to the article and approved the submitted version. The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fpsyg. 2020.573220/full#supplementary-material@story_separate@Health and well-being promotion are linked to the constellation of services available at therapeutic landscapes. The ongoing COVID-19 pandemic has influenced pre-defined health and wellness philosophies. A deeper understanding of people's perceptions of their physical and psychological needs in times of crises and disasters is essential. This may help to advance recovery of health and wellness tourist destinations, promote place attachment, and encourage re-visitation. Health and wellness tourism service providers will likely face challenging times post the COVID-19 pandemic. There is a need to revitalize the underperforming elements of health and wellness tourism destinations during COVID-19 and have further crisis management and recovery strategies in place.","Therapeutic landscapes encapsulate healing and recovery notions in natural and built environmental settings. Tourists’ perceptions determine their decision making of health and wellness tourism consumption. Researchers struggle with the conceptualization of the term ‘therapeutic landscapes’ across disciplines. Drawing on extant literature searched in nine databases, this scoping review identifies different dimensions of therapeutic landscapes. Out of identified 178 literature sources, 124 met the inclusion criteria of identified keywords. We review the contribution and the potential of environmental psychology in understanding tourist behavior to promote health and wellness tourism destinations in a post COVID-19 context. We develop and propose a conceptual framework comprising: (1) perceived goodness of therapeutic landscapes, (2) health and wellness consumption, (3) COVID-19 pandemic perceived health and wellness risk, (4) place attachment, and (5) re-visitation. We propose measurement scales and discuss implications and major issues in the immediate and post the COVID-19 pandemic to inform future research."
"During the last three decades, video games have become one of the major pastimes and one of the most growing industries worldwide (Sepehr & Head, 2012) . 67% of all Americans play video games, for example. This is a highly varied phenomenon, ranging from primary games to highly advanced 3D ones, and is an increasingly frequent activity worldwide. Today, computer games include sophisticated virtual worlds, online competitions, and multiplayer strategic games. In 2008, the American National Purchase Diary (NPD) group reported that 3% of the 174 million players using PC, MAC, or game consoles were extreme gamers who are playing an average of 45 h a week. NPD reported that the percentage of extreme gamers had increased to 4% by 2010 (https:// www. npd. com/). The internet gaming disorder (IGD) is a growing and prolonged behavioral pattern of gaming leading to behavioral and cognitive syndromes. It is the increasing loss of control over gaming, tolerance, and the presence of withdrawal syndrome. The addicts are usually 12 to 20 years old and spend 8-10 h a day or more playing video games. Preventing them from playing can lead to tension and anger and they may spend long stretches of time playing without food and sleep (American Psychiatric Association, 2013) . According to the reports given by scientists and psychologists, gamers are increasing their playing time to a problematic degree. Investigations have also shown that, in some cases, gaming may seriously damage subjects' school, work, and social relationships in the real world. Even though video gaming has some positive effects (including good concentration, memory, and solving skills), researchers have shown that excessive use of computer games may lead to negative effects like stress, aggressive behavior, verbal memory deficiency, depression, lowered cognitive abilities, sleeping disorders, anxiety and, behavioral addiction. Moreover, clinical evidence has shown that subjects addicted to online games experience biopsychological symptoms and complications. These symptoms may include the traditional symptoms of drug addiction such as hangover, changes in mood, adaptability, withdrawal, conflict, and recurrence symptoms. On the other hand, Given the increasing advancement of technology and, subsequently, computer games, the prevalence of this abnormality in societies can be expected. Thus, there is a growing need for further investigation of this phenomenon and its potential effects on people. The first study about video gaming addiction was done by Ross, Finestone, and Lavin, who referred to it as ""space invader obsession"" (Ross et al., 1982) , 10 years after the first video game release. Soper and Miller are pioneers in calling this disorder a kind of addictive behavior (Soper & Miller, 1983) . The first assessment and questionnaire was conducted by Kimberly Young (Young, 1998) . In 2013 after numerous studies with a variety of methods, DSM5 defined internet gaming disorder as addictive behavior. According to the Diagnostic and Statistical Manual of Psychiatric Disorders (DSM-5), computer-based or online gaming addiction is a preoccupation with playing games. It usually includes a group of players, often resulting in several consequences within 5 to 12 weeks (American Psychiatric Association, 2013). Working memory plays an important role in facing addiction; thus it is unfavorably affected by addiction. Therefore, studying the consequences of gaming addiction on working memory is one of the interesting research subjects; however, it needs careful task designing. In task designing, it is important to just peruse a function by controlling other functions as much as possible (Hollnagel, 2003) . Thus, a mental calculation task is considered a cognitive task. Related to working memory, a mental calculation is a routine, everyday ability that everyone possesses, regardless of their level of education. Moreover, focusing on the working memory, we tried to limit brain activity in other areas like auditory and visionary activities. Consequently, we assessed and compared the working memory of two groups via a mental calculation task. Neurobiological differences have been discovered between healthy controls and individuals with Internet Gaming Disorder using PET, VBM, fMRI, rsfMRI, and EEG studies. As a popular technique in the assessment of the neurobiological differences, EEG is used to compare (i) excessive and addictive gaming, (ii) gaming addiction and other comorbid disorders, and (iii) gaming addiction (miscellaneous). Brain dynamics are highly complicated, having multiple spatial-temporal scales. Thus, non-linear dynamics methods have been used to analyze the brain's neurophysiological outputs. Stochasticity, determinism, causation, and correlations of neurodynamics are epitomized and quantified on the complexity measures of brain waves and other biosignals data of the brain. Causality, correlation, and stochastic phenomena turn QEEG data into a complex time series. There are several lines of evidence suggesting that this aspect of the brain waves is influenced by cognitive disorders. Thus, various complexity measures have been put forward to analyze EEG data, including measures developed using random fractal theory, information theory, and chaos theory. Gao et al. Have described the different approaches to analyzing the complex dynamics. They distinguish between chaos and random phenomena. Chaos theory considers irregular behaviors in a complex system. These behaviors are deterministic and are caused by only a few degrees of freedom. Here, noise or intrinsic randomness is not of primary concern. In contrast, randomness is the pivotal principle of random fractal theory and information theory. They consider the dynamics of the system to be inherently random (Gao et al., 2007) . While long-range correlations form the subject of random fractal theory, short-range correlations are considered in information theory. in their study on the relations among different complexity measures for EEG, Gao et al. "" found that the variations of these complexity measures with time are either similar or reciprocal."" (Gao et al., 2011) . In what follows, the salient steps of our study will be presented.@story_separate@Feature extraction is the process of transforming original data to remove redundant or irrelevant information and producing a much smaller and more manageable data set of more discriminator variables. The goal of feature selection, however, is to reduce overfitting, improve accuracy, and decrease training time. After feature extraction and feature selection, the resulting features are valuable if they are highly correlated with the class and uncorrelated with each other. Hence, we are interested in the feature subset containing the minimum number of features that contribute to accuracy the most. Fractal theory can be used to extract features from a series. The Higuchi Fractal Dimension (HFD) algorithm is a method for measuring the fractal dimension of discretetime sequences (Higuchi, 1988; Kesić & Spasić, 2016) . It is a criterion of the complexity and self-similarity of the signal. where m is initial time; k is the time interval in the way that m = 1, 2, …, k. L(m, k) is the length of each time series: is a normalization factor and the average length is computed as This procedure is repeated k max times for each k from 1 to k max . This results in an array of mean values L(k). Then, a least-square method is used to find the slope of the line that best fits the curve of ln(L(k)) versus ln(1/k). That slope is the Higuchi Fractal Dimension. HFD is a scalar feature. It is noteworthy that the selection of k max could strongly influence the results. Fuzzy set theory was first introduced by Zadeh (1965) . This theory renders classification flexible by allowing partial set membership rather than binary, 0 or 1, membership. The fuzzy function maps the membership degree of an element for a given set to a real value in between [0,1]. There are some feature selection methods based on the Partition generator function that comes from the fuzzy set idea. This study is aimed at finding a simple approach with a low computational cost approach for discovering associations between clinical issues and modification of complexity of the neuronal activity. We expected to find the brain waves of healthy individuals to differ from gaming addicts. Therefore, the chaotic behavior of brain electrical activity was investigated through a time-domain analysis and extracting the fractal-like features of EEG signals. In line with our previous studies and to keep the approach simple and decrease the computation steps, we calculated the HFD for the total EEG signals (without focusing on any specific frequency band) was calculated (Roozbehi et al., 2020) . Finally, the EEG signals obtained were classified based on these fractallike features. We believe our research is more valuable as the COVID-19 lockdown has caused people to be at a higher risk of gaming addiction disorders. This experimental case-control study was carried out on video game addicts and normal individuals living in Tehran. Thirty participants were recruited from 14 to 20 years old boys from two gaming centers using available sampling. To exclude individuals with any learning or mental disabilities, the experimental group was screened and all participants were interviewed by a qualified psychologist. Finally, 3 subjects were excluded due to their Symptom Checklist-90-Revised (SCL-90-R) scores while 7 others were excluded based on their Video game addiction test (VAT) scores. 20 participants were selected as addicted gamers. Twenty subjects were randomly selected from normal students aged 14 to 20. Eventually, two groups of 20 participants (addicted and normal) were formed. Ethical authorization for research was received through letter No. IR.TUMS.VCR. REC.1395.1562 from the Ethics Committee of the Vice-Chancellor of Research of Tehran University of Medical Sciences on January 29, 2017. The inclusion criteria for the study included males 14 to 20 years of age and the exclusion criteria included an SCL-90-R score higher than 1 and a VAT score less than 2.5. The following questionnaires were used as research tools: This questionnaire is a tool for the rapid assessment of subjects' mental pathology. It is a 90-item questionnaire assessing 9 psychological dimensions including physical complaints, obsession, and coercion, interpersonal sensitivity, depression, anxiety, aggression, phobic anxiety, paranoia, and psychosis. The validity and reliability of the Persian translation of this test were confirmed in Iran by Bagheriyazdi et al. (1994) and its re-test reliability was ascertained at 0.97 within a week's interval. This test was taken by all participants via a trained psychologist in a clinical interview. Those scoring higher than 0.77 in each item were excluded from the test. The anxiety subscale was of special interest in exclusion as it may affect arousal activity and the brain's electrical activity. The mean ANX score was 0.44 (± 0.24) for the control group, while the addicted group scored 0.48 (± 0.22)-a seemingly insignificant difference. There are several instruments to assess gaming addiction. Among the questionnaires designed to detect Internet and gaming addiction, the The Compulsive Internet Use Scale (Meerkerk et al., 2009; Van Rooij & Prause, 2014; Van Rooij et al., 2011) . However, the Van Rooij video game addiction test was the one finally employed since DSM-5 has introduced criteria to detect Internet addiction and Internet gaming: brain drain, withdrawal complications, compatibility (more time spent playing games), lack of control, loss of other interests, using despite negative consequences, temptation, changes in mood, loss of a job, relationship, or other important aspects of life and compatibility was not considered in the first two questionnaires (American Psychiatric Association, 2013). The validity and reliability of the translated version of this questionnaire were investigated in an article entitled ""Psychometric Properties of the Persian Translation of the Video Gaming Addiction Test (VAT)"" (Hosseini et al., 2019) . The subjects in both groups underwent EEG testing in three steps, each lasting 3 min. The test was performed using the 21-channel EEG system (Medicom; Russia, sampling rate: 256 Hz) by qualified personnel and according to guidelines of recording location and situations. The electrodes used consisted of Fp1, Fp2, F3, F4, C3, C4, P3, P4, O1, O2, F7, F8, T3, T4, T5, T6, FZ, CZ, PZ, and all electrodes amplitudes were evaluated relative to the earlobes (A1, A2) (Fig. 1) . The recordings were taken between 9 and 13 o'clock, with each recording taking about 20 min, including preparation and cleanings. This experimental design included three parts; resting state, open eye state, and cognitive task. The working memory was selected for assessment, as the main target of the lesion in addiction. Based on prior studies, mental calculations and arithmetics are related to working memory. As such, the working memory function is one of the main components of cognitive ability. In accordance with the literature on working memory and mental calculation and to reach a pure activation of working memory, here the visuospatial working memory and verbal working memory omission subvocal task was preferred. To achieve working memory function in arithmetics, a complex calculation is more preferable to a simpler one, because in a simple calculation the solution is retrieved from long-term memory instead of working memory. Another important factor in designing tasks and choosing a routine arithmetic fact 1 was removing the effect of expert and non-expert strategies in problem-solving, which leads to the activation of different brain areas. In the first stage, each participant was asked to sit in a relaxed state and close his eyes. He was also asked to not think of anything and refrain from moving his body. In the second stage, he was asked to look at a point marked on the opposite wall without blinking and or moving. In the third stage, the participant was asked to act as he did in the second stage but to also count down by 3 s from 1000 mentally and as fast as possible. The final statistical population of this study comprised 40 subjects (20 addicts + 20 controls). All of the participants of the IGD group were between 14 and 20 years old, living in Tehran, and all right-handed (based on the Edinburgh Handedness Inventory). A clinical psychologist conducted all the diagnostic interviews for the primary assessments of participants. As mentioned in the previous sections, DATA was recorded from the surface of the scalp of participants according to a standardized electrode placement scheme. The next step was signal pre-processing. After that, data analysis was performed using a machine-learning approach. The machine learning perspective consists of five parts: (1) pre-processing; (2) feature extraction; (3) feature selection and dimensionality reduction; (4) classification; and (5) post-processing. In this study, we applied a machine learning approach and let the model filter the features. Therefore, the data obtained from all channels were used to extract and select the most relevant features. The fractal dimensions were extracted using the HFD algorithm as the features which epitomize the obtained data. Moreover, feature selection was applied based on fuzzy set theory using the partition membership filtering technique and was used to select the subset of features. Supervised machine-learning classification using support vector machine (SVM) method was applied for feature selection. Waikato Environment for Knowledge Analysis (WEKA), a non-commercial and open-source data mining system was utilized for this purpose. To calculate these feature vectors for all instances, WEKA's PartitionMembershipFilter was employed, which can apply any partition generator to a given dataset. Signal preprocessing was performed on the recordings obtained from all 19 channels for each participant according to the following steps via EEGLAB v.2019: (1) Artefact Detection and removal: EEGLAB was used to remove the artifacts of the recorded EEG signals. To this aim, from the ""Tools"" menu ""Remove baseline"" and ""Reject data using Clean Raw data and ASR"" options were used to remove artifacts. (2) To remove out-of-band noise, the EEG time series were filtered within a range of 1-60 Hz using a Finite Impulse Response (FIR) filter. (3) EEG Re-referencing: In this study, a common average referencing was used, i.e. the average of all channels. (4) Line noise suppression was performed using a notch filter at 50 Hz. (5) Bad channels or missing channels were repaired by replacing them with the average of all neighbors (interpolation). (6) Ran ICA to detect components of each signal in each channel. (7) Removed the components originated from undesired sources like electrocardiography (ECG) and electromyography (EMG) to prepare artifact-free EEG signals. During the preprocessing steps, some records were detected as being corrupted or disturbed; therefore, the final numbers of analyzed participants of different groups were as follows: Healthy and closed eye (Hec) = 20; Healthy and open eye (Heo) = 17; Healthy and calculation task (Hct) = 17; Addicted and closed eye (Aec) = 17; Addicted and open eye (Aeo) = 18; Addicted and calculation task (Act) = 18. After preprocessing, for each channel of each participant, a total of 44,700 records (equals 179 s) were kept. However, the HFD algorithms converted this series into two scalars. Therefore, we had 19*2 = 38 features for every participant. The fractal dimensions were extracted via the HFD algorithm with k max = 8. These features were filtered and combined through WEKA's Partition Membership method before using SVM and MLP as two salient methods of supervised machine learning algorithm and classification problems divide the participants into different classes. The results are displayed in Table 1 . The independent t-test used to compare two groups in each channel revealed meaningful differences 2 channels: the O2 channel (p.value b = 0.0339) in open-eye state and the F4 channel (p.value a = 0.027, p.value a = 0.006) in closed-eye state. Meaningful differences with two points level (0.05) found in another two channels: at P4 channel (p.value b = 0.0529) in closed-eye state and F3 channel (p.value b = 0.0524) in closed-eye state. Finding an appropriate method to recognize individuals addicted to gaming with neuroimaging devices is an important matter that eases the process of diagnosing the disorder and facilitates the treatment process. EEG is relatively lowcost, easy to use, and portable, making it is a very good fit for everyday clinical needs. Thus, in the current study, the brain waves and working memory of IGD individuals and normal people were compared. To this aim, QEEG data were obtained in 3 different situations and the Higuchi complexity-measure and Partition Membership Filter were applied. Based on the analysis, it was possible to classify the participants with acceptable accuracy. There are studies conducted to find a neurophysiological marker for IGD. Park et al. have proposed the heightened phasic synchrony in the gamma band during the resting state as a marker of IGD . Son et al. suggest using lower absolute beta power as a potential trait marker for IGD (Son et al., 2015) . In another study, Park et al. found significantly higher intrahemispheric fast-frequency coherence among IGD patients and proposed using it as a neurophysiological trait marker for these patients (Park et al., 2018) . We tried to diagnose IGD based on the change in a complexity measure of whole QEEG data; as it is a more practical method and easier to use. Moreover, we find it a more reliable method as other suggested markers are not shown to be consistent. When it comes to interpreting EEG data, researchers have a wide range of analytical tools at their disposal (Dauwels et al., 2010; Delorme & Makeig, 2004) and in recent years they have explored some new correlations between different measures of complexity (Cao & Slobounov, 2011; Dauwels et al., 2010; Sitt et al., 2014; Šušmáková & Krakovská, 2008; Weiss et al., 2011) . The fractal dimension (FD) of a signal is a measure for describing its complexity and self-similarity in the time domain. The fractal dimension of EEG was calculated using Higuchi's algorithm, which displayed the best result for EEG and other electrophysiological data. The Higuchi algorithm was run with the maximal 10 scales and k max = 8 parameters. The Higuchi complexity-measure and Partition Membership Filter have proven a good method for diagnosing IGD simply and more accurately. According to Table 1 , it has been shown with 95% accuracy that our finding is a good result for differing individuals with IGD and normal people. Several resting-state EEG studies related to behavioral addiction have also been conducted. Lee et al. used EEG data to compare individuals having gambling disorders with normal people, in resting-state and open-eye states . Son et al., used the same method to compare individuals with IGD, AUD, and healthy controls (Son et al., 2015) . Lee et al. conducted an eye open to eye closed comparison in another study to find patterns associated with comorbid depression in Internet addiction (Lee et al., 2014) . We have used the same method but added recording during a cognitive task as other studies have reported alternation in the cognitive abilities of IGD patients (Batthyány et al., 2009; King et al., 2013; Peng & Liu, 2010) . Moreover, we compared the complexity of brain waves in the three aforementioned states and observed the following differences: (1) A significant difference in the opened-eye state at the O2 channel. This alternation of brain wave complexity in the right occipital region has not been previously reported in brain imaging studies. (2) A significant difference in the closed-eye state in channel F4; Lin et al. had previously reported alpha band alternation in this channel in addicts (Lin et al., 2010) . (3) A nearly significant difference in the closed-eye state in channel P4. The P4 electrode was placed in the right Parietal and Angular gyri (BA39) and such alternation have been previously reported using fMRI in resting state. (4) A nearly significant difference in the closed-eye state in channel F3; previously, Lin et al. had observed alpha band alternation in this channel in addicts (Lin et al., 2010) . The differences in P4 and O2 channels suggest asymmetrical differences in the right-sided parieto-occipital areas of the brain in gamers. The P4 area (right 39th Brodman) represents the right angular gyrus which is involved in visuospatial processing. Also, the O2 area (right 18th Brodman) illustrates the right side V2 area, involved in visuospatial information processing. It seems visuospatial processing (activation of the right parieto-occipital area) might be considered as an important neuro marker for gaming addiction. This research is a single-sex study due to the gaming centers in Iran accepting only male players, which can be considered as the limitations of the study. Also, the number of participants and their age range were limited. Moreover, observed differences in the delta pattern, potentially, indicate the early onset of learning disorders, to ensure the occurrence or absence of this complication in addicts people do not affect our results it is better to measure this issue with tests. Machine-learning methods only show differences between pre-defined groups. They can not provide insights into the physiological mechanisms of the brain and reveal the causal interactions responsible for observations. For example, the complexity changes in the brain waves could be related to better 3-D rotating tasks after gaming. Thus, like other classification studies, this study only proposes that the complexity of the brain waves has changed due to gaming. Hence, it is important to design molecular biology studies to find out the details and reasons for the observations. On the other hand, a longitudinal study should be designed to assess the working memory before and after gaming addiction and find out the changes in brain waves in terms of time. It is a reasonable hypothesis that the dynamics of EEG are inherently random and variations of complexity measures of these signals are either similar or reciprocal with time. To assess the effect of games on this complexity, an experimental case-control study was carried out on computer game addicts and normal individuals in Tehran. EEG data was obtained from each participant in both groups in three steps (resting state, open eye state, and cognitive task), each lasting minutes. The fractal dimensions were extracted using the HFD algorithm and the Partition Membership method. The extracted features were then filtered and combined to prepare the inputs of the support vector machine (SVM) and MLP classifier. Finally, without focusing on any special band, we found statistically significant changes in P4, F3, and F4 channels in the closed-eye state and the O2 channel in the open-eye state. The differences in the brain waves may indicate a pre-existing difference in the gamers' brains or a neurophysiological change in the brain as a result of playing 3-D games. Further research should be conducted to explore these findings.@story_separate@Brain waves are the result of the brain's neurodynamic processes. Hence, these changes in brain waves are the signs of a neurophysiological change in the brain. A combination of Higuchi complexity-measure and PartitionMembershipFilter can help classify IGD and normal participants with 95% accuracy as a simple and low-cost method that demonstrates the importance of the brain wave complexity as an EEG data feature. On the other hand, the findings of this study strongly indicate that gaming addiction, as a cognitive disorder, has associated brain wave alterations. Given the ongoing COVID-19 pandemic, people tend to stay more at home and, as such, are in more danger of gaming addiction disorders. Thus, an accurate investigation of cognitive disorders and gaming addiction is vital.","To compare the pattern of brain waves in video game addicts and normal individuals, a case–control study was carried out on both. Thirty participants were recruited from 14 to 20 years old males from two gaming centers. Twenty healthy participants were gathered from different schools in Tehran using the available sampling method. The QEEG data collection was performed in three states: closed-eye and open-eye states, and during a working memory task. As expected, the power ratios did not show a significant difference between the two groups. Regarding our interest in the complexity of signals, we used the Higuchi algorithm as the feature extractor to provide the input materials for the multilayer perceptron classifier. The results showed that the model had at least a 95% precision rate in classifying the addicts and healthy controls in all three types of tasks. Moreover, significant differences in the Higuchi Fractal Dimension of a few EEG channels have been observed. This study confirms the importance of brain wave complexity in QEEG data analysis and assesses the correlation between EEG-complexity and gaming disorder. Moreover, feature extraction by Higuchi algorithm can render support vector machine classification of the brain waves of addicts and healthy controls more accurate."
"When COVID-19 appeared in Wuhan in December 2019 and started to spread rapidly all around the world, concern about its course in patients with autoimmune diseases including MS and neuromyelitis optica spectrum disorder (NMOSD) arose. The effect of immunomodulatory drugs and other possible risk factors on the course of this new enemy had to be evaluated as soon as possible. The results would influence clinical decisions that would have a long-term impact due to the chronicity of the diseases and the long-lasting effects of some treatments. Already reported data indicates that the majority of MS patients have a mild course. Risk factors associated with worse clinical severity seem to be similar to that of the general population Mares and Hartung, 2020; Möhn et al., 2020; Salter et al., 2021; Sharifian-Dorche et al., 2021; Sormani et al., 2021) . However, the effect of immunomodulatory therapies on the course of COVID-19 has not been satisfactorily elucidated yet. As for NMOSD, reports on COVID-19 infection are scarce, but the available data (Alonso et al., 2021; Ciampi et al., 2020; Creed et al., 2020; Fan et al., 2020; Louapre et al., 2020b; Sahraian et al., 2020; Zeidan et al., 2020a) indicates a high proportion of hospitalized patients and a high mortality rate among these patients. The aim of this study was to evaluate the incidence, severity and risk factors of the more severe course of COVID-19 among MS and NMOSD patients when the Czech Republic is one of the countries with the highest number of COVID-19 infected people per capita. The large homogenous cohort based on the Czech nationwide registry of MS and NMOSD patients (ReMuS) may help to clarify COVID-19 characteristics among MS and NMOSD patients and help with clinical decisions about prevention, treatment and vaccination.@story_separate@This was a multicenter, retrospective, observational cohort study of patients with MS or NMOSD with laboratory-confirmed infection by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The data were collected via registry ReMuS from March 1, 2020 , to February 28, 2021 ReMuS was established by the Endowment Fund IMPULS (""NF IMPULS,"" n.d.). The guarantor of expertise of this registry is the Section for Neuroimmunology and Liquorology of the Czech Neurological Society. The estimated number of MS patients in the Czech Republic is 20,000, ReMuS represents all 15 Czech MS centres and approximately 80% of Czech MS patients. The ReMuS is based on informed consent, thus it is possible to use retrospective data for scientific and research purposes without requiring new approvals. All patients signed an informed consent form for inclusion in ReMuS. Inclusion criteria for analysis were (1) MS or NMOSD, (2) a COVID-19 diagnosis based on a positive result of a SARS-CoV-2 polymerase chain reaction test (PCR) or positive antigen test or positive serological test and (3) known outcome of acute illness (return to normal activities or end of self-isolation in asymptomatic cases; or death). Data were collected by healthcare professionals retrospectively from the first contact until an outcome, taking as baseline the day of symptoms appearance or positive laboratory test (if earlier). The collected data set was based on the Global Data Sharing initiative COVID-19 core data set (Peeters et al., 2020) and the experience of MS clinicians and epidemiologists. Data on demographics, MS, immunomodulatory treatment, COVID-19 course, comorbidities and basic laboratory parameters were obtained (Table 1, Table 5 ). The primary endpoint was the participant´s clinical status at the most severe point of their COVID-19 course (on an 8-point ordinal scale), referred to as the COVID-19 severity score, where 1 indicated the asymptomatic patient; 2 the symptomatic patient; 3 patient with suspected pneumonia defined by both dry cough and shortness of breath; 4 patient with radiologically confirmed pneumonia (chest X-ray/CT scan); 5 need of supplemental oxygen; 6 need of non-invasive ventilation or high flow oxygen therapy (HFOT); 7 need of invasive ventilation or extracorporeal membrane oxygenation (ECMO); and 8 death. The whole analysis was applied to MS patients. Cohort characteristics were summarized using mean (SD) for continuous variables and frequencies (%) for categorical variables. Data were compared between patients without radiologically confirmed pneumonia  corresponding to COVID-19 severity scores 1-3) and patients with radiologically confirmed pneumonia, resp. COVID-19 severity scores of 4 or more (more severe COVID-19). Our ""more severe COVID-19 course"" corresponded to a ""moderate"", ""severe"" and ""very severe COVID-19 course"" according to the World Health Organisation (WHO) definition (World Health Organisation, 2020). We did not use any data imputations. Comparison between groups was made using t-test and χ2 as appropriate. Two-sided P values were considered statistically significant at .05. Univariate logistic regression models were performed on relevant identified variables to assess their association with COVID-19 outcome (mild vs more severe COVID-19). Because of the prior comparison between mild and more severe COVID-19 groups as well as prior reports of an association between B-cell depleting antibodies with an increased risk of worse COVID-19 courses (Sormani et al., 2021) , we categorized disease-modifying treatment (DMT) into 3 groups: rituximab and ocrelizumab (anti-CD20), no current DMT and other DMT (reference). Subsequently, a multivariate logistic regression model was performed to determine which variables were independently associated with more severe COVID-19. Variable selection was based on univariate logistic regression. Associations were reported using odds ratios (ORs) and 95% CIs. Additional analyses were focused on the anti-CD20. We performed 1:2 propensity score matching. Patients treated with anti-CD20 were matched with patients treated with other DMT by determined variables from a previous multivariate logistic regression model. Association with more severe COVID-19 was reported using OR and 95% CI. We also investigated the effect of the duration from the last anti-CD20 infusion and the effect of the time since therapy started. Sensitivity analyses were run by repeating all analyses using a leave one out procedure, rerunning the analysis excluding one of the largest MS centres (Prague 2, Prague 5, Teplice) at a time. Data analyses were performed in R version 4.0.2. Due to the small sample size of the NMOSD patient cohort, we used just descriptive statistics for them. As of February 28, 2021, 958 MS laboratory-confirmed COVID-19 patients with known infection outcome and 13 NMOSD patients were reported. The characteristics of MS patients are shown in Table 1 . Briefly, almost half of the patients were reported by MS centres in Prague (47.60%), mean age was 43.36 years (SD 10.94), most patient´s Expanded Disability Status Scale (EDSS) was lower than 4 (75.42%) and the mean MS duration was 12.52 years (SD 11.25) . In a majority of patients, COVID-19 infection was confirmed by PCR (89.46%). Approximately one third of patients had one or more comorbidities. Not all data were available for all individuals, but we did not use any data imputations. We could not have classified 34 patients as mild or more severe COVID-19 because of their unknown pneumonia status. The estimated number of MS patients in the Czech Republic is 20,000. At the time of this analysis, ReMuS contained information about 13,471 patients from 12 participating MS centres with at least one visit to an MS centre in the previous 12 months, thus our patient base represented almost 70% of Czech MS patients. As of February 28, 2021, 1004 laboratoryconfirmed COVID-19 patients with MS were reported (ongoing COVID-19 included). That means approximately 7.45% of MS patients had COVID-19. At the same time, there were 1,240,302 laboratory-confirmed COVID-19 cases in the Czech Republic (11.59% of the Czech population) (Komenda M. et al., 2021) ,(Český statistický úřad). The incidence of COVID-19 among patients with MS seems to be similar (or lower) to the general Czech population. The number of patients with particular COVID-19 symptoms is shown in Table 1 . The most common symptom was fatigue. New or worsening neurological symptoms were reported in 122 (13.25%) patients, 26 (21.31%) of them had a consequent relapse treated with glucocorticoids. All symptoms, as well as consequent relapse, were more common among patients with more severe COVID-19, except for sore throat, nasal congestion and loss of smell or taste. The distribution of COVID-19 severity scores according to the different DMT in MS patients is presented in Table 2 . A total of 50 patients (5.41%) had a more severe COVID-19. Supplemental oxygen was necessary for 9 patients (0.98%), non-invasive ventilation or HFOT for 12 (1.30%), invasive ventilation for one (0.11%) and 3 patients died (0.33%). Risk factors for more severe COVID-19 in univariate analysis are reported in Table 3 . Variables associated with increased risk of more severe COVID-19 in the univariate logistic regression model that were considered for retention in the multivariate logistic regression model are reported in Table 4 . From the variables with significant mutual correlations, the one with the highest predictive value was always selected for the multivariate analysis. Among selected variables, older age (OR per 10 years 2.01, 95% CI, 1.41-2.91), higher BMI (OR 1.07, 95% CI, 1.00-1.14), anti-CD20 therapy (OR 7.04, 95% CI, 3.10-15.87) and high-dose glucocorticoid treatment during the 2 months before COVID-19 onset (OR 2.83, 95% CI, 0.10-7.48) were shown to be independent variables associated with a more severe COVID-19 course. In 1:2 propensity score matching ( Figure) , patients treated with anti-CD20 compared to the same sex, age, presence of pulmonary comorbidity, BMI and high-dose glucocorticoid treatment during the 2 months before COVID-19 onset, patients treated with other DMT had an almost 9-fold increased odds of a more severe COVID-19 course (OR 8.90, 95% CI 3.04-33.24, p<.00001). Exploratory analyses revealed no association between COVID-19 severity and the time passed since the last anti-CD20 infusion as well as the duration of anti-CD20 treatment. Sensitivity analyses run by repeating all the analyses using a leave one out procedure rerunning the analysis excluding one of the largest MS centres one at a time, showed risk factors that were consistent with the entire cohort.  We present a large homogenous cohort of MS and NMOSD patients with COVID-19 collected via the Czech nationwide registry ReMuS. Our patient base represents almost 70% of Czech MS patients. The data collection was initiated when the first case of COVID-19 was spotted in the Czech Republic on March 1, 2020, the majority of patients was, however, infected from October 2020 to January 2021 (88.67%). The Czech Republic was one of the countries with the highest number of COVID-19 infected people per capita, but at that time the availability of COVID-19 laboratory tests was quite sufficient. Unlike the previous studies Salter et al., 2021; Sormani et al., 2021) we didn´t have to include suspected COVID-19 cases. That´s the probable reason we have a higher proportion of asymptomatic patients. We also didn´t use any data imputations and all values were obtained from healthcare professionals. As opposed to previous publications, our data analysis was based on the WHO definition We also included only laboratory-confirmed cases. In older patients with higher EDSS, there is a lower probability of undergoing a laboratory test due to their limited mobility. Some patients also may have behaved more cautiously and adhered more strictly to public health recommendations due to their chronic illness. Furthermore, the mortality rates are not consistent among publications probably because of the low numbers of deaths. Second, we identified independent risk factors for COVID-19 in multivariate analysis. Similar to data from other MS registries and the general population, we confirmed higher age and BMI as independent risk factors of more severe COVID-19 (Goumenou et al., 2020; Louapre et al., 2020a; Möhn et al., 2020; Salter et al., 2021; Sharifian-Dorche et al., 2021; Sormani et al., 2021) . In agreement with the COViMS (Salter et al., 2021) , Musc-19 (Sormani et al., 2021) and with data in other autoimmune diseases (Gianfrancesco et al., 2020) , we confirmed that high-dose glucocorticoid treatment during the 2 months before COVID-19 onset is associated with a worse disease course. This was not unexpected, as glucocorticoids affect the immune system, reducing responsiveness to infections. However, the 4 largest publications Möhn et al., 2020; Salter et al., 2021; Sormani et al., 2021) are not entirely consistent on the question of the effect of immunomodulatory therapies on the course of COVID-19, especially anti-CD20. The Covisep registry , as well as the German review of 873 patients (Möhn et al., 2020) , reported no association of anti-CD20 therapies with worse COVID-19 outcomes. Its small sample size and inconsistency may have limited the ability to detect associations. On the other hand, the increased frequency of more severe COVID-19 in people treated with anti-CD20 compared to other DMT was observed in Musc-19 (Sormani et al., 2021) as well as in our study. In our cohort, 81 MS patients were treated with antiCD20 and 16 of them contracted pneumonia. We proved that assumption via multivariate logistic regression and propensity score matching. Nevertheless, none of the antiCD20 treated MS patients died. The most common adverse events in patients treated with anti-CD20 therapy are viral respiratory infections. Anti-CD20 therapy binds to CD20 on the surface of B-cells, effectively depleting them, and interferes with antibody development. Therefore, B-cell depletion could potentially compromise antiviral immunity, including the development of SARS-CoV-2 antibodies. (Mehta et al., 2020; Syed, 2018) Serological studies following COVID-19 infection as well as COVID-19 vaccination in patients treated with anti-CD20 therapy will be crucial to determine the characteristics of the immune response to COVID-19 to help with clinical decisions about treatment and vaccination. We did not observe a link between time from last infusion of anti-CD20 or duration of anti-CD20 treatment. This can be due to the small sample size, but it is consistent with the idea that the immunological effect of anti-CD20 treatment may last longer than 6 months. We should also mention the higher proportion of patients with consequent relapse after COVID-19 infection among those with a more severe COVID-19 course in our cohort (Table   1 ). Longitudinal studies are needed to evaluate the long-term consequences of COVID-19, relapse rate included. Information on COVID-19 and pregnancy is still scarce, even more so when it comes to pregnancy in MS patients. Pregnant women do not appear to be at greater risk of COVID-19 infection. While the risk of critical care appears increased relative to the general population, there does not appear to be a significantly higher mortality rate. (Yam et al., 2020) However, data available up to now suggest a high risk of a more severe COVID-19 course as well as a higher mortality rate among NMOSD patients. Limitations of this analysis include low representation of children as well as older patients without DMT, with comorbidities and long MS duration, who are not followed in ReMuS. In older patients with higher EDSS, there is also less probability to undergo a laboratory test because of their limited mobility. Not all patients underwent a CT scan or chest X-ray so more severe cases could be underestimated. Otherwise, there can be an improved outcome in comparison to the general population due to greater adherence to public health recommendations because of MS diagnosis. Finally, although the multivariate analysis and propensity score matching adjusted for the effect of DMT on COVID-19 severity for the main confounding factors, we cannot exclude that some residual confounding can partly explain the observed associations.@story_separate@Overall, this study confirms that a majority of MS patients have a mild COVID-19 course. Anti-CD20 therapy, high-dose glucocorticoid during the 2 months before COVID-19 onset and risk factors known in the general population such as higher BMI and age were associated with more severe COVID-19 course. These findings are in agreement with previous studies as well as knowledge about infections in MS patients. It will be important to look at longitudinal and serological studies to evaluate the long-term consequences of COVID-19 and the characteristics of the immune response in MS patients. Contrarily, it seems that NMOSD patients are at higher risk of worse COVID-19 course, even though the COVID-19 reports are scarce. The results from this analysis are very important for clinical practice. Based on this study, we have already started an early administration of anti-SARS-CoV-2 monoclonal antibodies and preferential vaccination in the group of patients treated by anti-CD20. We continue to collect this data and plan to publish it soon.","Background: When the novel coronavirus disease 2019 (COVID-19) appeared, concerns about its course in patients with multiple sclerosis (MS) and neuromyelitis optica spectrum disorder (NMOSD) arose. This study aimed to evaluate the incidence, severity and risk factors of the more severe COVID-19 course among MS and NMOSD patients. Methods: From March 1, 2020, to February 28, 2021, 12 MS centres, representing 70% of the Czech MS and NMOSD population, reported laboratory-confirmed COVID-19 cases via the Czech nationwide register of MS and NMOSD patients (ReMuS). The main outcome was COVID-19 severity assessed on an 8-point scale with a cut-off at 4 (radiologically confirmed pneumonia) according to the World Health Organisation´s (WHO) COVID-19 severity assessment. Results: We identified 958 MS and 13 NMOSD patients, 50 MS and 4 NMOSD patients had pneumonia, 3 MS and 2 NMOSD patients died. The incidence of COVID-19 among patients with MS seems to be similar to the general Czech population. A multivariate logistic regression determined that higher body mass index (BMI [OR 1.07, 95% CI, 1.00-1.14]), older age (OR per 10 years 2.01, 95% CI, 1.41-2.91), high-dose glucocorticoid treatment during the 2 months before COVID-19 onset (OR 2.83, 95% CI, 0.10-7.48) and anti-CD20 therapy (OR 7.04, 95% CI, 3.10-15.87) were independent variables associated with pneumonia in MS patients. Increase odds of pneumonia in anti-CD20 treated MS patients compared to patients with other disease-modifying therapy (same age, sex, BMI, high-dose glucocorticoid treatment during the 2 months before COVID-19 onset, presence of pulmonary comorbidity) were confirmed by propensity score matching (OR 8.90, 95% CI, 3.04-33.24). Reports on COVID-19 infection in patients with NMOSD are scarce, however, data available up to now suggest a high risk of a more severe COVID-19 course as well as a higher mortality rate among NMOSD patients. In our cohort, 4 NMOSD patients (30.77%) had the more severe COVID-19 course and 2 patients (15.39%) died. Conclusion: The majority of MS patients had a mild COVID-19 course contrary to NMOSD patients, however, higher BMI and age, anti-CD20 therapy and high-dose glucocorticoid treatment during the 2 months before COVID-19 onset were associated with pneumonia. Based on this study, we have already started an early administration of anti-SARS-CoV-2 monoclonal antibodies and preferential vaccination in the risk group of patients."
"Some of us have been closely involved in observing crude oil price movements for around fifty years, and in those early days we were constantly warned by Shell's then head of scenario planning, Pierre Wack, of a proverb: ""Those who claim to foretell the future lie, even when they foretell the truth."" But for me it was part of my jobs in the years 1970-1987 to try to guess how and when crude oil prices might move. From 1970 until 1973 it was seeking to guess how much of an increase might occur after the Teheran Agreement, a guess greater than the general view although without foresight of the Yom Kippur War. Then from early 1976 fear of what would happen in the wake of the Shah of Iran's overthrow, likely to be a sharp rise in crude oil prices followed by relapse. This was reflected in a 'Producer Miscalculation' scenario proposed in September 1976, followed by a 'Hard Times' scenario -first proposed in April 1979, and adopted by Shell in Europe as the 'European Relapse' scenario in December 1979. This was the CRUNCH which was expected to be caused by an uprising in Iran leading to more general stresses in the Middle East and use of oil as a weapon in international dealings [1, 2] . The weakening of crude oil prices which began from early 1981 was not a surprise, nor was the collapse in late 1985 and early 1986, partly reflecting Saudi Arabia's decision to cease propping up oil prices and instead to increase production. In January 1986 two crude oil (notional Brent) price scenarios were offered in an internal Shell International Petroleum Co. Supply & Marketing document: an 'Orderly Recovery' from March 1986; or a 'Belated Accord' following a full OPEC meeting in July 1986, which would be assisted by an increasing winter demand effect in the major economies of the Northern Hemisphere. A small residual possibility of 'Disorder Continuing' was given little credibility because of that seasonal demand effect. Despite the Brent crude oil price having fallen sharply through March 1986, and remaining weak into early July 1986, the ""subjective probability"" (that is a ""guess"", after considerable thought) remained that the price would quickly recover from July into a range of $15-$20 per barrel, within which it was expected to remain for the rest of the decade and, barring ""accidents"", perhaps through the following decade. The crude oil price fall between December 1985, and early July 1986, had been around 58%. One ongoing threat, which had long been in the psyche of Shell people, was concern about the effects of 'peak oil' given that M. King Hubbert (founder of the 'peak oil' hypothesis as applicable to the USA in particular) had been an employee of Shell Oil from 1943 until 1964. It turned out that apart from the years 1990 ($23.80) and 1996 ($20.80) the annual average price of Brent crude remained below $20 until the year 2000, when it rose to $28.40 (WTI peaked at $34.42 in November 2000). This rise reflected OPEC's decision the previous year to curb production, and some 'peak oil' enthusiasts would claim increasing focus on a possible global peak from 2005. From the year 2000 through to the financial crisis year of 2008 crude oil prices rose steadily. They peaked at over $130 in July 2008, before falling to around $40 that December. The upward drive mainly reflected increasing demand from China, India, and other emerging economies, and weaker output from Nigeria and Iraq. The fall of nearly 80% in crude oil prices in five months was followed by rises during 2010 as the global economic recovery got under way. Then in December 2010, the ""Arab Spring"" began with widening tensions across North Africa and in some Middle Eastern countries through 2011. These tended to push up crude oil prices, although this shift was partly countered by a return of economic uncertainties in the USA and Europe. In 2012 further uncertainty was introduced as sanctions were imposed T upon Iran due to its nuclear ambitions, and there was fear that closure of the Straits of Hormuz might result. Oil supplies had continued to remain high throughout, but in June 2014, with US shale oil production increasing apparently inexorably and Saudi Arabia unwilling to support oil production cuts, crude oil prices fell by about one-third. Between June 2014, and March 2015, there was a fall of some 75%. Crude oil prices briefly fell at the end of 2015 through to April 2016, and showed some strengthening through much of 2018, but otherwise remained fairly stable through to early February 2020, when the impact of COVID-19 began to be felt in oil and most other commodity markets. Between 1985 and 2015 there were in fact seven periods when crude oil prices fell 30% or more in a seven-month period, reflecting shifts in OPEC policy (or divisions within OPEC), appreciation of the US $, changing perceptions of geopolitical risks, weakening global demand, excess refining capacity, and the production of unconventional (primarily shale) oil. In the run-up to the collapse of crude oil prices in early 2020 it was primarily a division between Russia and Saudi Arabia within OPEC which appeared to be the main force at work, but then the COVID-19 pandemic took over, followed by US oil prices turning negative in April 2020, as May contracts expired and traders had to offload stocks with ongoing storage becoming extremely limited. Then by May 1st, 2020) WTI has almost doubled in a couple of days to $25 per barrel, and Brent had risen to about the same amount ( Fig. 1 ).@story_separate@One of the more surprising features of the current pandemic is the multiplicity of warnings about future pandemics and large-scale epidemics that have been published in recent years. This is especially surprising as the SARS (Severe Acute Respiratory Syndrome) epidemic of 2002-2003, MERS (Middle East Respiratory Syndrome) epidemic since 2012, and recurrent worries about avian flu and the existence of 'wet markets' in Asia, have received considerable attention. They appear to have been largely ignored by many analysts and policymakersnot least by those who have been involved with energy issues. This was a reason for my adverse criticism of the huge, 1865-page, ""Global Energy Assessment: Towards a Sustainable Energy Future"" published in 2012 by the International Institute of Applied Systems Analysis. This Assessment omitted any reference to pandemics or epidemics and their potential impacts on 'the Anthropocene Age', for which it was adversely criticised by this author [3] Perhaps most of those now living in the industrialised countries are too young to have listened to elderly relatives recounting their recollections of the 'Spanish' influenza epidemic of 1918-1920, or experienced the 'Asian' flu epidemic of 1957 or 'Hong Kong' epidemic of 1968. Others may not be aware of the wide range of infections resulting from exposure to RNA (ribonucleic acid) viruses within which coronaviruses form a sub-group, such as Marburg and Ebola, their high mortality rates, or their potential to spread widely. It still does not appear to be widely known that coronaviruses have been the subject of research since the early 1930s, and furthered by their portrayal through electron microscopy since the 1960s. 'The Economist' claimed on April 29th, 2020, that ""oil and commodity prices are where they were 160 years ago"", and ""forecasting commodity prices is a mug's game."" Here there is, as explained in the Introduction, no attempt to prophesy or forecast, but simply to indicate some forces at work and guesses as to where they might lead. This task is made particularly difficult because the death toll of COVID-19 could already have been 60% higher than reported in official counts according to an analysis of overall fatalities conducted by 'The Financial Times' and published on April 26th, 2020. On April 17th, 2020, it was widely reported that estimates of deaths from COVID-19 in Wuhan had been raised 50%, reflecting earlier mis-diagnosis. Then there has been regular reporting of extensive asymptomatic infection by COVID-19 and weak evidence for contagion as a result. There has also been intense debate on the benefits of, and problems which may result from: self-isolation, social distancing, social shielding, and total isolation. In April 2020, it was estimated that about 40% of the World's population were engaged in some degree of isolation. With intensifying pressure to relax measures intruding on social and economic interaction, the current unknown consequences of doing so (or doing so prematurely), fears of a second peak of infection, and little expectation of a widely available vaccine before 2021, it is impossible to know when global oil demand and oil prices will recover, and to what extent. Here an attempt is made to consider the main forces at work (Table 1) . The biggest share of oil demand after industry's consumption comes from the transportation sector. For the OECD member countries about 50% of this comes from road transportation; 8% from aviation; 14% from petrochemicals; and 9% from the residential, commercial and agricultural sectors. About 15% comes from miscellaneous industrial activities. The aviation and private road transport sectors have already been hit hard by the pandemic, as have sections of the petrochemicals, commercial and industrial sectors. Many airline passengers have been stuck for longer than they wished to be somewhere other than they had planned. Others consider they have not been well treated either as passengers or would-be passengers. There are those in the industry who believe it may take three to five years for airline passenger demand to recover. Prospects for individual airlines are likely to be heavily dependent upon whether government subsidies to tide them over become available. Many workers are still furloughed and do not know when they will be permitted to return to work, using road transport to boost oil demand. There may be a longer-term switch to working from home, although expectations of this on a large scale have been around a long time (over fifty years) and has not yet occurred. These forces may have a knock-on effect on the transportation sector even when the pandemic is over. Recovery of the transport sector will benefit producers of lighter crudes, petrol and diesel demand (as production of diesel is a required by-product of petrol production), and aviation fuel -being the product of the lighter end of the oil barrel. The petrochemicals sector has aroused interest as ethylene is produced mainly from oil and natural gas (the proportions can vary widely), and some major investments are currently being made to produce plastic pellets from ethylene, notably the Shell Pennsylvania Petrochemicals Complex where construction workers were furloughed on March 18th due to COVID-19 concerns. However, this huge project (reputedly around $6 billion) is located close to the Marcellus shale gas formation, and unless the pandemic leads to a major push for the concept of ""the circular economy"" and away from plastics it would appear that a shale gas project is not closely relevant here, although shale oil projects may be [4] . The impact of COVID-19 did have a particularly large role to play in the collapse of WTI (West Texas Intermediate) prices in April 2020, especially on April 20th, for reasons other than simply weakness of demand, and ongoing production in the face of storage limitations. The reason was that WTI oil futures contracts were ending on April 21st and the United States Oil Fund (an exchange-traded fund that attempts to track the price of WTI, founded in 2006 by the American Stock Exchange and Victoria Bay Asset Management) held 25% of the May 2020, WTI futures. They either had to take delivery of a vast quantity of oil by the end of May, knowing the tight storage situation, or sell it immediately at whatever price they could get for it. The WTI contracts for June, which expired on May 19th, fared much better -getting close to $30 -but weak demand and storage limits are liable to have an ongoing depressive effect. The International Energy Agency, while recognising the uncertainties in the oil market outlook, has considered transport fuel demand to be ""the most affected sector"" [5] . It is likely that while some national economies will be very badly affected by COVID-19, others could emerge looking relatively resilient. For example, US employment figures in second-quarter 2020 seemed to be surprisingly robust whereas some more services-oriented oriented economies (such as the UK) may prove to have been more adversely affected. So much for the demand side. On the supply side there are a number of complicating forces at work, which can most readily be considered first by major producing countries and then by crude oil qualities (as indicated by their API -American Petroleum Institute -gravity or density). In the United States of America over 300 drilling rigs were shut down between November 2019, and the end of April 2020. US oil and gas companies have cut their capital expenditure by close to $100 billion in recent months -Exxon alone by 30%, mainly at the Permian Basin. Although the USA has been producing crude oil surplus to its domestic requirements, and has had a surplus in motor gasoline since late 2014, it has needed to import crude oils of heavier specific gravity to meet the pattern of domestic demand (not least demand for diesel) and US refinery configurations. This will assist some producers of heavier crudes (see below). But the main concern is, and will continue to be, on the economic viability of producing shale oil. Shale oil production in the USA boomed from 2014, accounting for over a third of onshore crude oil production in the lower 48 States by early 2020. This resulted in the USA becoming the World's largest crude oil producer and a 15% drop in its crude oil imports between 2013 and 2019. One advantage that shale oil has is that its oil can be stored in the ground once extraction has ended. It can then be retrieved once prices have risen to an acceptable level -widely considered to be about $60 per barrel. Shale oil appeared a very attractive proposition when crude oil prices recovered to around $100 in March 2011. Prices weakened by around 10% in its wake. The sector's greatest challenge currently is how to maintain an involvement in shale oil with little income being derived from it. At the 'virtual' OPEC meeting on April 12th, 2020, Russia reluctantly agreed a 10% cut in OPEC's oil production commencing in May 2020. Russia had been reluctant to cut production in the wake of falling demand due to COVID-19, the State having relied upon oil and gas sales for some 40% of its annual revenue. Prior to January 2020, OPEC Member States had cut their total oil production by over 2 million barrels per day since 2016, Saudi Arabia taking the main brunt of the cuts. With further evidence of falling demand, it was agreed at an OPEC meeting on March 5th, 2020, that a cut of a further 1.5 million barrels per day was required through the second quarter of 2020. OPEC called on Russia and other non-OPEC members (OPEC+) to follow suit. The following day Russia rejected the request, resulting in a 10% fall in oil prices immediately thereafter. Saudi Arabia responded on March 8th by initiating a price war with Russia, announcing price discounts of between $6 and $8 a barrel, and pushing up production from under 9.7 million barrels per day in February 2020, to over 10 million barrels per day the following month. That figure rose to about 12 million barrels per day by the time of the OPEC meeting on April 12th. There has been debate about why Russia initially sought to maintain its production level, with claims that some considered it too early given uncertainty about the likely impact of COVID-19 on oil prices, and whether there was a conscious price war between Saudi Arabia and Russia. Other claims are that Russia thought maintaining price levels would hurt the USA, in response to the introduction of sanctions against Rosneft. Perhaps more relevant are the State's dependency on oil and gas revenues, and the fact that sixty new oil fields came into production in Russia between 2016 and 2019 with a total capacity approaching 900,000 barrels per day. The prospect of cutting output by close to 2.5 million barrels per day was, and is likely still to be, unattractive from Moscow's vantage point. Just over half of this 2.5 million barrels per day cutback is expected to come from Urals crudes via Baltic Sea ports (Primorsk and Ust-Luga), with a further 1 million barrels per day cutback from the Black Sea port of Novorossiisk. A cutback of around one-third of the 500,000 barrels per day of Siberian Light crude exports is believed to be planned. Russia has faced challenges arising from sanctions introduced by the USA and some European countries since 2014, reflecting events in and around the Ukraine and the Crimea. These have been somewhat mitigated by costs and liabilities being quoted in roubles rather than US$, resulting in some Russian crudes costing the equivalent of under US$ 15 per barrel. There are some quality problems associated with Russian crude oil which may prove to have future relevance, especially the passing of a range of crude qualities (with varying gravities and sulphur contents) through its pipeline system from the Urals. Russia's supply chains continue to come in for adverse criticism, reflecting issues around awareness of refiners' needs, which go back decades. Importers of Russian crudes may be more sensitive about these issues after the COVID-19 pandemic subsides. Although Saudi Arabia has been able to rely upon large oil reserves and oil export revenues since 1950, this has not come without costs. With constraints on oil export revenues has come the need to draw down on the central bank's reserves and to cut back on expenditure. Although the central bank's net foreign assets are around $450 billion, the drawdown in 2020 is expected to exceed $30 billion. The country's fiscal deficits have grown markedly (a 34 billion riyals deficit in firstquarter 2020), and public sector salaries for Saudi nationals are a significant burden. The government tapped international bond markets twice in the first few weeks of 2020, and borrowed a total of $19 billion from local and international investors [6] . On the oil side Saudi Arabia continues to be well placed in terms of exploitable reserves. Most of its onshore crudes are relatively light (Nuayyim, Qatif, and most of Ghawar -though the API gravity ranges from 30 to 34 by some accounts, and 33 to 36 by others). The standard API gravity for Arab Light is 32.8; for Arab Medium 30.2; and Heavy 27.7. Apart from Manifa (production capacity 900,000 barrels per day of Arab Heavy), the heavier crudes are probably located offshore although this is not clear from ARAMCO data. Reports that Saudi Arabia's crude oil production would peak soon after 2005 (Matthew Simmons: ""Twilight in the Desert: The Coming Oil Shock and the World Economy"", published in 2005) now seem overly pessimistic, but the underlying argument should not be lightly dismissed [7] . The quantity of lighter crudes puts Saudi Arabia in a relatively strong position in post-COVID-19 markets provided that there are no serious military conflicts in the area. In that context, it is worth noting that on April 2nd, 2020, there was a telephone conversation between President Trump and Saudi Crown Prince Mohammed bin Salman in which the President apparently advised that he would be powerless to prevent legislation being passed in the USA withdrawing US troops and military equipment from Saudi Arabia unless Saudi Arabia cut its oil production. Ten days later came the OPEC+ agreement to cut production. Nevertheless, despite recent efforts to seek peace between the Sunni coalition led by Saudi Arabia and Houthi Shia dissidents in the Yemen, backed by Iran, there remain concerns about Sunni/Shia conflict in the region, particularly if it were to encroach on the freedom of passage through the Straits of Hormuz. In Saudi Arabia there is also clear recollection of the attack from Iran on the Saudi oil processing facilities of Abqaiq and Khurais on September 14th, 2019. Iran is poorly placed under its present regime and US-led sanctions to benefit from recovery of oil demand following the pandemic. The sanctions imposed in May 2018, immediately led to a halt in the import of oil rig equipment, resulting in over 25% of Iran's 160 rigs being out of commission by early March 2020. Sanctions were tightened in May 2019, to block buyers of Iranian oil, and China has been left as the main purchaser though its oil demand has been hit hard by the pandemic. The US is also discouraging shippers, port authorities, and insurers from giving support to Iran's floating storage. Iran has seen its crude oil exports fall from 2.5 million barrels a day before the May 2018, sanctions were introduced to 248,000 in February 2020. Iraq is another crude oil exporter suffering from concerns about stability and conflict in the Arabian Gulf area. The International Energy Agency categorised Iraq as a ""vulnerable supplier"" in January 2020, shortly after the leader of Iran's Quds Force (responsible for foreign military and clandestine operations) had been killed at Baghdad airport in a US drone strike, which was quickly followed by Iran firing missiles at US and Allies military bases. The timing of this conflict is particularly unfortunate because Iraq's crude oil exports had doubled from 2 million barrels per day in 2010 to nearly 4 million in 2019 (more than the then OPEC quota). Half of these exports went to China and India in roughly equal quantities, some 25% to Europe, and nearly 10% to the USA, in 2019. Provided there is no further major conflict in the Arabian Gulf area Iraq can be expected to push its crude oil exports close to OPEC quota limits, from its Kirkuk (API gravity 33.9) and Basrah (not particularly!) Light (API gravity 30.5) fields. Nigeria's economy is not well placed to weather the current pandemic, and its light, low sulphur, crudes (Bonny Light-API gravity 33.4, and Qua Iboe -API gravity 36.3) are both heavily discounted against the bench mark Dated Brent they use -a discount of about $4 per barrel at the end of April 2020. Despite its moderate API gravity of 30.8, Forcados has long been regarded as a relatively heavy crude by purchasers for most refineries. Despite cutting exports in the wake of the pandemic sales have been going slowly, with about half of its Mayloading cargoes unsold at the end of April according to Bloomberg (April 28th, 2020). Nigeria also lacks storage capacity. Nigeria's economy is likely to struggle through the COVID-19 saga, and then being faced with a wide variety and large volume of light and sweet crudes on offer (not least in the USA) is likely to struggle to achieve balance again. Venezuela's economy is in a weak state, its political leadership under heavy criticism, and its crude oil export potential severely limited by the heaviness of much of its crude oil availability. Not all of Venezuela's crude oils have a low API gravity -Santa Barbara stands at 39.5; Puerto Jose at 32; Tia Juana Light at 31.9; and Furrial, Mesa and Sincor around 30.0. But six others fall between 10 and 20, the lowest being Boscan at 10.1. So heavy are these latter crudes that they cannot flow through pipelines. They need to be diluted by agents such as naphtha, but in January 2019, the USA banned US firms from exporting diluting agents to Venezuela and banned US purchases from buying Venezuelan oil from April 28th, 2019. About 80% of Venezuelan crude oil production is of heavy oil. As domestic political, economic and social strife are also chronic, the country is not well placed to weather the pandemic. Although Canada has a few oil fields producing relatively light crudes, the focus there has mainly been on the Athabascan tar sands of Alberta and fields with API gravities running between 19 and 22. Canada is five years on from the last crash, when major international companies pulled out of oil sands operations. Even when prices recovered pipeline cost, water and chemicals usage, and environmental issues continued to discourage involvement. Among these challenges are the costs of seeking to use Carbon Capture and Storage technology, which up until now has made little progress. With the pandemic demand and prices have slumped to the point where, at barely $5 per barrel, it is lower than the cost of conveying it to the currently weak US market. Although it is difficult and costly to shut down tar sands there have been reports of up to 25% being shut down. Some estimates suggest tar sands production costs can be covered at an average of $45 per barrel for a crude such as Brent -about double the price at the time of writing. This may look a bit better than the $60 per barrel price said to be required to keep US shale oil afloat, but the Canadian economy was already pronounced to be on the brink of recession at the end of March 2020. The heart of Canada's oil industry is in Alberta and Saskatchewan, where up to 200,000 job losses are feared. The question is whether the Alberta Government in particular, and the Canadian Government also, will be prepared to step in and how effective could that prove. They will face opposition from those who consider the pandemic offers a great opportunity for expediting a shift to electric vehicles and transition to a low carbon or zero carbon economy. Such views are not, of course, confined to Canada but consideration of them falls outside the remit of this paper. Numerous other countries are actual or potential oil producers and exporters, but many of these have been exploiting, or wish to exploit, offshore deposits. The costs of such developments are high; and the political, economic and social stability of many of the potential suppliers is uncertain. Angola is a case in point. Just as news of the COVID-19 pandemic began to spread around the World came the announcement that several new projects were about to come onstream, after twenty-seven years of civil war and the costs of offshore field development blocking further efforts. Although some of these elements may particularly apply to sub-Saharan Africa, the costs of offshore developments are also an inhibiting factor for Latin America in general. This paper began by recalling that we are unable to foretell the future, and that in considering prospects for oil prices in the light of the COVID-19 pandemic one is engaging in a considerable amount of guesswork. This paper has also devoted a significant amount of space to oil market essentials -by crude oil qualities, exporting countries, and quantities available, as well as demand factors. This is what one would expect of a journal focussed upon energy research and its potential impacts. However, the first message is that there are three major uncertainties which fall outside the realm of strict energy research and analysis. The first is that, at the time of writing, we do not know whether a second peak in the incidence of COVID-19 infection and mortality will occur on a substantial scale. If it does it will delay recovery of oil demand and prices substantially. The second is that it is not yet clear when an effective vaccine against COVID-19 will become available and on the required scale. The third uncertainty is whether a major conflict will occur that could dramatically change the stability of world oil markets and international relations. We might give this scenario the name: ""Hormuzed"", reflecting the most likely cause of it being a major conflict in the Arabian Gulf area with longer term impact on supplies originating from the Gulf. This 'worst case' scenario could see current oil prices quadruple for a short period. It would not be in the best interests of Iran or Saudi Arabia if this were to happen. President Trump has recently warned against Iranian gunboats approaching US warships or oil tankers generally. Assuming there is no second peak in COVID-19 infection, and therefore a gentle relaxation of self-isolation and social distancing allowing economies to 'restart', it would seem reasonable to look for a rough doubling of late-April 2020 crude oil prices by third-quarter 2020. A range of $40 to $60 per barrel would appear to be feasible although, given the ongoing weakness in the aviation sector and slow return to pre-pandemic industrial and commercial activity constraining road transport and maritime oil demand, the possibilities point to an outcome towards the bottom of that range through much of the third quarter. Looking further forward, global economic recovery post-COVID-19 is likely to be muted. It would appear highly likely that there will be widespread abandonment of drilling, closure of wells considered not to have longer term economic viability, and further severe cutbacks in US shale oil and Canadian tar sands activity. A lot of planned further oil exploration and production is likely to be abandoned on cost grounds and perceived weakness or uncertainty of demand. The best guess this writer can offer is that, provided COVID-19 has no further damaging effects to reveal than what is now known or widely anticipated, crude oil prices are likely to move from close to the bottom of the $40 to $60 per barrel range in third-quarter 2020 to closer to the top in first-half 2021. The author declares that he has no known competing financial or personal relationship that has influenced the work reported in this paper.@story_separate@In the absence of a major Middle East conflict, crude oil prices may be expected to recover somewhat by third-quarter 2020. This paper concludes a rise from the trough in mid-April 2020 level to the lower end of the $40 to $60 per barrel range, moving towards the top of that range in first-half 2021. Many forces arising from the COVID-19 pandemic which have cut oil demand severely back will only permit slow recovery, thereby curbing major oil price rises due to demand weaknesses for at least three or four years.","Assessing prospects for future oil prices is an uncertain activity but, barring Middle East conflict creating severe supply issues, crude oil prices are expected to stage a recovery by third-quarter 2020 and modest further recovery in first-half 2021, with the range $40 to $60 per barrel for WTI and Brent. Despite such a recovery there will be many oil sectors incurring losses, from US shale oil and Canadian tar sands producers, to many standard crude oil exporters incurring problems with production equipment access and costs, or experiencing lack of competitiveness in key markets."
"Infectious diseases are common in childhood. Acute respiratory tract infections are the most common cause with high mortality and complication rates. The most common agents for acute respiratory tract infection are viruses [1] and include respiratory syncytial virus (RSV), parainfluenza viruses (PIVs), influenza viruses (IFVs), enteroviruses (EVs), adenoviruses (ADVs), human rhinoviruses (HRVs), human metapneumovirus (hMPV) and human coronaviruses (HCoVs) 229E, OC43, NL63, and HKU1. Coronaviruses NL63, HKU1 and human bocavirus, WU and KI polyomaviruses are the other viruses that cause serious respiratory tract infections [2] . Although viruses are the most common causes of acute respiratory tract infections, main etiological diagnosis is often missed and unnecessary or inappropriate antibiotic use is seen in more than 50 % of acute respiratory tract infections worldwide [3] . This leads to development of serious outcomes such as high resistance rates or multidrug resistance along with drug side effects in the children infected with virus [3, 4] . There are many pathogens causing similar clinical manifestations suggestive of acute respiratory tract infection [3] . Group A beta hemolytic streptococcus (GAS) is the most frequent bacterial agent in the etiology of acute respiratory tract, accounting for 15-30 % of acute pharyngitis cases especially in the children [5] . Clinical manifestations of GAS respiratory tract infection are mostly presence of sore throat and fever and absence of cough [5] . Clinical manifestations like cough, nasal discharge, and diarrhea are more suggestive of viral causes [5] . Clinical differentiation between viral and bacterial etiology is important for performing appropriate laboratory test, treatment and follow-up. In the index study, the authors investigated clinical manifestations and laboratory tests of these two most common etiological causes seen in the children. The authors investigated the results of respiratory viral panel test (RVPT) (Mutiplex PCR panel) for the diagnosis of frequently isolated viral etiologic groups: RSV, PIVs, IFVs, ADVs, HRVs, hMPV and HCoVs with the results of rapid strep A (RSA) antigen detection test and throat culture test for the diagnosis of GAS.@story_separate@The authors retrospectively evaluated 1654 patients aged 0-16 y with clinical presentation of acute respiratory system infection such as: fever [>38°C (tympanic)], nasal discharge, cough, rash, sore throat, hoarseness, hyperemia of oropharyngeal region, hyperemic and hypertrophic tonsils, retropharyngeal secretions who presented at Acibadem Maslak Hospital from February 2012 through January 2013. With these clinical findings RVPT, RSA and throat culture tests were performed. Admission date, date of birth, gender, complaints and season of infection were recorded. Tests and results were performed in SPSS database. In this study, NCSS (Number Cruncher Statistical System) 2007 Statistical Software (Utah, USA) package program was used for the statistical analysis. During the evaluation of the study data, regarding the comparisons of descriptive statistical methods (frequency and percentage distribution) as well as qualitative data, Chi-square test and Fisher's exact tests were used. Sensitivity, specificity, positive predictive value, negative predictive value and LR + (Likelihood Ratio) values were calculated for the reliability of diagnostic methods. The results obtained from the study were evaluated at a significance level of p < 0.05 and within 95 % confidence interval. RSA test, throat culture test and RVPT were performed in the patients presenting with symptoms of acute respiratory tract infection. The patients' gender, age, clinical signs (fever, cough, sore throat, headache, rash, nausea, vomiting, hoarseness, ear pain, abdominal pain and foot-knee-leg pain) and season of getting infected are shown in Table 1 . Of the total patients, 45.9 % (n = 759) were girls and 54.1 % (n = 895) were boys. Patients were classified according to the age groups: < 2 y, between 2 and 6 y and >6 y. There was no difference between the age groups with respect to gender (p = 0.886) and no difference between the genders with respect to winter, spring, summer and autumn seasons (p = 0.808). RVPT and RSA tests were performed simultaneously in 10.3 % (n = 4) < 2-y-old, 53.8 % (n = 21) 2-6 y old and 35.9 % (n = 14) > 6-y-old. RVPT and throat culture tests were performed simultaneously in 18.6 % (n = 11) < 2-y-old, 52.5 % (n = 31) 2-6 y old and 28.8 % (n = 17) > 6-y-old children. Throat culture test and RSA test were performed simultaneously in 4.6 % (n = 22) < 2-y-old, 45.5 % (n = 218) 2-6 y old and 49.9 % (n = 239) > 6-y-old children. Distribution of the tests according to the age groups is shown in Table 2 . The number of tests performed due to the complaint of fever were higher in 2-6 y age group as compared to the patients in <2 y and >6 y age groups (p 0.0001). The number of tests performed due to the complaint of cough were less in >6 y age group as compared to <2-y-old and 2-6 y age groups (p 0.0001). The tests performed due to the complaint of sore throat were less in <2 y age group as compared to 2-6 y and >6 y age groups (p 0.0001). Also the number of tests performed due to the complaint of headache were higher in >6 y age group as compared to <2 y and 2-6 y age groups (p 0.002). No difference was observed between the number of tests performed in <2 y, 2-6 y and >6 y age groups due to the complaints of foot-knee-leg pain, nausea-vomiting, nasal discharge, nasal congestion, rash, fatigue, abdominal pain, hoarseness and ear pain (p > 0.05). Complaint of fever in the patients in whom the test was performed in the spring and winter months was found to be higher than those in whom the test was done in the summer and autumn months (p 0.005). Absence of cough in the patients in whom the test was performed in the spring and winter months was found to be higher than those in whom the test was performed in the summer and autumn months (p 0.0001). No difference was observed between distribution of presence of sore throat, headache, nasal congestion, rash, hoarseness and ear pain with respect to the winter, spring, summer and autumn seasons (p > 0.05). Presence of fatigue in the patients in whom the test was performed in the winter months was found to be higher than those in whom the test was performed in the summer, spring and autumn months (p 0.012). Positive RSA test was not observed in <2 y age group and the number of patients with positive RSA test was higher in >6 y age as compared to 2-6 y age group (p 0.0001). Positive throat culture test was not observed in <2 y age group and the number of patients with positive throat culture test were found to be higher in >6 y age group as compared to 2-6 y age group (p 0.0001). Number of patients with positive RVPT were higher in <2 y age group as compared to 2-6 y and >6 y age groups (p 0.002). Positive RSA test and throat culture test in the winter and spring months were higher than in summer and autumn months (p 0.001, p 0.008 respectively). Distributions of tests according to the complaints are shown in Table 3 . No difference was observed between distribution of positive RVPT in winter, spring, summer and autumn season groups (p 0.135). The number of patients with RSA test (+) in >6 y age group were higher than those in RSA test (−) group (p 0.0001). No difference was observed between distribution of gender of RSA test group (−) and rapid strep A test (+) groups (p 0.770). The number of patients with fever in the RSA test (+ ) group were higher than those in RSA test (−) group (p 0.022). The number of patients with cough in the RSA test (+) group were less than those in RSA test (−) group (p 0.001). The number of patients with sore throat in the RSA test (+) group were higher than those in RSA (−) group (p 0.0001). No difference was observed between distribution of footknee-leg pain, headache, nausea-vomiting, nasal discharge, nasal congestion, rash, fatigue, abdominal pain, hoarseness and ear pain in the RSA test (−) group and the RSA test (+) groups (p > 0.05). In the >6 y age group number of patients with throat culture (+) were higher than those in throat culture (−) (p 0.0001). No difference was observed between distribution of gender in the throat culture (−) and the throat culture (+) groups (p 0.423). The number of patients with detection of infection in winter and spring months in the throat culture (+) group were higher than those in the throat culture (−) group (p 0.008). Presence of cough in the throat culture (+) group was less than the throat culture (−) group (p 0.001). Sore throat in the throat culture (+) group was higher than the throat culture (−) group (p 0.0001). No difference was observed between distribution of fever, foot-knee-leg pain, headache, nausea-vomiting, nasal discharge, nasal congestion, rash, fatigue, abdominal pain, hoarseness and ear pain in the throat culture (+) group and throat culture (−) groups (p > 0.05). Positive RSA test in the throat culture (+) group was higher than the throat culture (−) group (p 0.0001). In <2 y age group, number of patients with RVPT (+) were higher than those with RVPT (−) (p 0.002). No difference was observed between the distribution of gender in RVPT (−) and RVPT (+) groups (p 0.994). No difference was observed between distribution of season, fever, cough, sore throat, headache, nausea-vomiting, nasal discharge, rash and fatigue in RVPT (−) and RVPT (+) groups (p > 0.05). According to throat culture, specificity, sensitivity, positive predictive value, negative predictive value and LR(+) values of the results of RSA test were found to be 0.50, 0.98, 0.85, 0.88 and 20.83, respectively. In a patient positive with RSA test, the likelihood of positivity of throat culture is 20.83-fold higher than in a patient with negative RSA test. According to throat culture, specificity, sensitivity, positive predictive value, negative predictive value and LR(+) values of the results of RVPT were found to be 0.17, 0.64, 0.14, 0.87 and 0.46, respectively. In a patient positive with RVPT, the likelihood of positivity of throat culture is 0.46-fold higher than in a patient with negative RVPT (it is not successful since it is not more than 2). RVPT and RSA tests were performed simultaneously in 10.3 % (n = 4) < 2-y-old, 53.8 % (n = 21) 2-6 y old and 35.9 % (n = 14) > 6-y-old patients; RVPT and throat culture tests were performed simultaneously in 18.6 % (n = 11) < 2-yold, 52.5 % (n = 31) 2-6 y old and 28.8 % (n = 17) > 6-y-old patients; throat culture test and RSA tests were performed simultaneously in 4.6 % (n = 22) < 2-y-old, 45.5 % (n = 218) 2-6 y old and 49.9 % (n = 239) > 6-y-old. It shows that according to the patient's complaints, clinician could choose one or two tests for diagnosis. Viruses cause most common acute respiratory system infections but GAS causes 37 % of all cases of acute respiratory system infections in children older than 5 y. Streptococcal acute respiratory system infections have a peak incidence in the early school years and are uncommon before 3 y of age [6] . It was found that the ratio of the patients in whom the test was performed due to the complaint of fever was higher in 2-6 y age than the patients in <2 y and >6 y age groups. While the ratio of the patients in whom the test was performed due to the complaint of cough was significantly less in >6 y age group; the ratio of the patients in whom the test was performed due to the complaint of headache was higher in >6 y age group. The authors found that the number of patients in whom the test was performed due to the complaint of sore throat were less in <2 y age group as compared to those in >6 y age group. The ratio of patients with positive RSA test and positive throat culture test was higher in >6 y age group. Also the ratio of patients with complaint of cough and sore throat were low and high respectively in the patients with positive RSA and positive throat culture test. GAS is seen frequently during the winter and spring months especially in 5-15 y age groups [8] . The number of patients with positive GAS tests were higher in the winter and spring months. While viruses are responsible for 95 % cases of sore throat in <5 y age children, they are responsible for 70 % cases of sore throat in 5-15 y age group. The most common bacterial cause of sore throat is GAS. One-third cause of sore throat in children 5-15 y of age is GAS [9] . Absence of cough, headache, myalgia, fever >38°C has sensitivity of 51-79 %, 48 %, 49 % and 22-58 % respectively for GAS respiratory system infections [6] . The clinical presentations of GAS and viral acute respiratory system infections show considerable overlap and no single element of the patient's history or physical examination reliably confirms or excludes GAS acute respiratory system infection [6] . Most of the American authors suggest the necessity of microbiological confirmation for the diagnosis of GAS; clinical criteria can help a clinician to select patients who need to be tested [7] . Also in the index study, the authors found the ratio of positive RSA test and throat culture test in the winter and spring months to be higher in >6 y age group. They found the ratio of positive RSA test and positive throat culture test in the summer, autumn months to be lower in >6 age group. While complaints of fever and sore throat are more suggestive of GAS infection, symptoms like cough, nasal discharge, diarrhea and conjunctivitis are suggestive of viral causes [5, 8, 9] . Complaints like headache, nausea, vomiting and abdominal pain may accompany GAS infection especially in the children [8] . In the index study, the authors found no difference between the distribution of nausea, vomiting, nasal discharge, nasal congestion, hoarseness, headache, foot-knee-leg pain, rash, fatigue, abdominal pain and ear pain in the groups with positive RSA test and positive throat culture test. It was observed that GAS infection is higher in >6 y age group and again in this age group complaints of fever and sore throat are at the forefront and complaint of cough is lower. The authors found the presence of positive RSA test in the group with positive throat culture to be higher than the group with negative throat culture test. They found no positive RSA test or throat culture test in children <2 y age group. GAS infection is not seen frequently in <3 y age group. However, the authors found positive RVPT to be higher in <2 y age group than in 2-6 y and >6 y age groups. No statistically significant difference was found between distribution of positive RVPT in the winter, spring, summer and autumn seasons. Viral infections may show seasonal variance and peaks. However, there is no certain information regarding seasonal distribution of viral infection; viral infections vary according to the seasons, trophic-nontrophic regions and geographic locations [10] . No difference was found between the distribution of genders in the RVPT negative and RVPT positive groups. There was no difference between distribution of fever, cough, sore throat, headache, nausea-vomiting, nasal discharge, nasal congestion, rash and fatigue in the RVPT negative and RVPT positive groups. Although the complaints like fever, cough, nasal discharge and nasal congestion are suggestive of a viral etiology but they are not specific. Some clinical symptoms are nonspecific and variable in viral infections [11] . Rapid and precise determination of viral etiology in a laboratory test is necessary to initiate appropriate antiviral therapy, reduce the requirement of additional diagnostic studies and to limit unnecessary use of antibiotics in clinical therapy and also helps in epidemiological evaluation [12] . Considering and verifying the viral etiology is important for the treatment and prevention or epidemiological tracking of the disease. Currently, population of viral infection is changing and new viral agents causing serious infections are seen. According to the etiology, it is necessary to administer the required therapy to prevent the spread of the disease and to protect the patient. Also if the pathogen is viral, unnecessary antibiotherapy would be prevented. Contributions RD: Conceptualized and designed the study, designed the data collection instruments and coordinated and supervised data collection and drafted the manuscript and approved the final manuscript. SK: Designed the study, coordinated and reviewed and revised the manuscript. RD will act as guarantor for this paper.@story_separate@In patients of <2 y age group with acute respiratory tract infection symptoms and presenting with any complaint, primarily a viral etiology should be considered and should not be hurried for antibiotherapy. Viral etiology should be investigated and if it is necessary, antiviral therapy should be administered and the necessary precautions should be taken according to the viral etiology to prevent the contamination. In the patients of >6 y age group presenting with complaints of presence of fever, sore throat and absence of cough, primarily GAS infection should be considered and it should be confirmed with rapid strep A test and/or throat culture test and antibiotherapy should not be delayed.","OBJECTIVES: To evaluate clinical manifestations of acute respiratory system infectious diseases and specific tests for causative agents in pediatric patients. METHODS: The authors evaluated children aged 0–16 y with clinical symptoms of acute respiratory tract infections who were administered rapid strep A test and/or throat culture test and/or respiratory viral panel test, from February 2012 through January 2013 at pediatric department of Acıbadem Maslak Hospital, Turkey. RESULTS: A total of 1654 patients were evaluated; 45.9 % were girls, 54.1 % were boys. Absence of cough and presence of headache were higher in the patients >6 y of age (p 0.0001, p 0.002 respectively). Positive respiratory viral panel test was higher in the patients <2 y of age (p 0.002). Both positive rapid strep A test and positive throat culture test were higher in the patients >6 y of age (p 0.0001). Positivity of rapid strep A or throat culture test were not observed in children <2 y of age. CONCLUSIONS: A clinician should mostly consider viral infections in the etiology of acute respiratory infections in children under 2 y of age and there is no need to rush for the use antibiotherapy. Bacterial etiology should be frequently considered after 6 y of age and rapid use of antibiotheraphy is essential to avoid the complications."
"In the last two decades, we have seen various epidemics conditions. These conditions were started from SARS in 2002 and followed by SWINE FLU in 2009, after that EBOLA in 2013, then MARS in 2014, and now COVID-19 in 2019 [1] [2] [3] [4] [5] . These epidemic encounters can cause severe human and economic losses. If we talk about the latest COVID-19 disease, which came into the picture in late December of 2019 from china. The first case of this virus came from Wuhan city of China, which was new and never seen before. Initially, it was known as the Wuhan virus, and after that, it was coded as COVID-19 or novel coronavirus or 2019-nCov [6] . According to the hypothesis, this virus had come from the fish market (probably from the bat) of Wuhan city. Initially, it started infecting the people of Wuhan city and spread in other cities in a short span [7] . In fifteen days, china was brutally affected, and within a month, it becomes a global epidemic. Initially, it was claimed that it is an air-born disease, but after the proper assessment, the scientist told that it is a touched contagious disease, and it lasts from hours to days in different environments or surfaces. As we know, it is touched contagious disease, so we can say that it can be spread from the human to human interaction or human to surface contact. Due to the rapid spread rate of COVID-19 worldwide, the warning regarding global health emergency had been issued by the World Health Organization (WHO) [8] in the last week of January 2020. In the first week of March 2020, the WHO had declared the COVID-19 as a pandemic disease [9] . The novel coronavirus, or COVID-19, has come from the same virus family from where the Severe Acute Respiratory Syndrome (SARS-CoV) and Middle East Respiratory Syndrome (MERS-CoV) came. It is a new disease for the human that came into the picture at the end of December 2019 [10] . Before 2019 it was not identified in humans, so we did not know much about it. The COVID-19 is a zoonotic disease, which means it was transmitted from animal to people. This hypothesis is correct because some known coronaviruses are circulated from animals but have not affected humans yet. From the studies, we found that the SARS-CoV and MERS-CoV were transmitted from the animals. The SARS-CoV came from the civet cats, and MERS-CoV came from camels [1] [2] [3] [4] [5] . These diseases were born from the mutation process, which means they had transformed their properties before going into the human body from the animals. In Table 1 , some virus-based epidemic diseases have been shown [1] [2] [3] [4] [5] . This table consists of, disease name, year of its occurrence, total cases, and total death caused by the virus, totally recovered people, and the number of countries where these viruses were caught. In the novel coronavirus or COVID-19, the patient initially feels usual flu-like symptoms i.e., shortness of breath, cough, fever, and breathing difficulties, which can become more severe in a couple of days. It targets the human respiratory system, or we can say that it is a respiratory system-based disease. In severe cases, it can cause acute respiratory syndrome, pneumonia, kidney failure, other severe respiratory-related diseases, and even death too. To protect ourselves from COVID-19 and to stop its spread, we have to take precautions such as cover nose and mouth when sneezing and coughing, regular and proper handwashing, and eating those eggs and meat that is adequately cooked. Use hand sanitizer and mask on public places, don't spit on the road, avoid close contact with the ill person, avoid traveling with public transport and stay at home as much as possible [5, 8, 11] . In Fig. 1 , the situation caused due to COVID-19 outbreak is represented with a bar graph. In the figure, the y-axis represents the number of people, and on the x-axis, the number of cases, the number of recovered cases, number of active cases, and deaths caused by COVID-19 have been presented [11] . In this epidemic situation, any small finding can help a lot. Therefore, in this challenging pandemic situation, the forecasting of coronavirus outbreak plays a vital role and gives an idea about its widespread in upcoming days, which will help the government to take preventive measures for minimizing its spread [12, 13] . In this case, we need such a model that can be accurate, efficient, and widely applicable. It is a challenging task, and it becomes more challenging because we don't have sufficient real-time data. Considering these limitations in our mind, we start testing with the basic forecasting models, which are not as accurate as we are looking for [14] . After several trials, we found that our proposed Enhanced Multi-Task Gaussian Process Regression (MTGP) model on the COVID-19 outbreak forecasting is better than the traditional forecasting model. The primary aim of this study is: & To develop such a model that can be capable of dealing with this epidemic situation and give the best forecasting results. & To provide information on possible conditions in the upcoming days due to the outbreak of COVID-19, which will help in planning the preventive measures accordingly. & Along with that, the significance of IoT in COVID-19 detection and IoT based possible solutions for minimizing the impact of the COVID-19. The rest structure of this research paper is as follows. The related work has been presented in Section 2. Section 3 deliberate about the data sets and proposed methodology along with the four traditional forecasting models. The experiment results are based on performance evaluation of the COVID-19 dataset and which has been presented in Section 4. In Section 5, the detailed discussion about the results, and the significance of IoT in the detection of COVID-19 with IoT based possible solutions are shown. In Section 6, concluding remarks with the future scope is drawn.@story_separate@Complexity in developing epidemiological models encourages the researchers to find out the machine learning-based model to deal with the epidemic situation. The primary aim of the machine learning models is to develop models with better prediction reliability and better generalization ability [15] [16] [17] [18] [19] . Various machine learning models were used to predict multiple pandemics such as Ebola, SARS, Swine flu, Cholera, H1N1 influenza, Zika, Dengue fever, Oyster norovirus, and MARS [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] . These machine learning methods are limited to some basic models such as Neural Networks, Random Forest Regression, Bayesian Networks, Genetic Programming, Naïve Bayes, Classification and Regression Tree, Linear Regression, and Support Vector Regression. However, over a long time, machine learning models are being used to serve in natural disasters and weather predictions [31, 32] . For dealing with this COVID-19 epidemic, various researchers and research groups have given the mathematical and algorithmic approaches. The sub-epidemic model, the Richards model, and the logistic model had been used by Roosa et al. [33] for the prediction of confirmed cases in upcoming days (in the next 5 and 10 days) of Zhejiang province and Guangdong province. The mathematical model for the propagation status simulation due to COVID-19 in China was used by Liu et al. [34] . This mathematical model will further help the government in minimizing the impact of the pandemic. The transmission dynamics' time-dependent compartmental model was adopted by Boldog et al. [35] for estimating the confirmed cases outside china's Hubei province. The improved version of the salp swarm algorithm and the flower pollination algorithm based on ANFIS (Adaptive Neuro-fuzzy Inference System) had been proposed by Al-Qaness et al. [36] , for the prediction of confirmed cases in the next ten days. For evaluating the performance of the proposed algorithm, GA (Genetic Algorithm), PSO (Particle Swarm Optimization), ABC (Artificial Bee Colony), and FPA (Flower Pollination Algorithm), had been taken. The statistical induction and delayed distribution estimation based mathematical model was proposed by Jung et al. [37] for predicting COVID-19 cases. An analytical method based mathematical model was proposed by Fan et al. [38] for predicting the floating population of Wuhan city. In this paper, the authors had established the correlation between the floating population and daily confirmed cases. The deep learning algorithms are being widely used in the genome-based prediction of COVID-19 propagation. The SEIR (Susceptible Exposed Infectious Removed) model with LSTM (Long Short-Term Memory) model had been proposed by Yang et al. [39] for the integration of the epidemic curve. Hu et al. [40] had suggested the improved version of the stacked autoencoder and clustering algorithm for the grouping of promptly confirmed cases in each province. In this paper, the authors had also found that the AI-based methods achieve higher accuracy for the prediction of COVID-19 trajectory. The deep learning algorithm for the gene sequence-based virus prediction had been used by Guo et al. [41] . In this paper, the authors had compared the gene sequence of SARS-CoV (Severe Acute Respiratory Syndrome), bat SARS coronavirus, and MERS-COV (Middle East Respiratory Syndrome) with the COVID-19 to find out the similarity among the viruses. The early outbreak trajectories were predicted by Riou et al. [42] to determine the reproduction rate of COVID-19. Besides that, the authors had also told the possibility of frequent infections among people due to COVID-19. The improved version of the SIR (Susceptible Infectious Recovered) model for the prediction of infection cases due to COVID-2019, was proposed by Ming et al. [43] . The authors also predicted the actual load on the ICU (Intensive Care Units) under the various public health intervention efficacies and diagnosis rates. Zhao et al. [44] had proposed a probability model for the accurate prediction of the infection nodes by the snapshots of spreading. The machine learning-based pathogen-risk models were introduced by Fountain-Jones et al. [45] for predicting the COVID-19 outbreak over the various machine learning models. The ARIMA (Autoregressive Integrated Moving Average) model had been used by Benvenuto et al. [46] for the prediction of the trend and morbidity of the COVID-19 outbreak. In this paper, the authors also cited that, if the virus does not mutate, then the number of cases will reach a plateau. In this section, we are going to discuss the materials and methods which have been used for result finding. This section is divided into four subsections, i.e., dataset description, proposed methodology, model comparison, and statistical analysis. In the first subsection, the detailed discussion about the COVID-19 dataset has been presented. In the second subsection, the proposed MTGP model has been discussed in detail. In the third subsection, a brief discussion with the mathematical foundation of the four-prediction algorithm has been presented. In the last subsection, the performance evaluation metrics have been discussed. For this research work, we had gone through the health bulletin of the WHO. Based on the WHO's situation reports, the dataset has been earned, and all the experimental evaluation task has been performed on that. Due to COVID-19, approximately 213 countries have been affected. The data we took for making the forecasting model was from 31/12/ 2019 to 25/06/2020 time stamp. This COVID-19 dataset is consisting of the nine columns which are: country/territory/area name, date, the total number of confirmed cases, the total number of deaths, the total number of new confirmed cases, total number new deaths, the total number of recovered patients, the total number of active patients, and transmission classification [11] . Based on these nine columns, the data of all the affected countries has been recorded. The visualization of the dataset is shown in Fig. 2 . The total number of confirmed cases in the period of 31/12/2019 to 25/ 06/2020 has been drawn on the map. The radius of the circle is depended on the exposer in the respective country. For the visualization on the map, we had taken the country's geographical location, which is mapped with the number of confirmed cases. Gaussian Process Regression (GBR) is the non-parametric based regression model that is most commonly used in the predictive analysis [14, 47] . It can also be used for a complex system like an arbitrary system. Multi-Task Gaussian Process Regression (MTGP) is the extensive model of the basic GPR model. It is also known as the advance or special case of a typical GPR model [48] . It is applicable when we want multiple outputs using a standard GPR model. This MTGP model was proposed by Bonilla et al. in 2008 [49] , and its advanced version was introduced by Dürichen et al. in time series analysis of multivariate psychological application [50] . More recently, this method was utilized by Richardson et al. to predict battery capacity with improved results [51] . In respect to the prediction of the COVID-19 outbreak using the proposed MTGP model, the COVID-19 time series data has been given at the input side, and in the output side, the historical and reference series has been received. In the MTGP model for the prediction of time series, we follow the same testing and training mechanism as we were using in the traditional GPR model, excluding the kernel matrix. For a better understanding of the kernel matrix in the MTGP model, the two cases of output tasks are considered as an example. The standard GPR model is described in Eq. (1) Where the output and input have been denoted by a and b, the mean function has been defined as m(b), f(b) denotes the latent variable, and i(b, b′) denotes the covariance function. The squared exponential kernel (SEK) function is defined as, Where d denotes the Euclidian distance, and θ 1 , θ 2 denotes the hyper-parameter, which needs to be optimized. Thus, the hyper-parameter of the kernel matrix I have been estimated by minimizing the NLML (Negative Log Marginalized Likelihood) has been shown in Eq. (3) The mathematical implementation of the MTGP regression model has been delivered in Eq. (4). Where, a r , a p and b r , b p = two input and two output having with the same dimensionality (In the case of 1D the b r and b p are sever as time indicators for two time series). θ rr , θ rp , θ pr and θ pp = correlation coefficients of output series Where, The algorithm for the proposed MTGP for COVID-19 outbreak forecasting has been deliberated below in Algorithm 1. In this section, a brief discussion with the mathematical foundation of the prediction algorithm used in the experimental evaluation has been presented. Linear Regression (LR) is one of the most commonly used regression models for predictive analysis. The LR model uses two-variables, where the first one is dependent or reliant, and the second one is explanatory or descriptive variable. It is being used for the establishment of the relationship between the two variables. It is denoted by the slope formulary [52] . The LR model has been represented in Eq. 7, where slope in the line has been denoted by b, y-intercept has been indicated by a, the reliant or dependent variable has been denoted by y, and the descriptive or explanatory variable has been denoted by x. The LR (Linear Regression) model with the mathematical formulation is defined in the below equation: For calculation of a and b the following formulas have been used: Support Vector Regression (SVR) is one of the most commonly used regression models for predictive analysis. For the prediction using the SVR model, Eq. 10 is used [53] . Where, high dimensional feature space has been denoted by ∅ and coefficient of ∅(x) are ω and b. Where empirical risk has been denoted by R emp , Euclidian norms have been denoted by 1 2 ω k k 2 , the empirical error has been denoted by c Â 1 n ∑ n i¼1 L ε d i; À y i Þ ; and empirical risk cost has been denoted by c. In Eq. (12) the loss function has been shown, and it is obtained from Eq. (11) . Minimize, Subjected to, The testing error minimization has been shown in the Eq. (13), where slack variable for ups and downsides have been denoted by ξ * and ξ * i . Random Forest Regression (RF) comes from the family of ensemble learning. It is an ensemble learning-based regression model that has been used for predictive analysis. It was formulated in 1995 by TinKam Ho [54] . In Eq. (14) mathematical RF model has been shown h X ð Þ ¼ 1 Where a large number of predictions have been ensured by k → ∞. The random forest prediction error has been defined in the Eq. 16, and the selection of pE * t has been defined in the Eq. 15 to protect the model from overfitting. The average error of an individual tree h(X; θ) has been shown in Eq. (16) Here we adopt that all θ are unbiased for each tree, i.e., Then, Where weighted correlation has been defined by p with independent of θ and θ′, lies between residuals y − h(x; θ) and y − h(x; θ ′ ). The Long Short-Term Memory (LSTM), which is an evolutionary model of Recurrent Neural Network (RNN), was proposed by Hökreiter and Schmiduber [55] . It had been developed to deal with the deficiencies of RNN's anterior with the help of additional interactions cell or module. In other words, we can say that the LSTM is a special type of RNN capable of remembering past information and learning long-term dependencies. Olah [56] , quoted that the LSTM model can be organized as a series structure. It consists of four interaction layers instead of a single layer, such as in standard RNN. It also follows the unique communication method for interaction between the four segments. The basic structure of the LSTM model has been shown in Fig. 3 . The LSTM model with the mathematical formulation has been defined in the below equations: The Input gate is calculated by Eq. 18: Where sigmoid function has been denoted by σ, the output of the previous unit has been denoted by h t − 1 , and W i indicates the weight matrix. The Forget gate is calculated by Eq. 19: Where the output of the previous unit has been indicated by h t − 1 , the sigmoid function has been denoted by σ, and W f denotes the weight matrix. The Output /Exposure gate is calculated by Eq. 20: Where the sigmoid function has been denoted by σ, the output of the previous unit has been indicated by h t − 1 , and W o denotes the weight matrix. The New memory cell is calculated by Eq. 21: Where the output of the previous unit has been indicated by h t − 1 , and W c denotes the weight matrix. The Final memory cell is calculated by Eq. 22: Forget gate has been denoted by f t , f c t−1 , and e c t indicates cell states at time t − 1 and t respectively. Thus, the final output is opted by, Where, o t and c t denotes output /exposure gate and final memory cell, respectively. For the statistical analysis, two performance evaluation metrics have been taken: Mean Absolute Percentage Error (MAPE) and Root Mean Squared Error (RMSE). Based on these results, we can justify the performance, accuracy, and suitability of forecasting models. In this section, we have discussed the mathematical foundation of the evaluation metrics [57] . The RMSE (Root Mean Absolute Error) is one of the critical statistical measures which is based on the concept of standard derivation for residuals. It is used for the validation of the predicted result. The measurement of distances between the regression line and data points is known as residuals mean error prediction. In the Eq. 24, the number of errors has been indicated by, the squares of errors have been denoted by b y i −y i ð Þ 2 , b y i & y i denotes the observed values and forecasted values, respectively. The RMSE (Root Mean Absolute Error) is one of the significant statistical measures used to calculate the accuracy of the forecasted system. In the Eq. 25, the number of predicted values have been denoted by N, X i & Y i indicates the predicted value and actual value, respectively. In this section, we are going to discuss the prediction result of the COVID-19 outbreak based on the five prediction models,  Finding out the accurate forecasting model, which will be very useful for predicting the COVID-19 outbreak worldwide, is a very complex task. This study's fundamental purpose is to build such a forecasting model that can correctly forecast the epidemic caused by COVID-19 across the world. The correct forecasting is an essential need because all the preventive measures depend upon the forecasting results. With the help of an accurate forecasting model, we can reduce the COVID-19 outbreak's exposure by making the plan accordingly. In Fig. 4 , four traditional regression models and one proposed model i.e., Linear Regression (LR), Random Forest Regression (RFR), Support Vector Regression (SVR), Long Short-Term Memory (LSTM), and Enhanced Multi-Task Gaussian Process Regression (MTGP) has been shown. These models have been used in the forecasting of the COVID-19 outbreak. This study aims to determine the suitability and accuracy of the proposed model among the traditional models. In Table 2 , the hyperparameter setting, which has been used in the experimental evaluation, has been shown. This table consists of the information such as Prediction Model, Hyperparameter, Parameter Selection, and Best Hyperparameter Used. Before performing the experimental evaluation, we have hyper-tuned each model under the various selection criteria to determine the best parameter for the model. That best hyper-tuned parameter has been used in this experimental evaluation. Table 3 shows the result of four regression models based on the performance evaluation to forecast the COVID-19 outbreak worldwide. The forecasting result has been divided into five parts. In the first part, the forecasting of COVID-19 confirmed cases worldwide has evaluated. In the remaining part, the country-specific (China, India, Italy, and the USA) forecasting has been performed. China, India, Italy, and the USA has been taken for the prediction of COVID-19 confirmed cases. The forecasted result has been evaluated using two performance measures: MAPE (should be low) and RMSE (should be low). The performance of each model has been calculated using performance measures to find out the best suitable forecasting model among them. All the experiment has been performed using five selection or prediction criteria which are 1-day ahead, 3-day ahead, 5-day ahead, 10-day ahead, and 15-day ahead. The proposed MTGP model wins the battle with the lowest MAPE and RMSE throughout the experiment under different selection criteria (various countries). In the process of result finding, we have made the dataset with the help of the WHO health bulletin. Day to day bulletin report has been taken into consideration from the timestamp of 31/ 12/2019 to 25/06/2020. The data is consisting of approximately 213 affected countries with the country/territory/area name, date, the total number of confirmed cases, the total number of deaths, the total number of new confirmed cases, total number new deaths, the total number of recovered patients, the total number of active patients, and transmission classification. The default settings have been used in four machine learning models i.e., Linear Regression (LR), Random Forest Regression (RFR), Support Vector Regression (SVR), and Long Short-Term Memory (LSTM). But in the MTGP model, the improved kernel matrix has been used. We followed the same testing and training mechanism for the prediction of time series as we were using in the traditional GPR model, excluding the kernel matrix. In the proposed MTGP forecasting model, the dataset is given at the input side, and in the output side, the historical and reference series is received. In Figs. 5 and 6 , the performance measures-based prediction outcomes of China, India, Italy, USA, and worldwide using various forecasting model has been shown. Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) have been used as performance measures. The performance of each model has been calculated using these performance measures to determine the best suitable forecasting model among them. All the experiment has been Figs. 7, 8, 9 , 10 and 11, on the y-axis, the number of infected patients has been taken, and, on the x-axis, the date has been represented. In this experiment, the 15-days advance forecasting of confirmed cases Worldwide, China, India, Italy, and the USA, have been performed, and their results have been plotted in Figs. 7, 8, 9 and 10, respectively. Four forecasting models have been used to perform the experiments. The models we have taken are LR, SVR, RF, LSTM, and proposed MTGP model, and based on these models' results; the graph has been plotted. The prediction results for Worldwide has been presented in Fig. 7a to e. The prediction results for China, India, Italy, and the USA has been shown in the graph 8(a) to 8(e), 9(a) to 9(e), 10(a) to 10(e), and 11(a) to 11(e) respectively. All the models simulate the prediction of the COVID-19 outbreak relatively well. In the context of performance, the proposed enhanced MTGP model performs better among all other forecasting models. The bitter truth about the technologies is that we cannot replace humans with the technology because the human is enriched with decision-making authority and technologies have limited power. However, it is also a truth that humans can opt for the latest technology for making their life simple and smooth. The keywords which will define IoT for everything are efficiency, convenience, and automation. Emerging of IoT technology is a game-changer not only in the industrial perspective but also in the healthcare domain because it connects to various heterogeneous devices using wired or wireless connections and sends or receives the data to cloud base stations. The beginning of IoT in healthcare has been seen, such as the use of smart sensors, remote monitoring of patients, and the integration of various medical devices. Apart from this, the use of applications like wearable biometric sensors, activity recognition via sensors, medication dispensers, glucose monitors, and smart beds gives the wing to IoT technology and emergence to the IoHT (Internet of Healthcare Things). The significance of the IoT devices in disease detection has been discussed below. Data should always ready into action, and if we are using the IoT device for health monitoring, so we don't have to worry about the data at an epidemic stage. In the case of the COVID-19 outbreak, we face data-related issues because we don't have the correct numbers about infected patients across the world. We have some data where such smart healthcare infrastructure has been developed, but it is very lesser. We are only dependent on the WHO, which is somehow managing informative data of all countries with respect to current scenarios. That is one of the most significant issues to date. Thus, neither can we control the virus spread rate nor make an efficient prevention plan. If we have such infrastructure in the future, we will never suffer like this, because we will have enough data and could make plans accordingly. With the help of wearable IoT devices, humans can track their health and take precautions to improve their health. If we talk about the significance of IoT devices in detecting the COVID-19 outbreak, we can follow each ill person and take appropriate action to minimize its spread. Suppose we have collected data that are coming from various tracking devices. In that case, we can identify the maximum exposed area in terms of disease spread as well as the people who are escaping from the hospitals or isolation wards can also be tracked. We can also keep on eyes at the suspects. So overall, with the help of IoT devices, we can efficiently control the exposure rate as well as improve the health of patients. With the help of IoT infrastructure, we can circulate the prevention method for the public and aware of them with its consequences and effects on human health. As we know that IoT devices may generate the data in real-time thus, we can share this information or data among the mobs so they can keep track of the epidemic situation. Apart from it, we can warn people not to go in such areas where the maximum exposure has been being taken place. Thus, with the help of a real-time system like IoT for healthcare, we can promote and spread awareness among people. We can also guide them on how to deal with epidemic situations. Due to the COVID-19, the people who are suffering from respiratory diseases need extensive care. Thus, with the help of a health dataset, we can identify and track the persons who are having such problems. The prevention strategies can be made using the real-time data of disease spread and applying efficient management strategies to deal with it. It was earlier not possible because we didn't have real data. So, advanced management strategies need real-time data to deal with any epidemic diseases like COVID-19. That is possible only if, when we are using IoT infrastructure for the healthcare system. As we know, the COVID-19 is a virus-based contagious disease that has been widely spread nowadays. It can affect all the age group person but deadliest for the persons who are suffering from the below-mentioned diseases. Such a person needs extensive care from COVID-19. In Table 4 , the persons who need extensive care has been discussed [11, 58, 59] . For the detection of novel infectious diseases by existing resources and definition is the step by step process. The realtime data and their analytics are needed for taking preventive measures. With the help of accurate information and quick action, we can reduce the overall impact of the novel diseases worldwide, which can also reduce the social and economic factors of countries. The real-time tracking and detecting of the novel diseases are an arduous task, but by using the IoT, it is possible too. IoT can play a vital role in detecting and controlling the outbreak of virus-based infectious diseases in real-time. The emergence of technologies such as big data and IoT in healthcare gives researchers an area to work on. With the help of IoT, we can get the data from the various places in real-time where earlier, it was either possible thru manually or not possible at all. The device like a smart thermometer and smart thermal cameras plays a vital role in the people's initial screening so that we can detect the people suffering from COVID-19. Intelligent devices such as thermal cameras can be installed at every place like airports, railways, roadways, and home doors. Thus, we can easily identify the healthy person and ill person. All systems should be integrated with the base stations (not in a case of home automation), where we can monitor the data and plan the desired action accordingly. These things are real, which means the data has been collected and analyzed in real-time. Thus, with the help of IoT based systems, the real-time tracking of the disease spread rate and spread density can be achieved. As we know, the IoT is an interconnection of heterogeneous devices or systems, and with the help of this, we can also collect the data from remote areas. Integrating these data globally for participating in the global health system will not only help in the real-time tracking of the diseases but also in the prediction mechanism for the prevention of disease spread. The use of IoT can change individuals' lives by integrating smart clinics. Smart clinics mean the clinics which are using the various IoT devices and collecting the data in real-time. It can also communicate among the other smart clinics and also share information for medical studies in real-time. These smart clinics are connected to the central server, where all the data is being collected and monitored in real-time. All the records about the patient should be available at the primary database so, it will easy for the government to take the preventive measure when the epidemic situation comes into the picture. The primary aim of such infrastructure is to enable IoT devices and enable the associated health clinics to manage public health crises. It will also be helpful in detecting suspicion outbreaks as well as in the detection of a confirmed outbreak caused by virus-based diseases. In the situation of growing suspicion of an explosion, it can use the IoT devices to obtain focused data by locating the epidemic source. Similarly, the same network can be used for providing medication and health services in the affected areas. The lack of data availability and relevant data is a big hurdle toward making prevention policies. Data is one of the essential requirements for making appropriate approaches and test the hypothesis. It also plays a vital role in controlling infectious diseases. With the help of IoT and advanced technology in the proficient healthcare system, we can overcome these limitations or challenges. With the help of IoT based systems, we can collect the data from various locations and resources. After that, these data are sent into the central health server, which will serve as an input to the researcher for the analysis. Based on the analysis result, we can find the impact of the outbreak and make the preventive roadmap accordingly to minimize the overall effect. As we know, the whole world is suffering from the COVID-19, where preventive measures are significant to minimize the overall impact. With the help of Table 4 The person who needs extensive care Diseases Severe health problems for COVID-19 ✓ The person suffering from heart disease ✓ The person suffering from congestive heart failure ✓ The person suffering from coronary artery syndrome ✓ The person suffering from asthma, ✓ The person suffering from Emphysema ✓ The person suffering from COPD (Chronic Obstructive Pulmonary Disease) ✓ Women with pregnancy ✓ Outdoor labors ✓ Old age peoples ✓ Sportsperson who exercise strongly in outdoors IoT based smart system, we can easily find highly infected areas. Based on IoT-based intelligent systems, we can make effective solutions such as where to place the sanitizing points, which area should be a lockdown, and where we need massive health support.@story_separate@In an epidemic situation, any small finding can help a lot. In this challenging pandemic situation, the forecasting of the COVID-19 outbreak plays an important role. It gives an idea about its widespread in upcoming days, which will help the government to take preventive measures for minimizing its spread. Correct and efficient forecasting of outbreaks in any epidemic situation is a very complex but novel task. It becomes more complicated when preventive measures depend upon the prediction, and we don't have real-time data. In this paper, a COVID-19 outbreak forecasting method has been proposed to deal with all limitations compared to other traditional models. For the experimental evaluation, we have compared the performance of four traditional forecasting models, i.e., Linear Regression (LR), Random Forest Regression (RFR), Support Vector Regression (SVR), and Long Short-Term Memory (LSTM) with our proposed MTGP forecasting model to find out its suitability and correctness. Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) have been used as performance measures. The performance of each model has been calculated using these performance measures to determine the best suitable forecasting model among them. All the experiment has been performed using five selection or prediction criteria: 1-day ahead, 3-day ahead, 5-day ahead, 10-day ahead, and 15-day ahead. With the help of these measures results, we have found that our proposed model's performance is better than all other models. The proposed model achieves the lowest MAPE and RMSE throughout the experiment under various selection criteria. Apart from that, we have found the significance of IoT in healthcare as well as the importance of IoT for COVID-19 detection and IoT based possible solutions for minimizing the impact of the COVID-19. In the future, we again analyze the proposed model with different datasets and find out the further boosting techniques which can boost the model efficiency. The Sparse Gaussian Process method is one of the probable solutions.","Virus based epidemic is one of the speedy and widely spread infectious disease which can affect the economy of the country as well as it is life-threatening too. So, there is a need to forecast the epidemic lifespan, which can help us in taking preventive measures and remedial action on time. These preventive measures and corrective action may consist of closing schools, closing malls, closing theaters, sealing of borders, suspension of public services, and suspension of traveling. Resuming such restrictions is depends upon the outbreak momentum and its decay rate. The accurate forecasting of the epidemic lifespan is one of the enormously essential and challenging tasks. It is a challenging task because the lack of knowledge about the novel virus-based diseases and its consequences with complicated societal-governmental factors can influence the widespread of this newly born disease. At this stage, any forecasting can play a vital role, and it will be reliable too. As we know, the novel virus-based diseases are in a growing phase, and we also do not have real-time data samples. Thus, the biggest challenge is to find out the machine learning-based best forecasting model, which could offer better forecasting with the limited training samples. In this paper, the Multi-Task Gaussian Process (MTGP) regression model with enhanced predictions of novel coronavirus (COVID-19) outbreak is proposed. The purpose of the proposed MTGP regression model is to predict the COVID-19 outbreak worldwide. It will help the countries in planning their preventive measures to reduce the overall impact of the speedy and widely spread infectious disease. The result of the proposed model has been compared with the other prediction model to find out its suitability and correctness. In subsequent analysis, the significance of IoT based devices in COVID-19 detection and prevention has been discussed."
"Over the past decade, mindfulness training has received unprecedented popularity and widespread application in education (Maynard et al. 2017) , health (Creswell 2017) , and workplace (Beard 2014) sectors. While an increasing amount of research has been devoted to evaluating the efficacy of mindfulness training in each of these sectors, an early caveat was issued to pay equal attention to testable theories of possible mechanisms underlying the training effects . The investigation into the potential underlying process prompts a challenge to the fundamental basis of dependent and independent variables for measuring and detecting the training effects (e.g., MacCoon et al. 2012; Davidson and Kaszniak 2015; Quaglia et al. 2016; Kreplin et al. 2018) . In line with this critical approach to investigating the mechanisms of mindfulness training, the present study focuses on the effects of brief guided mindfulness meditation to elucidate the contribution of verbal guidance and the altered state of mindfulness. Mindfulness meditation is a part of the standard mindfulness training curriculum (e.g., Kabat-Zinn 2005; Williams and Penman 2011) which typically introduces students to raisin exercise, body scan, and yoga. Meditation exercises are often scheduled later in the curriculum, starting with instruction on sitting postures, followed by a suggestion that students pay attention to their breath and physical sensations. This stage of the meditation exercise is called sitting meditation (e.g., Kabat-Zinn 2005) or breath-and-body meditation (Williams and Penman 2011) . In an advanced stage of the meditation exercises, students are instructed to cultivate their love kindness, empathy, or compassion first towards close people who students relate well to, then towards neutral people (e.g., strangers on the street), and even towards least favorite people. This type of meditation is called love kindness [metta], compassion (e.g., Kabat-Zinn 2005) , or befriending meditation (Williams and Penman 2011) . Thus, there are two types of meditation exercises, sitting and compassion meditation, in mindfulness training. To understand how novice meditators experience the two types of standard 35 min-long guided mindfulness meditation, Miyahara et al. (2017a) piloted and tested the feasibility of the meditation and measuring its effects on empathic concern, that is, ""the ability to empathize with the victims of circumstance and the attitude or readiness to engage in prosocial behavior"" (Miyahara et al. 2017b, p. 160) , compassionate love, and stress response. With caution in mind that the efficacy data from pilot and feasibility studies were preliminary for hypothesis testing (Lancaster et al. 2004) , Miyahara et al. (2017a) analyzed data from the pilot and feasibility study. The pilot trial indicated an increase in empathic concern and compassionate love, and a decrease in stress response in both meditation groups. In contrast, the feasibility study not only found a decrease in stress response, but also a decrease in empathic concern in both meditation groups with a more prominent decline in the sitting meditation group than in the compassion meditation group. The authors attributed the seemingly inconsistent findings between the pilot and feasibility trials in their paper (Miyahara et al. 2017b) to the influence of a monetary reward for research participation offered to participants in the pilot trial, the drowsiness of participants in the feasibility trial who had just had lunch, and a potential Hawthorne effect in both trials. An alternative interpretation for the decline of empathic concern after both types of meditation could be desensitization to avoid compassion fatigue (Miyahara et al. 2017b) . To obtain less biased effects of the two types of guided mindfulness meditation, we planned to double-blind the current study to ensure both participants and the experimenters were unaware of which condition was being tested or the true purpose of the present study (Frey 2018) . If a researcher uses an inactive control design, it is impossible to double-blind studies of mindfulness meditation because participants know whether they meditated or not (Davidson and Kaszniak 2015) . However, double-blinding is possible in an active control trial if participants in the experimental and control groups believe that they experience the same meditation. Such a double-blind condition was devised for the present study as detailed in the method section. We also offered neither cash nor tangible reward and limited the guided meditation to 8 min to avoid drowsiness. Thus, the primary objectives of this randomized pilot study were to ensure the integrity of study protocol, data collection formats and questionnaires, and the acceptability of mindfulness meditation intervention. The effects of brief (4-8 min) mindfulness meditation have been investigated for both sitting (breath-and-body) meditation and compassion meditation. Brief sitting meditation was effective in improving mindful awareness (Ridderinkhof et al. 2017) , attention (Ridderinkhof et al. 2017; Norris et al. 2018) , pain threshold (Reiner et al. 2015) , mood, anxiety, and cardiovascular variables (Zeidan et al. 2010 ), but not on mind reading accuracy or on empathic responding (i.e., compensating for social exclusion) in a Cyberball game (Ridderinkhof et al. 2017 ). On the other hand, there is only one brief compassion (love kindness) meditation study by Hutcherson et al. (2008) who provided evidence for increased feelings of social connection and positivity towards neutral strangers. Despite these reported benefits of brief mindfulness meditation, the current understanding of the underlying process is limited (Heppner and Shirk 2018) . No past research has examined the effects of sitting (breath-and-body) meditation and compassion meditation on empathic concern in order to determine whether altered empathic concern is an effect of verbal suggestion by the guide (suggestion hypothesis) or an effect of mindfulness induced by meditation (mindfulness hypothesis). The present randomized pilot study also aims at conducting preliminary testing of the alternative hypotheses. The suggestion hypothesis (Shuck 1991) posits that an idea which intrudes the mind is accepted uncritically and actualized reflexively by activating predisposed capability and memory. During guided mindfulness meditation, verbal guides utter suggestions for meditators to follow in which there are ""differences in the status or position of the speaker and hearer as these bear on the illocutionary force of the utterance"" (Searle 1976, p. 5) , one of the 12 classifications of illocutionary acts in the speech-act theory (Searle 1976 ). If the suggestion hypothesis is true, and if the ideas conveyed by verbal suggestions are accepted and carried out, the participants allocated to the compassion meditation group would listen to the verbal guide for the compassion meditation, accept without reservation the guide's suggestions to be compassionate to all, and rate the post-test measures of their empathic concern and compassionate love as higher than the pretest measures. Such a change in the ratings on empathic concern and compassionate love should not occur in the sitting meditation group who are only told to focus on the breath, posture, and physical sensations. Instead, the sitting meditation group is expected to increase mindfulness only. Because compassion meditation is also a mindfulness meditation (Condon 2019; Kreplin et al. 2018) , an increase in mindfulness ratings is also anticipated in the compassion meditation group. The mindfulness hypothesis postulates that a single brief session of mindfulness meditation increases mindful awareness, enhances meta-awareness of self and others (Ridderinkhof et al. 2017) , and thus results in improved empathic concern (Condon 2019). If the mindfulness hypothesis is true, the participants not only in the compassion meditation group, but also those in the sitting meditation group would increase empathic concern as a result of meditation, despite the differences in the verbal guides. It is also logical to assume that the post-test measure of mindfulness would be higher than its pre-test measure in both groups.@story_separate@Study 1 was set to examine the effects of the two types of meditation (sitting meditation and compassion meditation) on mindfulness, empathic concern, and compassionate love in randomized, double-blind, two separate parallel-group, non-placebo-controlled, 1-hour protocols. It was hypothesized that verbal suggestion would be a potential mechanism in enhancing empathic concern (suggestion hypothesis) and would be supported if a significant increase in empathic concern and love kindness were observed only in the compassion meditation group. An alternative mindfulness hypothesis (i.e., a state of mindfulness, that is presumed to be induced by meditation, enhances empathic concern) would be supported if a significant increase in empathic concern, mindfulness, and love kindness were observed in both types of meditation groups. We used a 2 × 2 factorial design with repeated measures of mindfulness, empathic concern, and compassionate love. The first independent factor was a between-subject factor (the type of guided mindfulness meditation: sitting vs. compassion), and the second factor was a within-subject factor (pre-test vs. post-test). A total of 32 participants were recruited from a New Zealand university campus via word of mouth, flyers, posters, and discussion in classrooms. They were asked to participate if they: & were University students (18-30 years old) & had a total of 1 hour available to participate & had no or little (up to 6 months) former experience of meditation, and & had neither neuropsychiatric disorders nor long-term disability (lasting 6 months or more) that stops them from doing everyday things other people could do. All participants signed an informed consent form approved by a university research ethics committee before participating in the study. No course credit or monetary reimbursement was given to the participants. The Cognitive Affective Mindfulness Scale-Revised (CAMS-R) (Feldman et al. 2007 ) is a 12-item self-report questionnaire on a 4-point Likert scale which measures the quality of mindful approaches to thoughts and emotions among respondents who are not familiar with the terms related to mindfulness. The scale has shown evidence of reliability (Cronbach's alpha: .81-.85), construct (attention, present focus, awareness and acceptance), convergent and discriminant validity with other measures (Feldman et al. 2007) , and sensitivity to change as a result of mindfulness-based therapy (Lenze et al. 2014) . The Compassionate Love Scale (CLS) (Sprecher and Fehr 2005 ) is a 32-item self-report questionnaire which assesses altruistic love for close others and humanity on a 7-point Likert scale. This scale demonstrated high internal consistency (Cronbach's alpha = .94) and concurrent validity with the measures of social support (r = 0.56 and 0.27, p < .001) (Sprecher and Fehr 2005) . The Empathic Concern for Disability and Accessibility (ECDA) task (Miyahara et al. 2017b ) was developed to measure empathy and prosocial attitude by recreating real-life situations. The task consisted of participants viewing 60 slides and responding to them. In each slide, the participant read a text passage which described a person with disability in an environment and a photograph depicting the environment. The environment was illustrated as either accessible or in some way inaccessible for the person with impairment, impacting on their ability to perform a particular task, such as walking across a road. The person depicted in each slide had either mobility or visual impairment, and used a white cane, wheelchair, etc., appropriate to the impairment and situation portrayed. After viewing each situational slide for 6 s, the participant read and answered two consecutive questions on a 4-point Likert scale (0 = not at all to 4 = very much): 1) ""How much do you empathize with this person?""; 2) ""How much do you want to help this person?"". Preliminary psychometric evaluation was examined on the helping intention item which indicated strong internal consistency (α = .96) and construct validity with a four-factor solution: Factor 1: obvious inaccessible situations; Factor 2: obvious accessible situations; Factor 3: complex inaccessible situations; Factor 4: complex accessible situations (Miyahara et al. 2017b ). The responsiveness of the ECDA scale to change has been demonstrated as an effect of mindfulness meditation (Miyahara et al. 2017a ) and of the effects of gender, culture, and priming self-construal (Miyahara et al. 2018 ). Thus, the content validity and sensitivity to change have been ensured. For the current study, we modified the Likert scale from 4 points to 11 points to be consistent with the method of equalappearing interval for measuring attitude (Thurstone 1928) , while increasing variability, reliability (Givon and Shapira 1984) , and sensitivity (Leung 2011) . We also divided the 60 slides into two similar sets of 30 slides (Set A and Set B). Each participant was presented with one set of slides before meditation (either Set A or Set B) and the alternative set of slides after the meditation (See the feasibility study in Miyahara et al. 2017a ). Based on our standardization data (Miyahara et al. 2017b ), we ensured the equivalence of the two sets of slides. The order of presenting the two sets of slides were counter-balanced within each meditation group (A-B for 8 participants in the sitting and the compassion meditation groups; B-A for 8 participants in the sitting and the compassion meditation groups) to minimize familiarity bias, desensitization, and compassion fatigue (Ashar et al. 2016) . Conventional self-report measures, such as the CAMS-R for mindfulness and the CLS for love kindness (described below), are vulnerable to response bias or prone to the inherent demand that mindfulness efficacy research implicitly expect participants to ""fake good"" (Levinson et al. 2014 ). The ECDA is expected to detect such participants' ""cooperation"" and serve as a ""lie"" scale (see Crowne and Marlowe 1960) by showing participant's willingness to empathize and help people with impairment in accessible conditions in which empathy and help are not required as much as in inaccessible conditions. The Toronto Mindfulness Scale (TMS) (Lau et al. 2006 ) was developed to measure mindfulness state after mindfulness meditation. The scale consists of 13 items to tap into curiosity of current experience (6 items) and decentered awareness (i.e., awareness of experience with some distance, or meta awareness) (7 items). This scale has been used for manipulation check of brief mindfulness meditation (e.g., Hafenbrack et al. 2019 ). For brief guided mindfulness meditation, two types of prerecorded audio stimuli were prepared by slightly modifying the publicly available audio files on the web site http:// franticworld.com/free-meditations-from-mindfulness/one for guided sitting (breath and body) meditation and the other for compassion (befriending) meditation (Williams and Penman 2011) . The audio guides for both types of meditation started with an instruction for the posture and included guidance for meta-awareness of mind wandering (Levinson et al. 2014 ) and meta-cognitive control of switching attention (Bishop et al. 2004) back to the breath and the body. The modifications involved deleting the name of meditation (i.e., breath and body, befriending) and adding a bell sound at the beginning and the end. The duration of both audio files were approximately 8 mins. A pilot randomized control trial was carried out in the following steps. First, the first author (MM) generated a 32 random sequence of meditation types (either sitting or compassion meditation) on a computer. Secondly, a series of numbered icons (1-32) were created for the sequence of audio files, each of which was linked to one of the two types of mindfulness meditation guides. Third, one of the two paid research assistants (RW, TP), who were blind to the allocation of the meditation types embedded in the numbered audio flies, used Qualtrics on a Mac computer and conducted the experiment which consisted of: When a participant finished the pre-test and informed a research assistant, the research assistant told the participant that meditation can be done in any comfortable position of preference, such as sitting on the chair, beanbag, floor, or lying down on the yoga mat. The research assistant turned on a dim light, turned off the florescent light, told the participant that the recorded meditation instruction would start and end with a bell sound, and left the experiment room to give privacy after clicking the numbered audio file and hearing the bell sound. It was not possible to verify how participants were responding to the guided mindfulness meditation in situ (i.e., during the intervention) as checking in on them would disrupt the meditation. Instead, the Toronto Mindfulness Scale (Lau et al. 2006 ) was administered to measure the mindfulness state for manipulation check immediately after the meditation before the post-test. After the post-test, the first author conducted debriefing interviews on the participants' past meditation experiences, how the guided mindfulness meditation was similar or different to their past experiences, and any comments on the research experience. Prior to analysis, we screened all dependent variables. Normality was tested by two tests which examined different aspects of normality (Yap and Sim 2011) . The Shapiro-Wilk test of normality detected that the pre-test measures of the Cognitive Affective Mindfulness Scale-Revised and empathy under accessible condition, and the post-test measure of the Cognitive and Affective Mindfulness Scale violated the normality assumption. The Kolmogorov-Smirnov test for normality revealed that the pre-test measure of helping intention under inaccessible condition and all post-test measures except the Compassion Love Scale violated the normality assumption. However, ANOVA is robust to the violation of normality assumption (Harwell et al. 1992) . Moreover, Levene's test for homogeneity and Mauchly's test for sphericity showed no significant departure from the assumptions in all dependent variables. Therefore, we proceeded ANOVA with based analysis without transforming the raw data. All potential research participants, who contacted, made appointments and came to a research lab, read research information, agreed and signed the consent from. The data of Item 11 to 21 in the Compassion Love Scale from the first 13 participants were unavailable due to a technical problem with Qualtrics. The missing data were imputed with the personmean substitution approach (Hawthorne and Elliott 2005) , using the mean of Items 1 to 10. Demographic characteristics of the Study 1 sample in Table 1 showed no significant (p > .05) age or gender difference between the sitting and the compassion meditation groups. With regard to the acceptability of treatment, Table 2 indicates that the mindfulness state experienced by the participants in the both meditation groups reached equivalent levels of decentering and curiosity similar to the levels of the standardization sample (Lau et al. 2006 ) who had prior experiences of mindfulness meditation less than 1 year and practiced a 15-min mindfulness meditation session. There was no significant difference between the three groups (p > .05), therefore, both types of mindfulness meditation intervention were considered acceptable. Table 3 shows means and standard deviations of the CAMS-R, the CLS, and the empathy and helping intention scales of the ECDA task before and after the two types of meditation. Effects on Cognitive and Affective Mindfulness-Revised (CAMS-R) There was a significant main effect of meditation time, F (1, 30) = 6.88, p = .014, η 2 = .187, but not of meditation type, F (1, 30) = 2.03, p = .164. The meditation main effect was not qualified by an interaction between meditation type and time, F (1, 30) = 1.27, p = .269. This indicates that CAMS-R increases after meditation, regardless of meditation type. There was a significant main effect of meditation time, F (1, 30) = 23.025, p < .001, η 2 = .434, but not of meditation type, F (1, 30) = .401, p = .532. The time main effect was not qualified by an interaction between meditation type and time, but not of meditation type, F (1, 30) = .401 p = .532. This indicates that CLS increases after meditation, regardless of meditation type. There was a significant main effect of meditation time (pre vs. post meditation) on the empathy scale of the ECDA, F (2, 29) = 7.88, p = .002, η 2 = .35, but the main effect of meditation type (sitting vs. compassion) and the interaction between meditation time and meditation type were not significant on the empathy scale of the ECDA. Follow-up ANOVAs revealed that the change from pre-test to post-test was significant only for empathy in the inaccessible condition, F (1, 30) = 16.15, p < .001, η 2 = .35. Examination of the means indicates that meditation enhanced empathy for people with impairment in the inaccessible condition regardless of the type of meditation.  There was a significant main effect of meditation time on the helping scale of the ECDA, F (2, 29) = 7.21, p = .003, η 2 = .33, but the main effect of meditation type or the interaction between meditation time and meditation type was not significant. Follow-up ANOVAs reveal that the significant change from pre-test to post-test was significant for helping intention both under the accessible condition, F (1, 30) = 7.20, p = .012, η 2 = .19 and under inaccessible condition, F (1, 30) = 13.40, p = .001, η 2 = .31. Examination of the means indicates that meditation decreased helping intention for people with impairment in the accessible condition, and increased helping intention under the inaccessible condition, regardless of the type of meditation. Study 1 was designed to test whether the effect of guided mindfulness meditation on empathic concern was due to the verbal suggestion for love and kindness (suggestion hypothesis) or due to mindfulness attained through meditation (mindfulness hypothesis), irrespective of the different content of verbal suggestions given in the two types of meditation. The concerted results of increased cognitive and affective mindfulness, compassionate love, and empathy, prosocial intention in both meditation groups provided empirical support for the mindfulness hypothesis over the suggestion hypothesis. The results concur with the findings by Hafenbrack et al. (2019) who found that brief sitting (breathing) meditation and love kindness meditation increased a variety of employee prosocial behaviors in simulated work contexts. By contrast, our results are partly consistent and partly inconsistent with Ridderinkhof et al.'s (2017) study on the effect of brief sitting meditation. On one hand, our result of increased cognitive and affective mindfulness in the sitting meditation group is in line with the findings by Ridderinkhof et al. (2017) who reported increased mindful attention and awareness after brief sitting mindfulness meditation. On the other hand, our results on the enhanced empathic concern and compassionate love in the sitting meditation group appears to be incongruent with the Table 3 Mean and standard deviation of the cognitive and affective mindfulness, compassionate love, and empathic concern for disability and accessibility before and after the two types of meditation null finding by Ridderinkhof et al. (2017) on empathy and prosocial behavior. The reason for the seemingly different results may lie in the measures of empathy and prosocial behavior. Ridderinkhof et al. (2017) measured empathy with the Reading the Mind in the Eye (RME) Test ( Baron-Cohen et al. 2001 ) and prosocial behavior with a Cyberball game. The RME test taps into the emotional and mental states of people in the photographs and does not necessarily assess empathic concern towards victims of circumstance, that is, a combination of personal attributes (visual and physical impairments) and inaccessible environments. Moreover, Cabinio et al. (2015) found a stability of the RME Test across different age groups, which suggests the RME test scores might not be sufficiently sensitive or amenable to change. The validity of responses to witnessing someone being excluded in a Cyberball game has also been questioned as measures of empathic response and prosocial behavior because Cyberball is virtual and its measures may have no relation with real life prosocial behavior (Boyes and French 2009) . By contrast, the ECDA in the present study assesses the degree of respondents' empathy and the intention to help individuals with impairment in real-life situations. Future research should further examine the effect of sitting meditation on empathy and prosocial behavior in the real world. It is reasonable that empathic concern and love kindness increased in the compassion meditation group who were directly instructed to be kind and compassionate in the meditation session. However, why did the sitting meditation group, who were only verbally encouraged to focus on the breath and physical sensations, rate empathic concern and love kindness higher after the meditation than before? If they were not influenced by the verbal instruction to focus on the breath and body, what else could affect the compassion of participants in the sitting meditation? At the time of this writing, we found an in-press article by Hafenbrack et al. (2019) who had demonstrated that state mindfulness, induced by brief sitting meditation and love kindness meditation, had increased self ratings of compassionate responding in a workplace scenario. Whereas empathy mediated the increase in the compassionate response after love kindness meditation, perspective taking mediated the increase in the compassionate response after sitting meditation. By contrast, our results of Study 1 do not differ between the two types of meditation in the effect of increased empathy and helping intention in the inaccessible conditions, thus providing evidence that the novice meditators enhanced perspective taking for disabled people, despite the type of meditation. The possible differences in the mediating factors between Hafenbrack et al.'s (2019) study and our Study 1 may be due to the consistent scenarios employed for assessing both empathy and helping intention in the present study. Digging deeper, we would like to discuss a few more possible mechanisms underlying the influence of mindfulness on empathic concern, including values clarification, cognitive, emotional and behavioral flexibility, social desirability and response bias. Shapiro et al. (2006) proposed four mechanisms of mindfulness that lead to change and positive outcome, including self-regulation, values clarification, cognitive, emotional and behavioral flexibility, and exposure. Of the four mechanisms, values clarification operates when one observes and reflects on values with greater objectivity, then rediscovers and chooses values that are truer to oneself. If this mechanism is in operation during the sitting (breath and body) meditation with no direct or indirect suggestion for compassion, the participants' deep values (Brown et al. 2007; Grecucci et al. 2015; Lim et al. 2015; Shapiro et al. 2006; van der Velden et al. 2015) , such as empathic and prosocial values or values for compassionate love, are clarified. Value clarification leads to value-based decision (Eberth et al. 2019; Zerubavel and Messman-Moore 2015) , and further wise and meaningful actions (Baer 2015) . For this reason, the meditator would be more willing to help the victims of circumstance after than before the sitting meditation. Furthermore, the mechanism of cognitive, emotional and behavioral flexibility also facilitates adaptive response to the environment (Franquesa et al. 2017) , thereby fostering prosocial intention appropriate for the given built environment. Thus, the mechanisms of values clarification, cognitive, emotional and behavioral flexibility may contribute to understanding this noteworthy and unexpected finding. It is remarkable to note that after meditation the participants in both groups were less willing to help people with impairment in the accessible condition, and more willing to help them under the inaccessible condition. This finding can be interpreted as enhanced insight into appropriate prosocial behavior after meditation. Wen et al. (2013) define insight in terms of problem-solving performance that involves executive functioning. To gain insight and solve a problem, one needs to take an unorthodox perception of a situation and a creative approach to solving the problem (Parker et al. 2015) . To make a judgement of when to and when not to help people with impairment, the participants may gain insight as an outcome of critical thinking which includes three metacognitive skills (Dwyer et al. 2012) : (1) analyzing the ability of the potential support recipient and the environment; (2) evaluating whether the environmental demand exceeds the ability or not; (3) inferring the potential need of support recipient. The two types of mindfulness meditation appear to have facilitated the usage of these skills and resulted in more appropriate intention for prosocial behavior. Improved insight through critical thinking has been a target outcome of mindfulness meditation for a long time. For instance, the cultivation of insight into impermanence is encouraged through meditation practice focusing on the body in the classic Buddhist canon, entitled Satipaṭṭhāna-sutta (Anālayo 2015) . However, there is surprisingly few studies that have examined the relation between mindfulness meditation and insight through critical thinking. To date, there has been only one cross-sectional study (Noone et al. 2016 ) which demonstrated a link between dispositional mindfulness and critical thinking. Brown (2015) also pointed out a lack of research that had examined the relation between insight and compassion. The present study may be among the first intervention studies to provide evidence for appropriate empathic concern, or compassion through enhanced insight and critical thinking as an effect of mindfulness meditation. Future research needs to confirm the effects of enhanced insight and critical thinking with each of their specific measures. Before fully accepting the mindfulness hypothesis, we should consider the limitations of and alternative explanations for Study 1. In addition to the relatively small sample size of the pilot randomized double-blind trial, Study 1 has no inactive control group, but instead has an active control group (i.e., sitting meditation and compassion meditation served as a control for each other). There is a possibility that the same effects may be obtained with no intervention or with a non-mindfulness intervention. For example, Quaglia et al. (2016) warn that social desirability bias and response bias may lead to mindfulness training-related changes on mindfulness scales. MacCoon et al. (2012) further demonstrate that an active control of a non-mindfulness intervention, named Health Enhancement program, has an effect on reducing psychological distress similarly to the effect of a standard Mindfulness Based Stress Reduction program. To investigate the possibility of response bias and estimate non-treatment effect, we planned Study 2. The purpose of Study 2 was to examine if the same dependent measures as Study 1 would significantly change as a result of repeated measures administered to an inactive control group without mindfulness meditation. For this study we used a pre-post trial design of a nonmindfulness intervention. Right after the completion of Study 1, a total of 16 participants were recruited in the same manner as Study 1 via word of mouth, flyers, posters, and discussion in classrooms, using the same inclusion/exclusion criteria and the ethical procedures, so that the participants would think that they were participating in the same study as Study 1. We used the same Cognitive Affective Mindfulness Scale-R e v i s e d (C A M S -R ) ( F e l d m a n e t al . 20 0 7) , t h e Compassionate Love Scale (CLS) (Sprecher and Fehr 2005) , and Empathic Concern for Disability and Accessibility (ECDA) task (Miyahara et al. 2017b) . As in the case of Study 1, the order of presenting the two sets of the ECDA are counter-balanced (A-B for 8 participants in the sitting and the compassion meditation groups; B-A for 8 participants in the sitting and the compassion meditation groups). After the pre-test, the first author (MM) conducted a debriefing interview on the participant's knowledge and experience of meditation for approximately 8 min. An inactive waiting control was not used because those participants who were interested in meditation might have meditated while waiting. A pre-post trial was carried out by the first author (MM) by using Qualtrics on the same Mac computer and conducting the experiment, consisting of  Demographic characteristics of Study 2 sample in Table 1 show no significant (p > .05) age and gender difference from the Study 1 sample. Table 4 shows the means and standard deviations of the empathy and helping intention scales of the ECDA, the CAMS-R, and the CLS before and after the nonmindfulness intervention. For unknown reasons, data from the second administration of the CAMS-R were unavailable from Qualtrics for one participant, and a pairwise deletion of CAMS-R data was applied to this participant, leaving a subtotal of 15 datasets for CAMS-R. There was no significant change from pre-test to post-test in empathy both under accessible (t = .953, 95% CI: −7.340-19.215, p = .356) and inaccessible (t = −.169, 95% CI: −17.006-14.506, p = .868) conditions. There was no significant change from pre-test to post-test in helping intention both under accessible (t = 1.235, 95% CI: −5.942-22.317, p = .236) and inaccessible (t = .234, 95% CI: −17.700-22.075, p = .818) conditions. There was no significant change in the CAMS-R from pre-test to post test (t = −.463, 95% CI: −.347-.223, p = .650). There was no significant change in the CLS from pre-test to post test (t = −.459, 95% CI: −.377-.243, p = .653). Study 2 examined the effect of a non-mindfulness intervention on empathic concern, cognitive and affective mindfulness, and compassionate love. The results revealed non-significant changes in these variables, thus suggesting that the significant meditation effects obtained in Study 1 were not simply due to the repeated measures, but the effects of guided mindfulness meditation. Coupled with the results of Study 1, the results of Study 2 lend further support for the mindfulness hypothesis that mindfulness induced by the guided meditation altered empathic concern, mindfulness, and compassionate love. This result echoes the findings of Bayot et al. (2020) who compared the effects of two types of mindfulness training over 8 weeks: the standard mindfulness training (SMT) (Kabat-Zinn 2005) and the ethics-oriented mindfulness training (EMT) which integrated the Buddhist teachings of loving kindness, compassion and common humanity into the SMT. Their findings revealed a significant increase in self-rating measures of mindfulness as a result of both SMT and EMT and no significant interaction between meditation type and time for self-rating measures of empathic concern, as in the case of our Study 1. They also found that the SMT significantly increased self-report measures of compassion, and that the EMT increased self-report measures of tendency to empathize with the feelings and situation of others more than the SMT had done. Bayot et al. (2020) concluded that their findings on the effects of SMT and EMT on empathy were ""marginally significant and lacking specificity"" (p. 8), attributing this finding to self-report response bias, which included social desirability discussed earlier, the ""short"" duration of training, and a lack of specific focus on empathy in EMT. It is interesting that even eight-weeks of mindfulness training, comprising 2 hour sessions per week, were considered inadequate, but still resulted in similar findings to our brief guided mindfulness Table 4 Mean and standard deviation of the cognitive and affective mindfulness, compassionate love, and empathic concern for disability and accessibility before and after the two types of meditation meditation study. The present study therefore adds to the literature by partially ruling out the effect of repetitive measures. While Study 1 and Study 2 results provide evidence for the mindfulness hypothesis, there remain three primary limitations of these studies. One of the limitations of the studies is their small sample sizes and the missing data. Although ANOVA is robust to violation of normality assumption, some dependent variables were not normally distributed. A second limitation is the fact that the non-mindfulness intervention group in Study 2 is not allocated randomly from a single pool sample as part of Study 1. There may be a possibility that the time lag between Study 1 and Study 2 could influence the participants' interest in and motivation for the study. A third limitation is a possible experimenter expectancy effect (Colman 2015; Kreplin et al. 2018) due to lack of blinding of the single experimenter in Study 2 who knew the purpose and the hypothesis of the study and conducted the debriefing interview as a non-mindfulness intervention. The experimenter's knowledge and expectations may have influenced the participants' response to the repeated measures. However, it is still likely that the participants would have expected and demonstrated no change between pre-test and post-test even if a blinded research assistant had conducted Study 2. These three limitations could be resolved by a future study based on a large sample size, single/double-blind, three separate parallel-group protocol. If guided meditation is not administered between the pre-test and post-test measures, but at the end of the experiment, the participants would know the absence of meditation between the repeated measures, and therefore, double-blinding of the inactive control is not possible (Davidson and Kaszniak 2015) . Directions for future research also include administering the same protocol to intermediate and advanced meditators. If more developed mindfulness coincides with profound empathic concern and love kindness, such a finding would lend further support to the mindfulness hypothesis. Conflict of Interest On behalf of all authors, the corresponding author states that there is no conflict of interest.@story_separate@In support of the mindfulness hypothesis, novice meditators increased compassionate love and situationappropriate empathic concern as a result of an altered state of mindfulness induced by guided mindfulness meditation. Mindfulness meditation seemed to foster deepened insight into, and enhanced critical thinking of values, irrespective of whether the verbal guidance drew attention to the breath and body or love kindness. The same effect was not obtained when a control task of a debriefing interview was conducted on the topic on meditation experience and knowledge in place of meditation, which further supports the mindfulness hypothesis.","Despite the widespread popularity of mindfulness meditation for its various benefits, the mechanism underlying the meditation process has rarely been explored. Here, we present two preliminary studies designed to test alternative hypotheses: whether the effect of brief guided mindfulness meditation on empathic concern arises from verbal suggestion (suggestion hypothesis) or as a byproduct of an induced mindfulness state (mindfulness hypothesis). Study 1 was a pilot randomized control trial of sitting (breath-and-body) meditation vs. compassion meditation that provided preliminary support for the mindfulness hypothesis. Study 2 was set up to rule out the possibility that the meditation effects observed in Study 1 were the effects of repeated measures. An inactive control group of participants underwent the repeated measures of empathic concern with no meditation in between. The pre-post comparison demonstrated no significant changes in the measures. Thus, the results of two studies supported the mindfulness hypothesis. Limitations of the present study and future research directions are discussed. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (10.1007/s12144-020-00881-3) contains supplementary material, which is available to authorized users."
"The way healthy societies are conceptualised plays a role in shaping efforts to achieve them. Within and across countries, different ideas coexist. Some assume dominance, whether by force or consent. In a constructivist analysis, that explores beyond the material reality the socially constructed nature of knowledge, the dominance or hegemony of particular ideas is a consequence of many factors. These include production relations and the use of material power to dominate others, but also the sociopolitical forces and relations, and the institutions, rules and procedures used Summary box ► Two approaches have coexisted for centuries in global thinking on healthy societies: social determinants and rights-based approaches and biomedical/ pathogenic approaches, with global positions and policies presenting a dominant view that masks significant diversity in thinking about healthy societies in different regions. ► When biomedical approaches were imposed in India, Latin America and East and Southern Africa, they undermined local cultural understandings of health, and in all three regions stimulated rights-based, social determinants and social medicine approaches to confront the alienation and health inequities generated by colonialism and globalisation. ► Advancing ideas into policy depends on growing social, scientific and policy networks and calls for spaces to debate contesting ideas, investment in a more equitable circulation of ideas between regions in framing global approaches, and transdisciplinary, reflexive and participatory ways of building knowledge that are embedded in and learn from action. ► In responding to threats posed to health by climate change, the damage to ecosystems and pandemics, how we think and act on healthy societies and how far the choices are understood and made beyond elites and states within society itself can lead us to significantly different futures.@story_separate@to impose, negotiate, build convergence and maintain consent around particular ideas, and to suppress others. 1 A social constructivist analysis brings the public into this analysis, arguing that hegemonic power is exercised when dominant ideas are embraced by society. It is thus not only the ideas advanced or imposed by socioeconomic elites and states that matter, but also those that are promoted by social actors and that exist in the public mindset. 1 COVID-19 has exposed major shortcomings in our thinking about healthy societies and raises both demand and opportunity to reflect on, debate and challenge our thinking. We face a range of old and new challenges to building healthy societies. As pandemics, commercial practices, climate and ecosystems increasingly call for collective strategies across countries, what can we learn from the paradigms emerging from different regions globally? To explore this, with the 1978 Alma Ata Declaration on Primary Health Care (PHC) as an entry point, we investigated the trajectory of frameworks for healthy societies that had wide or sustained policy influence. We covered those at global level, with its influences from Europe and the USA, and in three southern regions, India, Latin America and east and southern Africa (ESA). The southern regions were purposively selected as having significant populations, diverse cultures and histories that the authors (RL, EV and RB) had direct and sustained system and policy experience of. We analysed the features and drivers of the paradigms to generate insights on building shared frameworks for how to achieve healthy societies. At global level and in the three aforementioned southern geopolitical areas-termed 'regions'-we identified dominant, persistent or influential paradigms post-1970, noting earlier contributions to these ideas. We defined paradigms as systems of beliefs, ideas, values and actions that reflect thinking about the real world, and identified a healthy society as one that promotes health and does not wait for people to become ill. 2 We included 150 English and Spanish documents obtained from online searches using key terms, regions and time frames and drew also on the authors' own experiences of the regions covered. A shared analytical framework was applied to document the goals, ideas and approaches within these paradigms and their drivers. A grounded thematic analysis was used to identify key themes. A structured meeting covering the review of the findings, the conclusions and the implications for policy and practice was held with experts to review and validate our findings. The reviewers were purposively selected from those identified from the source publications and those known to authors to collectively represent the different regions and global level; roles in academia, civil society, government, national, regional and global agencies; and health, rights, social determinants, system, political and social science and international relations disciplines. Further literature was sourced after the meeting to respond to feedback on methodological, paradigmatic, evidence and analytical issues. Figure 1 shows the regions and paradigms included. Table 1 lists key policy events chronologically. We recognise limitations: While the regions included cover significant populations, other important regions were excluded due to limitations of time, resources and language. The breadth of period and geographical scope implies a loss of detail. We did not explore policy implementation nor what affected this. The evidence is qualitative and intends to make no associations between paradigms and their health impact. Notwithstanding these limitations, the regions reviewed featured compelling and influential discourses about healthy societies that can generate new insights on how to better engage with historically produced and contextdependent ideas of 'healthy societies', within and across countries globally. This section summarises key features of the findings, presented separately in more detail. 3 Box 1 summarises early ideas that contributed to paradigms covered. A pathogenic, biomedical paradigm A pathogenic paradigm that aimed to reduce disease as a basis for improved health flourished with advances in scientific knowledge and technology. It informed an optimistic expectation that disease could be eradicated by technology and modernisation, reinforced by the expansion of medical care in Europe. In the three southern regions, its colonial application was less benevolent. Military, material, legal and scientific power was used to suppress local economies and cultures, undermining or criminalising traditional health systems even while appropriating their therapies. [4] [5] [6] Colonial public health laws, like India's 1897 Epidemic Diseases Act, enabled authorities, sometimes supported by militaries, to forcefully segregate people and demolish 'infected places', with limited attention to remedying social conditions. 5 7 8 Allopathic 'tropical medicine' was portrayed as a superior approach. 9 After independence, many governments in ESA countries or Nehru's India sought to modernise through a 'catch-up' of Western models, expanding curative services and biomedical prevention to underserved populations. [9] [10] [11] This yielded important gains in disease reduction. However, ignoring social realities and underlying causes also led to failures, such as in India's technologically driven 1955-1969 malaria eradication campaign. 12 When combined with eugenic theories, it led to rights violations, such as in India's coercive sterilisation programme in the late 1900s. 13 Although the 1978 PHC Declaration discussed later provided a contrasting approach, subsequent economic, oil and debt crises reinvigorated a biomedical focus. A 'Washington Consensus' of Organisation for Economic Co-operation and Development-country governments BMJ Global Health and Bretton-Woods institutions responded to the crises with neoliberal reforms favouring free trade, deregulated markets and reduced social budgets. They argued that the wealth from macroeconomic growth would 'trickle down' and improve population health. The resulting social deficits and inequalities were seen as transitional and addressed by targeted social schemes and development aid. 14 Within these neoliberal reforms, comprehensive PHC was seen to be infeasible. A 1979 Bellagio meeting sponsored by the Rockefeller Foundation and World Bank instead proposed 'selective PHC' as a set of technical, low-cost interventions, covering growth monitoring in children, oral rehydration, breast feeding and immunisations. 12 Investment in public health was further weakened by the World Bank promotion of a 'cost-effective' package of biomedical services based on their unit cost for the disability-adjusted life years achieved. The World Bank also proposed a split of health systems into state-provided preventive services and primary care as public goods, with privately provided higher-level curative services. 11 15 While private philanthropic foundations have been involved in international health for over a century, the promotion of selective PHC and of private actors in health financing and systems opened a space for greater influence of the private sector in policy and governance and partnership with state and non-state organisations within countries and at the global level, including in global funds and alliances. 16 While this was seen to bring new resources and technology to the sector, it also raised concerns about conflicts of interest between private, commercial interests, broader public health norms and interests and goals,  including in relation to the focus and commercialisation of health services. 16 In India, these measures strengthened the private medical industrial complex, while many ESA countries moved from comprehensive services to efficiency-led largely curative service packages. [17] [18] [19] As a response to the rising poverty and resurgent infectious diseases from neoliberal reforms, UNICEF and others promoted targeted initiatives to reduce poverty as targeted, temporary philanthropy, not as a right. 20 These developments triggered protest, especially from civil society. 21 However, the paradigm shift was substantial: a 'healthy' neoliberal economy set the parameters within which measures for a healthy society should be achieved. It privileged individual responsibility and a limited role for the state, replacing universal health systems and social policy with commodified or targeted approaches. 20 Globally, and with HIV surging in the late 1980s, attention focused on biomedical management of high mortality diseases. This magnified vertical diseasefocused approaches and gave growing policy influence to newly created institutions like the Global Fund for AIDS, TB and Malaria and the Global Vaccine Alliance, and to private foundations like the Gates Foundation. 14 These global partnerships helped to fill perceived gaps in system responses to high-mortality diseases. However, the significant technical and financial resources they directed to a selective, vertical disease approach was observed to skew agendas within countries and globally towards specific targeted biomedical outputs rather than systems or the deeper causes of diseases. 16  Paradigm  The 2000 Millennium Development Goals (MDGs), in their focus on infant, under-5 year and maternal mortality, HIV, tuberculosis and malaria largely reflected this understanding of a healthy society being achieved through cost-effective interventions to reduce major causes of mortality. Having global goals did reassert state obligations for population health. 22 23 However, the MDGs did not challenge the biomedical paradigm, and in their targeted approaches left many aspects of healthy societies poorly addressed, including those from commercial determinants associated with rising levels of chronic disease. 18 The MDGs shifted the focus from what was technically and scientifically feasible for population health to what could be funded through bilateral aid and global institutions. 23 24 While contested and unresolved, the focus on universal health coverage in the later Sustainable Development Goals (SDGs) could enable a positive rights-based approach to access to healthcare. 25 However, when framed in terms of what can feasibly be funded, it still focuses more on biomedical services than action on social determinants of health (SDHs). 26 A social medicine, social determinants paradigm In 1948, the Universal Declaration of Human Rights (UDHR) situated health within rights to living conditions, health and social services and social protection, a broad lens that was also reflected in the 1948 WHO constitution. 27 Cold War political contestation between a US focus on civil and political rights and a USSR focus on economic and social rights divided the UDHR framing into two separate covenants: the International Covenant on Civil and Political Rights and the 1966 International Covenant on Economic, Social, and Cultural Rights, with implicit tensions between individual and collective rights. 27 Meanwhile sociopolitical movements in many southern regions were raising claims for socioeconomic justice, including those for their role in improving health. In ESA countries, nationalist movements from the 1950s built solidarity (and ubuntu) across countries in anticolonial struggles. They linked improved health to economic and political justice, socioeconomic rights and self-determination. Post-independence, this motivated a range of early redistributive socioeconomic policies to address health inequities, including comprehensive PHC. 7 Comprehensive PHC was applied as a strategy to resolve historical inequities in health, to guide health development and to involve people in community health. PHC-related strategies promoted nutritious local food crops and community gardens, school health and gender parity in education, and expanded access to safe water and sanitation. 7 Redistribution of land and greater domestic control over minerals, biodiversity and other resources, in a form of 'resource nationalism' was also seen as necessary for the economic inclusion needed to promote health equity and well-being and promoted in policy by countries, regional economic communities and the African Union. [28] [29] [30] This has been a sustained focus into the 2000s, with the first goal of the African Union's Agenda 2063 development plan focusing on inclusive growth and sustainable development, through ensuring a high standard of living, food and social systems for a quality of life, sound health and well-being. 30 Domestic efforts to apply comprehensive PHC also led ESA countries to engage globally in medicines access, migration of health workers, control of breastmilk substitutes, food security, debt cancellation and fair trade. 29 In many Latin American countries, political activists adopted Virchow's SM approach noted in box 1. Rather than reducing health outcomes to individual risk factors, they viewed health as linked to social class and organised evidence and sociopolitical activism to confront the socioeconomic causes of ill health. 31 Followers of Virchow who migrated to Latin America established SM courses. One of those trained was Salvador Allende, who was Chile's health minister and later president in 1970 who applied SM in socialist policies and in creating a tax-funded, universal National Health System. 31 In Argentina, Ramón Carrillo and Juan Justo promoted investments in nutrition and living conditions to improve workers' health. Argentine-born physician Ernesto (Che) Guevara influenced the radical socioeconomic changes made after the 1959 Cuban Revolution, addressing the determinants of well-being and expanding universal primary care. 32 Notwithstanding their positive health impact, when US-supported military dictatorships took power from the 1970s; they overturned these SM policies in favour of Box 1 Paradigms prior to the 1978 Alma Ata Declaration with sustained or resurgent influence Debates over the relative roles of microbes versus wider health determinants emerged and persisted for centuries historically, including between Hippocrates and Aristotle, BC, to Pasteur and Bechamp in the 1800s. A pathogenic paradigm informed quarantines to contain health risks and 'sanitary' reforms internationally, in Europe and in USA. 12 14 61 71 In contrast, Rudolf Virchow and Frederik Engels in the late 1800s promoted social medicine (SM) to address the sociopolitical, structural causes of illness. 37 74 Both pathogenic and SM approaches informed policies of the League of Nations Health Organisation, the precursor of the WHO. Extreme ideas also emerged. Eugenic theories attributing workers' risk in the 1918 influenza pandemic to 'inferior' genes rather than poor environments found conducive conditions during European fascism in the 1930s. 71 The three southern regions had their own traditional approaches. Latin American Andean indigenous beliefs of buen vivir or sumaq kawsay in Quechua integrated harmony across human, spiritual and natural systems as a basis for well-being. 75 In India, supernatural, moral, spiritual and material worlds were integrated in Ayurveda, Siddha, Unani and Tibb systems. 76 Ubuntu ideas identified reciprocity in relationships between community members and ancestor spirits as a factor in well-being, informing practice in east and southern African countries. 77 78 These approaches reflected common features of community, collective interests, complementarity and reciprocity, positioning health as a consequence of harmony and equilibrium with nature and spiritual cosmic forces. They drew on and protected local biodiversity for their role in health, such as in the use of 1200 plants with therapeutic benefit in Kenya. 4 79 BMJ Global Health neoliberal market reforms, with the repression and exile of many SM proponents. 31 In India, when state-led modernisation failed to deliver on social expectations, social movements advocated that '…the struggle for liberation (was) not just from alien rule but also from internal decay' (Kothari, p220). 33 They stimulated grassroots community health projects that connected health with social justice and local democratic control. 34 Mahatma Gandhi, the lawyer and anticolonial nationalist, was critical of earlier biomedical approaches. He proposed health promotion to achieve a balance between body, mind and spirit. He saw this as starting at village level, with healthy lifestyles, conditions and local herbal remedies promoted by primary health centres and community health workers. 35 Many grassroots groups and issue-based coalitions adopted this paradigm in the 1970s. They learnt new concepts of a 'health worker' from the Chinese barefoot-doctor experience and promoted the idea of 'people's health in people's hands'. 34 36 In the more multipolar world at the end of the Cold War, alliances widened around demands for more inclusive, long-term socioeconomic growth and fairer terms of trade and development finance, spearheaded by international institutions such as the Non-Aligned Movement, the Group of 77 and the UN Conference on Trade and Development. A 1974 UN General Assembly resolution called for a new international economic order. 12 The view was that if the determinants of health are economic and social, the remedies must be too. 37 WHO observed, 'people are beginning to ask for health and to regard it as a right' (Gostin et al, 2732) . 27 Halfdan Mahler, WHO Director General from 1973 to 1988, responded to these international pressures and local innovations, calling for new approaches (Chorev, p1). 38 'Health for All in the Year 2000' recognised the pressures for equity and justice, with many emergent ideas and innovations integrated in the 1978 Alma Ata Declaration's comprehensive PHC. 12 Comprehensive PHC as a multidimensional, bottom-up and sociopolitical framing of health resonated with and reinforced these SM, social justice-driven, rights-based intentions. As noted earlier, PHC was central to postindependent ESA country health policies. 7 11 Indian social movements advanced comprehensive PHC and rights-based approaches to health. 39 The new governments replacing military regimes in Latin America in the 1990s implemented rights-based, redistributive, pro-poor social programmes and schemes that drew on SM and 'collective health' approaches. 40 Internationally, the 1986 Ottawa Charter for Health Promotion built on the comprehensive PHC vision of healthy societies in promoting intersectoral action for health (IAH), recognising peace, socioeconomic conditions, sustainable ecosystems, social justice and equity as fundamental conditions for health. In contrast to the prior view that health improvements depended on rising aggregate wealth, the Charter posed health as a right and a resource for development. A 1993 World Conference on Human Rights brought socioeconomic and civil/political rights into one framework and identified collective agency as critical to realise such socioeconomic rights. 41 A growing body of research evidence, including those from the 2008 WHO Commission on SDH, indicated how acting 'upstream' on SDH would tackle unjust inequalities in health. This motivated first IAH approaches, and then 'Health in All Policies', to integrate health into different sectoral policies, laws and measures. 37 42 43 'Whole-of-Government' approaches went further to locate leadership for health outside the health sector, such as in the urban mayors of the European Healthy Cities Network. 44 These approaches aimed largely at domestic intervention. However, new sociopolitical configurations also emerged around international-level challenges. Solidarity-based south-south cooperation grew through forums such as the Brazil, Russia, India, China and South Africa forum and in transnational social rights movements, such as the global People's Health Movement. 29 These alliances engaged in and convened global processes on SDH. 45 46 They challenged global barriers to public health. For example, an alliance of African, Indian and Brazilian diplomats and treatment activists successfully advanced the 2001 World Trade Oorganisation (WTO) Doha declaration on Trade-Related Aspects of Intellectual Property Rights (TRIPS) and Public Health to enable access to medicines, notwithstanding contestation by some high-income countries. 22 47 By the end of the 1900s, the context in which states constructed their national interests and ideas on how to promote healthy societies was changing, raising collective interests and opening space for non-state actors. Rising global wealth in the 2000s, together with rising social inequality, economic insecurity and worsening living, working and community environments, challenged the idea that neoliberal economic growth guaranteed improved well-being. It signalled the limits of macroeconomic growth as a measure of progress, with a more multidimensional well-being, equity and intergenerational lens on development articulated, for example, in the 2009 Sarkozy Commission on Measurement of Economic Performance and Social Progress. 12 14 In 1998, Yach and Bettcher identified the global diffusion of ideas, values, rights, knowledge, practices and products from transnational actors affecting health as global-level SDH. Rising food prices, a 2008 energy and financial crisis, conflict, population displacement, environmental and biodiversity degradation added growing evidence of such global determinants and their impacts, including on increased chronic disease, pandemics and social deprivation. 14 Some countries and social movements called for global responsibilities to inform international cooperation and intervention. 12 37 In the early 2000s, various global measures were passed to promote cooperation and to limit market practices shown to be BMJ Global Health harmful to health, including those in the International Health Regulations (2005) and the Framework Convention on Tobacco Control (2003). In Latin America, the negative local consequences of extractive transnational activities on environments, cultures and well-being motivated a renewed focus on the early 'buen vivir' (BV) ideas described in box 1, while the Latin American Social Medicine Association networked academic and sociopolitical actors in a sustained mechanism for SM influence, including those in global processes. 48 BV resonated with the aspirations for social justice, environmental protection, cultural diversity and the anti-imperialist perspectives of both indigenous people's organisations and left-wing governments, such as in Venezuela, Ecuador and Bolivia. 49 50 The social policies informed by BV improved health and education outcomes and reduced poverty and social inequality. However, a dependence on foreign-owned extractive industries and deep integration in the global economy made BV-related economic policies more difficult to implement. 51 An intercultural health (ICH) approach thus had wider application in Latin America. It too confronted the sociocultural alienation, inequities and racism from both colonialism and globalisation. A concept of 'plurinational' states legally recognised the multiethnic nature and rights of indigenous peoples, including the 'right to be different' and to participate and coexist at all levels. ICH integrated indigenous health, farming, food and herbal knowledge and practices, and community power within comprehensive PHC. 52 53 54 In the 2000s, indigenous groups, technical experts and some governments worked with regional health organisations to operationalise ICH, while UNESCO, the International Labour Organization Convention 169 and the United Nations Declaration on Indigenous Peoples and their Right to Health widened its uptake. 55 56 In ESA countries, where neoliberal reforms and a net outflow of resources from extractive activities diminished resources for social improvements, countries engaged in various south-south cooperation platforms and through African diplomatic unity to negotiate fairer returns from the global economy around trade, biodiversity, health worker migration among other issues, and for greater voice in global processes and governance, including to deliver on healthy societies nationally. 5 18 29 57-59 Many of these processes were state-led. However, the rise in social movements described earlier and the global impact of social movements on HIV, including in the 1994 establishment of Joint United Nations Programme on HIV/AIDS (UNAIDS), suggested that social activism using rights-based approaches could overcome powerful interests impeding health action by anchoring health development in claimant and duty bearer capacities and systems. This moved action from the optional realm of benevolence and aid into the mandatory realm of law, positioning people as active claimants of rights, rather than passive beneficiaries, and raising attention to the mechanisms and processes for exercising claims and holding duty bearers accountable. 27 60 Within this global context, the 2015 SDGs integrated goals relevant to many SDHs. However, as shown in box 2, the SDGs left unresolved debates on the global determination of inequalities in these SDHs. 61 It was thus the later 2016 Global Conference of Health leaders' 'Shanghai Declaration' that took a more challenging global position on the sociopolitical determination of commercial and global determinants of healthy societies. The declaration raised the duties of different actors and sectors to address these determinants, calling for a whole of society engagement and global collective action to advance equity, and to address powerful commercial forces that work to counteract health. 62 In the 2020s, climate change, the degradation of ecosystems; financial, energy and food crises; pandemics and antimicrobial resistance have given evidence of intensifying international determinants of healthy societies. These crises have highlighted links to production and consumption patterns and the extreme social inequality generated in the current global political economy, widening the differences between pathogenic and SDHdriven responses. 54 The emergence of planetary health Zoonotic pandemics, antimicrobial resistance and environmental challenges led in the 2000s to 'One Health' and 'Ecohealth' approaches that connected human, animal and environmental health, and to growing global dialogue on biodiversity and health. 54 61 63 64 By the 2010s, the immediate and intergenerational climate and ecosystem threats to survival and growing evidence of policy alternatives gave impetus to a planetary health paradigm, intensifying demands to address global determinants of healthy ecosystems, with social protest, In the background work for the SDGs, one 'post-Millennium Development Goal' stream led by the UK advocated an international aid and technical development lens, while a second, with strong southern, environmental and equity voices, challenged the sociopolitical nature of development inequalities. Inequality was recognised by both streams, but there was a debate on whether it meant tackling the distributional inequality of power and wealth between social groups and countries, or focusing only on the exclusion of vulnerable and marginalised populations. This contestation between countries crystallised around whether and how to include a specific goal on inequality. 80 When the World Bank introduced the concept of ending extreme poverty as the goal, it was contested for not addressing the growing concentration of wealth in the top decile. The concept was, however, advanced in a manner that masked political influence by shifting the debate to a technical committee focusing on how to 'frame' and measure the goals, locating inequality within a narrow set of individual factors that focused on vulnerability of individuals rather than inequalities in wealth. 80 BMJ Global Health much youth-led, over environmental degradation and biodiversity losses. 65 Planetary health builds on SDH approaches to integrate ecosystems essential for well-being and the actions needed to support them. Resonant with debates and traditional ideas noted in box 1, it departed from a hierarchical cause-effect understanding of life and applied a social determinants paradigm to ecosystem issues at planetary scale, exploring the balance and interdependency between humans and nature. 37 Consistent with SM approaches, it focused not only on risks and harms but also on the power relations and sociopolitical factors determining problems and responses from local to global level. Following the path of the 2016 Shanghai Declaration, proponents of the paradigm, such as in the 2015 Lancet Commission on Planetary Health, called for measures to tackle the vested interests and power imbalances undermining more sustainable and equitable patterns of consumption. 64 The escalation of a biosecurity focus While a healthy society was increasingly understood to demand a healthy planet, the pathogenic paradigm and its focus on technical interventions also obtained new momentum in a biosecurity paradigm, responding to recurrent health emergencies and perceived threats from biological weapons, biotechnology and bioterrorism that opened space to reconceptualise 'security' beyond military threats. 14 Biosecurity, defined by WHO as the prevention, detection and response to infectious disease threats of international concern, became more pronounced in global policy-making in the 2000s. The September 11 terror attack in the USA possibly also gave greater impetus to its already increasing focus on health security. 14 In 2014, a USA-supported Global Health Security Agenda was launched with 69 countries, international and non-state organisations, and corporations to respond to 'global health threats posed by infectious diseases'. 12 66 The COVID-19 pandemic in 2020 escalated this focus on biosecurity. On the one hand, some countries and communities have applied holistic, rights-based and SDHbased responses to COVID-19, catalysing debates about state obligations and global, collective responsibilities in the pandemic, including for key health technologies to be made available as global public goods. 67 However, the more dominant response has been biosecurity-focused, largely through centrally led and sometimes coercive quarantining and control measures, often unresponsive to local conditions and communities. National protectionism has generated significant inequalities in access to essential health technologies, despite UN appeals for collective security. [67] [68] [69] While still evolving, the pandemic demonstrates the risks of a dominant technology-driven biosecurity focus, including in terms of socioeconomic inequality and insecurity, rights violations and social distrust, with the lowest income countries and communities most affected, and the ecosystem and deeper public health determinants of pandemics poorly addressed. [67] [68] [69] INSIGHTS FROM ACROSS DIVERSE IDEAS The findings highlight the influence of often coexisting and contrasting paradigms and approaches to healthy societies. While the trajectories reflect different cultures and political economy contexts, they suggest some shared insights for future engagement on healthy societies. Overcoming the consequences of imposed paradigms The evidence points to how an imposed pathogenic paradigm in the three southern regions undermined the local cultural understanding of health. The application of tropical medicine, the coercive segregation of local populations, the promotion of selective PHC as better aligned to neoliberal reforms and of allopathic medicine as a catch-up with Western development asserted a superiority of Western approaches and neoliberal policies, discounting, suppressing and even criminalising local systems. When combined with eugenic theories, a biomedical focus enabled racist or discriminatory discourses in health. In more recent years, significant technical and financial resources from private actors, international and global agencies reinforced a selective, vertical disease-focused approach. In all three regions, precolonial ideas, outlined in box 1, re-emerged in new forms in anticolonial and antineoliberal movements, with ideas of BV and ICH; Gandhi's mind, body, soul and community health paradigm in India; and the promotion of reciprocity and claims over natural resources articulated by ESA countries. An understanding of healthy societies has thus been linked to reclaiming cultures for dispossessed countries and people, a process that is ongoing, given the deep link between health, identity and justice. At the same time, such indigenous practice may be susceptible to manipulation, as, for example, has been observed in Hindu nationalism's use of Ayurveda to drive forms of ethnic exclusion and a discourse of obligation and security over that of rights and citizenship. 70 A tropical medicine exceptionalism in how healthy societies are achieved in the south can be argued to have raised a barrier to the mutually useful exchange of learning between all regions on shared population health problems. It blocked for decades the wider uptake of useful positive learning from southern regions on local food and dietary practices; community health systems and community health workers; and on cultural and psychosocial integration in health, despite the relevance for multicultural, multiethnic societies in diverse regions. Ideas on healthy societies call for openness to 'reverse innovation', moving beyond the current dominance of institutions in high-income countries as a source of global ideas towards greater mutual horizontal exchange between and across regions. Engaging with structural determinants and social determination SM and SDH paradigms looked beyond disease and biomedical approaches to promote health and to act on BMJ Global Health the political determination of the conditions affecting health. However, a dominant argument that a growth in national wealth would achieve improvements in health subjugated health approaches to neoliberal measures, even when this intensified inequalities. In all regions, and often in a more radical form in the southern regions, there appears to be a growing understanding that any paradigm for healthy societies must engage with commercial determinants and the drivers from a neoliberal globalisation, with implications for redistributive, intergenerational and ecological justice. Crisis within the global political economy would itself appear to generate momentum for this. Yet, crisis itself is not a guarantee of such momentum. After the 1978 adoption of comprehensive PHC, for example, rather than intensifying impetus for it, subsequent energy, financial and other crises were used to prioritise existing economic interests and to promote selective, biomedical, targeted interventions as being more feasible. The sustained drivers for a deeper engagement with global determinants of healthy societies may thus be more likely found in growing networks of social movements, forums and processes questioning the current global political economy and its markers of progress, and in the sharing of ideas on alternatives. Building a values-based, reflexive, context-dependent knowledge While positivist methods have significantly contributed to the understanding of health risks and to disease control, they have been less successful in building the multidisciplinary, reflexive and context-dependent knowledge needed for population health equity. Positivist methods consider that a single observable reality exists and that knowledge can be derived from this reality using impartial measurements that are free from contextual or subjective influence. In posing as values-neutral, positivist approaches can rather reflect dominant forces and ideologies, and negate the sociopolitical and cultural ways in which knowledge is generated. Approaches to healthy societies such as comprehensive PHC, BV, SM, the Gandhian paradigm, people's health in people's hands, ubuntu, resource nationalism and planetary health have, in contrast, all explicitly articulated the values and collective rights that inform their knowledge and action on improvements in well-being. The multidimensional complexity and ethical policy choices required to build healthy societies increasingly demand embedded, transdisciplinary, reflexive and participatory approaches. This does not imply an unquestioning absorption of 'facts' asserted by the loudest voices, but rather systematic, organised processes to draw, analyse and validate evidence from lived experience of the many actors and levels involved in action on healthy societies, to build collective analysis and learning from action. Contestation as a fertile basis for change The trajectories described point to a 'battle for ideas' that has infused debates on how to advance healthy societies within and between countries and globally. This persistence of contestation in advancing paradigms for healthy societies needs more open recognition of both its underlying basis and its value, together with spaces for transparent engagement between proponents. While global institutions have had significant influence on ideas for healthy societies, ideas have also flowed in other ways. A core-periphery model where ideas flow from highincome to low-income countries and regions, as applied in colonial modernisation, in aid-supported 'development' programmes and in neoliberal reforms appears obsolete, particularly in developing global health policy. Latin American ideas of ICH have been integrated in global declarations. Brazil and Chile influenced the ideas in the 2008 WHO Commission on SDH. India's community health experience with other country and local experiences influenced the thinking behind comprehensive PHC. ESA treatment activists and African diplomats established a precedence for public health in trade in the Doha declaration on TRIPS. Even ideas that flowed globally or north-south were reinterpreted locally, such as in the more politically radical view of SM in Latin America compared with its expression in Europe. 71 A model of 'circulation' may better enhance understanding of and investment in the flows and the give and take of ideologies, policies and practices between different regions and networks in framing global ideas, 72 and better suit the engagement between regions and processes for developing shared paradigms on healthy societies. Provenance and peer review Not commissioned; externally peer reviewed. Data availability statement All data relevant to the study are included in the article.@story_separate@Beyond the hegemony imposed by military coercion, the findings suggest that ideational power has combined with material, political and institutional power to give some ideas on healthy societies greater dominance and policy influence. Ideas matter in producing change. Accepting a plurality of ideas There is not, nor has there been, a singular idea of healthy societies. We would suggest that neither should one be imposed. There has been significant effort to impose a singular, often Western-centric, hegemonic view on how to achieve healthy societies as superior to and more 'realistic', 'technically correct' and feasible than all other thinking. 73 However, the notion of a singular idea is problematic for various reasons. First, while values may be shared, health is as much sociocultural and political as it is technical and material. Ideas about healthy societies are embedded in different histories and polities. A competition over which ideas become hegemonic reflects wider political and economic contestations. Second, ideas have changed over time, and while some paradigms may have dominated in discourse and policy internationally and within regions at points in time, others emerged or resurfaced in new spaces, bringing new policy and practice. Paradigm choices take us to significantly different futures We are more informed than ever of the challenges we face to healthy societies in our way of life, production BMJ Global Health and consumption patterns, environmental degradation and in the extreme social inequality generated in the current global political economy. By the 2020s, two profound global conditions with significant local and national impact provide a useful insight on the critical point we have reached for the way we think and act on these challenges. The first, the COVID-19 pandemic, is providing evidence of the insufficiency of and inequity generated by reactive, nationally self-protective, singularly biomedical-focused approaches to health emergencies. Such approaches ignore and thus fail to remedy the deeper structural drivers of 'emergencies'. They discount the critical contribution of comprehensive, equity-and rights-based, participatory and ecological approaches, or of a reassertion of early ideas of reciprocity and collective interests in health. A second challenge lies in climate change and extreme biodiversity losses, their existential threat to healthy societies and the proactive reciprocal, collective cooperation they call for. As these planetary threats become increasingly immediate and more widely understood, they are stimulating a new understanding of interdependency; new forms of international cooperation reflecting collective interests and new demands to tackle the vested interests and power imbalances that undermine sustainable and equitable patterns of production and consumption, reasserting early ideas of health demanding harmony with nature. 64 Pandemics and climate change as manifestations of global crises show a potential of significantly different futures in the dominant thinking about and shaping of healthy societies. We live in a Gramscian moment of old and new ideas, where health threats are responded to by reviving old coercive public health approaches that leave many determinants unaddressed, even while new frameworks for global cooperation and collective responsibilities are advocated. At this critical moment of choice, the social constructivist analysis suggests that we look not only to ideas advanced by elites and states for what assumes dominance, but also to those promoted by social actors. A key driver of healthy societies may thus be when sufficient people in communities, countries, regions and global institutions converge in seeing an unhealthy status quo as no longer acceptable; when we have generated the space and processes to fairly share and build ideas that benefit, are understood and embraced by the wider public; and when we have the confidence and assert the collective power to produce change. Twitter Robert Marten @martenrobert Acknowledgements The authors had a rich and informative (remote) meeting with the reviewers of the paper and thank them for their review feedback and perspectives. The reviewers were Professor Ghanshyam Shah, Dr Moeketsi Modisenyane, Dr Carlos Dora, Dr Oscar Feo, Dr Sharmila Mhatre and Professor Kelley Lee. Thanks to Sonam Yangchen and Solip Ha for formatting of references. This work was supported by the Alliance for Health Policy and Systems Research. The Alliance is able to conduct its work thanks to the commitment and support from a variety of funders. These include our long-term core contributors from national governments and international institutions, as well as designated funding for specific projects within our current priorities. For the full list of Alliance donors, please visit https://www. who. int/ alliance-hpsr/ partners/ en/. Contributors RL prepared the analytical framework used in the work with review input from RM, EV and RB. RL prepared background findings for the global level with review inputs from RM, and the background inputs on Africa. EV prepared background findings for the Latin American inputs and RB for the inputs from India. RL synthesised the findings and prepared the draft of the full paper, discussion and conclusions for review and input from EV, RB and RM. All authors made text input to iterative drafts and provided reference materials. RL coordinated the inputs and revisions and edited the final manuscript that all authors reviewed and signed off on. Funding Funding for this paper was received from the Alliance for Health Policy and Systems Research, WHO (grant 202563639). Map disclaimer The depiction of boundaries on the map(s) in this article does not imply the expression of any opinion whatsoever on the part of BMJ (or any member of its group) concerning the legal status of any country, territory, jurisdiction or area or of its authorities. The maps are provided without any warranty of any kind, either express or implied. Competing interests None declared. Patient and public involvement Patients and/or the public were not involved in the design, conduct, reporting or dissemination plans of this research.","The way healthy societies are conceptualised shapes efforts to achieve them. This paper explores the features and drivers of frameworks for healthy societies that had wide or sustained policy influence post-1978 at global level and as purposively selected southern regions, in India, Latin America and East and Southern Africa. A thematic analysis of 150 online documents identified paradigms and themes. The findings were discussed with expertise from the regions covered to review and validate the findings. Globally, comprehensive primary healthcare, whole-of-government and rights-based approaches have focused on social determinants and social agency to improve health as a basis for development. Biomedical, selective and disease-focused technology-driven approaches have, however, generally dominated, positioning health improvements as a result of macroeconomic growth. Traditional approaches in the three southern regions previously mentioned integrated reciprocity and harmony with nature. They were suppressed by biomedical, allopathic models during colonialism and by postcolonial neoliberal economic reforms promoting selective, biomedical interventions for highest-burden diseases, with weak investment in public health. In all three regions, holistic, sociocultural models and claims over natural resources re-emerged. In the 2000s, economic, ecological, pandemic crises and social inequality have intensified alliances and demand to address global, commercial processes undermining healthy societies, with widening differences between ‘planetary health’, integrating ecosystems and collective interests, and the coercive controls and protectionism in technology-driven and biosecurity-driven approaches. The trajectories point to a need for ideas and practice on healthy societies to tackle systemic determinants of inequities within and across countries, including to reclaim suppressed cultures; to build transdisciplinary, reflexive and participatory forms of knowledge that are embedded in and learn from action; and to invest in a more equitable circulation of ideas between regions in framing global ideas. Today’s threats raise a critical moment of choice on which ideas dominate, not only for health but also for survival."
"Hepatocellular carcinoma is the fifth-most common diagnosed malignancy, and the third-most frequent cause of cancer-related deaths world-wide (Bhardwaj et al, 2010; Rempp et al, 2011; WHO, 2012) . Although surgical resection is the preferred treatment choice for liver cancer, up to 80% of these patients cannot be operated on due to tumor location or existing co-morbidities (Bhardwaj et al, 2010; O'Rourke et al, 2007; Pearson et al, 1999) . Focal ablation (removal of tissue with extreme temperatures), a localized, minimally invasive treatment option for small-to medium-sized (Rempp et al, 2011) tumors with fewer side effects than surgery, radiation, or chemotherapy, is then the treatment option for such patients. Ablation has been used to treat several cancer sites including liver, abdomen, renal, lung, and prostate (Dupuy et al, 2000; Eggener et al, 2007; Livraghi et al, 2003; Pavlovich et al, 2002) . It has few side effects, short recovery times, out-patient delivery, and minimal organs-at-risk (OARs) damage due to localized treatment (Goldberg et al, 2000) . There are several ablative therapies including microwave ablation (MWA), radiofrequency ablation (RFA), high intensity focused ultrasound (HIFU), laser ablation, and cryoablation. We present a systematic approach to deliver RFA treatments by quantifying tissue damage using several different models. This framework is applicable to other ablation modalities. In RFA, a needle is inserted into the target (tumor or lesion) percutaneously or via open surgery, and high frequency alternating current is passed through the needle. Heat is generated due to tissue resistance and the target achieves necrosis when exposed to high temperatures for an adequate amount of time. Despite its appealing characteristics, RFA has the potential for incomplete ablation, and therefore a high local recurrence (regrowth) (Bhardwaj et al, 2010) , when the tumor is close to large blood vessels, the needle is incorrectly placed, or insufficient heat is delivered. Needles are typically guided into position with the assistance of ultrasound imaging (Neshat et al, 2013) , with the patient optionally sedated, though patient cooperation can be useful in some situations, particularly liver and lung ablation (Piccioni et al, 2019) . In inverse planning, the target and OARs are divided into unit grids called voxels (""volume pixels"") and optimal doses are sought for these structures. This methodology has been previously used successfully to plan cancer treatments using radiosurgery (Ferris and Shepard, 2000; Ferris et al, 2002; Ghobadi et al, 2012 Ghobadi et al, , 2013 and intensity modulated radiation therapy (Romeijn and Dempsey, 2008) . Unfortunately, unlike radiation treatments, where dose delivered from several beams is additive, heat delivered from multiple needles is not directly additive and must be calculated using Pennes' bioheat transfer equation (BHTE), a partial differential equation (PDE) (Wissler, 1998) . Further, BHTE does not consider the amount of time a voxel is exposed to a temperature. Alternate thermal damage models, e.g., the Arrhenius thermal damage model (ATDM) (Henriques, 1947; Henriques and Moritz, 1947; Moritz, 1947; Moritz and Henriques, 1947) and cumulative equivalent minutes at 43 • C (CEM 43 ) (Sapareto and Dewey, 1984) , use a voxel's temperature history, obtained from BHTE, during the course of treatment to determine tissue thermal damage. These models, although nonlinear, are additive across multiple needles. Thus, the development of inverse plans for ablation is mathematically challenging due to the inherent nonlinear nature of thermal damage. Because RFA operates at temperaturs ≥ 60 • C, CEM 43 is not an appropriate model for this ablation therapy. Existing work on RFA inverse planning can be categorized into exact and inexact methods. Inexact methods approximate the ablated region to a sphere or an ellipse of a known fixed size based on the needle used (Butz et al, 2000; Mundeleer et al, 2009; Villard et al, 2005; Zhang et al, 2007) . A voxel within the ablated sphere or ellipse is considered destroyed. Thus, there is no actual dose computation and the needle is positioned by unconstrained optimization models solved using Powell's (Butz et al, 2000; Villard et al, 2005; Zhang et al, 2007) or Nelder-Mead (Downhill Simplex) (Mundeleer et al, 2009; Villard et al, 2005) algorithms. The objectives of these models is typically to maximize the difference in unablated target and OAR volumes for single (Butz et al, 2000; Villard et al, 2005; Zhang et al, 2007) or multiple RFA applicators (Mundeleer et al, 2009) . Although these methods are fast and the assumption of knowing the ablation radii a priori is plausible, they do not consider the presence of cooling effects like blood perfusion and therefore may result in incomplete ablation. Exact methods (Altrogge et al, 2007; Chen et al, 2006 Chen et al, , 2009 Haase et al, 2012) compute the thermal dose received by a voxel at each time step using BHTE where the energy absorbed due to the radiofrequency electric source, referred to as the specific absorption rate (SAR), is obtained using the Laplacian equation, an electrostatic PDE. Thus, there is no prior assumption on ablation radii. The decision variables in exact models are the position and the orientation of the needle with fixed treatment time, and hence, needle positioning and thermal dose optimization are simultaneously performed. The resulting models are nonlinear, constrained by a system of PDEs describing the electric potential of the applicator and steady-state BHTE with (Haase et al, 2012) or without (Altrogge et al, 2007) consideration of risk structures (e.g., ribs), and are solved using gradient-based optimization methods (Altrogge et al, 2007; Haase et al, 2012) . Models that use the Arrhenius-based thermal damage model to minimize the survival fraction of the target using steepest descent (Chen et al, 2006 (Chen et al, , 2009 have better computational tractability. Since needle positioning and thermal dose computation happen simultaneously, these models require computation of a PDE, a computationally intensive task, at every new needle position and orientation. Further, these methods are tailored to RFA-specific PDEs (electrostatic field) and therefore cannot be immediately applied to MWA (electromagnetic field) or HIFU (acoustic field). We approach the RFA inverse planning problem in two stages, incorporating ideas from exact as well as inexact methods. In the first stage, called needle orientation optimization (NOO), we use geometric shape approximations to compute needle position and orientation for single needle and multiple independent single needle scenarios, where clustered needles with relative fixed positions are treated as a single needle. In the second stage, we use the NOO solution to optimize the duration and voltage of the needles using BHTE; this stage is called thermal dose optimization (TDO), and several common thermal damage models are explored. Using the solution from NOO, we enumerate solutions for different damage models by pre-computing them for a fixed treatment time for different source voltages and needle types. We then perform a lookup to identify minimum source voltage and treatment time based on full target coverage. Using this large amount of information, we are able to perform several different analyses, including change in target and OAR  coverage volumes against increasing source voltages and needle types. Finally, we identify the best needle configuration that gives full target coverage and the least OAR damage. Our methodology has several benefits over current strategies, both in terms of computational methodology and clinical practicality. Methodologically, we eliminate the need to compute BHTE at each iteration, thereby saving several hours of computation time, and we eliminate geometric assumptions from NOO in TDO where we compute the actual thermal dose delivered. By pre-computing damage models, we again save computation time and are able to analyze target damage at different source voltages. With respect to clinical practicality, we are able to determine OAR damage, which we exploit to determine the best needle configuration for treatment. The detailed analysis enables the decision maker to obtain a complete treatment plan for the preferred damage model. Finally, we can also extend our framework to other focal ablation methods like MWA by solving a different set of PDEs instead of BHTE. The remainder of this paper is organized as follows. Section 2 presents the methodology, including NOO and TDO. Numerical results and discussion are provided in Section 3 and 4, respectively.@story_separate@Let T be the set of target structures. Voxels not identified as target form the OAR set, H. Further, let N , V, and D be the set of needles, source voltages, and damage models, respectively. For n ∈ N , we perform NOO for a target in T . Using the computed needle position and orientation, we determine thermal damage to the target for each φ ∈ V. Finally, we identify the best needle configuration ((φ, n) ∈ V ×N ) and treatment time. The complete framework is presented in Algorithm 1. We explore NOO for three kinds of needle configurations: (i) single needle, (ii) clustered needles, and (iii) 2-3 independent needles (called multiple needles) (Medtronic, 2016) . A clustered needle is a single device with three parallel tines (needles) that operate simultaneously. Multiple needles are multiple single needle devices that can be inserted randomly or in parallel. They can either be operated simultaneously or individually to ablate a larger volume or several smaller volumes, though simultaneous operation is clinically more common (Medtronic, 2016) for individual target volumes as heat damage (scarring) from previous needles in sequential ablation results in unpredictable ablation to remaining untreated cells. In practice, a single needle configuration is used according to specific equipment availability and the preference of the interventional radiologist performing the procedure, and we therefore present models for each configuration, allowing interventional radiologists to chose the model that corresponds to their clinical preferences. We assume that the needles are inserted in a random order and are operated simultaneously. Vendor specifications indicate an ellipsoidal (Figure 1 (a)) and spherical (Figure 1 (b)) shape of thermal lesions for single and clustered RFA electrodes, respectively (Medtronic, 2016) . The NOO problem can therefore be represented as fitting a smallest ellipse (minimum volume covering ellipse, MVCE) or sphere (minimum volume covering sphere, MVCS) around the target. The central axis of the fitted ellipse or sphere is the orientation of the needle. We formulate the MVCE and MVCS optimization models as follows. Let T ⊂ T be the set of target boundary voxels, c be the center of the needle, x j be the coordinate position for voxel j ∈ T . Using a fixed space separator, multiple electrodes placed parallely and operated simultaneously assume a spherical lesion and can be treated as a clustered electrode (Figure 1(b) ). However, when needles are inserted randomly, geometric shapes are unclear. Therefore, for the purpose of NOO, in the case of k multiple needles, we treat each needle as though it were operated independently and divide the tumor into k clusters where each cluster corresponds to single needle coverage. A similar approach was used by Chen et al (2009) . The orientations are determined by MVCE and the entire process is referred to as NOO-Kmeans. The independent needle operation assumption is later relaxed in TDO. From basic algebra, the equation of an ellipse in m dimensions with center (c 1 , . . . , c m ) and radii (a 1 , . . . , a m ) is given by where x 1 , . . . , x m are coordinates of target voxels inside the closed ellipse. Using matrix notation, we can rewrite Equation 1 as a set of points, ξ: where A ∈ S m ++ , a set of m × m symmetric positive definite matrices, is full rank, and m is the dimensionality of the matrix A, which in our case is 3 since the target is 3D. The eigenvalue decomposition of matrix A is given by A = Q Σ Q, where Q ∈ R m×m is an orthonormal matrix representing the eigenvectors of A and Σ ∈ R m×m is a diagonal matrix whose entries (λ 1 , . . . , λ m ) represent the eigenvalues of A. From the Principle Axis Theorem, the square root of the inverse of the eigenvalues represent the length of each semi-axis of the ellipse, i.e., a i = 1/ √ λ i , while the eigenvectors, i.e., columns of Q, represent its orientation. The volume of an ellipse is therefore proportional to a 1 × · · · × a m = ( For any B ∈ S m ++ , the determinant is given by where C ij is the minor matrix obtained by dropping row i and column j from matrix B. The determinant is a high-degree polynomial and therefore we perform Cholesky decomposition on B and use the simplified convex log det() function. We decompose B into lower triangular matrices, B = L L where L ∈ R m ++ . Thus, log det( B) = log(det( L L )) = log(det( L) det( L )) = 2 log(det( L)). Since L is a lower triangular matrix, its determinant is simply the product of its diagonal entries, i.e., log(det( L)) = log Now, we formulate a convex mathematical model to find the minimum volume covering ellipsoid (MVCE) covering a set of finite points using a log det() function (Boyd and Vandenberghe, 1996) : where enforces positive definiteness on A. This model has a convex objective function, but a non-convex constraint. However, the constraint can be reformulated as convex by defining M = A and b = M c: This problem is a maximization of a concave function with convex constraints and is thus a convex optimization problem, which can be solved to optimality. From the global optimal solution, M * and b * , we can obtain needle orientation and position by A = ( M * ) ( M * ) and c = ( M * ) −1 b * , respectively. The eigenvalue decomposition of A will give the orientation and stretch of the ellipse as described before. The eigenvector corresponding to the smallest eigenvalue represents the longest semi-axis of the ellipse and hence gives the orientation of the needle. The center c corresponds to the center of the conducting part of the needle. We can solve NOO-MVCE to optimality since it is a maximization of a concave function with convex constraints and is therefore convex. We can obtain the needle position by c = ( M * ) −1 b * and orientation by eigenvalue decomposition of A = ( M * ) ( M * ). We treat a clustered needle applicator (Figure 1(b) ) as a single needle, and identify smallest sphere covering all the voxels by formulating a convex MVCS optimization model with an affine objective and a second-order conic constraint (Boyd and Vandenberghe, 2004) : (Altrogge et al, 2007) . Barycenterx and needle orientationā corresponds to c and θ, respectively. Note that ther is not the same as r. where r and c are the radius and center of the sphere, respectively. The tines in the clustered applicator are fixed, parallel, and equidistant. Therefore, the center of the fitted sphere corresponds to the barycenter or centroid of the equilateral triangle formed by the centers of the conducting tips of each tine in the cluster. We choose the cluster orientation along the diameter that maximizes needle-tumor contact. If the conducting tines overlaps non-target voxels, then we rotate the cluster in increments of 5 • until we find a better needletumor contact. We note that the equilateral triangle has a rotational symmetry of 120 • , which means the triangle (or the needles of the cluster) maps onto itself after 120 • rotation. Thus, we explore only 24 cluster rotations in a given direction ( Figure 2 ). We note that since covering the boundary target voxels within an ellipse or sphere also covers the internal voxels, we can reduce the constraints in models NOO-MVCE and NOO-MVCS by only considering the boundary target voxels, i.e., j ∈ T , which we obtain with a grassfire algorithm (Blum, 1967) . For multiple non-parallel k needle placement, we first divide tumor voxels into k clusters and then identify needle orientation by fitting an ellipse around each cluster using NOO-MVCE ( Figure 3 ). The methodology is referred to as NOO-Kmeans. For a set of k needles, we use the classical k-means clustering optimization model to identify these clusters: where µ k is the mean of cluster k and r jk ∈ {0, 1} indicates if voxel j is in cluster k. The objective is to minimize the Euclidean distance of voxels from the center (µ k ), thereby assigning a voxel to a cluster k whose center is closest of all clusters. Constraint 4 computes the mean of a cluster, and Constraint 5 assigns each target voxel to a cluster. Constraint 6 ensures a non-empty cluster. The k-means model is a nonconvex model due to the bilinear term in Constraint 4 as well as in the objective function. A 0-1 SDP-relaxation of k-means has been proposed (Peng and Wei, 2007) , but it is intractable for our problem size where the case sizes range 6 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; from approximately 900 to 62,000 target voxels. Therefore, we solve k-means with Lloyd's algorithm, which iteratively assigns each voxel to the nearest cluster while updating the centroids until convergence (Lloyd, 1982) . Once needle positions are known, we compute the optimal treatment time for adequate thermal dose delivery. We lift the geometric assumption made on the shape of thermal lesion in NOO and compute the actual thermal dose received by the target using BHTE and ATDM thermal damage models. Unlike BHTE which provides temperature at a given time, the ATDM (Henriques, 1947; Henriques and Moritz, 1947; Moritz, 1947; Moritz and Henriques, 1947) thermal damage model considers thermal history of a voxel, i.e., how long a voxel is exposed to a given temperature, and compute cumulative thermal damage over a period of time. BHTE describes the relationship between tissue local interactions and heat delivery, and is given by the following equation in a 3D system (Ahmed and Goldberg, 2004; Wissler, 1998) : where ρ and ρ b are the densities of tissue and blood (kg/m 3 ), respectively; c and c b are the specific heats of the tisue and blood (J/kg-K), respectively; K is the thermal conductivity of the tissue (W/m-K); ω is the blood perfusion coefficient, i.e., blood flow rate/unit mass tissue (1/s); T and T a are the temperatures of tissue and arterial blood (K), respectively; Q p is the power absorbed per unit volume of the tissue (W/m 3 ); and Q m is metabolic heating, which is usually considered negligible (Chang and Beard, 2002) . The values used for the biological constants and other parameters are given in Table 1 . The solution of BHTE gives the temperature of each voxel at each time step. The heat source, Q p , is approximated by (Chen et al, 2006 (Chen et al, , 2009  where σ is the electrical conductivity of the tissue and Φ is the electric potential. We obtain the electric potential using the Laplacian equation with constant electrical conductivity (Chang and Nguyen, 2004) as follows: The needle is positioned so that the center of its conducting part is placed at the ellipse or sphere center obtained from NOO. The voxels in contact with the needle are computed from a ray tracing algorithm (Amanatides and Woo, 1987) and form a needle-voxel intersection set. For Laplacian, the initial conditions (voltage) are set to 0 for all voxels except the needle-voxel intersection set, whose initial conditions are set to input voltage of the needle. Both BHTE and Laplacian are solved using a finite difference scheme with homogeneous Neumann boundary conditions (Appendix A). The Arrhenius thermal damage index is a dimensionless number Ω js computed for every voxel j of structure s and may be interpreted as the probability that the tissue is irreversibly damaged (Pearce, 2009) . ATDM is defined as where A is the frequency factor, E A is the activation energy, and R is the universal gas constant (Table 1) . T (t) is the average tissue absolute temperature (i.e., temperature in Kelvin) in the time interval [0, t] and is obtained from BHTE. Physically, Ω js is a natural log of the ratio of the original concentration of undamaged molecules to those at the end of the heating (Pearce, 2009) : Blood density(ρ b ) (Tungjitkusolmun et al, 2002) 1000 kg/m 3 Blood heat capacity (c b ) (Tungjitkusolmun et al, 2002) 4180 J/kg-K Blood thermal conductivity (Tungjitkusolmun et al, 2002) 0.543 W/m-K Liver density (ρ ) (Tungjitkusolmun et al, 2002) 1060 kg/m 3 Liver heat capacity (ρ ) (Tungjitkusolmun et al, 2002) 3600 J/kg-K Liver thermal conductivity (K) (Tungjitkusolmun et al, 2002) 0.512 W/m-K Liver electrical conductivity (σ ) (Tungjitkusolmun et al, 2002) 3.33E-3 mS/cm Blood perfusion (ω) (Ebbini et al, 1988) 6.4E-3 1/s Arterial temperature (T a ) 310.15 K Frequency factor (A) (Schwarzmaier et al, 1998) 3.1E98 1/s Activation energy (E A ) (Schwarzmaier et al, 1998) 6.28E5 J/mo Universal gas constant (R) (NIST, 2015) 8.3145 J/K-mol because exp(−Ω js ) = C t = undamaged molecules at time t. We describe these percentage damage models as D63 for p = 63% tissue damage, D70 for p = 70% tissue damage, etc. A value of p = 0.63 or 63% is associated with irreversible thermal damage and corresponds to Ω js = 1. We define a set of needle configurations as a combination of needle type (n ∈ N ) and source voltage (φ ∈ V). The set of damage models is given by: d ∈ D = {BHTE, ATDM, D63, D70, D80, D95}. For each needle configuration, (φ, n), we first compute the BHTE for fixed treatment time using inputs from Laplacian and then compute the ATDM followed by the percentage damage models if required for thermal damage d. We save this information to determine the minimum treatment voltage and treatment times. We define a numerical dose structure H d (φ, n, x j , t) to identify damage using model d to voxel x j ∈ H ∪ T at time t due to needle configuration (φ, n). For a fixed treatment time t max , the minimum treatment voltage for full target coverage using damage model d ∈ D and needle type n ∈ N is given by where H d TH is the threshold damage value for model d, H d (φ, n, x j , t max ) is the damage to voxel x j at t max minutes when using needle configuration (φ, n). If temperature is used to quantify thermal damage, then H d TH = T TH = 60 • C; if the Arrhenius damage index is used to quantify thermal damage, then H d TH = Ω T H = 1; and if p percent damage is used to quantify thermal damage, then H d TH = p%. Similarly, for a fixed voltage φ, the minimum treatment time for full target coverage using damage model d ∈ D and needle type n ∈ N is given by To choose a single best needle configuration for damage model d, we select the needle configuration with 100% coverage and the least OAR damage (Algorithm 2). We perform all computations on Intel Core i7-3770 CPU with 3.40 GHz and 8 GB RAM using MATLAB R2015b (Mathworks, Inc.). Our case studies are liver cases (Table 2 ) obtained from Robarts Research Institute, Western University. In a clinical setting, tumors are over-ablated to ensure microscopic tumor particles are killed along with the target itself. Therefore, we add surgical margins of 0 mm (N), 3 mm (S), for φ ∈ V do 3: (Table 2) . Further, in liver ablation OAR sparing is insignificant due to its regenerative properties and hence no explicit OAR margin is added to the target. However, we consider damage to non-target voxels outside surgical margin as OAR damage to understand the impact of input parameters. We use CVX (CVX Research, 2012; Grant and Boyd, 2008) to solve NOO-MVCE and NOO-MVCS models and test our NOO approach under two scenarios, (1) considering all the target voxels, and (2) considering only boundary target voxels, obtained using a grassfire algorithm (Blum, 1967) . For faster computation, both these scenarios are solved for the entire target as well as targets sampled at 50%. We restrict our needle types, N , to eight Covidien specifications (Table 3) (Medtronic, 2016) . As the number of voxels increases, the runtimes for both NOO-MVCE and NOO-MVCS increase ( Figure  4 ). The runtimes of NOO-MVCS are under 8 seconds for all unsampled target voxels and under 3 seconds for unsampled boundary target voxels (Figure 4(a) ). Using boundary target voxels gives an average computational gain of 60% and 53% for NOO-MVCS for unsampled and sampled case, respectively (Figures 4(a) (Figure 4(c) ). However, NOO-MVCE runs in under a minute for unsampled boundary target voxels in all cases. An average computational gain of 81% and 83% is obtained for unsampled and sampled cases, respectively, when only boundary voxels are used for NOO-MVCE (Figures 4(c) and 4(d)). We use boundary voxels to solve MVCE for NOO-Kmeans since using boundary voxels only has significant computational advantage demonstrated earlier (Figures 4(e) and 4(f)). For unsampled cases, NOO-Kmeans runs under a minute (Figure 4(e) ). These fast runtimes may appear counter-intuitive since NOO-MVCE is solved k times, once for each cluster. However, each cluster contains only a subset of target voxels, and we consider only the boundary voxels of these clusters. When using boundary voxels, runtimes are under a minute for the largest unsampled case (Case 3L). Therefore, we report results only for unsampled cases for both NOO and TDO. For selected cases, Figure 5 shows the needle orientations given by MVCE, MVCS, and NOO-Kmeans models, and Table 4 shows their fitted volumes. We solve BHTE and Laplacian using a finite difference scheme (Appendix A) to obtain thermal distributions over a 20 min simulation with a 0.5 times step for eight needle types (Table 3) with source voltages, V, varying from 2.5 V to 30 V in increments of 2.5 V. Thermal distributions are computed only if non-intersecting needle positions are found. Each case consists of 384 runs: 8 needle types × 4 surgical margins × 12 source voltages. The computational runtime of each run is the total time to solve Laplacian, BHTE, and ATDM; computational time is largely driven by the Laplacian (Figure 6(a) ). We assess target and OAR damage using the following thermal damage models: (1) ≥60 • C threshold temperature from BHTE (T60), (2) Arrhenius damage model (ATDM), (3) 63% damage (D63), (4) 70% damage (D70), (5) 80% damage (D80), and (6) 11 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint 13 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint The maximum temperature in the target increases with an increase in source voltage; at least 7.5V is recommended for the representative target treatment (Figure 6(b) ). High source voltage increases the numerical value of the initial conditions for the Laplacian, causing high target temperatures, while longer or multiple needles increases the needle-voxel intersection set, resulting in larger thermal spread. Hence, more needles or high source voltage yields large ablation volumes ( Figure 7 ) and high target ( Figure 8 ) and OAR damage (Figure 9 ), and consequently high tissue molecular damage. Full coverage is seen when more needles operate at low voltage or fewer needles operate at high voltage. Further, a low and high source voltage is recommended when damage is quantified by BHTE and D95 models, respectively, resulting in a different needle configurations for the same case. This difference in needle configuration arises because tissue molecular damage increases with the duration of exposure to temperatures ≥60 • C, and BHTE damage occurs before D95 damage ( Figure 10) . Therefore, certain needle configurations achieve full BHTE coverage but partial D95 coverage because all the target voxels are not exposed long enough at temperatures ≥60 • C. Thus, BHTE damage requires a low source voltage and high tissue molecular damage requires high source voltage (Table 6 ). Finally, our framework indicates the use of a single needle for targets up to 15 cm 3 and multiple needles for larger targets (Figure 11 ). Needle configurations that do not attain full coverage are not recommended for treatment. Our multiple needle placement methodology is unable to find non-intersecting needle positions for smaller tumors using longer multiple needles (e.g., MN3K30, MN3K40 for Case 1N), and hence no TDO computations were performed for such cases. However, for Case 3N, NOO-Kmeans could not find non-interesting needle positions for MN3K40, and none of the other needle configurations were able to obtain 100% target coverage. In such circumstance we increase the target size by adding margins to obtain needle positions and perform TDO analysis for the original target. 14 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint 15 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; 19 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10. 1101 /2021 Due to the lack of standards based on either conformity or OAR-sparing, complexity of optimization models, and difference in data sets and needle types used, it is difficult to draw direct comparisons with existing simultaneous models. In ablation planning, simultaneous optimization provides the benefit of needle placement by simultaneously computing thermal damage without any assumptions on ablation shape. Due to inherent non-linear nature of ablation, simultaneous optimization methods, that solve PDEs as constraints with needle position and orientation as only variables, are only able to produce locally optimal solutions. They must be tailored to needle type as well as ablation modality thereby restricting their clinical viability. Trajectory planning is difficult to incorporate in such models and due to long run-times experiments on multiple source voltage (or power) selection is not tractable. Further, due to the mathematical complexity of ablation optimization models, it is difficult to comment on the quality of their optimal solutions and none of the existing models comment on optimality gaps. Decomposing needle placement and thermal damage computation, as proposed in this work, results in inherent sub-optimal solutions. However, such an approach provides several benefits, including computational advantage, flexibility towards ablation modality, flexibility to incorporate trajectory planning, and needle types, that is not seen in simultaneous models. Typically, a good cancer treatment plan will provide a full conformal target coverage with maximum OAR sparing. However, unlike radiation, rigidity of heat deposition makes it difficult to control the shape or spread of ablation. If full target coverage is the only necessary requirement, then any needle position that achieves this goal is an acceptable solution. However, it is obvious that some needle positions are better than others. For instance, a needle, that is larger than target radius, placed closer to target boundary may provide full coverage but is less desirable than one closer to the center of the target. This choice can be attributed to better target thermal dose, coverage of microscopic tumor particles surrounding the target, and less OAR damage. Existing models do not provide information on OAR sparing and use different data sets for any comparative analysis and we did not find any standard in the literature to evaluate quality of an RFA treatment based on either OAR-sparing or target conformity. Intuitively, for a single needle placement, the needle position will correspond to the centroid of the target and its orientation will correspond to the shape of the target. This hypothesis has been previously validated through experiments using simultaneous optimization (Altrogge et al, 2007) . Our fast convex NOO model, NOO-MVCE, is able to deliver similar solutions. The grassfire method to extract boundary voxels yields NOO solutions in <1 minute. For multiple needle placement, we provide detailed methodological explanation absent in previous work using same approach (Chen et al, 2009) . Any geometric assumptions in NOO stage are lifted in TDO stage and actual thermal dosimetry is computed using several damage models. The thermal dose for the largest target (Case 3L) is computed in <20 minutes, which is a significant improvement over the 1-2 hours reported by simultaneous optimization (Altrogge et al, 2007; Chen et al, 2009) . We can easily extend our work to other ablation modalities by solving a different set of PDEs, e.g., Maxwell's equations for MWA, which can be difficult in a PDE-constrained systems. Further, new needle types can be seamlessly added in the NOO stage without affecting the methodology for thermal dose computations. Similar to simultaneous optimization methods, we assume a fixed treatment time which in our case is 20 minutes. This conservative longer treatment time gives us enough simulation data to analyze the treatment quality while ensuring maximum target coverage. However, for the recommended needle configurations, full coverage is achieved within the first few minutes. Since tissues eventually reach thermal equilibrium, treatment time does not significantly affect the treatment quality, unlike radiation treatments. Gradual heat deposition ensures larger ablation volumes and therefore the coverage of microscopic tumor particles with longer treatment time increasing the tissue molecular damage. We addressed models for design ablation treatments in a deterministic setting, where needle placements are exact. However, ultrasound image guidance may be inaccurate up to 2.5 mm (Neshat et al, 2013) , and further, needles may deflect (bend) unexpectedly during insertion. Clinicians can often counteract deflection when it is observed, however, the frequency and causes of deflection are not well understood, though there are efforts to anticipate and estimate needle deflection (e.g., Jiang et al (2018) ). We note that despite these uncertainties, clinical treatments, like our models presented here, are not designed with these uncertainties in consideration. We also note that our decoupled NOO and TDO approach sacrifices an unknown amount of objective function quality compared to simultaneous NOO and TDO, but simultaneous optimization of 20 All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 9, 2021. ; https://doi.org/10.1101/2021.06.07.21258239 doi: medRxiv preprint both yields a challenging and intractable model.@story_separate@While the current state-of-the-art in ablation planning performs simultaneous optimization, these methods lack in computational tractability and flexibility to accommodate different needle types and ablation modality. In this work, we present a novel systematic approach to radiofrequency ablation where we present a dissociated needle placement and thermal dose computation methodology that can be extended to other ablation modalities (e.g., microwave ablation). We eliminate the need to iteratively compute thermal dose thereby improving the computational tractability of developing a treatment plan. Further, our framework considers NOO and TDO for eight different needle types and is able to accommodate other needles (e.g., umbrella-shaped needles). We designed fast convex NOO models for single and clustered needles that can be solved to optimality as well as fast heuristic approach for multiple random needle placement. We are also able to compute the Laplacian, BHTE, ATDM, and percent damage models in reasonable amount on time. However, the use of commercial PDE solvers that include RF modules ((COMSOL Inc., 2017)) can enhance the quality of these solutions, and therefore treatment plans, since several physiological, thermal, and electrical process (e.g, change in tissue thermal properties with temperature change) are difficult to capture by mathematical simulations presented here. Further extensions to this work include addressing uncertainties in needle placement and deflection. Although trajectory planning and thermal dose validations must be performed before clinical applicability, we present a promising framework that gives 100% target coverage while, for the first time, performing OAR damage analysis using several different thermal damage models. We analyse the effect of different needle types (needle tip length and number of needles) on target and OAR damage using several damage models when operated under different source voltages. Finally, our methods culminate to the best needle configuration based on full target and minimum OAR coverage.","Radiofrequency ablation (RFA) offers localized and minimally invasive treatment of small-to-medium sized inoperable tumors. In RFA, tissue is ablated with high temperatures obtained from electrodes (needles) inserted percutaneously or via an open surgery into the target. RFA treatments are generally not planned in a systematic way, and do not account for nearby organs-at-risk (OARs), potentially leading to sub-optimal treatments and inconsistent treatment quality. We therefore develop a mathematical framework to design RFA treatment plans that provide complete ablation while minimizing healthy tissue damage. Borrowing techniques from radiosurgery inverse planning, we design a two-stage approach where we first identify needle positions and orientations, called needle orientation optimization, and then compute the treatment time for optimal thermal dose delivery, called thermal dose optimization. Several different damage models are used to determine both target and OAR damage. We present numerical results on three clinical case studies. Our findings indicate a need for high source voltage for short tip length (conducting portion of the needle) or fewer needles, and low source voltage for long tip length or more needles to achieve full coverage. Further, more needles yields a larger ablation volume and consequently more OAR damage. Finally, the choice of damage model impacts the source voltage, tip length, and needle quantity."
"The world population is growing constantly. This means that energy consumption from the burning of fossil fuels is increasing every year. Therefore, the emission of the greenhouse gases (GHG) is also increasing at a high rate [1] . Greenhouse gases (GHG), such as carbon dioxide, methane and nitrous oxide trap some of the energy that goes out of the Earth and heat the atmosphere. This causes the Earth's energy received by the sun-and the energy going out from the Earth-to be unbalanced, leading to climate change. climate change is a major problem because it causes catastrophes such as heat waves and floods as well as increases the risk of heat-related illnesses to people [2] . The emission of GHGs into the atmosphere also increases the concentration of air pollution; it has been proven that air pollution is one of the main causes of respiratory diseases. High concentration of pollution in the air has increased the number of people with cardiovascular illnesses, asthma and cancer [3] . Due to its big dependence on fossil fuels consumption, the transportation sector plays a great role in the distribution of greenhouse gases. Research and studies have been done to minimize the burning of fossil fuels and move towards the adoption of renewable [4] [5] [6] [7] energies/green energy strategies. The adoption of renewable energies in the transportation sector can be enhanced by reducing the number of internal combustion engine (ICE) vehicles-and by the adoption of EVs. The mass production of the first generation of EVs happened in the 19th century, but these vehicles were ruled out of the market due to their high initial purchase costs and low autonomy. Today, people still prefer purchasing ICE vehicles compared to EVs due to their higher reliability. Over time, the usage of large number of ICE vehicles has led the transportation sector to being one of the top emitters of GHGs. This concerning fact has renewed interest in replacing ICE with EVs [8] . The Republic of China has the largest market of EVs, followed by Europe and the US. The global sales of EVs increased by 2 million from 2017 to 2018, where the total number of EVs purchased in 2018 were just over 5 million. The increasing trend in the purchase of EVs has made the leading countries in EV sales to develop economic instruments that would reduce the differences in cost between EVs and ICE vehicles and develop more charging infrastructures. As technology advances, EV batteries are being further improved, and the manufactures of EVs are being expanded to attract more EV purchases. Furthermore, innovative designs of EVs and better batteries are developed to accelerate the adoption of EV. In the new policies scenario in 2030, it is mentioned that the sales in EVs are predicted to reach 23 million, with over 130 million in stock. In the EV30@30 scenario, EV sales are expected to reach 43 million in 2030 with a stock of more than 250 million. The new policies scenario is expected to cut the demand for oil by 127 million tons of oil equivalent (Mtoe) which is equal to about 2.5 million barrels per day (mb/d) in 2030. On the other hand, the EVs in the EV30@30 Scenario are expected to reduce oil demand by 4.3 mb/d. The demand of electricity to serve the EVs in 2030 in the new policies scenario is calculated to be almost 640 terawatt hours (TWh) while that of the EV30@30 Scenario is 110 TWh. By using well-to-wheel technologies, the GHGs emitted from EVs will continue to be reduced compared to emissions from ICE vehicles. GHG emission from the EVs as per the new policies scenario will reach almost 230 million tons of carbon-dioxide equivalents (Mt CO2-eq) in 2030. This value will compensate about 220 Mt CO2-eq emissions. An average using electricity that is characterized by the current global average carbon intensity which is 518 g of carbon dioxide equivalent per kilowatt-hour (g CO2-eq/kWh) emits lower GHG than an average ICE vehicle that uses gasoline for its whole lifetime. However, the reduced emission of CO2 is more effective for hybrid vehicles, compared to EVs in countries where power generation is obtained from the burning of coal [9] . The adoption rate of EVs still varies around the world. However, this adoption can be affected by the vehicle price, total cost of owning EVs, driving experience, the availability of Charging Station (CS), social influence, environmental awareness and others [10] . In [11] , it is stated that the popular EV categories: i) battery-based EVs (BEVs)-complete EVs without any ICE options, and ii) plug in hybrid EV (PHEV)-EVs that have an ICE option and high storage capacity battery with options of charging, has increased significantly from 2010 to 2016, as shown in Figure 1 . Figure 1 also shows the anticipated trends of adoption of EVs until 2030 using the data available from [9] . [9] . Reproduced from [9] , Global EV outlook: 2019. Although EVs provide many benefits to the environment, there are still a lot of barriers that prevent them from be widely adopted around the world. Many studies report barriers to EV-adoption in different parts of the world [12] [13] [14] [15] . According to [12] , consumer viewpoint is one of the most significant barriers that limits the widespread adoption of EV. The authors focused on three main aspects that fall under the consumers demand: financial, performance and the infrastructure. Financial barriers consist of the price of EVs, cost of the battery, lack of knowledge of the fuel cost and maintenance cost. The initial purchase cost comparison between ICE vehicles and EVs from different manufactures are tabulated in Table 1 [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] . For each manufacturer, an EV is compared with an equivalent ICE vehicle of the same manufacturer in terms of model, category and size. It can be seen that the buying price of EVs and PHEVs is exorbitant compared to ICE vehicles. In contrast, the maintenance and operational costs of EVs are much lower than ICE vehicles. This comparison is shown in Table 2 . The maintenance cost comparison mainly considers the first 100,000 miles of a vehicle [27, 28] . Table 2 shows the basic costs of maintaining an EV or ICE vehicle. Many other options and safety options are offered by vendors that are not considered in this table. Operating cost is the main continuous cost involved in operating vehicles. While EVs consume electricity, ICE vehicles consume gasoline. The prices of electricity and gasoline are different in each country. In Qatar, the rates of electricity are USD 0.032/kWh and the average gasoline price in 2020 is USD 1.65/gallon. A large fluctuation in gasoline price has been seen due to COVID-19; however, this can be considered an outlier, due to this extraordinary situation not seen in the last century. The EV Nissan Leaf has a 40 kWh battery and a range of 149 miles [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] . According to the electricity rates in Qatar, it would cost 0.0086$/mile. The ICE vehicle Honda Civic has tank capacity of 12.4 gallons and a consumption of 30 miles/gallon. With Qatar gasoline average rates, it would cost USD 0.055/mile. It is clear that an EV has around 5-6 times cheaper operating costs than ICE vehicles: For 100,000 miles, an average operating cost for Nissan Leaf is USD 860 and for Honda Civic is USD 5500 [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] . EV performance barriers also consist of the safety, reliability, range, the life of the EV battery, the time for an EV to charge and the power of the vehicle. Finally, infrastructure barriers consist of the availability of the CS in various places such as highways, workplaces and public places. In [12] , it was also mentioned that consumer characteristics such as the gender, age, income and environmental awareness play a major role in the adoption of EVs. For example, people who Developing sustainable strategies for using energy resources efficiently requires a thorough evaluation of the three main factors of sustainability, i.e., society, economy and the environment. The widespread EV adoption is expected to change the structure of the energy industry. This change in the structure can be from the employment shifts in the supply chain of different energy sectors to tax balances and profitability. The utilization of renewable energies can be an important strategy to maximize the environmental benefits from the adoption of EVs. These environmental benefits are highly dependent on the source of electricity generation. For example, use of EVs in countries that depend on petroleum for generating electric power could be lower than using ICE vehicles with the exception of Norway which have very high penetration of EVs, due to the successful strategies it follows and should be used as an example by others. EV technologies are environmentally beneficial since they have the potential to minimize air pollution, airborne diseases, climate change, energy consumption and water footprint. According to International Energy Agency (IEA), some countries have set a target on the number of EVs they will adopt; some other countries have banned ICE vehicles. In the Middle East region, Qatar have targeted a 10% EV sales by the year 2030. The Qatar national vision 2030 is aiming to increase the economic and social growth as well as improving the environment. Qatar is one of the largest CO2 emitters per capita in the world [29] , which has encouraged Qatar to reduce CO2 emissions. While the major power generation in Qatar relies on natural gas, the country is currently constructing a large-scale solar power plant that will have a capacity of 350 MW [30] . According to World Health Organization (WHO), Doha is known to be the twelfth-mostpolluted city in the world, .and that the high concentration of pollution in the city poses major health risks Energies 2020, 11, x; doi: FOR PEER REVIEW www.mdpi.com/journal/energies to people [29] . In this study, the authors studied the transportation system of Qatar and the factors that would help the EV-adoptions in Qatar. Solar and wind power in Qatar may be the most significant renewable energy sources to compensate the usage of natural gases. An initiative called ""green car"" that aims to achieve sustainable transportation in Qatar has been signed by the Ministry of Energy and Industry, Ministry of Transport and Communications and KAHRAMAA. This initiative aims to increase the total number of EVs to a minimum of 10%-and to provide the CS required by these vehicles [29] . Several regional research works were carried out by different researcher in [9, [12] [13] [14] [31] [32] [33] but the studies do not reflect the possible reasons-according to public perception-as barriers for EV-adoption in a financially stable Middle Eastern country like Qatar. Moreover, the articles do not provide the details of the surveys. Furthermore, detailed analyses of the survey results is not provided in the articles. All these points are addressed in this study. The contribution of this study could be stated as: (i) systematic design of the survey to get two different public perception (technical and non-technical, which will be discussed in details later) of the EV-adoption, (ii) survey result analysis using statistical methods such as two-sample t-test analysis [34, 35] , (iii) recommendation based on the survey analysis. This study is organized as follows: Section 2 shows the considerations of adopting EVs in the literatures. Section 3 presents an overview of the implemented study to check the barriers of EV-adoption in mass scale at Qatar. The section also provides details of the survey conducted, along with how the questions were selected to get meaningful results. It also provides details of statistical analysis to interpret the survey results. Section 4 provides analysis carried out with survey followed by Section 5 where the survey results and statistical analysis results are provided. This section also provides valuable recommendation to help in EV-adoption based on the survey results. Finally, Section 6 presents conclusions and summarizes suggestions from the authors for improvements.@story_separate@The authors in [12] conducted a survey from the drivers in Tianjin, China, to study the viewpoint of the consumers on EVs. The questions are developed and divided into four parts: (i) General information such as gender, age, income, level of education, etc.; (ii) Fourteen possible barriers to rate; (iii) Respondents were asked to rate the policy incentives that may enhance the widespread of EVs such as paying fewer taxes or free parking for EVs; and (iv) Three questions were asked to the respondents about their willingness to purchase EVs, recommendation of EVs to others and having more EVs in the market. Each question is rated on a scale of 1 to 5 where 1 is 'strongly unwilling' and 5 is 'strongly willing'. Once the questionnaire was done, the authors ensured that the quality of the survey is high by removing the invalid questionnaires. The questionnaires are said to be invalid if the respondents completed it in less than 6 min, and/or there are missing answers, and/or there are six identical consecutive answers. Online questionnaires were also conducted to collect more samples for the study of the consumer behavior towards EVs. The survey answers were analyzed using the chi-squared test to explore the different perceptions of people on EVs. A study of EV-adoption was also conducted in Bangladesh [14] , which showed that the adoption of EVs would be beneficial to the environment in Bangladesh, but that the increase in electricity demand may produce harmonics in feeder current, hence reducing power quality. Moreover, the power losses in the distribution transformers and voltage disturbances would become major problems. The authors in [14] emphasized on some problems that may occur in the adoption of EVs in Bangladesh. These are lack of EVs CS, battery charging affects power quality, shortage of power supply, battery price and capacity, high charging cost and time, short EV battery lifetime, low EV speed, frequent accident, lack of government incentives, low driving range and uneven road tracks. The Bangladesh government has legalized 100,000 electric vehicles to operate on the rural roads in 2019 and the Bangladesh Road Transport Authority (BRTA) plans to bring these vehicles under their oversight. To make the adoption of these EVs more convenient, the Bangladesh government has installed eight 30-kW solar charging stations in the country which can charge 20 EVs at a time [36] . Developing countries like Bangladesh are not predicted to have a huge sales of EVs until the next decade, since the government had pledged that all new cars that will be sold will be electric by 2030 [37] . In comparison to the data for motor vehicle sales in Bangladesh between 2005 to 2019 which has an average of 38,500 units per year, there is a potential for Bangladesh to bring in over 30 thousand EVs per year by 2030 if all new vehicles will be electric [37] . The potential rise in the number of electric vehicles in Bangladesh will require more charging infrastructures and other facilities for a more convenient adoption of EVs. By the end of 2019, there were a total of 504,130 registered vehicles in Bangladesh-of which around 100,000 of these are electric. If most people start switching from combustion engine vehicles to electric vehicles, Bangladesh may reach over 300,000 EVs across the country [37] . In addition to the above, studies done in other Asian countries that are economically different from Qatar, one case study that was very useful for the research in this study was the example of Norway, also an oil-rich economy. In [31] , the authors examined how incentives effect EV-adoption in Norway. Norway is one of the countries that adopted EVs early, studying the incentives of Irish people for EV-adoption. In Norway, EVs have started the growth up since 2009, starting from around 2000 EVs and reaching almost 50,000 EVs in [31] . The market share of EVs in Norway 2020 has broken records in the world. By March 2020, the market share of EVs have reached around 75.2% of vehicles sales. The remaining 25% is divided between plug-less hybrids of 7.1%, diesel of 10% and petrol of 7.7% [38] . Norway has massive amounts of taxes for purchasing new vehicles. One of the main incentives of EV-adoption is the taxes exemption which drops down the prices of EVs to similar or even cheaper than ICE. In addition, EVs are exempted from the value added tax (VAT) which is huge as 25%. One more incentive is the fees of issuing and renewing a vehicle license, EVs have the lowest price in all fees regarding the vehicle license. There are more incentives in the local community of Norway such as free road tolling and parking slots. Lastly, Bus lanes are accessible by BEVs. A similar study is done in a neighboring country of Qatar in [13] , where the availability of infrastructure in Muscat, Oman, were analyzed for convenient accessibility. This analysis was done by looking at how the existing fuel stations are distributed. The distance for driving between different fuel stations, zone activities (e.g., hospitals, markets, housings, schools, etc.) and the knowledge of the people about EVs were also studied. Finding efficient locations for EVs CS may accelerate the adoption of EV, since it reduces the anxiety of the users related to battery recharge [13] . In [13] , the city of Muscat was divided into 17 zones and it was found that there was no logical connection between the existing fuel stations and the zones. The conclusion that could be made from the study of the fuel station distribution in [13] is that the area of the zone does not determine the number of stations in this zone, but it is determined by the population and activities existing in the zone. Populated zones and public places such as grocery stores and hospitals tend to have more fuel stations. Shorter distances between CS will also improve the convenience of EV-charging. It is crucial to know about the maximum driving range of the fully charged EVs, and the CS should be built with respect to the maximum driving range. Since the fuel stations were pretended to be EV-charging stations in [13] and the distance between each station were analyzed, Muscat shows a potential in EV-adoption if the driving range of the vehicles are limited to be within 100-200 km. There are relevant studies on the adoption of EVs in the Middle Eastern countries. In [39] , the authors have discussed the opportunities, challenges faced in the development of smart cities in the countries of Gulf Cooperation Council (GCC). The authors have stressed the need for technological advances of fast EV-charging stations and increasing the driving range to further enhance the adoption of EVs. The authors have provided examples of how well know international companies such as Tesla have tried bringing in some of their technologies in Abu Dhabi and Dubai to promote their use. The study utilizes the study and further strengthens the recommendations using the public perception using survey results. Similar studies on conducting a survey to analyze the factors hindering the EV-adoption was done in [32, 33] . The papers stated that despite government incentives, EV-adoption was not reaching a higher scale. This is due to the buying price, battery performance, driving range and charging time. There are external factors like CS, fuel price, public visibility and social norms. However, EVs have made its way into the market due to the development of battery technology, vehicles efficiency and due to less air pollution. Considering these benefits, several countries started setting targets in EV-adoption. According to the results of the surveys in these papers, vehicles price and its characteristics plays a major role in the decision of purchasing an EV. One of the survey results implied that 55% of the respondent marked ""major disadvantage"" and 30% marked ""disadvantage"" on EV-adoption due to its higher purchasing, i.e., people are not willing to pay higher price which an EV demands. On the other hand, industry survey showed that 63% of buyer claims that price of an EV is a large barrier to EV-adoption. As compensation to this, some automotive company reduced the prices of EVs to a significant amount. However, the study suggests that electric power in vehicles provides lower expense in the long run, but not high enough to compensate the higher purchasing price. The literature also found that according the claims of 70% of the respondents in a survey, the driving range of the EV is another major drawback to its adoption. The survey was taken from people living in urban areas, those who are not much concerned about driving ranges. In addition, 33% of the respondents pointed at battery range of an EV as a drawback to its adoption. One of the other surveys suggested that EV consumers are willing to pay extra money to increase the driving range of their EV. The study also showed that 70% of respondent expectation of vehicles befits the specification of a PHEV over BEV. Therefore, the conclusion was made that to eradicate the driving range anxiety, more CS should be built because the charging time of an EV and its driving range are important to consumers of EV. The study also suggested that EV-adoption will be feasible if it can withstand longer driving range with very less charging time. Otherwise, the EV being an efficient vehicle does not add much weight to its adoption. Other studies showed that highly educated people are more likely to prefer an EV rather than a rich person who can easily afford an EV. Sometimes, a person owning multiple cars would not be interested to purchase an EV. However, home-charging infrastructure draws people's interest to EV-adoption. Therefore, people having better educational background being more environments cautious as well as previous EV owners would be more interested into buying an EV. Some technology enthusiast found in a survey that 17% respondents marked ""Less CS"" to be the greatest concern. However, large numbers of CS would come into existence with large number of EVs on the road. Again, fast charging technology is not feasible with this low rate of EV in the road. It was also learned that government incentives like free parking and cheaper EV spare parts would increase the possibility of EV-adoption. In addition to this, a study shows that 1 CS for every 100,000 residents could have significant impact on EV-adoption rate. Based on some surveys done about EV general knowledge, it was learned that most of the people hold wrong idea regarding the EV purchases. The respondents impose their economic affairs whereas they are misinformed about a price of an EV. Overall, 2/3rd of the respondents marked wrong information about an EV. Almost, 95% of the people were not aware of the incentives in their locality provided by the government for using an EV. Therefore, raising awareness and correcting the misconception would increase the willingness of consumers to prefer an EV. The impact of policy incentives towards EVs were studied in detail in [9] . The authors discussed different policy incentives that may attract the adoption of EVs. It is mentioned that a particular policy incentive is effective if the number of EVs purchased rises after the incentive is introduced. The effectiveness is measured by the difference between the number of EVs sold when the policy incentive is applied and that without the policy incentive. They found that incentives to parking (free/paid), public charging (free/paid), access to bus lanes, price including subsidies and range play a major role in the Energies 2020, 11, x; doi: FOR PEER REVIEW www.mdpi.com/journal/energies purchase of EVs. The results obtained from the analysis conducted in [9] show that there is a great impact on the willingness of the people to purchase EVs when the above-mentioned incentives are provided to the EV users. As seen in the previous studies, most of them involved general consumer perspectives and the authors realized that it will be more important to have two different perspective-(i) the perspective of people who are aware of the EV technology and can be considered as technology reviewers, researchers (technical respondents) and (ii) the perspective of people who will be sole user of EV and may or may not be aware of the EV technology (non-technical respondents). This approach may help in providing unique perspective and concluding remarks which were not there in the previous studies. Magnossun in [40] , have found that different categorical perspective in surveys, have helped in providing meaningful insights and suggestions and this study also helped in motivating the authors to take similar approach. Present economy of transportation in Qatar is heavily based on fossil fuel. According to the Qatar Vision of 2030, CO2 emission must be reduced by 17% [41] . To achieve this, the Green vehicle Initiative was launched in 2017. The aim of this initiative is to ensure 10% of total cars in Qatar must be EVs by 2022. To achieve this vision, the culture of EVs or hybrid cars must be promoted in this region. Currently, there are 7 EV CS and recently a solar powered EV CS [42] is installed, which are also shown in Figure 2 .  With the help of the literature review done on similar studies done in various parts of the work, the purpose of this study is to conduct a survey on different categories of people who have had different understanding and willingness in purchasing EVs in the future. The methodology adopted in the study is shown in Figure 3 . The questionnaire begins with questions that ask about the respondents' personal information such as age, gender, nationality and their highest education degree (details in Table 3 ). An anonymous survey was carried out among local people (technical and non-technical) in Qatar. Instructions were provided mentioning that the study was to analyze the feedback of the respondents about the public perspectives on EVs and their willingness in purchasing those vehicles. The questionnaire was prepared Energies 2020, 11, x; doi: FOR PEER REVIEW www.mdpi.com/journal/energies carefully to avoid repetitive question. Authors' previous expertise in preparing surveys were used so that the obtained results can be analyzed for meaningful conclusions [43, 44] . Extreme care was taken to ensure that the anonymity of the study and confidentiality of responses were maintained by not asking about the identification of the participants. Furthermore, the data were analyzed and reported in a cumulative manner to prevent the identification of participants. Based on the prominent researches in the field of EV [45, 46] , the questions were designed so that analysis using two-sample t-test can provide meaningful conclusions. The purpose of this study was to analyze if different characteristics of the respondents would have different views on the adoption of EVs. We hypothesized that people who have higher educational degrees would have a better image on EVs and are more likely to purchase them due to their higher awareness on global warming. After that, a question about the number of years of driving experience was asked. Before the questions that are specific about EVs were asked, their willingness to contribute to reduce global warming was asked. It was required to see if there are still people who are unaware or do not care about the effects of global warming (Table 3) . All the details of the questions in the questionnaire are shown in the Appendix A. Moreover we have divided the questions to get the respondents viewpoints on various known factors affecting the EVadoption such as Financial, technological, Policy and Infrastructure. The final question in the survey was to summarize if the respondents after going through all the advantages and disadvantages are still willing to purchase an EV. The details of the questions and the objectives (financial barrier, technological barrier, policy barrier, infrastructure barrier, etc.) they correspond to are in Table 3 below. The purpose of question under interest on climate change was to see if the initial cost of EVs would be one of the major barriers of their adoption despite it being a green mode of transportation. The people who were willing to contribute to global warming reduction may not be willing to purchase EVs after knowing that they have high purchasing costs. Questions on financial barrier were aimed to back up the high initial cost of EVs by informing the people that EVs can be a good investment. However, their shorter driving ranges were mentioned to see if the driving ranges would also be a crucial barrier for EVs. The importance of the EV-charging time could be analyzed by asking questions on technological barrier. It was expected that it would be very unlikely for people to be willing to purchase EVs if the time of charging were still relatively long. The reasonable charging times in order for people to be willing to purchase EVs were also asked in this section and it would be very likely that everyone would go for the fastest possible time. Energies 2020, 11, x; doi: FOR PEER REVIEW www.mdpi.com/journal/energies After showing the advantages and disadvantages of EVs and asking about peoples' willingness due to those factors, questions about EV infrastructures were asked. The respondents were asked how placing the charging stations in different places (i.e., public, work, homes and highways) would affect their decision in purchasing an EV. The importance of providing good incentives for EV users were also asked to convince further the respondents to be more willing in adopting EVs. Then, some points that could prevent people from buying EVs were shown and they were asked if they would purchase EVs due to those factors. This is to see which factors would be the most to the least crucial factors for EV-adoptions. More details of the respondent list such as education background and driving experience (questions in general information of the respondents) can be seen summarized in Figure 4 . The respondents were divided into two categories as discussed earlier: technical and non-technical. The technical respondents (95) were from organizations, which were directly or indirectly related to technical fields of EV. The respondents were working in one of the prominent car distributions organization in Qatar and higher educational organization in the state of Qatar. The non-technical respondents (88) were local people working in non-technical fields such as banks, medical organizations, schools and non-profit organizations. The analyses of data was done in this study in two major ways: (i) analyzing the response-based indicator, i.e., the percentage in each answer category for each question, (ii) Two-sample t-test statistics to analyze whether the responses from both the groups are significantly different or not. Response-Based Indicator  The percentages of answer in each category for different questions were analyzed to get a perception of most of the respondents. These results were analyzed and recommendations were obtained based on this. T-Statistics In a statistical analysis, t-statistics is used to compare the means of two different groups. It is also called the t-test theory while applying it on survey results. Anyone can identify two different responses, but to find if the difference is statistically significant or not, can be done with the help of t-test theory. t-test theory works very well with survey database. As it compares and determines statistical difference, survey results from two groups are very good data to analyze with t-test theory. Based on the types of the samples and groups, t-test can be done in three different ways: (i) one-sample t-test, (ii) two-sample t-test, and (iii) paired t-test. For the purpose of analysis in this study, we will be using the two-sample t-test analysis which works with the means of two independent groups' response and finds if the means are significantly different from each other or not, by comparing the t-statistics value with the critical value. A t-test can only distinguish if the means are significantly different; it is the user's decision to make a meaning conclusion from this difference. Each question in the survey which were analyzed using the t-statistics had 5 options which were coded from 1 to 5, for example-strongly unwilling was coded as 1, unwilling was coded as 2, neutral was coded as 3, willing was coded as 4 and strongly willing was coded as 5, can be seen in Figure 5 . Figure 5 . Bar chart representation of the responses to questions in Table 3 . (a) Response to willingness in contributing to Climate Change, (b) Response to willingness on buying EV despite high purchasing cost, (c) Response to willingness on buying EV who have lower maintenance and operational cost, (d) Response to willingness on prefering EV which can take one hour to get fully charged, (e) Response to most preferred EV charging time, (f) Response to willingness on buying EV if there were incentives from the government, (g) Response to preferred location of EV charging station, (h) Response to understanding the difference between EV and ICE, (i) Response to understanding the importance of low power EV, (j) Response to willingness on buying EV after being aware of its advantages and disadvantages. In this section, the results from the survey are summarized and comparisons between technical, nontechnical respondents and the two categories combined are shown in the bar graphs Figure 5a -j for the questions in the interest on climate change objective onwards in Table 3 . As stated in the earlier section two-sample t-test statistics were done on the responses between the two categories of respondents (technical and non-technical) to see if they are significantly different from each other. The combined results are also shown in figure to see the approach in the study provides conclusive results. The results are shown in Table 4 and the details of how it was conducted were stated in the analysis section. The willingness of both the groups to purchase an EV after being told of all the advantage and disadvantage of EVs has increased. As expected the combined results could have the important information regarding the lack of awareness regarding EVs in general public and can be verified from Figure 5h , (i) where were questions on understanding the difference between EVs and ICE vehicles and understanding the importance of lowpower EVs, respectively. Similar comparison could be done in Figure 5a -c where the strong willingness of the technical people to contributing to climate change, buying EVs despite high purchasing cost is evident compared to the non-technical people, and this could have missed if the different perception were not captured. In figures, looking at combined results one could have easily missed the important conclusion that there is lack of awareness about sustainable mode of transportation among the non-technical people. It is evident from the results in Figure 5 and Table 4 that the general public needs to be made more aware regarding the green mode of transportation such as electric vehicles. A majority of the non-technical people was in favor of buying EVs, despite higher initial cost. There were some technical people who were neutral to this question and thus can be assumed that they believe that the prices of EVs can be made lower through research. In the following question where the respondents were informed regarding the low maintenance and operational cost of EVs, the technical people were in majority very positive in buying EVs unlike the non-technical people, but it can be confirmed from Figure 5c that the financial barrier is not a major hindrance to the easy adoption of EVs in Qatar. The response to the question on longer charging time of EVs were not significantly different between the two groups and can be used to assume that awareness for greener mode of transportation despite its lacking can be promoted as they do not have too illogical expectations. This can be considered as a positive sign as the unaware non-technical group were answering similar to the aware technical group and thus people are ready for the various options of charging time. The question on how government incentives can help in EV-adoption had technical people responding positive unlike the non-technical, which can be attributed to their less awareness on how such incentives can help in quick adoption of such green and sustainable mode of transportation. All the respondents replied similarly in preferring charging stations on all locations. There was a clear difference in the response to the question on understanding the difference between EVs and ICE vehicles and the preference of low power EV, which will help in charging in all places. As expected the technical people responded 'Yes' to these questions in majority unlike the non-technical group. Finally, a good fraction of both the categories were willing to buy EVs after understanding the advantages and disadvantages of EVs.@story_separate@The adoption of EVs is no doubt one of the best solutions for a greener environment, due to their low emissions of GHGs relative to ICE vehicles. However, barriers such as long charging times, lack of policy incentives, initial cost and insufficient charging infrastructures are significantly slowing down the widespread adoption of EVs globally. This study has investigated the different perspectives of technical and non-technical people on the adoption of EVs in Doha, Qatar, where almost all the existing vehicles are fossil fuel dependent. Survey questions were distributed and analyzed using two methods; (i) response based analysis and (ii) two-sample t-test analysis. The analysis has shown that unlike many other countries financial barrier is a not a major hindrance to the adoption of EVs but there needs to more awareness among the general public about climate change and how it can be tackled with greener and sustainable mode of transportation such as EVs. The people when made aware will help in quicker adoption of EVs which can be further boosted by adequate government incentives. Government incentives can play a major role in EV-adoption, as seen from the survey results and also proved from the successful adoption in countries like Norway. From the results obtained, the top factor that would prevent people from purchasing EVs is the lack of public awareness policy incentives towards EVs. Other potential EV adoption barriers were also informed to the people such as the longer charging time and the higher purchase cost but these do not have a significant effect on the peoples' willingness in purchasing EVs as long as they are within a suitable range. The shorter driving range of EVs was also not a major problem, since most people were still willing to purchase EVs, while knowing that the maintenance costs of EVs were cheaper than ICE vehicles. This may be due to the fact that Qatar is a small country with many fueling stations that could be integrated with EV-charging stations, so short driving ranges would not be a barrier to adoption. The authors believe that developing a mobile application that could share the latest features and news of EVs could help to raise awareness among the general public. This mobile application could be used in the future to suggest EVcharging stations to users as well to reserve slots-thus making EV-charging even more convenient for them and helping in the gradual adoption of EVs. Without a doubt, the number of EVs in Qatar will increase exponentially if the incentives towards EVs such as free parking in all places, cheaper spare parts and the selling of electricity using the vehicle-to-grid (V2G) system becomes available to consumers. While providing EV users with many incentives, providing them with sufficient charging infrastructures in various places is also an important solution for EV-adoption. Most of the respondents want charging stations to be available in multiple places (i.e., public places, workplaces, homes and highways), so providing EV users with convenient accessibility to charging infrastructures will convince more people to switch to EVs.","The adoption of electric vehicles (EVs) have proven to be a crucial factor to decreasing the emission of greenhouse gases (GHG) into the atmosphere. However, there are various hurdles that impede people from purchasing EVs. For example, long charging time, short driving range, cost and insufficient charging infrastructures available, etc. This article reports the public perception of EV-adoption using statistical analyses and proposes some recommendations for improving EV-adoption in Qatar. User perspectives on EV-adoption barriers in Qatar were investigated based on survey questionnaires. The survey questionnaires were based on similar studies done in other regions of the world. The study attempted to look at different perspectives of the adoption of EV, when asked to a person who is aware of EVs or a person who may or may not be aware of EVs. Cumulative survey responses from the two groups were compared and analyzed using a two sample t-test statistical analysis. Detailed analyses showed that among various major hindrances raising of public awareness of such greener modes of transportation, the availability of charging options in more places and policy incentives towards EVs would play a major role in EV-adoption. The authors provide recommendations that along with government incentives could help make a gradual shift to a greater number of EVs convenient for people of Qatar. The proposed systematic approach for such a study and analysis may help in streamlining research on policies, infrastructures and technologies for efficient penetration of EVs in Qatar."
"In the coronavirus pandemic, which has deeply influenced the world, the total number of confirmed cases has exceeded one million and the number of those who died has exceeded fifty-two thousand as of April 2, 2020 [4] . While this is the case, the world has been involved in an intensive study from preventive measures to therapeutic measures to combat the coronavirus outbreak [8, 9, 10, 11, 15] . Wuhan, China's Hubei Province in December 2019. This disease is transmitted from person to person through breathing [6, 10, 12, 13] . Within the scope of this study, a mathematical model was developed to measure the extent of outbreaks in other outbreaks, especially coronavirus pandemics, which deeply affected countries. With this model, it was aimed to calculate the wavelength of the outbreaks and to facilitate the follow-up of the outbreaks on a reliable and valid basis at the national and international level. Data sets retrieved from ""The Humanitarian Data Exchange (HDX)"" website were used to demonstrate the implementation of the models [4] .@story_separate@In this study, the size of the outbreaks, especially the coronavirus outbreak, was determined with the mathematical models developed in the current data set, and the size of the outbreaks was measurable, as well as the opportunity to compare outputs of these modes within the country and between countries. To calculate wavelengths, data sets was taken from the Human Data Exchange (HDX) platform which is the one of the websites of OCHA (United Nations Office for the Coordination of Humanitarian Affairs [4] . The number of cases in the data sets covers the period from 2020-01-22 until 2020-04-02 (including this date). Data sets having the extension csv (commaseperated value) were combined because they consisted of 3 different datasets, including confirmed cases and deaths, and recovered coronavirus cases. The number of cases in the data sets follows a cumulative course. Microsoft Excel 2016 and R Programming language was used in the analysis [2, 3] . Since there are duplicates in the time series for countries in the data sets, a unique time series was created within each country using data mining techniques. Descriptive statistics of the World coronavirus (COVID-19) cases in the data set are given in Table 1 . . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 11, 2020 The course of the COVID-19 cases in the world has been presented in graphs from 2020-01-22 until 2020-04-02 (including this date), which is handled separately on the basis of approved cases, deaths and recovered cases. The blue dashed line parallel to the x axis in the graphs shows the average of the cases. First, the course followed by the approved cases in Figure 1 is given. There was a sharp increase in the number of cases approved according to Figure 1 at the end of the first 60-day period. After this time period, it was observed that the number of approved cases was above the average number of cases. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 11, 2020 In Figure 2 , the course followed by the death cases is given by time. Similar to that in Figure 1 , it was observed that there was a sharp increase at the end of the first 60 days of the epidemic in death cases according to Figure 2 , and the number of death cases was above the average number of death cases. The progress of the recovered cases according to time is given in Figure 3 . Unlike Figures 1 and   2 , it has been observed in Figure 3 that there is a sharp increase at the end of the first 40 days of the outbreak in recovered cases, and the number of recovered cases was above the average number of recovered cases. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint The per-case statistics of the first 25 countries with the highest number of confirmed cases were also discussed in the timeframe from 2020-01-22 until 2020-04-22 (including this date). In this context, the number of confirmed cases and deaths per day as well as the ones of recovered cases per day was examined. The findings are given in Table 2 by country. The findings that stand out according to Table 2 are as follows:  In the number of cases per day, the USA ranked first with 3381.3 cases, followed by Italy, Spain and Germany, respectively.  Italy ranked first in the number of deaths per day with approximately 221 cases, followed by Spain, the USA, France and Iran.  China ranked first in the number of recovered cases per day with approximately 1064.3 cases, followed by Spain, Germany, Italy and Iran. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint In this section, the parameters used in model equation are firstly included. Then, case, death, recovered and net wavelength models are given respectively. The relation of wavelength equations with net wavelength equation is presented in Figure 4 . is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint After the parameters are included, it is the recommended equations for the wavelengths. The reason for using natural logarithm (ln) in equations is that the values obtained are wanted to be normalized. The reason why the natural logarithm product coefficient is included in 1 is that ln (1) = 0. Average is not used in wavelength equations. This is because, for example, the number of cases seen in a total of 20 days since the first epidemic case occurred in an ""A"" population was 2000. In another example, the number of cases seen in a total of 40 days since the first epidemic case occurred in a population ""B"" was 4000. In both samples, the average number of cases per day in the ""A"" and ""B"" population is equal. However, populations with different days and number of cases should be differentiated from each other. Therefore, evaluating these two populations with the same average on the same plane results in erroneous findings. These and similar situations also exist at epidemiological rates. Therefore, they are far from revealing the magnitude of the epidemic, in other words, wavelength. In general terms, as the values of the variables in the numerator and denominator grow or shrink simultaneously, there will be no differentiation. An example of this is the case-based fatality rate, which is one of the epidemiological rates. A case fatality rate (CFR) is the proportion of those who died of a particular disease at a given time. In CFR product coefficient is 100 [1] . For example, in the population ""A"", the total number of cases in a given disease and at a given time is 1000, and the number of deaths is 50. In the population ""B"", the total number of cases in a given disease and at a certain time is 10000, and the number of people who died is 500. In this case, the case fatality rate in these two populations is 5%. The issue to be considered here is to reveal how many cases were reached in which time period in COVID-19 or other epidemic data sets. The task that needs to be done later is to calculate the wavelength of the outbreak using these findings. Many models developed in the study were tested in measuring the wavelength of the outbreak. Finally, it was decided to use the wavelength equations mentioned in the following sections. Case wavelength was calculated with the help of equation (1) . The higher the case wavelength (Wc), the higher the size of the outbreak in the population. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020.  Death wavelength was calculated using equation (2) . As the death wavelength (Wd) increases, the epidemic's killer effect increases in the population. Recovered case wavelength was calculated with the help of wavelength equation (3). As recovered wavelength (Wr) increases, the recovery rate of cases infected by the epidemic increases in the population. (3) Net wavelength was calculated with the help of equation (4) . Here, the net wavelength is . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint Findings regarding case wavelengths are presented in Table 3 comparatively by the first 12 countries with the highest wavelengths. The findings that stand out according to Table 3 are as follows:  The USA, with the highest case wavelength, ranks first with 36.77 points, while Belgium is 12th with 28.56 points. The USA with the highest wavelength is followed by Italy, Spain and Germany, respectively.  Findings including death wavelengths are comparatively given by the first 12 countries with the highest wavelengths in Table 4 . The findings that stand out according to Table 4 are as follows:  Unlike case wavelength, Italy, with the highest death wavelength, ranks first with 28.24 points, while Turkey ranks 12th with 17.49 points. Italy, which has the highest death wavelength, is followed by Spain, USA and France, respectively. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint  Findings including recovered case wavelengths are presented by the first 12 countries with the highest wavelengths in Table 5 . The findings that stand out according to Table 5 are as follows:  Unlike other wavelengths, in recovered case wavelength, China was ranked 1st with 33.30 points, while Denmark ranked 12th with 20.99 points. China having the highest recovered case wavelenght, is followed by Spain, Germany and Italy, respectively. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint  Findings related to net wavelength are presented from large to small by the first twelve countries in Table 6 .Here, case and death wavelengths are summed first for the net wavelength. Then, the net wavelength was calculated by subtracting the recovered wavelength from this total. The net wavelength findings that stand out according to Table 6 are as follows:  Unlike all other wavelengths, in net wavelength, Canada was ranked 1st with 41.95 points, while Turkey ranked 12th with 28.83 points. Canada, with the highest net wavelenght, is followed by United Kingdom, USA and Italy, respectively. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint  The author declares that they have no conflict of interest. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 11, 2020. . https://doi.org/10.1101/2020.04.07.20056432 doi: medRxiv preprint@story_separate@Within the scope of this study, mathematical models were developed to measure the extent of outbreaks in other outbreaks, especially COVID-19 pandemics, which affect countries in social, economic and many other aspects. In this way, by calculating the wavelength of the outbreaks, it is aimed to facilitate the follow-up of the outbreaks in the country and at the international level as reliable, valid and at the same time as easy as possible. At the same time, the findings from the models are expected to contribute to policy making for decision makers. On the other hand, although the developed models are designed to reveal the extent of outbreaks, they can be used in other diseases with and without infection origin. The developed wavelength models were tested on datasets with COVID-19 cases, deaths and recovered cases in 181 countries. According to the findings obtained from the implementation, the first four countries with the highest case wavelength are USA, Italy, Spain and Germany, respectively. However, Italy ranks first in the death wavelength, followed by Spain, the USA and France. On the other hand, China has taken the first place in the recovered wavelength. This country was followed by Spain and Germany and Italy, respectively. Based on all these wavelength models mentioned, net wavelength lengths are calculated. According to the net wavelengths obtained, Canada ranked first, followed by United Kingdom, the USA and the Netherlands, respectively. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 11, 2020 Since there were no other variables other than the number of confirmed cases, deaths and recovered cases in the existing data sets, the models developed were limited to these variables. Of course, other variables can also be included in the wavelength equations mentioned as parameters, and wavelengths can be calculated.","The main purpose of the study is to introduce the wavelength models developed to measure the size of outbreaks based on the COVID-19 example. In this way, the wavelengths of the outbreaks can be calculated, ensuring that the outbreaks are valid, reliable and easy to follow at the national and international level. Wavelength models consist of approved case, death, recovered case and net wavelength models. Thus, the size of the outbreak can be measured both individually and as a whole. COVID-19 cases of 181 countries were used to demonstrate the application of the models. The prominent findings in the applied wavelength models are as follows: the countries with the highest case wavelength are USA, Italy, Spain and Germany, respectively. However, Italy ranks first in the death wavelength, followed by Spain, the USA and France. On the other hand, China has taken the first place in the recovered case wavelength. This country was followed by Spain and Germany and Italy, respectively. Based on all these wavelength models mentioned, net wavelength lengths are calculated. According to the net wavelengths obtained, Canada ranked first, followed by United Kingdom, the USA and the Netherlands, respectively."
"The outbreak of the Coronavirus 2019 disease (COVID-19) pandemic has strained the healthcare system in a variety of localities across the globe. In Italy (the European disease epicenter at the time of this writing), intensive care is required for > 15% of infected patients 1 and the number of hospital beds has been increased by 50% to meet care needs 2 . COVID-19 is highly infectious and a single patient typically infects 2-4 additional persons depending on level of isolation 3, 4 . In Italy alone, an additional 20,000 healthcare workers are needed to staff the patient surge, resulting in the shunting of non-ICU and non-internal medicine healthcare providers into the inpatient medicine care space from other specialties 5 . Further, physicians and other providers are at especially high risk of infection--treating physicians comprised 29% off those hospitalized in a study of 138 patients in Wuhan, China--and must be replaced and cared for by their colleagues 6 . Radiation oncology is not on the front-line of this pandemic but is directly impacted by the disease through anticipatory reductions in staffing to reduce exposure risks, quarantine of infected or exposed providers, and reallocation of the workforce as providers are called upon to reinforce other specialties. Absence of a certain radiation oncology sub-specialist or specialty staff member due to these factors could result in sub-optimal care or lack of availability of certain types of specialty care procedures like stereotactic body radiotherapy (SBRT) 7, 8 . Patients with cancer are also at higher risk of fatality from infection 9, 10 , which further underscores the need for increased efforts to minimize transmission within the radiation oncology department to protect these at risk patients. To maximize the availability of staff members, as well as to limit the exposure risks amidst staff and oncology patients incurred through common interactions like in-person SBRT coverage, digital care and coverage techniques must be implemented. Based on the desired use of remote techniques like telemedicine during the COVID-19 pandemic 11, 12 , a novel, digital method to provide physician SBRT coverage for image review was created and implemented in our department. Ease of use and HIPAA compliance were required design features for the deployment of this remote SBRT technology. Equally important was the widespread accessibility of this approach both within our multicenter network and in other clinic systems facing parallel staffing and exposure challenges. Thus, we utilized a commercially available combination of software and hardware to ensure broad reproducibility. The goal of our remote SBRT coverage technique was to provide reliable, timely, and similar quality specialty care for our patients to reduce the relative risk of infection in our department by encouraging physical distancing amongst personnel and oncology patients. We also aimed to provide a mechanism for our physicians and specialty staff to be allocated elsewhere in the hospital while continuing coverage for radiation oncology care. Here we describe the composition, implementation, and reliability of a digital remote SBRT coverage technique in our radiation oncology department, as well as how it is perceived by our SBRT care team.@story_separate@At pre-COVID-19 baseline, our daily SBRT coverage team consists of two radiation therapists, a medical physicist, and a radiation oncologist. Department policies, developed from national guidelines, require physician presence at every fraction for fusion review, image approval, and to direct treatment, while physics presence is required for all first-fraction treatments to review setup, image registration, motion management, setup corrections, and troubleshooting 13,14 . Apart from these specified roles, both physicians and physicists must also remain available within the department at all times during treatment delivery. Our department delivers an average of 10-15 SBRT treatments per day, the majority of which take place on a specialty stereotactic treatment unit, Edge (Varian Medical Systems, Palo Alto, CA). The typical workflow of coverage is as follows. The patient is set up on the table to marks by the therapy team, and a CBCT is obtained with initial positional match performed by the therapists. The physician is then called and verifies the setup, the shift is sent, and the physician verifies all subsequent images (kV/kV, fluoroscopy, etc) prior to delivery. At first fraction, a physicist is present at time of set up and through delivery. At first (and subsequent) fractions, the physician is called to the machine following initial CBCT match. To enable transition to remote SBRT coverage in the setting of a global pandemic requiring physical distancing between persons, a commercial grade frame grabber (DVI2USB 3.0, Epiphan Video, Palo Alto, CA) capable of capturing screen resolutions of 1900x1200 at 60fps was connected to the digital video interface (DVI) port on the treatment console through a DVI cord splitter, grabbing the entire display screen from the imaging (treatment console) computer on the Edge. This was then projected into a secondary computer via a USB cable connection between the frame grabber and secondary computer. Using an enterprise installation of Microsoft Teams (Microsoft, Redmond, WA), a video call was placed from the secondary computer and the secondary computer's screen was shared (displaying the grabbed treatment console screen) with the covering physician in real time. Microsoft Teams is behind the university's firewall and is within the university's HIPAA compliant Office 365 package. The covering physician can answer the Teams call using either a desktop computer, laptop, tablet, or mobile device. The physician and the treatment machine team (therapists and physicists) must have audio communication to properly communicate; this was fully enabled as long as the device they answer from has audio and microphone capability. To ensure the covering physician has adequate visualization of the treatment images and setup review, the physician can control the secondary computer's mouse via the Microsoft Teams application. If at any time, an SBRT team member feels uncomfortable with the remote physician process, the physician comes to the machine for an in-person review. The process is illustrated in Figure   1 . After implementation of the above process, we sought to evaluate the reliability, timeliness, and quality of our remote SBRT coverage system. Reliability was determined by evaluating the frequency and types of process failures that occurred over the first 15 SBRT fractions completed using remote coverage with the novel system. A list of potential failure modes that were recorded is available in supplementary section A. Apart from reliability, we also evaluated the timeliness of remote coverage as compared to contemporaneous fractions delivered using our traditional, in-person coverage system. Using the treatment timing stamps from the record and verify system (Aria, Varian, Palo Alto, CA), the time from CBCT acquisition (the time point at which the physician would otherwise be physically called to the machine) to treatment was calculated for 15 fractions after remote SBRT coverage implementation. For comparison, time from CBCT to treatment was also gathered for 15 fractions delivered in the weeks directly preceding remote SBRT coverage. Similar treatment sites were selected for the time analysis before and after remote coverage implementation to limit variations in expected duration. These time stamps represent when the covering physician was contacted and how long they were present at the machine or present on the Teams call. In addition to reliability and timeliness, we compared both the quantitative and subjective quality of audio and visual (A/V) connection for the remote SBRT coverage platform. Our specific concerns were potential for loss of A/V quality and potential system lag that could degrade coverage quality. Quantitative evaluation of overall A/V quality included comparison of treatment console images versus the physician's shared screen images using cross-correlation image registration metrics. Image lag was tested similarly, using cross-correlation over time to establish when the frame recorded on the physician's computer matched the secondary sharing computer's image frame. The time for the physician's computer to match the secondary computer was the image lag. With regards to subjective A/V quality, physicians, physicists, and therapists were all surveyed after each SBRT fraction, asking each group to rate A/V quality using a Likert scale ( Figure 2 ). Finally, we evaluated team member comfort with the novel remote SBRT process. The final question in the post-fraction survey administered to all three personnel groups involved in the SBRT treatment process was ""What was your comfort level with this case compared to how it would be in person?"" Responses were again recorded using a 5-point Likert scale. All statistical analyses were completed using SPSS Version 26.0 (IBM Corp., Armonk, NY). For analysis of survey Likert scale data, paired control comparison values of ""5"" were assumed for all data points, given that surveyed individuals were asked to scale responses such that 1 was ""very poor"" and 5 was ""same as if physician were at the machine"". Unpaired and paired T-tests were utilized for the comparative analyses for the timing data and survey responses, respectively. Using a commercially available frame grabber and collaboration platform, we were able to successfully place video calls to the covering physician, sharing the treatment console's imaging screen, for all 15 SBRT coverage calls. During all 15 remote SBRT coverage calls, a call was never was lost nor were there any noticeable glitches in audio or visual quality. Our physician team was also reliable in terms of responsiveness, never needing to be called more than twice with prompt call-back if missed. Remote SBRT physician coverage was successfully used for 14 out of the first sequential 15 treatment fractions. We observed occurrence of three system failures from our pre-determined set of potential failure modes during the first 15 cases implementing remote SBRT coverage. The first failure was a near-miss for treatment time out (case description and patient identification), which was not initially performed as planned prior to setup confirmation (preferred timing), but was detected and performed prior to delivery. The second failure was a distracted physician during remote SBRT coverage. This was detected by the treating therapists, who reminded the physician to not multitask during SBRT, with correction prior to delivery. The final failure was a treating physician being uncomfortable with visualization and ability to communicate changes for an abdominal gating case during the confirmation of the gating windows and fiducial fluoroscopy tracking, requiring the physician to come to the machine to clarify setup. This resulted in a physician comfort level of 2, or poor. The disease sites treated for the reported first 15 remote coverage fractions were abdomen (n=4), bony extremity (n=4), brain (n=3), spine (n=2), lung (n=1), and neck (n=1). The comparison cases selected from the preceding weeks using in-person physician coverage were intentionally selected to be of an identical disease site distribution. In terms of quantitative image quality, the cross correlation between the treatment console's imaging screen and the shared frame grabbed screen via Microsoft Teams was R = 0.96. The lag in Teams video sharing was 0.05s (50ms). An example screenshot from a physician's mobile device (iPhone X) during remote coverage is shown in Figure 4 . Two-finger pinch zoom-in and zoom-out was also feasible on touch-screen devices, without perceptible lag. A demonstration of the A/V quality and the workflow can be viewed in supplementary section B. The remote SBRT survey questions and responses for A/V quality and level of comfort are shown in Figure 2 . The only category that was statistically significantly different from in-person coverage was physician comfort (Figure 2 , p = 0.013). The lowest ranked comfort level was 2, which occurred once. There were 5 responses with scores of 4, and the majority of these 4s were because the physician would have ideally changed a windowing level or fusion review visualization setting (i.e. floating vs. gray/white overlay vs. checker-box). Nevertheless, the median response was 5 across all categories, including for audio quality. We have successfully implemented remote SBRT physician coverage within our department for a variety of treatment sites. The tools that we use are available to most radiation oncology departments and can be implemented quickly with a few wire connections and installations of commercial applications. Remote SBRT coverage will allow for flexibility in response as staffing resources are shunted or reallocated during the COVID-19 crisis, while providing similar quality to in-person SBRT coverage. All members of the treatment team received the process positively and were invested in making improvements as we continued to refine and gain experience with the process. Remote SBRT coverage is feasible with minimal observed potential failure modes based on our initial implementation data. Of the first 15 remote coverage cases attempted, only 1 case ultimately required physician presence. Specifically, nuances of communication using remote instructions for gating windows for a gated abdominal case led to physician discomfort with remote coverage, and the physician instead opted to be physically present at the console for more direct communication. Other observed failure modes were a distracted physician (multiple phone messages while covering via Teams mobile app call) and a nearly-missed pre-treatment time-out. Both of these were detected and corrected prior to treatment. Formal FMEA analysis is the optimal approach prior to implementation of novel technologies in a medical environment 15 . However, given the urgency of creating a remote coverage process in the pandemic setting, this will instead be formally carried out after remote SBRT implementation. With regards to timeliness, remote SBRT coverage compared favorably to our in-person process. Time delays are critical to avoid for successful deployment of the tool, as this would prolong patient time on-table, which can result in loss of setup accuracy 16 . We found that the time of CBCT to the time of treatment was not statistically different for remote coverage compared to in-person coverage. It is important to note that during this short time period of investigation most of the cases analyzed were not our institution's typical SBRT disease sites (majority lung and brain), lending to the possibility that pretreatment coverage could be faster for standard SBRT disease sites compared to our current process of requiring the physician to be physically present. Importantly, remote coverage physically removed physicians from the machine, which would otherwise be an average of 4.5min for in-person coverage at each case. This may reduce the relative risk of infectious exposure across personnel and patients. Physicians were able to remote review from areas in the department such as nursing wings, their office, and outside a consult room. We also found it helpful to inform the covering physician when the treatment team was bringing the patient into the room, allowing the physician to expect a call and increase the answer rate. Our image quality degradation through Microsoft Teams via the frame grabber was minimal and maintained high correlation within the hospital network, meaning the images were almost identical. The lag was 50msec, which is in the range of what is perceived as ""instantaneous action"" to a user based on published literature 17, 18 . Our image quality metrics as determined by post-treatment surveys demonstrate non-inferiority to the physician's visual perception if he or she were present at the machine. The comfort level amongst all members of the treatment team approached the in-person SBRT coverage comfort levels, demonstrating that our SBRT team felt comfortable proceeding with treatment despite not having a physician physically present. The lowest comfort level reported for any fraction was a 2, due to inconsistencies between the CBCT and fluoroscopic gated images, resulting in the longest CBCT to treatment time. Despite a low comfort level, we were able to correctly identify that the physician was needed at the machine and had minimal wait time for the physician to be present (approximately a minute or less). In the future, we look to identify cases where remote SBRT coverage may be challenging, such as first fraction abdominal gating cases or for lesions that have high potential for poor detectability even if in person (e.g. peri-diaphragmatic lung lesions). Additional time-outs during this process are necessary to ensure physicians have all needed information. Ordinarily, time out is performed before the patient is placed on the table and again when physician arrives for coverage. With in-person coverage, the physician has the opportunity to pull up patient charts and supplementary imaging alongside the treatment console on a separate computer from the Microsoft Teams computer. In the remote setting, especially by mobile app, a second time-out to transmit this information about the case to the physician is critical. Having available resources at the ready, including prior fraction notes, planning scans, etc. to answer whatever questions that the physician has may be helpful. Not having additional resources at the ready on the secondary computer resulted in the second slowest outlier seen in Figure 3 . Additional challenges include the greater importance of using direct verbal communication, as common non-verbal cues are lost with remote coverage. Limiting distractions from competing physician tasks is also critical to ensure quality and future steps may include a formal coverage script where physicians maintain an active verbal role in the process to ensure continued attentiveness. Future steps in our process include performing a formal FMEA analysis of remote SBRT coverage for our physicians. We would also like to perform a study investigating remote coverage differences for a larger set of patients over a longer period of time. This work allows us to explore avenues of real-time training and recording across our multi-institutional sites during deployment of new techniques for debrief and feeback. It also provides a platform for real-time collaboration across multiple individuals with expertise in a variety disease sites despite not being physically available at the time of treatment. At this current stage, we were able to quickly implement this novel technology, performing a brief yet informative and important study in the management of COVID-19 for the healthcare system.@story_separate@In our study, we were able to provide remote SBRT coverage that is of high visual and audio quality, reliable, timely, and similar to in-person physician SBRT coverage. Because of this, we may reduce the relative risk of transmitting COVID-19 amongst our colleagues and patients. Our physicians were able to perform remote SBRT coverage in various locations in our department and hospital, meaning coverage is possible even if physicians are allocated to other areas in the hospital. Remote coverage permits continued high-quality care for our oncology patients, maximizing physicians as resources for other types of patient care during the COVID-19 crisis, and minimizes exposure risk to our staff members and patients. What is your comfort level with this case compared to how it would be in person? Rankings 1 = very poor, 2 = poor, 3 = neutral, 4 = good, 5 = same as if physician were at machine","INTRODUCTION: During the COVID-19 pandemic, alternative methods of care are needed to reduce the relative risk of transmission in departments. Also needed is the ability to provide vital radiation oncological care if radiation oncologists (RO) are reallocated to other departments. We implemented a novel remote RO SBRT coverage practice, requiring it to be reliable, of high audio and visual quality, timely, and the same level of specialty care as our current in-person treatment coverage practice. METHODS: All observed failure modes were recorded during implementation over the first 15 sequential fractions. The time from CBCT to treatment was calculated before and after implementation to determine timeliness of remote coverage. Image quality metrics were calculated between the imaging console screen and the RO’s shared screen. Comfort levels with audio/visual communication as well as overall comfort in comparison to in-person RO coverage was evaluated using Likert scale surveys after treatment. RESULTS: Remote RO SBRT coverage was successfully implemented in 14/15 fractions with 3 observed process failures that were all corrected before treatment. Average times of pre-treatment coverage before and after implementation were 8.74 and 8.51min, respectively. The cross correlation between the imaging console screen and RO’s shared screen was r=0.96 and lag was 0.05s. The average value for all survey questions was above 4.5, approaching in-person RO coverage comfort levels. CONCLUSIONS: Our novel method of remote RO SBRT coverage permits reduced personnel and patient interactions surrounding RT procedures. This may help to reduce transmission of COVID-19 in our department and provides a means for SBRT coverage if ROs are reallocated to other areas of the hospital for COVID-19 support."
"Congenital unilateral pulmonary hypoplasia of a pulmonary artery is rare congenital anomalies [1] . With an estimated prevalence of one in 200,000 [1] [2] [3] , pulmonary hypoplasia can range from partial to near-total lung underdevelopment. In 1995, Boyden classified pulmonary hypoplasia as a variable amount of lung parenchyma, bronchial tree, and supporting vasculature [4] . Due to embryologic relationships, pulmonary artery agenesis commonly occurs on the side of the chest opposite to the aortic arch [5] . The distal intrapulmonary branches of the affected artery usually remain intact and receive collateral supply from bronchial, intercostal, internal mammary, subdiaphragmatic, subclavian, and even the coronary arteries [6] . As a result of diminished blood supply, the lung on the affected side is usually small and hypoplastic [6] . An appearance termed ""pseudofibrosis"" is sometimes seen in the affected lung apex due to the formation of transpleural collateral vessels between peripheral pulmonary arterial branches and systemic arteries [7] . Reported symptoms include dyspnea, cough, recurrent hemoptysis, recurrent respiratory tract infections (RTIs), tachycardia, and pulmonary hypertension (PHT) [1] [2] [3] [4] [5] [6] . A substantial portion of congenital lung anomalies is detected early in childhood, frequently prenatally. Diagnosis is usually made in the setting of severe respiratory insufficiency or with the occurrence of acute respiratory infections later in childhood [8] . However, lung and pulmonary artery hypoplasia diagnosis is challenging in adults as they can easily be mistaken for more common diseases [4] , and many patients survive into adulthood with minimal or no symptoms [9] . This report focuses on a rare etiology of unilateral pulmonary hypoplasia with an associated history of chronic lung disease presenting in a 14-year-old patient with 3-methylglutaconic aciduria (3-MGA-uria). We explore the potential etiologies for the development of unilateral pseudo-pulmonary fibrosis. This article was previously presented as a meeting abstract at the 2021 American Thoracic Society Virtual Conference on May 14-19, 2021.@story_separate@A 14-year-old Hispanic female diagnosed with 3-MGA-uria type 1 presented with her caretaker to our institution with complaints of chronic wet cough and recurrent RTIs since she was three years old that have led to multiple hospitalizations throughout her childhood. The patient was born at 40-week gestation, weighing 4lb, 14oz via cesarean section due to failure of labor progression. She was admitted to the Neonatal Intensive Care Unit (NICU) due to hyperbilirubinemia and discharged without complications. At one month old, the patient started having daily seizures, which were diagnosed as infantile spasms. The patient started demonstrating delays in developmental history, dysphagia, dystonia, psychomotor retardation, and failure to thrive during routine examinations. The patient was referred to a nutritionist, occupational, speech, and physical therapist, with minimal improvement in her condition. After a comprehensive genetic and metabolic evaluation, the patient was diagnosed with 3-MGA-uria type 1 at eight months old. Positive findings on her examination included: a small head, sunken eyes, and feet inversion. The patient body mass index (BMI) is 15.7 kg/m 2 (third BMI percentile) with a poor skeletal build. The respiratory evaluation was pertinent for intermittent episodes of wet cough and asymmetrical breath sounds with intermittent central rhonchi. Mild scoliosis and hypotonia in all extremities were observed. Chest x-ray (CXR) (Figure 1 ) demonstrated non-specific thickening of the interstitial markings. Echocardiography demonstrated mild tricuspid regurgitation by congenital defect and was negative for PHT. Diaphragmatic ultrasound (US) showed the adequate movement of both hemidiaphragm. Anteroposterior (AP) CXR demonstrated nonspecific thickening of the interstitial markings more confluent at the right pulmonary field (blue arrow). Mediastinum was shifted to the right side (green arrow). The tracheal deviation was noted (yellow arrow). For further evaluation and diagnosis, a contrast-enhanced computer tomography (CECT) of the thorax using multiple axial images (Figures 2A, 2B ) was ordered. Right pulmonary parenchyma demonstrated multifocal and radiolucent destructive-like pattern configuration. There were curvilinear areas of mild bronchiectasis changes noted at the right upper lobe. Also, multifocal reticular interstitial opacities and cystic lucencies extending at the periphery of the lung were present. Subpleural honeycombing pattern configurations were present at the right-sided pulmonary parenchyma. Asymmetry of the thorax with a smaller right lung and slight elevation of the right-sided diaphragm were also observed. Mild diffuse bronchial wall thickening changes are noted related to mild bronchial wall inflammatory disease. Three-dimensional (3D) reconstruction images of the cardiovascular and coronal reconstruction were performed ( Figure 3) . The main pulmonary truck measured 1.73 cm in maximal transverse diameter. The right main pulmonary artery was noted to be hypoplastic (8 mm) as compared with the left pulmonary artery (1.5 cm). Right upper and lower lobes arteries were hypoplastic. Posterior view of the pulmonary arterial circulation. The main pulmonary truck measured 1.73 cm in maximal transverse diameter. The right main pulmonary artery was noted to be hypoplastic (8 mm) (red arrow) as compared with the left pulmonary artery (1.5 cm) (yellow arrow). All findings on radiologic imaging were consistent with hypoplasia of the right-sided pulmonary artery system and branches with unilateral right-sided pseudo pulmonary fibrosis type changes. The patient was diagnosed with hypoplasia of the right-sided pulmonary artery system and its branches. Differential diagnosis includes: Swyer-James-MacLeod's syndrome (SJMS), lobar atelectasis, post-lobectomy status, and compensatory emphysema, and pulmonary thromboembolic disease can have a similar radiographic appearance [6, 9] . The symptoms and clinical manifestations associated with hypoplasia of a pulmonary artery may vary between patients. The presence of cough, dyspnea, recurrent RTIs, PHT, hemoptysis, and pulmonary hypoplasia findings are some of them. Typical findings on a plain chest radiographic image of unilateral pulmonary artery agenesis can be subtle but may include ipsilateral displacement of heart and mediastinum, absent hilar shadow, and volume loss of affected lung with hyperinflation of the contralateral lung [8] . Our patient's CXR demonstrated volume loss of the affected right lung but no hyperinflation of the contralateral lung nor other additional changes. When CXR is suspicious, the diagnosis of pulmonary artery hypoplasia can be confirmed by a CECT scan of the thorax, magnetic resonance imaging, or transthoracic echocardiography [6] . This noninvasive test was also used to evaluate the presence and extent of bronchial and pulmonary thickening lesions changes in our patient. CECT imaging revealed the marked hypoplasia of the right-sided pulmonary artery system and branches and areas of pseudo-fibrotic-like changes on the affected lung, which was concerning for pseudofibrosis. Echocardiography is necessary to exclude any other cardiac abnormalities and to evaluate the presence of associated PHT, which may preclude long-term survival [3, 9] .As aforementioned, echocardiography was negative for PHT in our patient. Pulmonary angiography is the gold standard investigation for the diagnosis of pulmonary artery agenesis and estimation of collateral circulation [6] . However, being an invasive procedure, it is better advised when a patient is planned for arterial embolization [6, 7] . Lack of arterial blood flow to the affected lung in pulmonary artery hypoplasia can result in poor delivery of inflammatory cells to sites of inflammation and impair ciliary function [5] . In addition, poor blood flow to the affected lung may result in alveolar hypocapnia, leading to secondary bronchoconstriction and mucous trapping increasing host susceptibility to bacterial and viral proliferation [3, 5] , which may be the cause of the multiple respiratory infections and hospitalization in our patient's case. Chronic infection can lead to bronchiectasis in some cases [4] . Limited blood flow to the patient's right lung parenchyma may restrict its development and accentuate pseudo-fibrotic changes seen in our patient's hypoplastic lung. Thus, pseudofibrosis can result from the presence of multifocal reticular interstitial opacities in a hypoplastic lung with a limited blood supply, which alters the parenchymal structure. An early diagnosis is extremely important because prognosis depends on the presence of many complications such as pulmonary infections, pulmonary hemorrhage, and, especially, PHT [3, 4, 6, 7] . The overall mortality rate in UAPA is 7% [3, 6, 7] . Common causes of mortality include right heart failure, respiratory failure, massive hemoptysis, and high-altitude pulmonary edema [6, 7] . There are no guidelines or consensus regarding treatment [3, 6] . For asymptomatic patients, yearly echocardiography evaluation is advised to rule out PHT [4, 6, 9] . Vasodilator therapy is advisable for patients with PHT [4, 6, 7] . Revascularization of the peripheral branches of the affected pulmonary artery to the pulmonary hilum has been attempted successfully and has yielded better results in the pediatric population [6] . For patients presenting with massive hemoptysis or with recurrent severe respiratory infections, surgical resection of the affected lung may be needed. Pulmonary artery embolization is an alternate option for patients not fit for surgery [6] . Follow-up with subspecialists should be considered for timely detection and treatment of complications, especially PHT secondary to unilateral pulmonary hypoplasia ( Table 1) . Cardiology Exclude concomitant cardiac anomalies and evaluation of the presence of PHT. Yearly echocardiography evaluation to rule out PHT. Management of PHT (vasodilator therapy is advised if needed). Diagnostic testing for underlining metabolic or congenital heart diseases. Referral of caretakers to a genetic counselor for diagnostic discussion, prognosis, and family planning.  Human subjects: Consent was obtained or waived by all participants in this study. Institutional Review Board of the University of Puerto Rico, Medical Sciences Campus, Department of Pediatrics issued approval B1730120. The study was conducted according to the guidelines of the University of Puerto Rico, Medical Sciences Campus. Conflicts of interest: In compliance with the ICMJE uniform disclosure form, all authors declare the following: Payment/services info: All authors have declared that no financial support was received from any organization for the submitted work. Financial relationships: All authors have declared that they have no financial relationships at present or within the previous three years with any organizations that might have an interest in the submitted work. Other relationships: All authors have declared that there are no other relationships or activities that could appear to have influenced the submitted work.@story_separate@This case report highlights the difficulty of identifying and diagnosing unilateral pulmonary hypoplasia due to its variable symptomatic presentation in children. Also, it recognizes the importance of early identification of the defect to prevent the worsening of complications such as recurrent pulmonary infections, irreversible bronchiectasis, and pseudo-pulmonary fibrosis in pediatrics. Early recognition of unilateral pulmonary hypoplasia and individualized treatment for associated complications may improve prognosis. Additional studies on how early interventions and treatment may change the natural history of this disease are needed.","Congenital unilateral pulmonary hypoplasia of a pulmonary artery is considered a rare congenital anomaly in the pediatric and adult population. With an estimated prevalence of one in 200,000, it can range from partial to near-total lung underdevelopment. The diagnosis of lung and pulmonary artery hypoplasia is challenging in adults as they can easily be mistaken for more common diseases. Many survive into adulthood with minimal or no symptoms, which makes their identification challenging. We present the case of a 14-year-old female with a previous diagnosis of 3-methylglutaconic aciduria (3-MGA-uria) with a history of chronic wet cough andrecurrent respiratory tract infections (RTIs) that led to multiple hospitalizations throughout her childhood. After further evaluation, the patient was diagnosed with hypoplasia of the right-sided pulmonary artery system and its branches. This case report highlights the importance of early identification of congenital unilateral pulmonary hypoplasia of a pulmonary artery to prevent pulmonary complications like recurrent RTIs in pediatric patients with rare diseases."
"Risk has been identified as a defining characteristic of contemporary society, an assemblage of discourses and practices that in a variety of ways shape not only the world within which we live but also how we make sense of our experience. This raises many issues for research but the broad question that concerns us here is how people experience and deal with risk, and specifically with hazardous technological facilities and structures, as a feature of their everyday lives. A now substantial literature, focusing on a variety of hazards in particular local contexts, has attempted to answer this question, examining how individuals and groups within society make sense of and cope with risk. Related work has emerged in several disciplinary fields, ranging from cognitive psychology to social anthropology, but each beginning from very different theoretical and epistemological assumptions. 1 This paper is concerned with one specific strand of research that applies what Lupton (1999a) describes as a sociocultural perspective -one centring on the everyday social worlds and contexts through which risks are experienced and negotiated -to the study of situated technological hazards. In particular, we focus on studies relating to industrial and nuclear facilities, examples where an established body of sociocultural work exists. Influenced initially by the social anthropology of Douglas (1966) , this body of work has developed to address a wide range of cultural processes or factors that influence risk perceptions and responses, all sharing the view that cultural assumptions across social groups are critical to understanding risk and, importantly, how we deal with it (Taylor-Gooby and Zinn, 2006; Lash et al., 1996; Lupton, 1999a,b; Beck, 1992; Pidgeon et al., 1992; Petts et al., 2001) . Several commentators have, however, suggested that an analytical lens that sees people's experience of risk as shaped by general cultural dispositions may direct attention away from specific, often local cultures and understandings which inform risk responses (Lupton, 1999a; Wynne, 1996; Baxter and Greenlaw, 2005) . In response both to the methodological assumptions of cognitive approaches and to the social generalisations of deductive theoretical approaches such as Douglas's, as well as to the deficit model of public (mis)understanding of risk issues that has informed much official thinking, there has been a burgeoning of work on chronic and acute technological hazards as they affect, both materially and socially, specific communities (e.g. Irwin Wynne, 1996; Couch and Kroll-Smith, 1991; Edelstein, 2003; Freudenburg, 1997) . In broad terms these studies view risk as, at least partly, a cultural construct that is rooted in everyday experience and assessed by reference to that experience (Wakefield et al., 2001) . One feature of this body of research is that, as a consequence of its community focus, it situates everyday experience of such technological hazards in specific places in a way that is informed by implicit -and sometimes explicit -constructions of space. For example, Fitchen et al. (1987) explore the significance of community experience of chemical contamination for symbolic constructions of home, while Walker et al. (1998, p. 13) , in their account of the perceptions of communities living with major industrial accident hazards, draw upon Agnew's (1993) model of place as being constituted of locale, locality and sense of place. Embedded in many of these accounts, then, is a relationship between the physical proximity of a hazard and the experience of risk, and it is the nature of this relationship that, in this paper, we want to interrogate and reconceptualise. One important step towards doing so is to move from thinking of risk as something that is simply experienced by individuals and communities in specific spatial relations with a potential hazard and to follow a more recent development in sociocultural work on risk by viewing this relationship in terms of the production and reproduction of risk subjectivities (Lupton, 1999a; also Tulloch and Lupton, 2003; Beck, 1992) . This work displays a concern with the multiple ways in which people construct risk in relation to the diverse social, institutional and spatial contexts of their everyday lives.@story_separate@We can begin our argument from a number of empirical observations about the relationship between hazard proximity and risk perception. On the one hand, many researchers have documented the tendency for local populations to express concern about and resist the siting of potentially hazardous industry or other pollution sources in their communities (Boholm and Löfstedt, 2004; Lesbirel and Shaw, 2005) , while people living further away often express less concern. This has in the past been explained in terms of a so-called NIMBY response, in which people reject facility siting for narrowly self-interested reasons. Latterly this notion has been subjected to critical scrutiny and the social, cultural and structural bases for the response taken more seriously -highlighting issues of trust, a lack of personal or collective agency and inequities in decision-making processes (e.g. Kemp, 1990; Burningham, 2000; Wolsink, 2006) . Indeed a number of sociocultural studies have highlighted the role of wider social relations of (dis)trust and powerlessness in accounting for (local) constructions of risk (Walker et al., 1998; Petts et al., 2001; Moffatt et al., 1999; Baxter and Greenlaw, 2005; Bickerstaff, 2004) . On the other hand, in an apparent inversion of this relationship, other research has found that populations living around established facilities often express less concern than people living further away (Baxter and Lee, 2004; Burningham and Thrush, 2004; Wakefield and Elliott, 2000) . Although conflicts over siting have tended to receive more attention, this latter situation is equally important for what it can tell us about the facets of 'distance' that affect the apparent social acceptance of risk. For instance, Zonabend's study of the nuclear reprocessing plant at La Hague, France was motivated by the apparent indifference of the local community to the presence of the plant: ''what struck me as remarkable and indeed as crying out for an explanation was the fact that people there refuse to believe in the reality of this colossal technological risk"" (1993, p. 122) . Several explanations have been offered to account for the phenomenon of localised acceptance. Many within industry point to familiarity and knowledge as a reason for accep-tance of the presence of hazardous facilities (Walker et al., 1998, cf. Baxter and Lee, 2004) . 2 Linked to this is an explicitly economic reading of risk which views muted local concern about industrial hazards as premised on a rational cost-benefit trade-off (see Lee, 2004, also Dunlap et al., 1993) . A number of studies (Bickerstaff, 2004; Moffatt et al., 1999; Wakefield et al., 2001; Baxter and Lee, 2004) refer to reluctance on the part of residents to connect risks such as industrial air pollution with the local area (and sense of place), choosing instead to distance the problem geographically and socially. It has been argued that the apparent lack of concern to be found in such communities may mask anxieties that are not openly expressed for a variety of social, cultural, economic or political reasons (e.g. Giddens, 1991; Wakefield and Elliott, 2000; Wynne et al., 1993; Zonabend, 1993; Solecki, 1996; Simmons and Walker, 1999; Burningham and Thrush, 2004; Bush et al., 2001; Phillimore and Bell, 2005) . Whereas a lack of expressed complaint or opposition is often construed by risk managers as acceptance of the presence of a hazardous installation or activity, such 'silence' has for example been interpreted by a number of researchers as being a sociocultural response born of powerlessness and political-economic dependency, defending the subject's sense of ontological security and protecting them from unmanageable anxiety (Hollway and Jefferson, 1997; Wynne et al., 1993 ; see also Giddens, 1991) . Although the accounts reviewed above often recognise the role of different spatial practices in everyday engagements with risk, these practices have not been brought to the fore in the research literature and their significance developed in a conceptually integrated way as a contribution to theorising the production of the subjectivities through which risk is experienced and lived. It is important to state here that we view risk experience as dynamic and fluctuating -a position that challenges a view of risk perceptions and concerns as relatively stable and fixed positions or categories. We seek to engage more directly with what authors such as Lash (1994) and Wynne (1996) refer to as the aesthetic, affective and hermeneutic dimensions of risk phenomena -in particular the role of unarticulated assumptions, moral values and practices in people's response to risk (Lash, 1994 (Lash, , 2000 . Lash (2000, p. 47) refers to the indeterminate and non-institutional constitution of risk cultures (which he distinguishes from the more normative and institutional or rule-bound ordering implied by risk societies). For Lash risk cultures are defined by aesthetic rather than cognitive reflexivity -estimations and judgements based on feelings, which take place not through orderly cognitive understanding, but through disorderly practices of imagination and sensation (Lash, 2000, p. 53) . It is here that we turn to alternative metaphors and ways of thinking about space and proximity and by extension of conceptualising risk subjectivities. Work by a range of authors (including Cooper, 1993; Mol and Law, 1994; Hinchliffe, 1996; Massey, 1993; Mort and Michael, 1998; Edensor, 2005a,b; Hetherington, 1997 Hetherington, , 2004 November, 2004) argues for a more topological reading of proximity, one that views time and space (or, rather, times and spaces) as contingent, open and as the effects of manifold possibilities of connection between the near and the far, the central metaphor for which is that of the 'fold' (Deleuze, 1993) . From this perspective places can be seen as the effect of the folding of spaces, times, things, people and events (Hetherington, 1997, p. 197) through the arrangement and synthesis of diverse representations, artefacts, identities, language, memories, sensations and emotions (Doel, 1996; Massey, 1993) . It is a set of ideas that we believe offer considerable potential for re-examining existing literature on the 'local' experience of risk and through this rethinking how we ap-proach, methodologically and conceptually, the geography of risk subjectivity. We are therefore concerned less with proximity as defined by objective measures of nearness or distance and more with understanding proximity as practice -that is, how things are made present and, in some situations, made absent. These practices of what we shall call absencing and presencing of risk in everyday life form the main focus of this paper -ideas to which we shall now turn. Our goal in this paper is to present an alternative conceptualisation of spatialised risk subjectivities, as constituted through (primarily discursive) practices which fold together different times and spaces to bring risk close or keep it distant. It is important here to clarify our interpretation of practices as performative; that is, as the lived, routinised mental and bodily activities (encompassing skills and know-how, meaning and emotions) which create spaces, times, places and landscapes (Thrift, 1999; Cloke and Jones, 2001; Latham, 2003) . The approach to social practices that we adopt here recognises the significance of what we shall term, following Zonabend (1993) , imaginative practices: the everyday routines, turns of phrase, associations, habits and ways of doing things through which people make sense of and order the world around them and, in the process, making risks experientially and emotionally close (present) or distant (absent). Zonabend has stressed the performative function of linguistic practices and the need to attend to the ways in which oral expression -with its digressions, censorship, intonations, and metaphors -can expose other (defensive) strategies. These imaginative practices, we suggest, disclose the meanings and ideas that flow into/out of places (see also Cloke and Jones, 2001; Adam, 1998; Lupton, 1999a; Burgess and Harrison, 1993) and have the effect of stitching together and (re)organising -socially and spatially -diverse forms of experience (cf. Edensor, 2005b; Gregson et al., 2007; Latham, 2003; Rabinow, 1986) . It follows that if we recognise practices and representations as constitutive of everyday life, we need also to sketch out what this more topological ordering of experience -which folds together objectively 'distant' places and times -might look like. Here we interpret 'presence' as the extent to which a source of risk is experientially salient. Our point is that the immediacy of risk is not an intrinsic property of or physical expression of proximity but will vary across spatio-temporal contexts in which the hazard is more or less 'present' to individuals or groups (Harrison et al., 1996; Hinchliffe, 1997) . Work by Petts et al. (2001) , for instance, focused on the role of the media in amplifying -and possibly attenuating -lay public risk responses (cf. Kasperson and Kasperson, 1996) . This study, which addressed a number of 'situated' risks, specifically demonstrated how in the process of making sense of risk people made links between a range of media arguments and direct local knowledge and experience. November (2004, p. 283) , in an analysis of the practices performed amongst different parties involved in identifying and managing the risk of fire in Geneva, similarly argues that to understand the links between space and risk we need to think in terms of relations of 'connexity' rather than proximity; that is, to attend to the links between the various elements of risk networks, beyond the physical distance that separates them. Two brief examples usefully capture the approach we are seeking to develop. First, in a study of accounts of the risks associated with living close to potential sources of pollution, Burningham and Thrush (2004) found that a local chemical plant in Wales was initially talked about by residents in the context of a strong sense of local community -based on a historical relationship be-tween the place, social networks and industry. In this case local people focused on a representation of the site in terms of a longestablished collective identity and the potential association with risk was seemingly kept absent. Indeed, when ''the issue of pollution from the factory was raised participants developed a range of social explanations [for instance changing attitudes or the increased sophistication of pollution monitoring technology] to challenge the idea that conditions had worsened"" (p. 221; and cf. Simmons (2003) on the way that changes in social context may weaken such collective representations and lead to risk reasserting itself). The second example is taken from ethnographic research in the town of Ludwigshafen, a chemical industry town in south-west Germany. In a recent account of this work Phillimore (2007) observes the ways in which the past is habitually recalled and imagined to affirm present day safety. For instance, Phillimore notes a comment from one retired employee of the local chemical plant who recalled the bright colours of industrial discharges entering the Rhine in the 1950s, a sight no longer witnessed, as evidence that gross environmental pollution was a thing of the past and, by implication, that the industry's presence was no longer a problem. It is a remark and observation which captures precisely the sorts of reflexive movements from past to present (or from far to near) that form the focus of this paper. Such findings indicate that the apparent 'acceptance' displayed by local people is constituted by a complex set of practices that absence/presence different space-time connections to place, the hazardous site and to risk (to which we return below). We can also find support for a more topological conception of risk in the work of Risk Society theorists -advancing alternative ways of theorising the presence and absence of risk, although remaining largely removed from empirical engagement or support (for an exception see Hinchliffe, 1997) . The central argument of authors like Beck and Giddens is that increasingly we are being confronted with the phenomenon of 'modernisation risks'; socially produced threats to human life that cannot effectively be delimited spatially, temporally or socially. What we see in the writings of both authors then is the identification of emergent risks that are effectively 'glocal' -both local and global (also Lupton, 1999a) . Giddens (1991) , in particular, talks of the disembedding forces that make individuals confront and deal with mediated interaction on an equal basis to more conventional face-to-face encounters. His theory of time-space distanciation is concerned with how the absent Other interacts with the present locale (1991) . In other words, what structures the locale and local experience is not simply that which is present (in space and time) but also distanciated relations concealed by the 'visible form' of the local (Giddens, 1991, pp. 18-19; also Lupton, 1999a; Adam, 1998; Hinchliffe, 1996) . Callon and Law (2004) , in arguing that geographical propinquity cannot be separated from that which we would normally call absence (recollection of a past event, sensation or emotion, the drawing of analogies and so forth), speak to precisely this folding of experience that brings distant places, people and objects unexpectedly into contact or co-presence. Shields (1992) has, similarly, explored how the figure of 'the stranger' ruptures the (physical and social) boundaries between proximity and distance. Crucially, Shields points to the need to acknowledge the presence of the remote: ''The stranger figuratively represents what is absent, far-off and foreign [. . .] the doubtful existence and dubious threat of what is not spatially present, of what cannot be verified at first hand. Yet the stranger is nevertheless 'here', present, and thus throws the doubtful and flickering quality of absence and non-existence back into the faces of those insiders in the local community, throwing into question the sanctity of presence"" (Shields, 1992, p. 189) . Edensor (2005a, p. 836) captures this sense of experiential flickering in his description of the sensual involuntary memories of presence and absence born of the 'ghosts' which haunt industrial ruins; a spatialising of memory that is characterised by the erratic and sudden presencing of the absent. This is a mental space where ''the sudden force of the remembered but inexplicable [...] rockets the past into the present"" and as such challenges ordered forms of collective memory and the orderly location of experience in a particular place or time. This idea of 'haunting' captures the many ways in which temporally or spatially distant entities can return as a lingering presence -through emotional and sensual resonances (Edensor, 2005a; Gordon, 1997; Thrift, 1999) . Our proposition here is that people's relationships to particular risky technologies are more open and transitory than references to 'fear', 'dread', 'anxiety' or 'concern' would imply (cf. Bondi, 2005) . In this way, we believe that focusing on practices of absencing/ presencing presents a productive (and challenging) tool for exploring the complex, contradictory and often fleeting nature of feelings that constitute experience. Rather than offering an explanatory framework, we foreground the mundane and routine ways in which hazardous facilities move in/out of proximity as part of everyday life. On this basis we highlight a number of directions for further work that extends our preliminary (and retrospective) analysis: that build more robust (if also messier) accounts of how and why risk is experienced as it is. Just as potentially hazardous technologies are not always and for everyone inherently threatening, so people are not always and in every context aware of a physically present technology in the same way. The technology and its risks may move in and out of personal and social awareness, 'flickering' between absence and presence (or between meanings -at one moment familiar and benign, providing needed materials or services or supporting the life of the community, at another alien, intrusive, threatening). In Macgill's study of the health controversy that focused on the Sellafield nuclear facility, and of the language of risk employed by members of local communities in West Cumbria, we see evidence of this flickering between absence and presence, between a sense of security and one of danger. An appendix to the book contains numerous quotations that show present experience to be continuously mediated by distant events -such as the 1983 radioactive discharge incident which contaminated local beaches: ''Didn't really used to think about it as much until the leakage, since then I've started to wonder about it"" (quoted in Macgill, 1987, p. 192) or events much further back in the past, in particular the 1957 Windscale reactor fire. Thus whilst such comments appear rooted in specific local contexts, we argue that they disclose temporary movements between the present and a recalled event which had on some level threatened a sense of ontological security. Such spatial and temporal foldings are crucial to the subjective experience of risk and, we suggest, warrant fuller engagement and development in the theoretical treatment of risk and place. This theme of conjoined absence and presence is central to Hetherington's (2004) conceptualisation of disposal, or what we might term here processes of absencing. He argues that absence is never fully eliminated, as implied by the notion of rubbish, retaining as it does a capacity for transformation into a presence. ''When we dispose of something to hand -a material form of some kind -we do not necessarily get rid of its semiotic presence and the effects that are generated around that"" (Hetherington, 2004, p. 159 ). Hetherington raises important questions about how we order or place absences as we do, about the role of the absent or absencing in managing social relations, and specifically about what happens when the management of absence doesn't work effectively. Crucially, where absencing is unfinished or unmanaged, Hetherington suggests, objects, entities, events or emotions can return as a 'ghostly' presence, their power to affect expressed in the idea of 'haunting ' (cf. Gordon, 1997) . In the following section we address precisely this issue of the haunting capacities of absence followed by a more speculative exploration of the affective potential of presence -two aspects of the spacing/timing of risk that have not been substantively developed in the literature and which we believe offer considerable scope to invigorate our approaches to understanding the geography of risk experience. As already noted, a growing body of research across a wide range of technological hazard contexts has found that those who might be expected, on the basis of their physical proximity to major technological hazards, to experience adverse psychosocial effects as a result of their exposure often do not express concern (Moffatt et al., 1999; Wakefield and McMullan, 2005; Burningham and Thrush, 2004; Wynne et al., 1993; Wakefield and Elliott, 2000) . Research on the everyday experience of living near to nuclear facilities -in particular the Sellafield complex in the UK (Macgill, 1987; Wynne et al., 1993) and plants in Western France (Zonabend, 1993; Boceno, 1997 ) -builds up a picture of the practical work that goes into keeping at bay or absencing risks. The collective findings of this literature point to habitual silences which, it is argued, conceal an all too active ignorance or shutting out of the technological risk. The following extracts from Macgill (1987) and Boceno (1997) do, however, capture individual reflections on these practices of absencing -both as an implicit sociocultural response to relations of political-economic dependency and as a conscious attempt to silence external reminders of risk (in the form of media reports). I am surprised how many women are worried but don't admit it because their husbands are employed there (quoted in Macgill, 1987, p. 184) In North-Cotentin, a young woman affirms that she only reads the newspaper hesitatingly because she dreads seeing an article with accompanying pictures about the Flamanville plant or the La Hague nuclear reprocessing plant. She does not read the local newspaper or watch the regional news on television because there, she would be more likely to be faced with the tragedy. She has behaved this way since the explosion of the Ukrainian plant (Boceno, 1997, para 21). 3 Developing this picture of the active silencing of risk, Zonabend comments on the ways in which people avoided naming the La Hague reprocessing plant at all -referring instead to 'up there', 'the thing' or 'it' -a discursive practice which is linked to a desire to place the technological object at a certain social distance (1993, p. 28). Zonabend (1993, p. 29 ) also notes the ways in which local residents actively try not to see the plant -''You can't see the plant from my place. . . So we're all right"" -which in some situations requires a rearranging (absencing and presencing) of the surrounding landscape. The author argues that what is clearly identifiable in communities like La Hague is a refusal to acknowledge (and see) the architectural embodiment of risk, a form of 'active blindness' which amounts to a denial of danger. The author also notes people's feelings of impotence in the face of risk, a situation in which the only realistic stance is one of silence. The following focus group extract 3 On the basis of this single quotation the avoidance of local newspaper coverage might be construed as the coping strategy of one particularly anxious individual. However, Wiegman et al. (1991) report the same practice among residents living close to a hazardous chemical industry site, although they interpret the motivation as being the rejection of biased media reporting of events at the plant or in the industry. from Wynne et al.'s (1993) study in the UK captures a similar defensive response to the encroachment of risk into everyday life. The risk is metaphorically too close for the individual to think about. It's like, putting your head in the sand but erm. . . it's too near home for me, I think, it's just too near home to even. . . I think you'd do your head in because we have to live here and. . . this is my way of handling it, it just, [I] don't tend to think about it (quoted in Wynne et al., 1993, p. 43) These comments are indicative of routinized forms of (dis)engagement with risk -but risks that nonetheless retain a lingering (if fleeting) presence and a capacity to return. We see precisely these themes of haunting and return in the findings of other local studies of risk experience, which hint at the potential for exploring the ghostly remains and reminders of past presences -both places and times -which mediate personal and collective relations with risk. Research focused on those places that surround nuclear installations reveals a series of imaginative practices (or performances) which serve the common purpose of trying to forget a habitual (and haunting) fear bound to this 'colossal technological risk' (Zonabend, 1993) : a social, material and fundamentally embodied threat that can never be entirely escaped or absenced (cf. Simmons, 2003 on performing 'safety'). Boceno (1997) uses the example of an employee of COGEMA (the French Government-owned nuclear group), whose wife died from cancer. While continuing to work at the plant the man cannot help but wonder about having contaminated his spouse with radioactive dust that he might have brought home from the factory on his clothing and on his hands. In this way the past viscerally haunts the present. Other work similarly points to the haunting bodily reminders of risk (experienced or anticipated) which leave their imprint at the level of personal and collective experience. A typical comment from Macgill's work illustrates this folding of past and present day bodily sensations (of ill/health) -as one woman commented: ''everytime I have an ache, the place comes to mind"" (quoted in Macgill, 1987, p. 185) . Zonabend (1993, p. 119) notes the remark of one wife whose husband left the La Hague plant some years earlier: ''it haunts me even now! He took some big doses. . . and cancers can take years to show. . . So it's still on my mind!"" Following Mort and Michael (1998) , the plant, the radionuclides -and thus risk associated with a working life some time in the past -retained an ongoing presence. Whilst temporally distant from the couple's present lives, the folding of past into present through imaginative and corporeal practices, produced an all too real and close sense of danger. Related work highlights how past events and local judgements (for instance, of an industrial company) persist in collective local memory -and impinge on everyday life and sense-making practices -long after the events that occasioned them. Research focused on a community in Jarrow in the northeast of England living close to a chemical plant highlights the complex, yet also binding, social and cultural qualities of place (Irwin et al., 1999) . Importantly, the authors comment that whilst the plant was viewed by safety regulators as a 'quiet site' with no recent accidents local people placed risk in a very different way, drawing together a complex set of social relations, practices and memories which stretched away from the plant in both space and time. These accounts revealed ''noisy silences and seething absences"" (Gordon, 1997, p. 206 ) -with the past literally pulled into the present in order to imagine and make sense of risk (Hamer, 1994) . These absent places and events continued to shape subjective experience of this outwardly quiet site. They embraced, for instance, major accidents in other localities which had been experienced vicariously through the media -such as Chernobyl or Bhopal. The following remark, taken from Macgill's study, highlights the folding together of distant places in order to make sense of the present 'nuclear' reality: ''This [the Sellafield discharges] can be seen much the same as the Indian incident [Bhopal] , except this is slower"" (quoted in Macgill, 1987, p. 182) . Chernobyl, in particular, furnished a language and conceptual space for localising industrial disaster (see also Zonabend, 1993; Boholm, 1998; Walker et al., 1998) . As already noted above, one young woman's active avoidance of the local news media in order to absence the possible local risks was directly linked to the legacy of Chernobyl (Boceno, 1997) . This underlines the constitutive role of the Chernobyl accident as a distant place (and an unmanaged absence) that is folded into present-day risk subjectivities, in relation not only to nuclear but also at times to non-nuclear hazards. In this way the presencing of these faraway places (Hinchliffe, 1997, p. 203 ) lent immediacy to conjectures about the often unknown (or even unknowable) hazards to which local people were exposed. It is a form of reasoning in the face of enigmatic blankness, so that in the absence of substance some individuals constructed their own (cf. Irwin et al., 1999) . Research also points to the ways in which imaginative practices that link to absent places evoke feelings of loss, neglect and decline -haunting capacities which can impinge on and complicate the experience of risk. For instance, some of the most intriguing issues developed by the Jarrow study (Irwin et al., 1999) centre on the performance of collective memory and the multi-faceted nature of risk discussed in relation to wider feelings about life in the town. So, against a backdrop of the decline of heavy industry and widespread redundancy in terms of both mechanical and human labour, the ambivalent relationship to risk was informed by longstanding memories from a previous industrial age based on the heavy industries of chemicals, coal and shipbuilding. It was a presence, now long absent, still woven into the fabric of everyday life in Jarrow that reasserted an association of pollution with economic vitality and well-being, rather than with social or ecological threats. Another example of past and present being folded together is offered in a study of processes of technological innovation and production centring on the decline of the 'core business' of the Vickers Shipbuilding and Engineering Limited firm at Barrow-in-Furness in Cumbria, in which Mort and Michael (1998) show how, having been rendered redundant, both absent workers and technologies continued to 'haunt' the place. Like the heavy industries of Jarrow, these redundant actors retained a lingering presence, in the form of what the authors term 'phantom intermediaries': entities which are physically absent but whose presence is felt (and articulated) through the memories, practices and skills of a range of actors (also Edensor, 2005b) . In ethnographic research in the major chemical and petrochemical centre of Grangemouth (Scotland), at one time a prosperous town that had attracted a large skilled workforce, Phillimore et al. (2007, p. 76 ) pick up on this theme of the sadness and disillusionment (about the present and future) that can haunt industrial places affected by sudden economic changes. The authors note the frequent references of local people to 'safety', 'distrust' and 'dumping ground' which, they suggest, can be read in terms of 'risk' even though that word has not been a staple of local public vocabulary. The sense of decline and of living in a place stigmatised by outsiders expressed by residents, was all the more profound for the haunting presence of what the town had once been. As the Jarrow example shows, the presence of such feelings of stigma and of loss is not only woven into the experience of place but is entangled with the production of risk subjectivities (see also Simmons and Walker, 2004) . In relation to issues of architectural form it is instructive to consider not only how physical structures are actively absenced or si-lenced but also how they are materially and affectively presenced. Work of humanistic geographers has demonstrated a concern with the feelings (hate, fear, pleasure, pride etc.) evoked by specific landscapes (Relph, 1976; Eyles, 1985;  cf. discussion by Bondi, 2005) . Tuan explored the human resonances of fearsome landscapes, referring to feelings not only of disorientation and chaos but also the agency of material (often 'natural') entities to affect and presence particular feelings and emotions; a sense of a personalised evil -''that the hostile force possesses will"" (1980, p. 7). However, whilst Tuan's work on fear associated with cities makes reference to physical form and layout, relatively little consideration is given to the ways in which different technological forms and materialities can stimulate sensations such as fear and awe (cf. Edensor, 2005a ,b on industrial ruins). Affect has attracted much recent attention in the risk literature, primarily amongst social psychologists (Taylor-Gooby and Zinn, 2006) , but, to date, there has been little engagement with an emerging field of geographical research concerned with the affective dimensions of experience -a form of thinking and conduct that is often indirect and firmly shaped by a set of embodied, lived practices (Thrift, 2004; Wylie, 2005; Whatmore, 2002; Dewsbury et al., 2002) . We might then view the markers of a particular technology not only as representing a taken-for-granted socio-technical order(ing) but also as a source of material and symbolic disorder that can present itself not only in a perceptual response but also, crucially, as an affecting sensibility or presence. These discussions of the shifting affective qualities of places and things (for instance Cloke and Jones, 2001; Thrift, 2004 Thrift, , 2005 Wylie, 2005) productively link to the anthropological concept of an 'affecting presence' (Armstrong, 1971 ) -that is, the material embodiment of physical conditions which generate or are constitutive of a particular emotion (cf. Roscoe, 1995) . Importantly, this affective quality is not, we suggest, simply inherent in the object but refers to our capacity both to be affected by a material presence and also to affect how that presence or entity is understood and responded to (Massumi, 2002; Wylie, 2005) . 4 Zonabend's account of community responses to risk in La Hague (1993) touches on the derogatory nickname for the plant -'The Dustbin' -and the fears that the numerous buildings of the La Hague reprocessing plant inspire. Moffatt et al. (1999, p. 85) , in their account of public awareness of air quality in the North-east, make reference, in passing, to the affecting qualities of Teesside's dramatic industrial landscape, quoting from one resident: ''When you stand on Eston Hills. . . and look down and you're seeing ICI and British Steel and it looks like something from Mad Max -post apocalyptic place"" (Moffatt et al., 1999, p. 93) . In contrast, it was the enigmatic lack of visual information offered by the physical structures of their local chemical plant that, for some residents of Jarrow, conjured up sinister associations with the science fiction TV series The X Files (Irwin et al., 1999) . It is not necessarily, therefore, only through what can be seen or through other sensory impressions (Abram, 2004; Simmons and Walker, 2004 ) that technological facilities may insinuate their presence into people's experience but also by the apparent absence of meaningful sensory 'evidence ' (cf. Vyner, 1988 on the destabilising impacts of invisible technological threats for those communities affected). These observations resonate with Edensor's work on the layers of cultural memories that are physically inscribed in industrial spaces, conjured up through smells, textures, soundscapes, as well as visual objects, juxtapositions, and vistas (2005a, p. 837) . Our point, and the corresponding insight gleaned from the literature, is necessarily provisional. We do not offer these practices of pres-encing and absencing as an explanation of variation in risk perceptions; rather our aim here is to draw attention to some of the morethan-rational, often seemingly inconsequential and ephemeral, aspects of everyday life that contribute to risk experience. Features of industrialised landscapes inevitably figure as presences that affect the lives of those living nearby. Whilst intuitively the sociocultural presencing of such infrastructures in terms of risk is more developed in the literature, work has primarily addressed presence (as physical proximity) at a cognitive and sometimes at a behavioural level. The empirical task remains, however, to understand better the constitutive role of presence in everyday life: how and in what ways do technological infrastructures impinge on or affect those living in physical proximity? What facets of these sites and of risk are made salient (and which are not)? And how are material presences and manifest absences infused with other (distant) spaces and times?@story_separate@In the opening section of this paper we have argued that, with a small number of exceptions, work that has investigated and sought to account for the 'local' experience of sited technological hazards is inscribed with spatial ideas or metaphors -as expressed in realist notions of proximity -that embed a Euclidean construction of space, one that constrains our understanding of the relationship between space and risk experience. In contrast, drawing upon recent theoretical work in cultural geography and in sociology, we have explored the potential of a topological approach to space, applying the metaphor of the fold, for understanding the production of risk subjectivities in such contexts. Whilst we acknowledge the constitutive role of immediate social and political-economic settings, relations of trust and power, and of collective memory, we have suggested that most existing accounts of the influence of local context on the experience of such hazards do not highlight sufficiently the ways in which other spaces and times impinge on everyday practice. We have therefore drawn together work that has begun to develop alternative ways of thinking about the spatial organisation of risk (Beck, 1992; Giddens, 1991; Hinchliffe, 1997; November, 2004) . In connecting this literature with concepts in cultural geography we have offered a set of ideas which reconceive relations between place, proximity and risk subjectivities and view experience as constituted by continuous practices of presencing and absencing. In this concluding section we outline a provisional research agenda for extending this work, setting out three lines of future enquiry. We have stressed the importance of studying spatial practices that work (actively or passively) to assemble proximity and distance, and the experience of threat and of security. Our account points to the significance of research that is sensitive to ways of working with risk 'proximity' as an ongoing spatial and temporal achievement. Here, we have highlighted how different imaginative practices have the effect of pushing away physically close hazards, but also how events or presences seemingly managed or absenced by such practices, or simply distant in time and space, can return as haunting reminders of what once was or might yet be, and which in turn therefore continue to mediate experience. Our analysis has, for instance, specifically highlighted the active production of silence as a recurring theme in the existing literature -that is, the apparent absence of anxiety, although often belied by a residual ambivalence towards the source of risk. Our account certainly does not proffer a generic framework to explain such silences but instead questions the premise that we can define, measure and account for risk experience as a stable (social, cultural or psychological) phenomenon. We have therefore sought to elucidate a number of ways in which silence is actively performed 4 Contra the impression of a stable or fixed 'hazard personality' given by psychometric research on the characteristics of technological hazards (e.g. Slovic et al., 1980) . through simultaneous practices of absencing/presencing many facets of risk (Zonabend, 1993; Mort and Michael, 1998) . More sustained attention to these practices of silence would not only furnish insights into the everyday experience of technological hazards but would also expand our spatial conceptions of the constitution of risk subjectivities. Indeed, we suggest that, from an analytical perspective, existing explanatory frameworks might usefully be extended and developed through an engagement with the ideas about the spatial practice of proximity we have outlined here. Research might, for instance, explore the ways in which contrasting risk configurations (in terms of spatial, temporal, politicaleconomic or material features) elicit different patternings of subjective proximity (i.e. practices of absencing and presencing). Such work might well provide more nuanced insights into how issues of trust relations, peripherality and dependency, place and identity impinge on the everyday experience of risk. Indeed, as discussed already, much research fails to directly acknowledge the role or implications of spatial practices or the contingency and even contradiction associated with them. In light of such transitory and fluid qualities, we therefore stress the need for further research directed less towards developing fixed categories, measures and typologies and more towards opening up this enlarged concept of risk proximity. Second, approaching the topic of risk experience from the perspective of materiality, we have argued that further research into everyday encounters with risky technologies should take account of the bodily presencing and absencing of risk as well as the affective presences and absences associated with material things. Our reflections on this topic have focused specifically on the ways in which people (and groups) invest structural features with particular meanings and ideas and how the material presence itselfform, shape, texture, including relative normality or invisibilitymay affect people and their sense of place, whether in positive or negative ways. In this regard further research is needed to better understand how collective and sometimes conflicting ideas, values, and emotions become bound up with these physical structures. We might also point to the potential for extending analyses beyond fixed material infrastructures, to include more mobile physical or symbolic absences and presences. To take the case of the UK 2001 foot and mouth (FMD) epidemic, we might, for instance, think of the affective potentialities of empty fields (and the absent livestock) or the scenes of animal culling and pyres (and the all too present deadstock). It is only from this position, we suggest, that research can move beyond the constraints to understanding and accounting for risk subjectivity imposed by a singular conception of experience (as fear, concern, anxiety etc.) and of physical proximity. Finally, and following on from this, our account has concerned itself with the experiential presencing and absencing of risks linked with site-based hazardous facilities or infrastructures. Here, then, we see scope for extending the analysis of imaginative practices to risks that have more fluid and open spatialities. 5 The spatial processes associated with risks such as the UK FMD epidemic, unprecedented flooding in the UK and elsewhere over recent years and the global outbreak of the respiratory illness Sars (Severe Acute Respiratory Syndrome) are best described as spaces of flow (Law, 2006; Appadurai, 1990 ) -that is they are characterised by a series of interactions between physically disjointed positions. To return to the case of FMD, the rapid spread of the disease through livestock, and controversy over the cause(s) of infection, literally and materially folded distant places together. In experiential terms, memory (the recall of previous crises and risk events, the 1967 outbreak in particular), the sensory and affective impacts of risk management practices such as the burning of culled animals on open pyres, as well as the invisible spread of the disease, which evoked an array of imaginative spaces (Nerlich et al., 2001) , bear witness to the significance of distant space-times in presencing/absencing risk. We suggest that these spatially diffuse events pose pertinent questions about the spatial constitution and performance of risk subjectivities. These conclusions, but in particular this latter set of issues, have implications for the methods we utilise to engage with everyday riskscapes. Law and Urry (2004) argue that the social sciences need to re-imagine their methods if they are to work productively with 21st Century realities of increasingly complex, elusive, ephemeral and unpredictable social relations. Here we recognise that our analysis has centred largely on linguistic and representational practices. Whilst such material does offer access to crucial aspects of risk subjectivity it does not and cannot stand in for the subtleties of routine knowledges and the active practices of embodiment that constitute experience (Latham, 2003; Longhurst, 1997; McCormack, 2003) . Methodological experimentation and pluralism is important to supplement the sorts of accounts we have drawn on here -and to capture the fleeting (here today and gone tomorrow, only to reappear the day after tomorrow), distributed (that which slips and slides between places) multiple, sensory and emotional (Law and Urry, 2004) manifestations of risk experience. Here we recognise the difficulties and challenges that come with more mobile ways of studying the 'ordinary', ways that are sensitive to the complex, non-causal and chaotic and which seek to acknowledge and embrace the slipperiness of units like risk, anxiety and proximity. Following Latham (2003) , Bondi (2005) and others we see the potential for multi-faceted approaches which embody 'a performative ethos' (Latham, 2003) , and that can, at least in part, access the transient and ineffable ways in which everyday life and place are constituted. These disparate fragments and juxtapositions of experience will not necessarily add up to a regular whole or an eloquent explanatory narrative -but they will enable us to unpack the sorts of analytical ambiguities discussed in the opening sections of this paper. The topologically-informed understanding of spatial practice, and of absence and presence, proposed here can therefore extend sociocultural approaches to the everyday experience of hazardous technologies, and more broadly hazardous events, by replacing fixed notions of locale and proximity that contribute to misplaced readings of risk subjectivities.","There is now a substantial body of sociocultural research that has investigated the ways in which specific communities living in physical proximity with a variety of polluting or hazardous technological installations experience and respond to their exposure to the associated risk. Much of this research has sought to understand the apparent acceptance or acquiescence displayed by local populations towards established hazards of the kind that are typically resisted when the subject of siting proposals. However, recent theoretical contributions, produced largely outside the field of risk research, have problematised the objective distinction between proximity and distance. In this paper we explore the potential of some of these ideas for furthering our understanding of the relationship between place and the constitution of risk subjectivities. To do this we re-examine a number of existing sociocultural studies that are predicated on a localised approach and conceptualise the relationship of physically proximate sources of risk to everyday experience in terms of practices of ‘presencing’ and ‘absencing’. We conclude with some thoughts on the methodological and substantive implications of this reworking of proximity for future research into risk subjectivities."
"The novel coronavirus SARS-CoV-2 ( Figure 1a ) emerged in December 2019 as a human pathogen 5 that causes the COVID-19 disease outbreak that rapidly spread worldwide 6 . This virus belongs to the family of Coronaviridae and it is the third documented spillover of an animal coronavirus to humans in only two decades that has resulted in a major epidemic 5 . Coronaviruses are enveloped, single-stranded RNA viruses, with the typical structure shown in Figure 1b . The virus envelope contains lipids and several proteins. These are the socalled envelope (E) and membrane (M) proteins, which play essential roles during virion assembly 7 and the spike glycoprotein (S) which is responsible for the interaction of a coronavirus particle with a host cell receptor (the ACE2 human receptor, in the case of SARS-CoV-2 8 ). The large protruding glycoprotein spikes on the envelope of coronaviruses give a characteristic appearance to this virus family, and give them their name (from ""corona"", which is Latin for ""crown""). In an unprecedented effort, the scientific community has been able to rapidly identify not only the nature of the pathogen causing the COVID-19 disease but also most details of its molecular structure with atomistic resolution. For example the identification and full characterization of the virus 9 was available in February 2020 and the atomistic structure of the spike glycoprotein, shown in Figures 1c,d, was published 3 as early as in March 2020. At the time of writing, the Protein Data Bank 10 hosts about ∼ 300 structures related to the SARS-CoV-2 virus. a) Electronic mail: jfaraudo@icmab.es This wealth of experimental data has been also augmented with structures obtained from modelling techniques and molecular dynamics (MD) trajectories. For example, in recent works 11, 12 the authors employ modelling software to include in the structure of the virus spike features that are not resolved experimentally (for example, the transmembrane domain) and they use these structures to develop molecular dynamics simulations. Also, the MD trajectories reveal interesting dynamical features 12 . Other theoretical studies consider aspects with direct biomedical implications: investigations of the molecular mechanisms related to the virus infection such as the binding of the virus spike with human receptors [13] [14] [15] , identification of targets for vaccine development 16 and molecular studies related to drug development [17] [18] [19] . The exceptionally of the situation also lead to most of the computational groups working in this question to share the structures generated by their models and even full molecular dynamics trajectories, which are being deposited in public repositories such as the COVID-19 Molecular Structure and Therapeutics Hub 20 . Our aim in this work is to contribute to these computational efforts by considering an important aspect not previously considered in simulation studies, namely the question of the interaction of the SARS-CoV-2 virus with surfaces of materials. There is substantial evidence that surfaces of materials contaminated by viruses (called fomites in the medical nomenclature) play an important role in human-to-human transmission of many respiratory diseases of viral origin [21] [22] [23] [24] , including the particular case of SARS-CoV-2 25 . Many respiratory viruses are believed to spread from infected people through infected secretions such as saliva or their respiratory droplets, which are expelled when an infected person coughs, sneezes, talks or sings 26 . These respiratory droplets from infected individuals can land on objects, creating fomites (contaminated surfaces) 25 . A recent review of experimental and observational evidence indicates that coronaviruses deposited onto surfaces are able to remain infectious from 2 hours up to 9 days 24 , depending on the surface material and thermodynamic conditions such as humidity and temperature. In the case of SARS-CoV-1 and SARS-CoV-2, evi-FIG. 1. (a) Electron microscopy image of a typical SARS-CoV-2 coronavirus particle, freely distributed by the NIAID's Rocky Mountain Laboratories (NIAID-RML) 1 , colored to emphasize the virus structure. The spikes protruding from the virus envelope (in yellow color) are clearly visible. Typical diameter ranges from 80 nm to 120 nm. (b) General scheme of a coronavirus indicating their main structural features. We show the nucleocapsid (purple) that packages the viral RNA and the viral envelope. The major ingredients of the envelope are lipids (pink), envelope protein E (in blue), membrane protein M (in red) and the protruding spike glycoproteins (in green). The scheme was made by the authors using CellPAINT 2 . (c) and (d) Snapshots of the atomistic structure of the SARS-CoV-2 trimeric glycoprotein spike available at the Protein Data Bank (PDB:6VSB). The scale corresponds to 1 nm. In (c) the protein is shown in cartoon representation with different colors for each monomer (grey, orange and red). The spike glycosylation is shown in yellow using Van der Waals representation. In (d) the structure of one of the monomers is emphasized. It has a membrane-fusion subunit S2 (in red) and a receptor-binding subunit S1 which has two independent domains (the receptor-binding domain RBD shown in green and the N-terminal domain NTD shown in blue). In this snapshot, the spike was in the prefusion conformation and the RBD shown in green was in its receptor-accessible state (the so-called ""up"" conformation) 3 . The snapshots were created using VMD 4 . dences from different groups 25 indicate that viable virus could be detected up to 4 hours on copper, up to 24 hours on cardboard and up to 2-3 days on plastic and stainless steel. This persistence of viable virus onto surfaces is the reason for recommendations of health authorities worldwide on continually disinfecting and cleaning surfaces that are frequently touched. At the present time, there is a lack of fundamental understanding of interactions between coronavirus and surfaces at the physico-chemical level. We think that such a fundamental knowledge could be very useful in the design and interpretation of experiments involving coronavirus on surfaces and even contribute in the future to the rational design of disinfection measures. In the case of coronavirus, it seems clear that the presence of the spike coverage in the virus envelope will play an important role in the virus-surface interaction. The spike is not only the most external feature of a coronavirus (see Figure 1 ) but also a protein which has the ability to interact with other molecules as its main function. Given the fact that the molec-ular structure and atomistic coordinates of the SARS-CoV-2 virus spike are known 3 , a timely question is to consider the interaction between the spike and surfaces of materials. Starting from the available structure, we perform here atomistic Molecular Dynamics simulations of the SARS-CoV-2 virus spike and surfaces of materials in presence of hydration. Concerning the materials to be studied, we remark here that previous experimental studies indicated that in general the hydrophobic or hydrophilic nature of the surface plays an important role in the virus-surface interaction 27, 28 . Therefore, we will consider here two materials with very different hydrophobic/hydrophilic character: cellulose and graphite. Cellulose is a material which is simultaneously hydrophilic and lipophilic since due to its molecular structure 29 both hydrogen bonding and the hydrophobic effect play an essential role. In the case of graphite, its surface is strongly lipophilic and mildly hydrophilic 30 , unable to pursue hydrogen bonds and prone to strong hydrophobic interactions. Both materials are widely employed in adsorbents and filters. Figure 1c with its secondary structure with different colors for each monomer of the trimeric protein (red, grey and orange) and the glycosylation in yellow. The solvation sphere is also indicated (transparent blue). b) Detail (side view) of the cellulose surface. Buried -OH groups involved in cellulose-cellulose hydrogen bonds are indicated. c) Initial configuration for the simulationa of hydrated SARS-CoV-2 spike glycoprotein on graphite surface. Color representation is the same as in a). d) Detail (side view) of the graphite surface. Up to the best of our knowledge, this is the first study involving the interaction of the SARS-CoV-2 virus external elements with materials. The results may be also relevant for other coronavirus, since all of them share very similar spike glycoproteins.@story_separate@We have performed all-atomic Molecular Dynamics (MD) simulations of a solvated glycoprotein spike near a cellulose and a graphite surface, as shown in Figure 2 . As seen in this figure, we have considered the spike inserted inside a large pre-equilibrated water droplet (∼ 6 × 10 4 water molecules). The reason for the inclusion of water in the simulation is that it is known that envelope virus (such as SARS-CoV-2) are transferred to surfaces in hydrated conditions (as discussed in the Introduction) and it is also known that the virus needs to be solvated in order to remain viable. The droplet also contains Na + counterions, neutralizing the charge (-23e) of the spike (both surfaces are neutral). Full technical details of the models employed and the protocols of the simulations are given in section IV Methods. The process of spike adsorption onto both surfaces is shown in the video provided in the supporting information (SI) and it is illustrated by the snapshots shown in Figure 3 . Additional snapshots, showing in more detail the time evolution of the adsorption process during the simula- tions are provided in the SI. The time evolution of the different quantities characterizing the adsorption process is shown in Figure 4 . The simulation results can be briefly summarized as follows. Initially, the spike adsorbs to both surfaces in a similar way (Figure 3 ), through contact of the receptor binding subunits of the spike with the surface. In the case of cellulose, this configuration is stable and the spike remains essentially in this configuration during all the simulation. In the case of adsorption onto graphite, the initial adsorption configuration is not stable and the surface induces a substantial deformation of the glycoprotein spike. In order to discuss the results in more detail, it is useful to divide the adsorption process into two different stages, an initial stage corresponding to the contact of the spike with the surface and a final stage reached after structural changes of the spike over the surface.  Full contact between the glycoprotein and the surfaces is established after t ∼ 10 ns of simulation in both cases, as indicated by the stabilization of the number of aminoacids in contact with the surface seen in Figure 4a . The number of aminoacids in contact with the surface remains relatively stable for both surfaces (i.e. without abrupt changes) up to t ∼ 20 ns, as seen in Figure 4a . We will consider this time interval (with about ∼ 60 aminoacids of the spike in direct contact with the surfaces) as the initial adsorption stage, as highlighted in Figure 4 . Illustrative snapshots of this stage are shown in the top panels of Figure 3 . After adsorption (t ∼ 10 ns), the RMSD between the adsorbed spike structure in absence of a surface and the adsorbed structure is ∼5 Å for both surfaces (Figure 4b) , indicating a small structural change during adsorption. In the case of adsorption onto cellulose, the RMSD remains constant during the initial adsorption stage but it steadily increases with time in the case of graphite. This can be considered as a indication that this adsorbed configuration of the spike onto graphite is not stable, as we will see. Comparison of the snapshots in Figure 3 and the structure shown in Figure 2d suggests that this initial adsorption of the spike at the surfaces is made through contact between the surfaces and the subunit S1 of each monomer of the spike. This is confirmed by a detailed description of the contact region between the spike and the surface, as shown by the contacts map in Figure 5 . As seen in this figure, in both cases (cellulose and graphite), the adsorption involves three RBD and two NTD domains of the receptor-binding subunit S1. In this initial stage, the spike has a similar distribution of contacts with both surfaces although the distribution is more compact in the case of the graphite surface. Therefore, all three monomers are involved in the adsorption process, although in one monomer only the RBD domain is involved and in two monomers both the RBD and NTD domains of the S1 unit are involved. There is only slight contact between the surfaces and glycans or with the S2 subunit of the monomers. After a similar initial adsorption process, the subsequent evolution reflects (Figures 4a,b ) the substantial differences between adsorption onto cellulose and graphite. In the case of the graphite surface, both the number of residues in contact with the surface and the RMSD show substantial evolution with time including abrupt changes (for example at t ∼ 40 ns) whereas it shows only minor time evolution in the case of the cellulose surface. At long times (t ∼75 ns), the spike adsorption onto graphite stabilizes, so we can define a final stage, as indicated in Figure 4 , to compare the obtained structures for both surfaces. The most remarkable feature of the final stage is the striking deformation and curvature of the spike towards the graphite surface seen in Figure 3 . This deformation is reflected in the large number of contacts of the spike with the graphite surface, which is near 100 residues in contact, as seen in Figure 4a . This deformation of the spike over the graphite surface involve structural changes captured by the time evolution of the RMSD (Figure 4b ). The RMSD stabilizes at ∼ 18 Å at the final stage, which implies a substantial structural change induced by graphite. In the case of the cellulose surface, the number of residues of the glycoprotein in contact with the surface remains approximately constant (∼ 50) between the initial and final adsorption stages. The RMSD remains at ∼ 5 Å up to simulation times of t ∼ 50 ns, and after that it increases slowly reaching ∼ 8 Å. This change in RMSD corresponds to a slight deformation of the protein to increase its contact with the surface accompanied by a slight change of the orientation of the main axis towards the cellulose surface (see snapshot in Figure 3 ). Figure 5 also shows substantial differences between the surface of contact between the spike and cellulose or graphite, as should be expected from Figure 3 . The contacts between the spike and cellulose changed only slightly from the initial to the final stage whereas in the case of graphite the region of contact increased substantially, due to the deformation of the spike discussed above. Figure 5 also shows that in the case of graphite the adsorption involves not only the receptor-binding subunit S1 but also a substantial contact with the membranefusion subunit S2. Therefore, the substantial deformation of the spike observed in Figure 3 involves the adsorption of the membrane-fusion subunit S2 at the graphite surface. Interestingly, neither the adsorption to graphite or cellulose induce changes in the secondary structure of the spike. Ac This could be related to the fact that the spike is known to be rather flexible. In fact, it has been suggested 31 that the mechanism of biding of the spike of coronaviruses to diverse host cell receptors is based on the flexibility of the spike. Before entering into a more detailed analysis of the spikesurface interactions, we would like to add a comment about the ions present in the simulation. As we mentioned before, the simulation also contains Na + counterions to neutralize the spike charge. The ions are observed to be mostly condensed at the spike, without being involved in the adsorption process. It is likely that the reason for this observation is that both surfaces are neutral and the spike is strongly charged. In order to obtain a deeper understanding of the adsorption results described in the previous subsection, we have performed a more detailed study of the particular aminoacids in-volved in the protein-surface interaction. In Figure 6 , we show the number of spike aminoacids in contact with cellulose or graphite, classified by aminoacid type, for both the initial and final adsorption stage. In the initial stage (Figure 6a ), we obtain a very similar distribution of residues of the spike in contact with both cellulose and graphite. The only difference is a slight tendency of graphite to favour more contacts with hydrophobic residues. In both cases, there is a substantial contribution from neutral polar aminoacids with ∼ 24 − 25 contacts (∼42-44% of contacts). The most abundant residue in contact with the surface is ASN (Asparagine) with an average of about ∼ 10 contacts (∼17.5% of the total). Overall, our results in Figures 5 and 6 imply that in the initial adsorption stage, the nature of the surface plays a minor role. In both cases, the spike is able to adsorb to both surfaces through essentially the same aminoacids located in the receptor-binding subunits S1 of the trimeric spike. However, it is possible that the magnitude of the interaction should be different for the different surfaces, given their different character regarding hydrogen bonding and hydrophobic interactions. In order to compare the magnitude of the spike-surface interactions for both cases, we have performed additional simulations using the steering molecular dynamics technique. In these simulations, the spike is pulled from the surface at constant velocity and the required detachment force is monitored. Our results (reported in Appendix A), indicate that the detachment forces are very similar for both surfaces at the initial adsorption stage. For the faster detachment velocity (5nm/ns) the detachment force for both surfaces is very similar. As we reduce the detachment velocity the difference in the maximum force between graphite and cellulose becomes more important, with graphite requiring a larger force to detach the glycoprotein from the surface (see Figure 8 in Appendix A). This higher detachment force for the graphite surface could be related to the density of contacts as shown in Figure 5 at the initial adsorption stage. As seen in that figure, the graphite tends to form a more dense contact surface with the spike glycoprotein, which may require a larger force to detach from the surface. In any case, this comparison between detachment forces should be considered with caution, since these SMD simulations are noisy, experiencing substantial fluctuations. The results for the analysis of the aminoacids involved in the protein-surface interaction during the final stage ( Figure  6b ) reflect the different evolution for the adsorption of the spike on cellulose or on graphite, in line with the results discussed in the previous subsection. In the case of graphite, the differences between the initial stage and the final stage in Figure 6 are obviously due to the deformation of the spike after adsorption described in the previous subsection. The total number of contacts of the spike with graphite increased from an average of ∼59.2 contacts in the initial stage to ∼ 102.8 in the final stage. Again, the most abundant residue in contact with the graphite surface is ASN (asparagine) with an average of about ∼ 17 contacts corresponding to a prominent peak in Figure  6b . This result is consistent with previous simulations that indicated a strong affinity of asparagine with carbon aromatic rings 32 . The final stage of adsorption at the graphite surface is dominated by contacts with asparagine, threonine, serine and glutamine neutral polar aminoacids but there is also a substantial number of contacts with hydrophobic aminoacids such as tyrosine, valine or leucine and with the glycans covering the lateral regions of the spike. In the case of cellulose, the number of contacts remains nearly the same (only a very slight decrease in the total number of contacts, from a total of 55.6 in the initial stage to 54.2 in the final stage). Comparison between Figure 6a and Figure 6b shows very minor changes. In the final stage there are slightly more contacts with charged aminoacids and less contacts with hydrophobic aminoacids than those obtained in the initial stage. Therefore, the small changes observed in the previous subsection (both in the RMSD and the map of contacts, Figures 4b and 5) can be attributed to a rearrangement of the protein at the surface to increase interactions with hydrophilic aminoacids and reduce the contacts with hydrophobic aminoacids, without significantly changing the number of contacts. In any case, Figure 6 shows a wide variety of residues with different chemical affinity in contact with cellulose. Again the peak in the case of asparagine is the most noticeable feature for the case of cellulose in Figure 6b , with ∼ 10 contacts (which corresponds to ∼19% of contacts). Overall, our results indicate that in the case of cellulose the spike is immobilized after adsorption, experiencing only minor changes during the adsorption process. This effect could be due to some sort of stabilizing interaction, that anchors the aminoacids of the receptor binding domain (RBD) after touching the surface. Since the surface of cellulose has a large hydrogen bonding ability, this interaction could be responsible for the observed stabilization. In order to check this possibility, we have analyzed in detail the presence of hydrogen bonds between the spike and the cellulose surface ( Figure 7 ). In Figure 7a , we show the number of direct hydrogen bonds between the spike and the cellulose surface. Similar to what is observed in Figures 4a and 4b with the number of contacts and the RMSD, the number of hydrogen bonds stabilizes after ∼10 ns of simulation time and fluctuates around an average of ∼18 hydrogen bonds total during the rest of the simulation. Further identification of these hydrogen bonds reveals that they are mostly located on the RBD domain of the glycoprotein, constituting almost ∼ 75% of the total hydrogen bonds. In Figure 7b , we report the number of hydrogen bonds for each aminoacid type together with the number of aminoacidspike contacts. In the case of the neutral polar asparagine and serine, a significant number of the aminoacid-cellulose contacts involve hydrogen bonding. It is also interesting to note a significant number of hydrogen bonds with cellulose from the aminoacids of hydrophobic character leucine (LEU) and tyrosine (TYR) that have also the possibility of hydrogen bonding. Probably the amphiphilic character of cellulose 29 tends to enhance the interaction with these aminoacids. Hydrogen bonding between the spike and cellulose is more complex than simply due to direct cellulose-spike hydorgen bonds. A closer look to the formation of hydrogen bonds between the spike and cellulose reveals the existence of hydration water molecules that share hydrogen bonds with cellulose and aminoacids. In Figure 7c we can observe that three of the aminoacids with larger contributions in the number of hydrogen bonds in Figure 7b (ASN, SER and TYR) also form bridging hydrogen bonds with surrounding water, which makes hydrogen bonds with both the aminoacid and the cellulose surface. Overall, this complex hydrogen bond network mainly located at the interface of the RBD domain tends to stabilize the spike glycoprotein on the cellulose surface and is possibly responsible for the differences in deformation observed between cellulose and graphite surfaces observed in Figure 3 . All Molecular dynamics (MD) simulations reported in this paper were performed using NAMD 2.13 software 36 . The preparation of the simulation models and most of the analysis were made using Visual Molecular Dynamics (VMD) software 4 . The force field employed in the simulations is the CHARMM36 force field which includes parametrization of carbohydrate derivatives, polysaccharides and carbohydrate-Protein interactions 37 . This forcefield is therefore appropriate for describing both the spike glycoprotein and all materials considered in the paper. The water model used in our simulations was the TIP3P model included in CHARMM36. The atomic coordinates for the SARS-CoV-2 spike glycoprotein structure were obtained from a cryo-EM structure 3 solved at 3.46 Å average resolution (PDB ID: 6VSB). This structure contains S1 and S2 spike subunits (with one RBD domain in ""up"" conformation) and a glycosylation pattern characterized by N-Acetyl-D-Glucosamine (NAG) residues, as shown in Figures 2c and 2d . The only modification made to this initial structure was the addition with VMD of missing hydrogen atoms and connecting links between the protein aminoacids and the NAG residues. The obtained structure contains 46,708 atoms and its total charge (assuming pH 7) is -23e. It should be noted that the glycosylation pattern present in this structure only includes glycans in close proximity to the protein due to lack of further information on the resolved structure of the spike. We are aware of ongoing work on the development of more accurate models of the spike in order to include details not resolved in the available structures 12, 16 such as improved models of the glycosylation. We think that these details, which are essential in questions such as recognition of the spike by the immune system or its interaction with specific receptors will not be essential in the study of the interaction of the spike with extended surfaces. In any case, developments on improved spike models should be carefully considered in future simulations of the virus interactions with materials. The spike structure was solvated using VMD with an spherical solvation shell in order to maintain its hydrated functional state. The number of TIP3P water molecules added to solvate the glycoprotein was 60,642. We also added 23 Na + counterions to neutralize the charge of the spike. The system made by the hydrated spike with counterions has a total of 228,657 atoms. The structures of the surfaces were built as follows. The cellulose structure was built using the Cellulose builder toolkit 38 from a cut of the crystallographic plane (100) from cellulose Iβ crystal structure as in our previous work 29 . We selected the (100) cellulose surface because it is the structurally simplest and smoothest surface that can be generated from cutting the Iβ cellulose crystal structure (see for example Figure 2 in Ref 29 ). In any case, our previous studies 29 show that the different surfaces of cellulose have similar wetting properties and similar hydrogen bonding capacity. An interesting feature of the (100) cellulose surface is that it has ""buried"" -OH groups involved in cellulose-cellulose hydrogen bonds that can be broken to generate hydrogen bonds of cellulose with adsorbing molecules (see for example Fig.3 in Ref 29 ). The generated cellulose structure has a surface with dimensions of 26.1 nm ×25.08 nm and a thickness of 3.18 nm (8 molecular layers) as seen in Figure 2b . The cellulose structure has 252,000 atoms and the full simulation box with the hydrated spike, Na + counterions and cellulose has 480,633 atoms. The graphite structure was build using the inorganic builder plugin of VMD 4 by replicating the unit cell 100 times in a, 100 times in b and 3 times in c direction. A detail of the surface can be observed in Figure 2c . Since graphite has a hexagonal crystal structure, we used also periodic boundary conditions with the same geometry, with simulation box vectors (in nm) a=(12.28,-21.27,0.00), b= (12.28,21.27,0 .00), c=(0.00,0.00,40.0). The graphite structure has 120,000 atoms and the full simulation box (hydrated spike, counterions and surface) contains 348,654 atoms. We recall here that all surfaces considered in our simulations are neutral. The protocol followed in all simulations includes an initial minimization, equilibration and production runs. In all simulations Newton's equations of motion were integrated with a 2 fs time step and electrostatic interactions were updated every 4 fs. All bonds between heavy atoms and hydrogen atoms were keep rigid. All simulations were performed in the NVT ensemble with a Langevin thermostat set at 298 K and a damping coefficient of 1 ps −1 . We employed periodic boundary conditions in all directions. Lennard-Jones interactions were computed with a cutoff of 1.2 nm and a switching function starting at 1.0 nm. Electrostatic interactions were computed using Particle Mesh Ewald (PME) algorithm using a real space cutoff set at 1.2 nm and a PME grid of 1.0 Å. We performed three different MD simulations. First, we performed a preliminary simulation (19 ns) of the solvated spike at 298K. Employing the results of the preliminary simulation as starting configuration, we have performed MD simulations of the protein spike adsorption onto cellulose and graphite. The equilibrated spike inside a water droplet was positioned at 2 Å away from the surface, as shown in 2. The simulation trajectory was run for 83.4 ns in the case of adsorption onto cellulose and 88.5 ns in the case of graphite. The snapshots and movies of the simulations were made using Visual Molecular Dynamics (VMD) software 4 . The different analysis were made using VMD tools and appropriate scripts as follows. As discussed in the main paper, for convenience in the analysis we introduce an initial adsorption stage and a the final adsorption stage. In the calculations of averaged quantities, the exact definition of these stages is as follows. We define the initial adsorption stage as the time interval between 12.55-19.44 ns for simulations of adsorption over the cellulose surface and between 11.0-21.0 ns for the case of graphite surface. Similarly, we define the final adsorption stage as the time interval between 74.5-83.4 ns for the simulation with cellulose and between 78.5-88.5 ns for the simulation with graphite. Note that this choice of time intervals is related to simplicity in data handling and the time intervals shown in Figure 4 are not exact (since the exact definitions slightly differ for each surface) but approximate for illustrative purposes. The number of aminoacids in contact with each surface (Figure 4a) was computed considering that a contact between aminoacids and surface occurs when at least one atom of the aminoacid is found at a distance smaller than 3.5 Å from any surface atom. In order to co count the number of aminoacids at each time timestep we employed a TCL script running on VMD implementing the distance requirement described above. The distribution of residues in contact with the surfaces ( Figure 6 ) was calculated over the initial and final adsorption stage with a similar TCL script, averaging over the intervals defined above. The 2-D contact map ( Figure 6 ) was calculated using VMD Volmap tool for residues at distance of less than 3.5 Å from surface atoms. The root mean squared deviation (RMSD) reported in Figure 4b was computed between each instantaneous structure and the initial structure using the RMSD trajectory tool implemented in VMD 4 . The analysis of secondary structure as function of time in Figures 4c and  4d was made using the timeline tool in VMD, which uses the STRIDE algorithm 39 to calculate the fraction of differ-ent secondary structure components. Hydrogen bonds ( Figure  7) were computed using VMD. We used an acceptor-donor distance cutoff of 3.5 Å and acceptor-hydrogen-donor angle cutoff of 30 degrees. This work was supported by the Spanish Ministry of Science and Innovation through grant RTI2018-096273-B-I00 and the ""Severo Ochoa"" Grant SEV-2015-0496 for Centres of Excellence in R&D awarded to ICMAB. We thank the CESGA supercomputing center for computer time and technical support at the Finisterrae supercomputer. D. C. Malaspina is supported by the European Union Horizon 2020 research and innovation programme under Marie Sklodowska-Curie COFUND grant agreement No. 6655919. The detachment force of the spike at cellulose and graphite surfaces adsorbed at the initial adsorption stage (Figure 3 ) was calculated using the Steered Molecular Dynamics technique 40 (SMD) as implemented in NAMD. The SMD simulations were conducted starting from the configuration obtained in the MD simulations at 21.0 ns for adsorption onto the cellulose surface and 19.44 ns for the graphite case. The spike glycoprotein was pulled from the center of mass of the residues located at less than 4nm from the surface, this roughly correspond to the RBD and NTD domains. The parameters for the SMD simulation are the same as previous simulations with the addition of a forcing to the spike (force constant 2×10 4 kcal/mol/Å 2 ) ensuring a constant velocity of pulling that was set to 1 nm/ns, 2 nm/ns and 5 nm/ns. According to these velocities the simulation time was selected in order to obtain a separation of at least 2 nm between the spike and the surface. As a result, in SMD we obtain force-separation curves corresponding to each pulling velocity. These forces as a function of spike-surface distance obtained in the SMD simulations were rather noisy (as usual in SMD simulations) so they were smoothed with a running average. We should keep in mind that the obtained forces from the SMD simulations correspond to nonequilibrium processes in which the motion of the spike will experience a viscous drag (which depends on velocity) in addition to the adhesion force. This viscous resistance can be identified by noting that the force should decay to zero as the protein separates from the surface. In the SMD simulations, we observe a decay of the force with distance to an approximately constant value. This value can be taken as an approximation to the viscous resistance. Therefore, in order to remove the effect of viscous drag and extract the adhesion force, we have shifted the force versus distance curves obtained in SMD so that they decay to zero force at large spike-surface separations. The values of the estimated viscous drag depend on the spike velocity in the SMD simulations. For the simulations with the cellulose sur- face they were 4,933 pN, 6598 pN and 11,150 pN for SMD simulations of velocities of 1nm/ns, 2nm/ns and 5 nm/ns respectively. Similarly, the values in the case of simulations with the graphite surface for SMD simulations with velocities 1nm/ns, 2nm/ns and 5 nm/ns were 4,390 pN, 7,489 pN and 11,797 pN respectively. The force versus distance curves obtained after this process were shown in Figure 8 . For the faster detachment velocity (5nm/ns) maximum force in both surfaces is approximately similar, been ∼8100 pN for cellulose surface and ∼8500 pN for the graphite surface. As we reduce the detachment velocity the difference in the maximum force between graphite and cellulose becomes more important, with graphite requiring a larger force to detach the glycoprotein from the surface. At the lower detachment velocity (1 nm/ns) the maximum force for cellulose surface is ∼4900 pN and ∼6200 pN for the graphite surface.@story_separate@In this work we presented molecular dynamics simulation of the SARS-CoV-2 spike glycoprotein interacting with two different surfaces: cellulose and graphite. The choice of these surfaces was made in order to compare two different materials with very different properties. Cellulose is a complex molecular material with amphiphilic properties and a high quantity of hydrogen bonds donors and receptors. Previous works (see for example ref 29 and references therein) demonstrated the capacity of cellulose to bind proteins by both hydrogen bonding and hydrophobic interactions. On the contrary, graphite is a crystalline hydrophobic material with no hydrogen bond capability. It is also known to be able to bind peptides and proteins via hydrophobic interactions (see for example 32 or the discussion in Ref 33 ). Our simulation results can be summarized as follows: Initially, the spike adsorbs to both surfaces through essentially the same residues belonging to the receptor binding subunit of its three monomers (in particular, involving all three receptor-binding domains (RBD) and two N-terminal domain (NTD)). From this point the adsorption on each surface dramatically differs. Adsorption onto cellulose stabilizes in the initial adsorption configuration with the help of a large number of hydrogen bonds developed between cellulose and the three receptor binding domains (RBD) of the glycoprotein spike. This adsorbed configuration also includes shared hydration water between the spike and cellulose. In the case of adsorption onto graphite, the initial adsorption configuration is not stable and the surface induces a substantial deformation of the glycoprotein spike with a large number of adsorbed residues not pertaining to the binding subunits of the spike monomers. It is interesting to note that our results are in line with previous MD results of other proteins at these surfaces. Cellulose tends to adsorb proteins in stable configurations without structural changes 29 whereas the interaction with graphite induce substantial structural effects on adsorbed proteins 33 . Concerning the possible practical implications of these results, obviously we need to remark that the present study is a simplification, since it ignores important effects such as the process of approach of the full virus to the surface, which is dominated by long range forces. Nonetheless, this represents the final stage of the adhesion of a virus with a surface, in which the most external element (the spike) interacts with the surface and it provides a reasonable approximation to the affinity between the virus particle and a given surface. With all these precautions in mind, we can say that our results suggest that interactions with cellulose will tend to maintain the integrity of the hydrated SARS-CoV-2 virus spike. Also, interactions with graphite deform the spike and may potentially help to inactivate the infectious potential of the spike glycoproteins interacting with the surface. As a recommendation for future experimental investigations, it will be of great interest to investigate the viability of the virus over carbon surfaces, in particular given the importance of these materials for filtration applications. Our study has to be considered a first step in the understand-ing of the molecular interactions between the SARS-CoV-2 virus and surfaces. Of course, our study has many limitations and further work is necessary in order to understand many relevant factors that are beyond the scope of this paper. One obvious limitation is that in our simulations we considered only the (hydrated) spike glycoprotein of the SARS-CoV-2 virus but not the virus a whole. The molecular scale analysis of the virus-surface interaction is only one of the relevant aspects that need to be considered in order to understand the interaction between this SARS-CoV-2 virus and materials. Other factors operating at larger length scales need also to be considered. For example, experimental studies for other viruses show evidence that porosity and nanostructuration of the surfaces at scales of the order of the virus size also have an impact 28 . Also, modelling of the respiratory droplets embedding the virus (which contain mucosal biopolymers, lipids and salts 34 ) and how these droplets interact with materials and textiles is of the highest interest. A simulation study of these factors will require the use of mesoscale models, which may be build from relevant experimental data -which is still unavailable-or eventually from the results of atomistic molecular modelling, as has been done recently for mesoscale simulations of a full influenza virus 35 .","A prominent feature of coronaviruses is the presence of a large glycoprotein spike protruding from a lipidic membrane. This glycoprotein spike determines the interaction of coronaviruses with the environment and the host. In this paper, we perform all atomic Molecular Dynamics simulations of the interaction between the SARS-CoV-2 trimeric glycoprotein spike and surfaces of materials. We considered a material with high hydrogen bonding capacity (cellulose) and a material capable of strong hydrophobic interactions (graphite). Initially, the spike adsorbs to both surfaces through essentially the same residues belonging to the receptor binding subunit of its three monomers. Adsorption onto cellulose stabilizes in this configuration, with the help of a large number of hydrogen bonds developed between cellulose and the three receptor binding domains (RBD) of the glycoprotein spike. In the case of adsorption onto graphite, the initial adsorption configuration is not stable and the surface induces a substantial deformation of the glycoprotein spike with a large number of adsorbed residues not pertaining to the binding subunits of the spike monomers."
"The growth and expansion of Dentistry in Latin America (LA), together with the increase in the educational needs of the profession, justifies conducting a comprehensive analysis on the trends in Implant Dentistry on this region López Jordi, Figueiredo, Barone, & Pereira, 2016) , with distinctive political, economic, and social perspectives (Romito et al., 2020) . Moreover, The COVID-19 pandemic has become not only a major challenging public health problem for most of the countries, but it is also changing the socioeconomic balance and affecting the society at all levels, including the dental profession. This outbreak was declared a Public Health Emergency by the World Health Organization (AL-Maweri et al., 2020; Meng et al., 2020) and since its outbreak, the COVID-19 has infected more than 29 million people, with 950,000 deaths, by September 14rd, 2020 (Nuzzo et al., 2020) . Coronavirus cases have increased considerably in Latin America. Brazil has registered more than 4.3 million confirmed cases, the third highest count in the world after the United States and India. Moreover, it is the second country, behind the United States, with the highest number of deaths. Mexico, Argentina, Colombia, and Peru have also had major outbreaks and are among the 10 countries that have confirmed more cases (Nuzzo et al., 2020) . As a health profession, Dentistry has been affected not only in terms of the prevention and spread of the infection, but also in the delivery of care, being implant dentistry one of the most affected specialties, due to its invasiveness since it combines surgical, prosthetic, and aerosol producing interventions (Boyce, 2021; Nibali et al., 2020; Rutkowski et al., 2020) . Under these circumstances, it will be desirable to develop scientific information at regional level (LA) on the trends of the education and practice in implant dentistry in the COVID-19 pandemic, since although living in a globalized world, there are regional peculiarities that need to be studied (Tiwari et al., 2018) . The Delphi method belongs to the subjective-intuitive methods of foresight, which is especially useful for forecasting, as expert opinions are the only source of information available (Dalkey & Helmer, 1963) . Its main objective is to evaluate the degree of consensus among experts in a specific topic. This method is characterized by allowing a structured group of individuals to deal with complex problems through structured communication, individual feedback, group judgment, and discussion (Woudenberg, 1991) . Using this methodology, the previously available information is evaluated, and suitable tendencies or evolution patterns are looked for in order to allow the most probable future environments (Dalkey & Helmer, 1963) . The answers of the experts are obtained in consecutive rounds of anonymous questionnaires, aiming at looking for a consensus among experts, but keeping the maximum independency of criteria of each individual. Once the collected data from the surveys are analyzed, the final prediction is developed through consensus by a selected group of experts (Dalkey & Helmer, 1963; Woudenberg, 1991) . Recently, this methodology has been successfully introduced in Dentistry to predict the development of different specialties in Europe, with the support of relevant scientific societies 7 topics, concerning the various trends in dental implantology. The survey was conducted in two rounds, which provided the participants in the second round with the results of the first. The questionnaires were completed on August 2020, and the online meeting conference was held on September 2020. The final prediction was developed through consensus by a selected group of experts.@story_separate@A total of 197 experts from Latin America answered the first and second questionnaire. In the first round, the established threshold for consensus (65%) was achieved in 30 questions (46.87%). In the second round, performed on average 45 days later, this level was achieved in 47 questions (73.43%). Consensus was completely reached on the item ""Diagnostic"" (100%), the field with the lowest consensus was ""Demand for treatment with dental implants"" (37.5%). consensus, COVID-19, Delphi technique, dental implant, education such as the European Federation of Periodontology (EFP) (Madianos et al., 2016) and the European Association for Osseointegration (EAO) (Sanz et al., 2019) . It was, therefore, the objective of the present study endorsed by the Ibero Panamercian Federation of Periodontology and the Peruvian Association of Oral Implantology to analyze the trends in Implant Dentistry in LA, under the perspective of the post COVID-19 pandemic. Special attention was placed to evaluate the future perspectives in epidemiological trends, education, biosecurity, and professional practice. The Delphi methodology was used to predict the future trends in Implant Dentistry in the post COVID-19 era based on different levels of consensus retrieved from expert opinions. An Advisory Committee (M.A., I.S., J.S., L.M., A.L.P, and M.S) was established: (a) to define the context and the timeframe in which it was desirable to forecast, (b) to design and validate the questionnaire, and (c) to select a Steering Committee with experts in oral implantology who represented each country in LA. This Steering committee was established to approve and finalized the questionnaire and to select the expert panel among each country considering the surgical and prosthetic fields of oral implantology. The study followed the COREQ (COnsolidated criteria for REporting Qualitative research) statement (Tong et al., 2007) . The structured questionnaire was designed and was expected to be completed in approximately 20 min. It contained 64 questions and was divided in the following 7 sections, specifically dealing with the following trends: 1. Demand for dental implant treatment (8 questions). 3. Biosecurity (15 questions). 4. Surgical approaches (12 questions). 5. Prosthetic approaches (7 questions). 6. Peri-implant Diseases and Maintenance (7 questions). Three well-defined possible answers were provided to all questions, except in one where four options were provided. Furthermore, an open-end space was always provided for each question in case the expert would like to answer differently or make any clarification to the question. These comments were analyzed in the consensus meeting to discuss and to clarify the responses. Experts in eighteen countries were selected according to their professional profile. One-third of the experts had a full-time academic position at the university, one-third worked mainly in the private clinic even though they could work part time at the university, and the remaining third worked in the public sector, including hospitals and/or state health centers. Ideally, each country contributed with a proportioned sample of surgical and prosthodontics experts. To be considered as an expert, one of the following inclusion criteria was considered: (a) specialist with a degree obtained at university; and (b) general dentist with more than 10 years of experience in dental implantology. Using these criteria, 213 experts received an invitation letter to participate in the study, as well as the online address, where the questionnaire should be answered. Each country was represented in the model by a number of experts proportional to the number of active dentists. A minimum of three experts were established for each country, as suggested by key persons assigned to each country or region by the advisory group. The online questionnaire was sent to the selected experts (July 2020). A timeframe of 2 weeks was given to get a response. The answers were collected by the Steering Committee, and the questionnaires were sent in the second round to the experts 45 days after (August 2020), including a summary of the results for the first round. This methodology allowed the expert to ""align"" themselves with the thoughts of the other participants, changing their answer or remaining with his previous answer. The responses were collected again, and a descriptive systematized data analysis was carried out to describe the different opinions and the consensus reached. Responses that achieved a minimum consensus of 65% among the expert panel were no longer discussed, while responses below this threshold were discussed in depth at the final online consensus meeting. By convention, the following consensus levels were established: (a) no consensus when the threshold of 65% was not attained in the second round; (b) moderate consensus when achieving 65%-85%; and (c) high consensus when reaching >85%. An online meeting conference was held on September 2020. During this meeting, the results from the second round to each question were presented. However, discussion during the meeting specifically dealt with those answers not reaching the 65% level of consensus after the second round and those issues requiring further explanation. These questions were further discussed until reaching consensus from those present at the conference. During this consensus meeting, the final conclusions based on the results were discussed representing the basis for this report.  The most frequent answer to each question is highlighted in bold. After the first and second round, the answers to each question were individually analyzed following descriptive statistics with data presented as absolute values and percentages, as well as means. In addition to statistical descriptors, the expert's testimonies were also taken into account in nonconsensual questions, as well as personal observations of those experts who remained opposed to the consensus achieved in certain questions. A total of 213 experts from LA were invited to participate. In the first round, 100% answered the questionnaire and 197 participants from those participating in the first round (92.48%) finally participated in the second round. The distribution of experts for each country is depicted in Table 1 . In the first round, the established threshold for consensus (65%) was achieved in 30 questions (46.87%). In the second round, this level was achieved in 47 questions (73.43%). Consensus was completely reached on the field of ""Diagnosis."" The field with the lowest level of consensus was ""Demand for treatment with dental implants."" The consensus achieved for each field is depicted in Figure 1 and Table 2. In the field of ""Demand for treatment with dental implants,"" there was moderate consensus in 3 out of the 8 questions ( Figure 2 ). The experts responded that there will be no changes in the fees of dental implants and prosthetic components (70.05%), laboratory cost (72.08%), or the costs for the patients (70.56%). However, there was no consensus in regard to the demand for dental implants irrespectively of the type of edentulism. The questions related to the field ""Diagnosis"" provided moderate to high consensus (Figure 3 ). There was a clear high consensus for the use of tomography during preoperative diagnosis (96.95%). In regard to digital tools, there was moderate consensus for the use of telemedicine as an adjunctive measure to conventional evaluation (75.64%) and to the fact that electronic dental record will replace physical dental history (74.62%). The use of tests to detect the virus SARS-CoV-2 reached the lower borderline of consensus (65%). The field of ""Biosecurity"" reached a moderate to high consensus in 12 out of the 15 questions ( Figure 4) . Some of the questions such as ""In COVID-19 pandemic, all patients should be considered as potential carriers of SARS-CoV-2"" and ""Transmission of SARS-CoV-2 can be 100% prevented,"" reached a very high consensus (98.48% and 98.98%, respectively). However, there was no consensus for the use of a diagnostic test for SARS-CoV-2 before surgical (42.64%) or prosthetic treatment (59.39%). Moreover, the need of a third assistant to take photographs did not reach consensus (61.42%). There was consensus in 8 out of the 12 questions related to the ""Surgical treatments"" (Figure 5 ). Most of the experts agreed that the patient should use mouthwashes before surgery (98.48%) and that the use of aerosol-generating instruments during surgical procedures will be less frequent (93.40%). Moreover, an important number of participants also disagreed that implants will be placed in the operating room (77.16%). In regard to medication, most of the experts answered that the prescription of nonsteroidal In the field ""Prosthetic treatments,"" there was high consensus for the fact that we must disinfect/sterilize the impression materials (97.97%), the prosthetic components sent to the laboratory"" (87.31%) and the prosthetic components from the laboratory (87.31%) ( Figure 6) . Also, most of the experts agreed that the use of CAD/CAM technologies in the field of implantology would be more frequently"" (90.36%). However, there was no consensus for the use of digital technologies to take impressions (50.76%). In regard to the time of loading, conventional protocols will be similar to before the pandemic (73.10%). Answers from the experts for each question on the field of ""Demand for dental implant treatment"" F I G U R E 3 Answers from the experts for each question on the field of ""Diagnosis"" Most of the questions evaluated in the field ""Peri-implant diseases and maintenance"" reached moderate consensus (Figure 7) . The respondents estimated that 6 out of the 7 items evaluated would have a similar frequency. However, there was no consensus for the prevalence of peri-implantitis (63.96%). Furthermore, the experts reached moderate consensus in regard to the question whether telemedicine will be a useful tool for monitoring and controlling patients (76.14%). Finally, regarding the questions related to the field ""Education and training in implant dentistry"" the respondents achieved a high consensus for those questions highlighting that changes should be made in the basis of the hours of clinical activity within the curriculum plan (91.88%), the learning methodology (95.43%), the shift from presence to virtual attendance (88.32%), and the design of education centers to maintain social distance (94.40%). Furthermore, the experts estimated that oral implantology education will be trained face to face and by virtual education (73.60%) and that simulator will be used for implant placement training (78.68%). There was no consensus to recognize neither if higher education centers or scientific organizations will head education (63.45%) nor to an increase in the number of hours of clinical practice with patients (48.73%) (Figure 8 ). The results from the present study have provided important and useful information on the trends in Implant Dentistry in the COVID-19 era. Medical publications have recently used this methodology to generate consensus and provide recommendations for care in times of COVID-19 (Alterio et al., 2020; Bhandari et al., 2020; Gelfand et al., 2020; Pouwels et al., 2020) . The importance of these results is magnified by the fact that the study was carried out in the LA region, which presents its own cultural and economic characteristics. Furthermore, due to the representativeness within Implant Dentistry of the selected experts, the high response rate achieved and the high level of consensus in most of the items evaluated, this report will be relevant for scientific organizations, universities, and dentists that may consider these F I G U R E 4 Answers from the experts for each question on the field of ""Biosecurity"" tendencies in the implementation of the needed changes for improving the practice of implant dentistry during and after the pandemic situation. In spite of the data from the increase in life expectancy and the concern to maintain teeth in the LA population (Kassebaum et al., 2017) , there was no consensus on how the demand for dental implant treatment will be in the future. It is interesting to observe the impact of the evolution of the COVID-19 pandemic, since there was a tendency toward a more positive outlook in terms of demand, between the first and second round of questionnaires, coinciding with the return to the dental practice after the pandemic lockout. It remains unclear, however, what will be the impact of the COVID-19 pandemic (Bolaño-Ortiz et al., 2020) on the treatment of totally edentulous elderly subjects (Srinivasan et al., 2017) . The experts concluded that more than the treatment costs, the cost-effectiveness will be affected by this pandemic. Among other issues, the implementation of strict biosecurity protocols will affect practice times and number of patients treated, hence causing a detrimental effect on the practice economic outcome. Answers from the experts for each question on the field of ""Surgical approaches"" Even though the experts agree that direct presence of the patient for a clinical examination is still a requirement of the appropriate diagnosis of a patient candidate for dental implants, the use of teledentistry will increase and thus reduce the duration of consultations and the exposure of staff and patients. Some aspects that could be remotely evaluated are the update of the medical and dental history, the radiographic examination and the assessment of patient preferences, and wishes and queries related to the prosed treatment plan (Ghai, 2020) . In this sense, the use of a digital dental records could also be advised (moderate consensus), although this will depend on the legal validity of this document in each country. The dental team has been regularly using infection control measures before the COVID-19 pandemic; however, most of the experts responded that these measurements should be enhanced in light of the SARS-CoV-2 infectivity, mainly in cases of procedures generating aerosols Li et al., 2020; Umer et al., 2020) . However, the experts did not agree on whether full personal protective equipment should be worn for each patient. Moreover, there was no consensus on the need of diagnostic for SARS-CoV-2 virus to every patient in the dental clinic (Gurzawska-Comis et al., 2020) , since some experts found it unattainable. Instead, experts suggested the filling by every patient of a self-reported medical questionnaire and telephone triage prior to each appointment, as well as the strict abidement to all the infection control measures during the patient visits to the dental office. Experts found this protocol sufficient to reduce the risk of infection in the dental office, in line with international recommendations (Centers for Disease Control & Prevention, 2020; Gurzawska-Comis et al., 2020; Ren et al., 2020) . It is interesting to discuss that experts agreed that the transmission SARS-CoV-2 can be 100% prevented despite the complete prevention of SARS-CoV-2 is yet almost unheard. This could be explained by their clinical experience during these pandemic months, employing suitable biosecurity measures that protected them from infection. Moreover, emerging evidence is showing that by applying proper biosecurity protocols, the risk of infection in the dental setting is very low (Froum & Froum, 2020; Kumbargere Nagraj et al., 2020) . Also, one could debate why the transmission of SARS-CoV-2 should be addressed in the future when the F I G U R E 6 Answers from the experts for each question on the field of ""Prosthetic approaches"" vaccine may end up with the pandemic. However, since we still do not know how effective it will be and how long it will stand, we might need to live together with the virus even after a vaccine is available, being the transmission methods against SARS-CoV-2 probably necessary. With vaccination starting now all over the world, one could think that the outcomes of this project would be different, which could be right in the best possible scenario where once the patients receive the vaccine they are immunized forever. However, as it occurs with influenza virus, we might need to live together with the virus having yearly vaccines, which are not 100% effective (Demicheli et al., 2018) . Moreover, the risk of future zoonotic diseases due to climate change and human expansion (Hashimoto et al., 2020) justifies evaluating how a future pandemic situation could affect the trends in Implant Dentistry. The surgical phase of dental implants may become a challenge with the newly established protocols for COVID-19. It is interesting to note that experts believed that a special operating room would not be a requirement to perform surgery as long as the dental office complies with the established protocols. There was a very high consensus toward the use of mouthwashes before each intervention and the reduction of aerosolgenerating instruments during surgical procedures, which should be taken with caution since there is not sufficient clinical evidence to support the antiviral activity of reagents in mouth rinses against SARS-CoV-2 (Carrouel et al., 2020) . Emerging data clearly shows extremely short-lasting action of mouthwash in reducing SARS-CoV-2 virus in saliva/oral cavity, and therefore, its use may give a totally false sense of security (Yoon et al., 2020) . Moreover, despite it is known that the virus content is reduced immediately after rinsing, implant procedures generally last longer than seconds or a minute, and tissue manipulation in the mouth may further increase the flow of contaminated saliva with newly produced virus. In addition, before a vaccine against COVID-19 is available, experts recommend the implementation of different strategies and measures, such as the personal protective equipment, barrier devices to minimize aerosol contamination, air purification systems, antiviral chemicals to clean surfaces, chairside screening for SARS-CoV-2, or other future innovations (Ali & Raja, 2020) . In regard to medications, most of the experts agreed that there would not be major variations to the prescription of nonsteroidal or steroidal anti-inflammatory drugs and systemic antibiotic therapy after surgery, although practitioners should be knowledgeable on the health risks of these medications, mainly in patients with systemic conditions (Crighton et al., 2020) . Answers from the experts for each question on the field of ""Peri-implant diseases and maintenance"" Experts agreed that the current situation will accelerate the shift from conventional prosthetic methods to a full digital workflow in implant dentistry. There was a very high consensus toward the increased use of CAD/CAM technologies, which is in agreement with a similar Delphi study on implant dentistry from Europe (Sanz et al., 2019) . Experts also agreed that it is currently necessary to apply strict methods of infection control during the restorative procedures, by disinfecting all prosthetic components and impression materials. In fact, there is scientific evidence of the importance of sterilizing prosthetic devices for biosecurity and prevention of biological complications (Bidra et al., 2020; Canullo et al., 2015) . Due to the pandemic, the fear of infection in the population will indeed refrain many patients from attending preventive and supportive therapy appointments. In spite of this, experts estimated that the incidence of peri-implant diseases and prosthetic complications will be similar to what is today. This problem could be counteracted by the use of telemedicine, providing a quicker access to F I G U R E 8 Answers from the experts for each question on the field of ""Education and training"" the dentist without attending the dental office . Nevertheless, clinical and radiographic evaluation are still necessary for the proper diagnosis of peri-implant health or disease, and therefore, it is important that the professional can discern when the patient must come in person. Implementing this tool proactively is likely to generate greater benefits in the long term and help with the everyday (and emergency) challenges of general health care (Smith et al., 2020) . One of the aspects that the COVID-19 has impacted more strongly is education, with clear shift to change presence to remote education. There was a high consensus that there is a need to change the educational plans and learning methods in higher education institutions (Spanemberg et al., 2020) . New educational models should be developed with an increasing use of virtual simulation technologies that will replace, at least in part, traditional preclinical education (Galibourg et al., 2020) . However, its use in LA may be limited, at least in the immediate future, due to their high cost, and therefore, universities should develop policies to adapt their infrastructures for maintain the recommended social distancing and for assuring the protection of students, staff, and patients during the practical education in implant dentistry (Iyer, Aziz, & Ojcius, 2020) . One important limitation of this study that could have influenced the results is the potential conflict of interest, as all experts could have an inherent conflict of interest related to their jobs, their business, or their research. The management of conflict of interests was discussed with the Steering Committee and the Advisory group following the principles provided by the Guidelines International Network (Schünemann et al., 2015) . According to these principles, experts with relevant potential conflict of interests abstained from commenting or recommending during the consensus conference. It should be noted that each country was asked to select experts with no direct conflicts of interest to the study. In conclusion, the present study using the Delphi methodology in LA has provided insightful and useful information in regard to the practice of Implant Dentistry during and after the COVID-19 era. Scientific organizations, universities, and dentists should consider these tendencies in the implementation of the needed changes for improving the practice of implant dentistry during and after the pandemic situation. The authors would like to acknowledge the support from the Ibero Panamerican Federation of Periodontology (FIPP) and the Peruvian Association of Oral Implantology (ASPIOI). This study could not have been possible without the efforts from the 197 experts participating in the project. The authors report no conflicts of interest related to this study. @story_separate@The present study in Latin America has provided relevant and useful information on the predictions in the education and practice of Implant Dentistry in the COVID-19 era. The consensus points toward a great confidence of clinicians in the biosecurity protocols used to minimize the risk of SARS-CoV-2 transmission. It is foreseen as an important change in education, with introduction of virtual reality and other simulation technologies in implant training.","AIM: To establish trends in Implant Dentistry in Latin America in the COVID‐19 pandemic. MATERIAL AND METHODS: A steering committee and an advisory group of experts in Implant Dentistry were selected among eighteen countries. An open‐ended questionnaire by Delphi methodology was validated including 64 questions, divided in 7 topics, concerning the various trends in dental implantology. The survey was conducted in two rounds, which provided the participants in the second round with the results of the first. The questionnaires were completed on August 2020, and the online meeting conference was held on September 2020. The final prediction was developed through consensus by a selected group of experts. RESULTS: A total of 197 experts from Latin America answered the first and second questionnaire. In the first round, the established threshold for consensus (65%) was achieved in 30 questions (46.87%). In the second round, performed on average 45 days later, this level was achieved in 47 questions (73.43%). Consensus was completely reached on the item “Diagnostic” (100%), the field with the lowest consensus was “Demand for treatment with dental implants” (37.5%). CONCLUSIONS: The present study in Latin America has provided relevant and useful information on the predictions in the education and practice of Implant Dentistry in the COVID‐19 era. The consensus points toward a great confidence of clinicians in the biosecurity protocols used to minimize the risk of SARS‐CoV‐2 transmission. It is foreseen as an important change in education, with introduction of virtual reality and other simulation technologies in implant training."
"Assessments of the impacts of school closures and risks of reopening continue to be of high priority as school districts plan for the fall 2021 semester and more transmissible variants dominate the ongoing COVID-19 pandemic [1] . While school closures are intended to curb the spread of COVID-19, major risks for children's mental health and educational and social development have been documented [2] [3] [4] . Introduction of vaccines with high effectiveness against infection [5] [6] [7] [8] with SARS-CoV-2 reduce the risk of transmission within school environments in two ways. First, community transmission rates-which strongly impact the probability of within-school transmission [9] -are suppressed in areas with high vaccination coverage, although vaccination coverage remains heterogeneous across school districts [10] . Second, teachers, high school students, and some middle school students are now eligible for vaccination, conferring direct protection against within-school transmission. Prior epidemiological study and model-based risk assessments found the vaccine-eligible school population has higher risk of school-based transmission as compared to vaccine-ineligible elementary students [9, [11] [12] [13] . Nevertheless, due to rising rates of the more transmissible Delta variant across the U.S. [14] , particularly in settings with low vaccination rates, there is concern that a return to schooling could be accompanied by increased risks of transmission [15] , particularly among elementary school populations who are not yet eligible for vaccination. While our understanding of the natural history parameters for children is limited to the parent strain and thus evolving with continued Delta circulation, elementary-aged students (aged 5-10) may be less susceptible to infection than older children and adults [16] [17] [18] [19] . Further, children under 18 have milder outcomes than adults [20] , and exhibit extremely low fatality rates from SARS-CoV-2 (2 deaths per million by one estimate [21] ) even among children with comorbidities [21] . However, there is already evidence that Delta's enhanced infectivity is increasing rates of infection among US children, concurrent with the launch of the fall 2021 semester, especially in areas with low vaccination coverage and no mask mandates [22] . While most cases in children are mild, there are rare but serious cases of long-term sequelae that persist after COVID-19 infection in children, including Multisystem Inflammatory Syndrome (MIS) [23] . Guidance issued late summer 2021 from the Centers for Disease Prevention and Control (CDC) as well as the California Department of Public Health (CDPH) urged K-12 schools to fully reopen for instruction during the fall 2021 semester with masks required indoors for all students and staff [24, 25] . Spacing of at least three feet between students is also recommended, but if this cannot be achieved, it is recommended to apply layers of additional prevention measures, such as additional asymptomatic testing, symptom screening, or hand washing. In March of 2020, the California Bay Area was among the first in the nation to close schools, moving the 2020 spring semester to remote instruction [26] . As of June 2021, California remained the state with the lowest percentage of students engaged in in-person instruction [27] , and large Bay Area school districts, including San Francisco and Oakland, launched very limited in-person activities from April to June of 2021. Previous work has estimated the effect of initial closure for the 2020 spring semester on COVID-19 cases, hospitalizations and deaths in students, teachers, family members, and community members, and has examined the effect of reopening under various strategies on COVID-19 outcomes across a new four-month semester [9] . With the 2021 fall semester forthcoming, we examine questions surrounding school reopening in the context of an increasingly vaccinated population of individuals 12 years and older. We expand a previously published model [9] to include vaccination of adults in the community, teachers/staff, and students aged 12 years and older in order to examine which additional prevention measures beyond vaccination are required to limit excess cases to fewer than two student cases per school (<50% probability of a case per month) [28] . We also estimate whether achieving high levels of within-school vaccination coverages for teachers and students over 12 years would allow schools to safely drop additional prevention measures while maintaining low transmission. Finally, we quantify the additional benefit of universal masking compared to masking only among the unvaccinated, as a function of varied vaccine effectiveness. We examine scenarios assuming circulation of the highly transmissible Delta variant, and compare to outcomes estimated for the Alpha variant.@story_separate@universal masking. Vaccination of adult community members and teachers protects unvaccinated elementary and middle school children. Elementary and middle schools that can support additional interventions, such as cohorts and testing, should consider doing so, particularly if additional studies find that younger children are equally as susceptible as adults to the Delta variant of SARS-CoV-2. Limitations: We did not consider the effect of social distancing in classrooms, or variation in testing frequency, and considerable uncertainty remains in key transmission parameters. We adapted a previously described agent-based model [9] to estimate the effect of fall 2021 reopening strategies under various vaccination coverages and SARS-CoV-2 variants, including the highly transmissible Delta variant. The model was informed by longitudinal data collected on children's social contacts, including data on post-vaccination contact rates of children and their adult family members during spring 2021 school closures. To parameterize community contact rates among the school-aged population and their adult family members within the model, we implemented a social contact survey of school-aged children in nine Bay Area counties (Alameda, Contra Costa, Marin, Napa, San Francisco, San Mateo, Santa Clara, Solano, Sonoma), as described elsewhere [9] . Survey respondents (one adult per household) reported the number and location of non-household contacts they and all of their children made within six age categories (0-4, 5-12, 13-17, 18-39, 40-64 and 65+ years) throughout the day prior. A contact was defined as an interaction within six feet lasting over five seconds [29] . Eligible households contained at least one school-aged child (pre-kindergarten to grade 12). We recruited participants using an online panel provider (Qualtrics) to be representative of Bay Area on the basis of race/ethnicity and income. The survey was implemented between February, 8 -April 1, 2021, when most (92%) of children were in remote schooling, and during a period where Bay Area healthcare workers, educators, and emergency personnel were eligible for COVID-19 vaccination. We generated 1,000 synthetic populations representative of the demographic composition of major Bay Area cities [30] , in which we assigned each individual an age, household, and occupation status (student, teacher, school staff, other employment, not employed), as well as membership in a school or workplace. We separated schools into elementary (grades K-5; ages 5-10 years), middle (grades 6-8; ages [11] [12] [13] and high (grades 9-12; ages 14-17) schools, and assigned individuals grades and classrooms within each school, based on age. All individuals interacted with all other individuals in one of six ways, according to a hierarchy of highest shared membership: household > classroom or workplace > grade > school > community [31] . Age-specific community contact rates used in the simulation were obtained from surveys of households where at least one adult was vaccinated, as these individuals from these households had higher contact rates than individuals from unvaccinated households. A discrete-time, age-structured, individual-based stochastic model was used to simulate SARS-CoV-2 transmission dynamics in the synthetic population ( Figure 1A ). At each time increment (one day), each individual was associated with an epidemiological state: fully vaccinated (V), susceptible (S), exposed (E), asymptomatic (A), symptomatic with non-severe illness (C), symptomatic with severe illness (H 1 , D 1 ) resulting in eventual hospitalization before recovery (H 2 ) or hospitalization before death (D 2 ), recovery (R) or death (M). The susceptible compartment included individuals who received the vaccine, yet remained susceptible to infection. Transmission was implemented probabilistically for contacts between susceptible (S) and infectious individuals in the asymptomatic (A) or symptomatic and non-hospitalized states (C, H1, D1). Movement of individual i on day t from a susceptible to exposed class was determined by a Bernoulli random draw with probability of success given by the force of infection, , : where N is the number of individuals in the synthetic population (N=16,000), and is the ratio of the transmissibility of asymptomatic individuals to symptomatic individuals. The fate followed by each individual after exposure was assigned from Bernoulli random draws at the start of each simulation based on age-stratified conditional probabilities ( Figure 1B ; Table S1 ). Once exposed, the duration of time spent in each disease stage were sampled from Weibull distributions (Table S1 ). Using estimates from studies evaluating risk of symptoms by age [18] , we assumed 21% of infected individuals <20 years and 69% of infected individuals 20 years and older experienced symptoms [18] . Following previous work [18] , we assumed to be less than one, as asymptomatic individuals may be less likely to transmit infectious droplets by sneezing or coughing [32]. Model schematic (A) Schematic of the agent-based susceptible-exposed-infected-recovered (SEIR) model. S, susceptible; E, exposed; A, asymptomatic; C, symptomatic, will recover; H 1 , symptomatic and will recover, not yet hospitalized; H 2 , hospitalized and will recover; D 1 , symptomatic, not yet hospitalized; D 2 , hospitalized and will die; R, recovered; M, dead; V, vaccinated effectively; λ, force of infection defining movement from S to E; η, vaccine effectiveness, θ, vaccination coverage among subgroup to which individual i belongs. Superscript i refers to individual. After an agent enters the exposed class, they enter along their predetermined track, with waiting times between stage progression drawn from a Weibull distribution. V. (B) Schematic of the conditional probabilities by which agents are assigned a predetermined track. Based on an average of R 0 for the Alpha (R 0 = 2.5) and Delta (R 0 = 5) variant weighted by the proportion of circulating variants in summer 2021 [33, 34], we calculated R 0 as 4.6 and solved for the mean transmission rate of the pathogen, ̅ , as the ratio between R 0 and the product of the infection duration and the weighted mean number of daily contacts per individual during the pre-intervention period (Supporting Information, equation 2) [35] . To understand the influence of the Delta variant, we also ran simulations assuming full coverage of the Alpha variant. To represent age-varying susceptibility [18] , we then calculated an age-stratified , that incorporated varying relative susceptibility by age while permitting the population mean to be ̅ (Supporting Information, equations 3-4). We assumed that children under 10 years of age are half as susceptible to infection as older children and adults, in accordance with prior metaanalysis and modelling work reporting lower household secondary attack rates in children as compared to adults [16] [17] [18] [19] , with the lowest secondary attack rates in children less than 10 years of age [16, 19] . Nevertheless, given that some studies report equal susceptibility across all ages [36] [37] [38] , and our current understanding of susceptibility is based largely on the Alpha variant, we also modeled scenarios without age-dependent susceptibility. The daily contact rate between individuals i and j on day t, , , was estimated for pairs of individuals following previous study [31] based on their type of interaction (e.g., household, class, community). Contact rates were scaled by a time-dependent factor between 0 (complete closure) and 1 (no intervention) representing a social distancing intervention to reduce contact between individual pairs. Pairs with a school or workplace interaction were reassigned as community interactions under closures. Because symptomatic individuals mix less with the community [39] , we incorporated isolation of symptomatic individuals and quarantine of their household members. Following prior work, we simulated a 100% reduction in daily school or work contacts and a 75% reduction in community contacts for a proportion of symptomatic individuals, and an additional proportion of their household members [40] . This means that a proportion of students and staff would stay home from school if they themselves were symptomatic, while a smaller percentage would stay home from school if one of their household members was symptomatic. We assumed that individuals were in the infectious class for up to three days prior to observing symptoms [41] , during which time they did not reduce their daily contacts. To establish the initial conditions for a new school semester, we simulated transmission continuously throughout three phases: 1) initiation of pandemic (schools open); 2) start of NPI enactment (schools closed for in-person instruction); 3) continuation of pandemic and NPIs across a long-term school closure period. This yielded 1,000 unique combinations of initial conditions. The simulated infection rates at the start of the semester ranged from 6-120 cases per 100,000, in accordance with infection rates among Bay Area counties in early August, 2021 [42] . The simulated infection seroprevalence at the start of the semester ranged from 1.5 to 10%, in line with seroprevalence data from San Francisco in late summer, 2020 [43] . Prior to simulating transmission over the school semester, a proportion of susceptible individuals aged 12 and older were moved to the vaccine compartment, according to a Bernoulli random draw with probability of success equal to the proportion vaccination coverage among the eligible population times the vaccine effectiveness. Vaccine effectiveness is set at 85% [44] for most simulations, but we also explore scenarios at lower effectiveness. We examined the effect of three non-pharmaceutical interventions across three levels of community vaccination coverage (50%, 60%, 70%), assuming that vaccination coverage within school children 12 years and older and teachers matches that in the community, and that the vaccine is 85% effective against infection [44] . First, we examined universal masking, assuming that the effectiveness of masks for reducing both inward and outward transmission [45] is 15% for elementary school students, 25% for middle school students, 35% for high school students, and 50% for teachers and staff [46] [47] [48] . Second, we examined a scenario of masking plus weekly testing of all students and teachers, in which we assumed a test with 85% sensitivity was administered every 7 days with 1 day to get results back [49] . We then assumed that the classroom and the household members of a positive test stayed home from school/work for 14 days and reduced community contacts by 75%. Third, we examined a masking plus cohort scenario in which classroom groups of 20 students were assumed to contact each other freely, with individuals within the cohort reducing their contacts with individuals outside their cohorts by 75%. While all of the nine Bay Area counties have achieved vaccination coverages of at least 60% as of summer, 2021, and some over 80% [50], we include the lower 50% to make the findings more generalizable to areas outside the Bay Area who may otherwise have similar demographics. Next, we considered within-school vaccination coverage in the absence of within-school NPIs (masking, testing, cohorting). We assumed a community vaccination coverage among the eligible population of 70%, which represented a conservative level of vaccination coverage among a Bay Area county [50] . We then examined COVID-19 outcomes if students 12 and older and teachers/staff had higher vaccination coverages (ranging from 70% to 95% coverage). Finally, we estimated the additional cases averted in each population by masking the entire student and teacher population, compared to masking only the unvaccinated student and teacher population, in the absence of additional interventions. We held community and within-. CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted August 23, 2021. ; school vaccination coverage of the eligible (12+) population at 70%, and varied vaccine effectiveness from 45% to 85%. We evaluated two primary outcomes. Our first primary outcome was the increase in the total number of symptomatic infections among students and teachers/staff between in-school and remote instruction over a 128-day semester. We refer to this outcome as the excess symptomatic infections attributable to school transmission. We also examined the increase in the total number of all infections and hospitalization among students and teachers over the 128-day period between in-school and remote instruction. Our second primary outcome was the minimum set of interventions required to maintain total excess infections among students and teachers attributable to school transmission below risk tolerances that may be relevant to decision-makers. We considered three school populationbased risk tolerances, that varied in leniency from <5 to <50 additional cases per 1,000 school population. Following prior study, we examined a school-based risk tolerance of a monthly probability of an in-school transmission below 50% (<2 excess cases per school) [28]. We examined outcomes among population subgroups, focusing on students and teachers/staff, stratified by schooling level. We summarized all outcomes using the mean, median, and the 89 th percentile highest probability density interval (HPDI) across the 1,000 model realizations. 89% intervals are deemed to be more stable than the 95% intervals [51, 52] . Ethical approval was obtained from the Office for Protection of Human Subjects at the University of California, Berkeley (Protocol Number: 2020-04-13180). Prior to taking the anonymous survey, parents were provided details of the study and asked to provide written informed consent. We estimated higher rates of excess illness among elementary and middle school students as compared to high school students across all combinations of NPIs tested (Table 1; Table S6 ; Figure 2 ). Excess illness was also higher among elementary and middle school teachers, as compared to high school teachers, but differences between schooling levels were smaller among teachers as compared to students (Table S6; Figure 2 ). Increasing community and school vaccination coverage reduced excess illness attributable to school transmission among all populations, but particularly among the vaccine-eligible population (i.e., teachers and high school students) (Figure 2 ), both in the absence and presence of additional NPIs. Upon achieving a 70% community vaccination coverage or higher (the coverage observed in May 2021 in most Bay Area counties)[50] and without additional NPIs, we estimated the average excess incidence rate as between 4-9 symptomatic cases per 100 students across all age groups ( Figure 2 ). Expressed as excess cases per school attributable to school transmission, this amounts to an estimated 27 excess cases per high school, 37 excess cases per middle school, and 25 excess symptomatic cases per elementary school across a 128-day semester (Table 1) . Tables S2 and S3 display results for 50% and 60% vaccine coverage. Full results for symptomatic and asymptomatic infection are included in Tables S6 and S7 . Under the most likely reopening scenario for Bay Area schools -dominant circulation of the Delta variant, vaccination coverages of at least 70% and universal masks (Table 1; Figure 3 )we estimated an excess of eight symptomatic cases per elementary school, 13 cases per middle school, and three cases per high school attributable to school transmission over a 128-day semester. This equates to school-attributable illness in an additional 2.0% of elementary school students, 3.0% of middle school students, and 0.4% of high school students owing to school transmission. We estimated that an additional 1.7% of elementary school teachers, 3.1% of middle school teachers, and 0.7% of high school teachers would experience symptomatic infection attributable to school transmission across a semester. While children <12 years remain ineligible for vaccination, increasing vaccination among the community and teachers lowered risk of asymptomatic and symptomatic illness among young children. As simulated community vaccination coverage of the eligible population increased from 50% to 60% to 70%, we estimated that the estimated percent of elementary school children with a school-attributable symptomatic illness fell from 8.7% to 7.8% to 6.6%, representing a 24% decline in school-attributable transmission. This suggests that adult to child transmission represents an important source of school-attributable illnesses ( Figure 2 ). Within-school NPIs were most effective at reducing excess symptomatic cases within elementary and middle schools regardless of levels of community vaccination coverage, and within high schools with lower community vaccination coverages ( Figure 2 ). For instance, where community vaccine coverage was 50% and no additional NPIs were taken, we estimated an excess incidence of 8.7 cases (89% HPDI: 2.9, 13.2) per 100 students in elementary schools, 12.5 (89% HPDI: 8.8, 16.6) per 100 students in middle schools and 9.6 per 100 students in high schools (89% HPDI: 6.5, 13.2). Adding masks but holding vaccine coverage constant, we estimated an excess incidence of 3.1 cases (89% HPDI: 0, 5.9) per 100 elementary students, 5.6 cases (89% HPDI: 0, 10.4) per 100 middle school students, and 2.0 (89% HPDI: -0.2, 4.4) cases per 100 high school students. We examined the effect of three non-pharmaceutical interventions across three levels of community vaccination coverage (50%, 60%, 70%), assuming that vaccination coverage within school children 12+ and teachers matches that in the community and the vaccine effectiveness is 85% against symptomatic infection. Masks indicate universal masks regardless of vaccination status. We calculated the mean (stars) and median (diamonds) of excess cases per 100 persons attributable to school transmission among population subgroups across 1,000 model realizations. Vertical lines reflect the 89 th percentile high probability density interval (HPDI). . It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. We projected the excess risk under the specific scenario likely to be observed during the Fall 2021 semester for the California Bay Area: 70% vaccination coverage among the eligible population and universal mask wearing among all teachers and students. We assume 85% vaccine effectiveness against symptomatic infection. The mean (stars) and median(diamonds) of excess cases per 100 persons attributable to school transmission among population subgroups across 1,000 model realizations. Vertical lines reflect the 89 th percentile high probability density interval (HPDI). . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; Across all model interventions scenarios and populations, hospitalizations and deaths were rare among students, but we simulated hospitalization in all scenarios except those that combined high vaccination (70%) with masks and cohorts. We simulated the highest estimated hospitalization rates among students of all grade levels when no NPIs were modelled. Following published estimates of age-dependent case hospitalization rate [53] , our model assumes a higher probability of hospitalization among individuals aged 10 to 20 years compared to individuals under 10 years (Table S1 ). The maximum hospitalization rate simulated was 4.8 hospitalizations per one million middle school students over the 128-day semester, under 50% vaccination coverage and no additional precautions. The highest hospitalization rate simulated among elementary school students was 1.3 hospitalizations per one million elementary school students, under the same conditions, assuming elementary children are equally susceptible to infection as older children and adults. Simulated interventions combining masks and cohorts yielded hospitalization rates for the four-month semester under 3 per 10 million students, regardless of assumptions about susceptibility. We estimated higher hospitalization rates among teachers and other school staff as compared to students. Under a 70% vaccine coverage scenario, excess hospitalizations among teachers was 48.6 per 100,000 teachers over the 128-day semester (daily rate: 0.40 per 100,000) without NPIs ( Table 2 ). With the current universal mask recommendation, the excess hospitalization rate was 12.6 per 100,000 teachers per semester, or 0.09 per 100,000 per day. Adding a cohort approach to masking reduced the estimated excess hospitalization rate to 1.4 per 100,000 teachers per semester. Effect of increasing vaccination among the school population in the absence of other interventions We examined under what vaccination coverages, if any, it might be possible to have a return to schooling without any additional NPIs ( Figure 4 ). Increasing vaccination coverage of the eligible school population from 70% to 95% reduced mean estimates of excess cases among elementary students, suggesting that increasing vaccination coverage among elementary school teachers can reduce the force of infection among their students. For instance, increasing the vaccination coverage of the eligible school population (here, teachers) from 70% to 95% reduced the . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; estimated excess rate of infection from 6.6 (89% HPDI: 0, 11.5) to 3.9 (89% HPDI: -0.2, 9.2) symptomatic cases per 100 elementary students across the four-month semester, representing a reduction of 41%. At the same time, increasing vaccination of teachers/staff from 70% to 95% reduced the estimated excess rate of infection among elementary teachers from 8.2 (89% HPDI: 0, 15.1) to 2.3 (89% HPDI: -0.9, 6.0) symptomatic cases per 100 teachers across the four-month semester, representing a reduction of 71%. While increasing within-school vaccine coverage indirectly reduced infections among elementary and middle school students, the effect of increasing within-school vaccination coverage was most pronounced among high school students and teachers of all grade levels. Only high school teachers and students could achieve a transmission tolerance of fewer than 10 excess cases per 1,000 population attributable to school transmission using vaccination only without NPIs (Table  3 ). At 70% coverage of the eligible school population, we estimated an excess of 4.0 (89% HPDI: 0, 7.1) symptomatic cases per 100 students and 10.4 (89% HPDI: 0, 21.5) per 100 teachers across the 128-day semester, and at 95% coverage an excess of 0.2 (89% HPDI: -0.2, 0.6) cases per 100 students and 0.6 (89% HPDI: 0, 3.8) per 100 teachers across the 128-day semester ( Figure 4 ). Among high school students and teachers/staff, we estimated a median of zero excess infections across the 1,000 model realizations when within-school coverages exceeded 90%. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; Figure 4 . We examined the effect of increasing vaccination coverage among school populations, in the absence of additional non-pharmaceutical interventions, and holding community and within-school vaccination coverage of the eligible (12+) population at 70%. We calculated the mean (stars) and median(diamonds) of excess risk per 100 persons attributable to school transmission among population subgroups across 1,000 model realizations. Vertical lines reflect the 89 th percentile high probability density interval (HPDI). . It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. We examined whether layering NPIs or increasing within-school vaccination could reduce incidence attributable to school transmission below specific risk tolerances (Table 3) . We estimated that universal masking and 70% community and within-school vaccination coverage or higher could reduce the number of excess cases attributable to school transmission to <50 per 1,000 students and teachers across all grade levels. In high school students, increasing the vaccine coverage among the vaccine-eligible school population above 70% could also reduce excess transmission to <50 per 1,000 students and teachers in the absence of NPIs. However, achieving lower risk levels among elementary school students-e.g., <10 cases per 1,000 students or teachers-required additional NPIs, such as testing or cohorts, and was not achievable through the NPIs investigated here if children under 10 years are equally as susceptible as adults. On a per school basis, reducing the excess cases attributable to school transmission to fewer than two cases per school across the full semester (i.e., <50% probability of a case per school per month) required both masks and cohorts. Among high schools, achieving this risk tolerance required combining masks with testing. Tables S2 and S3 display the minimum NPIs required to achieve the various risk tolerances assuming 50% and 60% vaccine coverage in the eligible community, respectively. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; Table 3 . The minimum non-pharmaceutical intervention(s), or minimum within-school vaccination coverage of the eligible population, needed to reduce the risk of symptomatic infection to beneath a given risk level (e.g., 50 cases per 1,000 population), assuming that 70% of the vaccine-eligible community has received a vaccine at 85% effectiveness. 'Not observed' indicates that no combination of interventions examined in this study reduced excess risk beneath the indicated threshold. Masks refers to universal masking regardless of vaccination status. Population-wide risk tolerance -symptomatic cases per 1,000 population Effect of masking all individuals in a school compared to masking only unvaccinated individuals We compared the differences in school-attributable transmission under scenarios where only unvaccinated individuals wore masks compared to if all individuals masked, across different levels of vaccine effectiveness (VE), assuming 70% of the eligible population is fully vaccinated ( Figure 5 ). Since all elementary students are unvaccinated, such a rule would change behaviors only among the vaccinated teachers, about 5% of the overall school population. In contrast, such a rule would affect the entirety of the vaccinated high school population, both students and teachers, about 70% of the overall school population. The difference between masking the entire student and teacher population as compared to only the unvaccinated school population is thus most apparent in middle and high school populations, and at lower VEs. For instance, given 45% VE, masking all middle and high school students and teachers would avert symptomatic infection for 3.9% of middle school students, 6.1% of high school students, 12.5% of middle school teachers, and 18.5% of high school teachers compared to masking only unvaccinated students and teachers. At 85% VE and above, there was little difference in school-attributable transmission between masking unvaccinated persons versus masking all persons. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; Figure 5 . We estimated the additional cases averted in each population by masking the entire student and teacher population, compared to masking only the unvaccinated student and teacher population, in the absence of additional interventions. We held community and within-school vaccination coverage of the eligible (12+) population at 70%, and varied vaccine efficacy (VE). We calculated the mean (stars) and median(diamonds) of excess risk per 100 persons attributable to school transmission among population subgroups across 1,000 model realizations. Vertical lines reflect the 89 th percentile high probability density interval (HPDI). Shaded bars and right axis reflect the vaccinated percent of the school population, for whom a universal masking rule as compared to a masking rule among the unvaccinated would apply. We found that the excess risk in elementary schools is substantially altered if children under 10 years of age are considered equally as susceptible to SARS-CoV-2 as older children and adults when compared with half as susceptible (Figures 2 and 3; Tables 1 and 3 ). Under the current Bay Area reopening scenario (70% coverage + masks), the estimated number of within-school infections due to school transmission jumps from 8 to 36 cases per 380-person elementary school over the four-month semester under equal susceptibility assumptions. This corresponds to excess illness attributable to schools among 9.7% (89% HPDI: 1.2, 15.7%) of elementary students and among 6.1% (89% HPDI: 0, 1.2%) of elementary teachers. Only the most lenient risk tolerance of <50 excess infections per 1,000 elementary students (5%) was achievable with the combination of interventions examined here. The strictest combination of interventions tested (masks + cohorts, 70% vaccine coverage), would result in excess infection among 1.7% (89% HPDI: -0.2, 4.2) of elementary students, and 0.8% (89% HPDI: -0.9, 3.4) of elementary teachers. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; The relative susceptibility of younger children to infection remains under debate, and the natural history parameters for emerging variants is evolving. Should younger children be as susceptible to SARS-CoV-2 as older children and adults, masking alone may not be sufficient to achieve low rates of transmission among elementary school populations. Our results were highly sensitive to the proportion of variants of concern circulating. We examined outcomes if the Alpha variant had remained the dominant variant (R 0 = 2.5), finding school attributable excess transmission to be nearly ten times lower than under circulation of the Delta variant when examining the most likely reopening scenario for this fall (70% vaccine coverage and universal masks) ( Figure S1 ; Table S8 ). Under this scenario, we estimated fewer than one additional infection per school (<25% probability of an in-school transmission per month). At the level of community vaccination coverage observed in the Bay Area (70% coverage or higher), the most lenient risk tolerance of <50 additional cases per 1,000 students, was achievable without additional NPIs (Table S8 ; Figure S1 ). Under this no-NPI scenario, risk to the student population was estimated at 1 excess case per high school, 4 excess cases per middle school, and 1-5 excess cases (depending on susceptibility to SARS-CoV-2) per elementary school. We estimated that high schools could achieve very strict risk tolerances (<1 excess cases in 1,000 students) without any additional NPIs as long as vaccination coverage among the eligible school population exceeded 75% (Table S9) . We also projected fewer hospitalizations and deaths if the Alpha variant had remained the dominant variant. Under full circulation of the Alpha variant, we did not observe hospitalizations among students and observed very few hospitalizations among teachers within our model realizations. Under a 70% vaccine coverage scenario, excess hospitalizations among teachers was 23 per 100,000 (daily rate: 0.19 per 100,000) without any NPIs. When any school interventions were present (e.g., masking) under a 70% vaccine coverage scenario, our model realizations observed fewer than 1 excess teacher hospitalization per 100,000 teachers attributable to school transmission over the semester. We simulated transmission of the Delta variant of SARS-CoV-2 in schools over an upcoming school semester with variable vaccine coverages within the school and community populations to approximate conditions that may be observed in the fall of 2021. Aligning with current CDPH and CDC reopening guidelines [24], which urge a full return to in-person schools with vaccination and universal mask usage, we estimated that an additional 0.4 to 3% of students, depending on schooling level, would experience symptomatic illness attributable to schools across the four month semester, with similar rates estimated for teachers ( Figure 3 ). Under these scenarios, we estimated a daily school-attributable hospitalization rate as 0.09 per 100,000 teachers per day ( Table 2 ). Vaccination is recognized by the CDC and CDPH as the leading public health strategy for reducing within-school transmission [24, 25], and our results highlight . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; that increased vaccination coverage-both among the general community and among the eligible school population-plays an essential role in limiting symptomatic illness attributable to school transmission. Our findings support the use of universal masks as precaution within schools, particularly elementary and middle schools, but also high schools that have within-school vaccine coverage <90%. Masks are supported as one of the simplest, yet effective, mitigation strategies [24, 25] . Masking is of particular importance for elementary and many middle school students who remain ineligible for vaccination; we estimated that a typical 380-person elementary school and 420-person middle school could see 25 and 37 symptomatic cases, respectively, of COVID-19 over the four-month semester under a reopening plan that did not involve masking (or other NPIs) and where community vaccination coverage is 70%. Using masks, even those that are only 15-25% effective, reduced that risk in our simulations to eight cases per elementary school and 13 per middle school per semester. Nevertheless, achieving lower risk tolerances, such as fewer than ten additional schoolattributable infections per 1,000 school population, required adding additional layers of protection, e.g., reduced contact between students via cohorting. This suggests that schools may want to consider additional precautions above and beyond the minimum requirement of masks. For instance, schools that can implement a cohort approach, or provide regular testing, should consider doing so. We estimated that high school students were at lower risk of infection, assuming vaccination rates among students matched those of the surrounding community, but nevertheless may require both masking and weekly testing to achieve a transmission probability of <50% per school per month. Uncertainty was greatest among middle school and high school teachers and students, in part because pockets of low vaccine coverage within these environments can be sufficient to support occasional outbreaks. In our model, vaccine coverage was distributed randomly throughout the full population, such that some school realizations had vaccination coverage of teachers or students well below 50%, where transmission was possible. This represents reality, where certain school populations may have lower vaccination coverages than others. Increased vaccine coverage of community members and teachers helped reduce illness among children not yet age-eligible for vaccination. We estimated that increasing vaccination coverage of the general population reduced the excess risk of transmission by 24% among elementary students. Similarly, we estimated that increasing vaccination coverage among teachers from 70% to 95% reduced the excess risk of school transmission by 41% among elementary students. This suggests that teacher to student transmission is an important route of transmission that can be eliminated by increased vaccination. This study has limitations. First, community contact rates measured in the survey may reflect underestimates of actual community contact rates, as vaccination prevalence has increased since February -April of 2021 and community contacts increased with vaccination prevalence (survey data). Thus, our estimates of excess cases attributable to school transmission may be slight . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; underestimates. Nevertheless, our previous work has shown that the effect of community transmission is minimized when within-school precautions are implemented [9] . Second, our transmission model does not capture all the precautions outlined in CDC guidance, including the effect of spacing desks three feet apart, or handwashing. Such precautions are difficult to model using a contact-based transmission model, and thus our estimates may overestimate risk if schools continue to emphasize such measures. Moreover, testing is an important component of the CDPH plan for return to in-person schooling. While we including testing as a potential NPI, we do not thoroughly investigate various testing routines that yield the optimal benefit, as does other work [54] . Third, most of our model simulations assume a high vaccine effectiveness against symptomatic COVID-19. Vaccine effectiveness may change as novel variants emerge and circulate; however, early studies indicate that vaccine effectiveness against variants of concernincluding Delta-generally remain high [55] . Fourth, our initial conditions for seroprevalence in the synthetic population encompassed published 2020 seroprevelance estimates for the Bay Area, so may represent an underestimate of the true seroprevalence in the community as of 2021. If so, our modelled estimates of excess cases may represent a slight overestimate. Finally, our modelling results are sensitive to assumptions about the values for certain parameters, such as relative susceptibility of children to SARS-CoV-2, for which there remains high uncertainty. As the Delta variant poses unseen challenges to school communities, we do not have empirical data to support our model results. However, our estimates of the school-attributable risk are consistent with that reported by another modelling study [28] , and consistent with increasing rates of infection among children, particularly in parts of the country with low vaccination coverage and no mask mandates in schools [22] . The copyright holder for this preprint this version posted August 23, 2021. ; Table S3 . The number of excess student cases attributable to school transmission expected across a four-month semester, for 60% community vaccination coverage. .............................................................. 4 Table S4. The minimum non-pharmaceutical intervention needed to reduce the risk of symptomatic infection to beneath a given threshold (e.g., 50 cases per 1,000 population), assuming that 50% of the vaccine-eligible community has received a vaccine at 85% effectiveness. 'Not observed' indicates that no combination of interventions examined in this study reduced excess risk beneath the indicated threshold. ................................................................................................................................................. ..... 5 Table S5 . The minimum non-pharmaceutical intervention to reduce the risk of symptomatic infection to beneath a given threshold (e.g., 50 cases per 1,000 population), assuming that 60% of the vaccineeligible community has received a vaccine at 85% effectiveness. 'Not observed' indicates that no combination of interventions examined in this study reduced excess risk beneath the indicated threshold. . . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; Table S1 . Parameters of the susceptible-exposed-infected-recovered model . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; https://doi.org/10.1101/2021.08.20.21262389 doi: medRxiv preprint . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; https://doi.org/10.1101/2021.08.20.21262389 doi: medRxiv preprint Table S4 . The minimum non-pharmaceutical intervention needed to reduce the risk of symptomatic infection to beneath a given threshold (e.g., 50 cases per 1,000 population), assuming that 50% of the vaccine-eligible community has received a vaccine at 85% effectiveness. 'Not observed' indicates that no combination of interventions examined in this study reduced excess risk beneath the indicated threshold. Table S5 . The minimum non-pharmaceutical intervention to reduce the risk of symptomatic infection to beneath a given threshold (e.g., 50 cases per 1,000 population), assuming that 60% of the vaccine-eligible community has received a vaccine at 85% effectiveness. 'Not observed' indicates that no combination of interventions examined in this study reduced excess risk beneath the indicated threshold. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; We developed a discrete-time, age-structured individual-based stochastic model to simulate COVID-19 transmission dynamics in the synthetic population ( Figure 1A ). At each point in time, representative of one day, each individual is associated with an epidemiological state: successfully vaccinated (V), susceptible (S), exposed (E), asymptomatic (A), symptomatic with non-severe illness (C), symptomatic with severe illness (H1, D1) resulting in eventual hospitalization before recovery (H2) or hospitalization before death (D2), recovered (R), or dead (M). Model parameters are in Table S1 . The daily contact rate between individuals i and j on day t, , , was estimated for pairs of individuals, for school interacion for workplace interaction for community interaction where the scaling ratios between classes, grades, and schools were obtained from previous study on transmission in various settings. [15] Community interaction represents the number of contacts expected between individuals from age groups of individuals i and j scaled by the number of individuals in the age group of individual j. ( , , ) is a factor between 0 and 1 representing a social distancing intervention to reduce contact between individual pairs, and is equal to one under a no-intervention scenario. Because symptomatic individuals mix less with the community [16] , we simulated a 100% reduction in daily school or work contacts and a 75% reduction in community contacts for a proportion (48%) of symptomatic individuals, and an additional proportion (50%) of their household members. [17] For these individuals, ℎ ( , , ) and ( , , ) is equal to 0 and ( , , ) is equal to 0.25, if: 1) either individual i or j is symptomatic (C, H1, or D1) on day t and isolates with some probability, or 2) either individual i or j is a household member of a symptomatic individual on day t and quarantines with some probability; and otherwise equal to 1. We assumed that individuals were in the infectious class for up to 3 days prior to observing symptoms [18] , during which time they did not reduce their daily contacts. Transmission was implemented probabilistically for contacts between susceptible (S) and infectious individuals in the asymptomatic (A) or symptomatic and non-hospitalized states (C, H1, D1). Movement of individual i on day t from a susceptible to exposed class is determined by a Bernoulli random draw with probability of infection per day given by the daily force of infection, λ i,t : . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 23, 2021. ; where α is the ratio of the force of infection between asymptomatic and symptomatic individuals; and is calculated from ̅ , the population mean transmission rate of the pathogen. ̅ is determined using the next-generation matrix method [19] as: where R 0 is the basic reproduction number (defined as the expected number of secondary cases from a single infected case in a completely susceptible population); p s is the proportion of agents destined for state s; d I is the average time between infection and recovery for tracks A and C; d H is the average time between infection and hospitalization for tracks H and D; and ̅ is the mean number of contacts an individual makes daily under no interventions, weighted by their probability of being contacted. [20] Here, we calculated R 0 as 4.6, based on an average of R 0 for the Alpha (R 0 = 2.5 and proportion = 16%) and Delta variant (R 0 = 5.0 and proportion = 84%), weighted by the proportion of circulating variants in summer 2021 [1, 2] . We represent age-varying susceptibility [9] using an age-stratified β i that incorporates the ratio of the susceptibility of adults to children and jointly solves equations (3) and (4):  The duration of the latent period, d L , for each individual transitioning from class E was drawn from a Weibull distribution with mean 5.4 days (95% CI: 2.4, 8.3). [3] [4] [5] Whether an individual remained asymptomatic, or was hospitalized, or died was determined via Bernoulli random draws from agestratified conditional probabilities ( Figure 1B , Table S5 ). The time to recovery for non-hospitalized cases (mean: 13.1 days, 95% CI: 8.3, 16.9) [6] , the time to hospitalization for severe cases (mean: 10.3, 95% CI: 6.5, 13.3) [7] , and time to recovery or death for hospitalized cases (mean: 14.4, 95% CI: 11.3, 16.6) were sampled from Weibull distributions (Table S5) . [8] Description of reopening strategies In this scenario, schools are open under a business-as-usual scenario. For all interactions, ( , , ) = 1. The average class size is 20 students, the average sizes of elementary (K -5), middle (6) (7) (8) , and high schools (9) (10) (11) (12) are 380, 420, and 620 students. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted August 23, 2021. ; Effect of within-school precautions under various community vaccination coverages -Alpha variant High school teacher 0.1 (-2, 1.9) 0 0 (-1.9, 1.9) 0 0 (-1.9, 1.9) 0 16 Figure S1 . We examined the effect of masks across three levels of community vaccination coverage (50%, 60%, 70%), assuming circulation of the Alpha variant only, and that the vaccine effectiveness is 85% against symptomatic infection. We examined the results across two assumptions about the susceptibility of children (children <10 half as susceptible to SARS-CoV-2 as those 10+ vs. equally susceptible across all ages). We calculated the mean (stars) and median (diamonds) of excess cases per 100 persons attributable to school transmission among population subgroups across 1,000 model realizations. Vertical lines reflect the 89 th percentile high probability density interval (HPDI). Interventions required to reduce incidence attributable within schools below certain risk thresholds -Alpha variant   Table S9 . The minimum non-pharmaceutical intervention(s), or minimum within-school vaccination coverage of the eligible population, needed to reduce the risk of symptomatic infection to beneath a given threshold (e.g., 50 cases per 1,000 population), assuming that 70% of the vaccine-eligible community has received a vaccine at 85% effectiveness. Simulations examine circulation of the Alpha variant alone. Masks or 85% withinschool coverage *not observed under the specific combination of interventions simulated **Assuming a 380-person elementary school, 420-person middle school, and 680-person high school@story_separate@Our findings support recommendations made by CDC and CDPH to fully reopen K-12 schools for the Fall 2021 semester; encourage high levels of vaccine uptake among eligible students and staff; and maintain mask usage, particularly among the unvaccinated elementary and middle school populations and high school populations with vaccine coverage <90%. Vaccination remains the most effective and sustainable means of risk reduction and efforts should focus on increasing vaccination coverage among the eligible community members and school population. Among populations not yet eligible for vaccination and communities with lower vaccination coverage, prevention measures, such as masking, may be needed to reduce the risk of school outbreaks. Schools may consider layering testing or cohorting as additional safety measures, particularly as the Delta variant takes hold. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.","Abstract Background: We examined school reopening policies amidst rising transmission of the highly transmissible Delta variant, accounting for vaccination among individuals aged 12 years and older, with the goal of characterizing risk to students and teachers under various within-school non-pharmaceutical interventions (NPIs) combined with specific vaccination coverage levels. Methods: We developed an individual-based transmission model to simulate transmission of the Delta variant of SARS-CoV-2 among a synthetic population, representative of Bay Area cities. We parameterized the model using community contact rates from vaccinated households ascertained from a household survey of Bay Area families with children conducted between February - April, 2021. Interventions and outcomes: We evaluated the additional infections in students and teachers/staff resulting over a 128-day semester from in-school instruction compared to remote instruction when various NPIs (mask use, cohorts, and weekly testing of students/teachers) were implemented in schools, across various community-wide vaccination coverages (50%, 60%, 70%), and student ([≥]12 years) and teacher/staff vaccination coverages (50% - 95%). We quantified the added benefit of universal masking over masking among unvaccinated students and teachers, across varying levels of vaccine effectiveness (45%, 65%, 85%), and compared results between Delta and Alpha variant circulation. Results: The Delta variant sharply increases the risk of within-school COVID transmission when compared to the Alpha variant. In our highest risk scenario (50% community and within-school vaccine coverage, no within-school NPIs, and predominant circulation of the Delta variant), we estimated that an elementary school could see 33-65 additional symptomatic cases of COVID-19 over a four-month semester (depending on the relative susceptibility of children <10 years). In contrast, under the Bay Area reopening plan (universal mask use, community and school vaccination coverage of 70%), we estimated excess symptomatic infection attributable to school reopening among 2.0-9.7% of elementary students (8-36 excess symptomatic cases per school over the semester), 3.0% of middle school students (13 cases per school) and 0.4% of high school students (3 cases per school). Excess rates among teachers attributable to reopening were similar. Achievement of lower risk tolerances, such as <5 excess infections per 1,000 students or teachers, required a cohort approach in elementary and middle school populations. In the absence of NPIs, increasing the vaccination coverage of community members from 50% to 70% or elementary teachers from 70% to 95% reduced the estimated excess rate of infection among elementary school students attributable to school transmission by 24% and 41%, respectively. We estimated that with 70% coverage of the eligible community and school population with a vaccine that is <65% effective, universal masking can avert more cases than masking of unvaccinated persons alone. Conclusions: Amidst circulation of the Delta variant, our findings demonstrated that schools are not inherently low risk, yet can be made so with high community vaccination coverages and universal masking. Vaccination of adult community members and teachers protects unvaccinated elementary and middle school children. Elementary and middle schools that can support additional interventions, such as cohorts and testing, should consider doing so, particularly if additional studies find that younger children are equally as susceptible as adults to the Delta variant of SARS-CoV-2. Limitations: We did not consider the effect of social distancing in classrooms, or variation in testing frequency, and considerable uncertainty remains in key transmission parameters."
"In December 2019, there was an outbreak of pneumonia of unknown etiology in the city of Wuhan, in the Hubei province. A new coronavirus was identified as the causal agent, and it was denominated COVID-19 by the World Health Organization (OMS). Considered to be from the same family as severe acute respiratory syndrome (SARS) and Middle Eastern respiratory syndrome (MERS), COVID-19 is caused by a betacoronavirus called SARS-CoV-2. This affects the lower respiratory tract and manifests as pneumonia in humans [1] . At the time of conducting the present research work, a large section of the global population is in confinement due to the COVID-19 pandemic caused by the SARS-CoV-2 virus [2] . As indicated by Guernsey et al. [3] , the phenomenon of online learning has emerged during the COVID-19 health crisis. Many schools have offered virtual learning to their students [4] as a tool for continuing education during the rest of the academic year. These teachers have been previously shown to reject online learning due to the struggles and challenges faced by teachers in trying to balance teaching [5] or difficulties caused by the technology available to students. The type of activities they and resources, in addition to sufficient time to gradually adapt to changes and be able to achieve success [23] . In addition to the emotions arising as a result of being enclosed and the family context, Kyriacou [24] states that teachers tend to experience higher stress levels than workers in other professions. This could affect their wellbeing, motivation, work satisfaction, and commitment, in different ways. According to Collie et al. [25] , teachers' perceptions in relation to work are fundamental for their psychological functioning. The adaptive situation of confinement may cause students to experience psychological effects which generate high levels of stress, anxiety, and depression [26, 27] . In this way, students are also dealing with an array of feelings as a consequence of confinement itself, whilst also having to respond to work demands. The intensity and quality of emotional relationships in this professional sector, according to Frenzel et al. [28] , will depend on the judgements made by each individual about an event, in regard to its novelty or the capacity of control they have over it. University students preparing themselves to be schoolteachers live this double dimension of teaching in their teaching placements. Further, psychological settings in adaptive contexts are becoming more interesting to study due to the fact that teachers in training must tackle the context of teaching whilst, at the same time, tackling the challenges of being a student who is still learning [29] . In this sense, work demands are described as physical, psychological, social, or organizational aspects of work, which require sustained effort or physical and/or psychological (cognitive and emotional) skills [30] . Work demands are not necessarily negative, although they can act as sources of stress when extreme effort on the behalf of employees is required to satisfy these demands [31] . As a function of that previously presented, the objectives and novel contribution of the present study are as follows: (1) Design and validate an instrument in order to analyze the impact of learning environments and psychological factors on university students during a teaching placement in adaptive contexts (confinement). This is important because no instrument currently exists to examine these parameters. (2) Determine potential associations between learning and psychological settings in adaptive contexts in relation to sex and other grouping variables to which they belong (primary education, physical education and sport, early education, or social education). This is relevant given that studies exist which state that females have a greater risk of suffering depression in confinement contexts [27] .@story_separate@The present study employed a social-analytical and empirical research method. It is descriptive in nature and uses quantitative analysis [32] . We analyzed group differences between associations in relation to learning environments and psychological factors in adaptive contexts, according to sex (male and female) and the subject being undertaken (primary education, physical education and sport, early education, or social education). Participants were selected through convenience sampling. Fifteen groups were selected (from a group of 15) from groups of education students training to be future teachers. Participants came from the University of Granada in Andalusia, Spain. In total, 441 students participated in the present study. The final sample was selected through non-probability (convenience) sampling used to select a sample of (28.2%) students enrolled on an Early Learning degree course, (30.8%) students enrolled in a Primary Education course, (19.4%) students enrolled on a Social Education, and (21.6%) students enrolled of physical activity and sport. This provided a total of 441 future teachers from Andalusia (University of Granada, Spain). Students were attending the fourth year of Primary Education, Social Education, Physical Activity and Sport, or Early Learning degree courses and were completing the placement period at the time of conducting the research. Participants had an average age of 22.73 years (Standard deviation (SD) = 3.688). Of these, 34.1% were male and 65.9% were female; 16.24% were females and 10.06% were males undertaking a degree in Primary Education, 10.69% were females and 16.39% males undertaking a degree in Physical Activity and Sport, 20.58% were females and 5. 48% males undertaking a degree in Early Learning, and 18.39% were females and 2.17% males undertaking a degree in Social Education. The questionnaire was administered to individuals who indicated an express desire to participate and provided written informed consent. Each student to participate in the present study was administered the questionnaire, which was based on the questionnaire developed by Olmedo [33] [34] [35] [36] . Development of the tool adhered to general theoretical guidelines for the construction of psychometric tests [37] . Responses were provided along a Likert-type scale which ran from 1 to 4, pertaining to ""totally disagree"" and ""totally agree"". In order to check interpretation and clarity of items, a preliminary version of the questionnaire was administered within a similar educational center to that included in the final study. Modifications were made to the initial design, eliminating elements that were detected as difficult to understand. This led to three of the original 30 items being removed from the questionnaire. The tool addressed basic principles taken from other international models from Italy and the USA. A group of students (n = 41), with similar characteristics to those of the sample used in the present study, were asked to indicate the elements with which they felt they most identified. Following the collection of this information, we proceeded to the process of content validity via an expert panel. Seven experts with PhDs in research fields related to that of the present study evaluated the instrument using the Delphi method [38] . They highlighted any element that they considered to be incomprehensible, whilst also examining the congruence, adequacy and belonging of each item. The final version of the adapted instrument was developed in the exploratory phase. To this end, three rounds of analysis were conducted by the expert panel. The agreement percentage for the first round was 78%, 81% in the middle round, and 91% in the final round. Following this, exploratory validity analysis was conducted. The final questionnaire comprised 26 questions, divided between four dimensions (factors). The instrument was split into two parts. In the first phase, participants were requested to provide their personal information. This included the reference group to which they belonged, sex, age in years, and religion. Informed consent was provided following receipt of a full explanation about the way in which data collected by the tool would be used. The second part included questions about the frequency with which participants' opinions were expressed. Opinions were provided in respect to elements expressed on a 4-point Likert scale (from ""totally disagree"" to ""totally agree""). Explanatory factor analysis (EFA) was applied in order to examine the construct validity of the instruments. The Kaiser-Meyer-Olkin (KMO) index was calculated and produced a highly acceptable result of 0.907. The sphericity test was used to ensure that an acceptable significance level was achieved, with a value of 0.000 being obtained. This permitted us to proceed to factor analysis. We applied the Scree criterion and yielded 4 factors. Finally, from the variance table for the varimax rotated matrix component, we were able to obtain variance results for all analyzed variables. Results of the previously described analysis identified the existence of four factors, explaining 75.673% of overall variance. We estimated reliability through the Cronbach alpha. This produced a value of 0.934 from the scores provided on the scale when using testing for ordinal data. Considering the data according to factors, for factor 1 a value of 0.92 was obtained, with values of 0.918, 0.913, and 0.895 obtained for factors two, three, and four, respectively [39] . Next, we conducted confirmatory factory analysis (CFA) using the method of structural equation modeling (SEM). From this, we examined the multivariate regression coefficients produced from the structural equations [40] . Evaluation of data fit to the developed model was conducted in accordance with the following criteria: Chi-squared and degrees of freedom (χ 2 /df), comparative fit index (CFI) and root mean square error of approximation (RMSEA). CFA results confirm adequate fit of the data to the model ( Figure 1 ). This model is based on both exploratory factors and a relevant theoretical model. Parsimonious fit was χ 2 /df = 1084.59 / 390; p < 0.001. A model was formed with 90 degrees of freedom (df) and with a maximum probability. The resultant p-value was lower than 0.05, whilst the CFI (comparative index of goodness of fit) was 0.90, TLI (Tucker-Lewis index) was 0.91, and RMSEA [41] was 0.073 (90% CI = 0.053-0.080). Data were analyzed using the statistical software package SPSS 20 (International Business Machines Corporation (IBM), Chicago, IL, USA, 2011), LISREL v9.1 (Scientific Software International, Princeton, NJ, USA, 2010), and PANTH GRAHF (Scientific Software International. Princeton, NJ, USA, 2010) [42] . The literature suggests that model fit can be considered as adequate when χ 2 /df < 5, CFI > 0.90 and RMSEA < 0.08 [43] . Our values, therefore, comply with requirements established in the literature for establishing acceptable fit. As can be observed in Figure 1 , all regression weights were greater than 0.05, whilst the covariance between factors varied between 0.29 and 1.00. The evaluation carried out according to SEM methodology confirms that the coefficients produced support the theory employed for configuring the measurement model [44] . Coefficients produced from the multivariate regression analysis were examined through examination of the covariance matrix of observed variables, each grouped component was expressed as a latent variable, and the various elements associated with each factor were expressed as observable variables. The LISREL 9.1 program was used to complete this analysis. Observed and latent variables were structured as shown in Figure 1 . Confirmatory analysis served to confirm the theoretical factors which significantly influence observed variables in the way predicted based on EFA. This explains 4 obtained factors: Factor 1: Personal management of learning; Factor 2: Essential values reported by university students; Factor 3: Basic psychological factors, and Factor 4: Learning environments in virtual contexts. The majority of existing questionnaires that have been developed to examine learning environments or psychological factors have not been administered in a situation as novel as the current situation of confinement in which we find ourselves. Likewise, they ignore the variable pertaining to values included in the present questionnaire. In addition, the present study is novel in that it is directed towards university students undertaking the final phase of their course, engaging in a period of practical development to be trained as teachers at the time of their participation in the study [45] . We developed an instrument which established four dimensions (factors) for analyzing the learning environments and psychological factors of implicated groups, whilst also considering the interactional influence of sex. The first dimension is called personal learning management and is related with perceptions of motivation, reflection, and planning. This dimension is linked with a factor previously presented by Olmedo [33] and Martínez [34] . The second dimension is associated with the essential values developed in response to confinement. It is based on a questionnaire developed by Gervilla [36] , focusing on aspects related to the categories of body, affect, decision making, uniqueness and opening. These values are seen as being respectful of collaboration and cooperation between students. The third dimension describes basic psychological factors in relation to the state of confinement. These factors are to be considered in relation to the adaptive context in which university students are currently having to develop their practice [35, 45] . They are mainly centered on factors linked to sleep, emotions, and physical disorders, such as headaches, exhaustion, or anxiety. Finally, the fourth dimension refers to the use of telematic learning environments for the learning of future teachers [33, 46] . Here, we consider the use of digital media at a personal and professional level, in terms of frequency of use, and knowledge about and learning of such media.  Questionnaires were administered online during April 2020. The department of social responsibility at the University of Granada approved the questionnaire. Prior to its completion, the following statement was provided to participants: ""Before beginning to respond to the following questionnaire it is crucial that you provide us with informed, unequivocal and express consent regarding data privacy and protection regulations, stating that you accept that those responsible for  Questionnaires were administered online during April 2020. The department of social responsibility at the University of Granada approved the questionnaire. Prior to its completion, the following statement was provided to participants: ""Before beginning to respond to the following questionnaire it is crucial that you provide us with informed, unequivocal and express consent regarding data privacy and protection regulations, stating that you accept that those responsible for the study will handle your personal data in compliance with that set forth in the (EU)2016/679 regulation, of the 27th of April (GDPR)"". Questionnaires were distributed and administered through the Google Forms platform. Participants were not fully informed about the ultimate purpose of the study in order to avoid the effects of social desirability. However, the following indication was also provided: ""The following questions aim to study university students undertaking teaching placements, some aspects relate to the confinement we are all currently suffering due to COVID-19"". Once internal consistency and factorial validity of the questionnaire was established, in accordance with the process previously discussed, we proceeded to carry out the most appropriate statistical procedure. For this, the Levene test was conducted and homogeneity of variance was examined, providing confirmation that parametric testing was appropriate [47] . In order to study the relationships between variables as proposed in the second of our objectives, a multi-variate analysis was conducted for multiple comparisons. Analysis of variance (ANOVA) with multiple factor levels was used to evaluate the difference between participating groups and differences according to sex. Tables 1, A1 and A2 (Appendix A) demonstrate the extent to which participants are dealing with the context of confinement. It can be seen that groups comprising students undertaking degrees in early education, as well as physical activity and sport, are adapting better, as shown through better values for psychological factors. They also have more positive perceptions of their learning environment than groups comprising primary education and social education students. It is also notable that females undertaking social education degrees reported more negative aspects at a psychological level. In contrast, males belonging to the degree of physical activity and sport students reported greater learning in their context. The critical alpha level was adjusted for multiple testing to reduce the type I error (α). Thus, the α-value was divided by the number of pair comparisons for each ANOVA. Table 1 shows ANOVA results in relation to grouping variables and sex, as well as the interaction between them. The effect size was analyzed using the eta-square tests (eta-square values greater than 0.14 are considered to show a large effect) [48, 49] . Initially, multivariate analysis of variance (MANOVA) testing indicated significant differences and large effect sizes for sex, significant differences and large effect sizes regarding degrees, and significant differences for the interaction between sex and degrees and large effect sizes. Multivariate tests enable simultaneous analysis of the relationship between different levels of the same variable and the relationship p between the levels of two different variables [50] . These tests identify covariance effects, enabling us to statistically study the influence of independent groups (with four levels: PE = Primary Education, EL = Early Learning, SE = Social Education, and PES = Physical Education and Sport) and sex (with two levels: male and female) using mean scores at an individual level. Results indicate significant differences and large effect sizes in relation to sex, degrees, and the interaction between sex and the degrees variable. The sample size and proportion of explained variance (in the ANOVA) [51] (see Table A2 ), with regard to the interaction variable of sex and group, produced a result of more than (η 2 > 0.14). This suggests that this proportion of differences can be attributed to the effect of learning environments and psychological factors. Typically, eta-square values greater than 14 are considered to show a large effect, but the literature explain that eta-square tests (low effect r = 10; medium effect r = 0.30; high effect r = 0.50) [48, 49, 52] . The high value could be due to both the gender representation within the sample and the concrete influence of degree choice, given that different levels and various measures derived from different populations were studied [52] [53] [54] [55] . Similarly, significant differences are shown with regard to sex as a function of study factors and sample size (ANOVA) [56] . With respect to the sex variable, significant differences were found (η 2 > 0.14), indicating that observed differences can be attributed to effects of the studied variables. This outcome should be kept in mind. When we consider the squared sample size between different groups of degree courses, (η 2 > 0.14) is due to the squared sample. The fit of ANOVA results to the data reveals significant associations in relation to the learning environments and psychological factors, determined according to sex and degrees. Analysis also focused on contexts during COVID-19, examining sex in relation to differences degrees in education practices variables. Significant results were produced in relation to: ""When I am faced with a problem I evaluate its importance, analyse its causes, and dedicate time and effort to solve it""; ""I am incapable of solving problems by myself, I draw on tools from my PLE [personal learning environment] which aid me in this communication (p = 0.001)""; ""I am able to specify what I want to achieve and where I want to get to as a function of my goals (p = 0.002)""; ""I have developed better links with my family and friends during confinement"" (p = 0.003); ""during confinement I have frequently suffered from headaches"" (p = 0.020); and, ""during confinement I have felt bored, sad, wanted to cry, etc."" (p = 0.020). Thus, it can be seen that learning environments and psychological factors in adaptive contexts, when considered in relation to the groups to which they belong (whether they are undertaking a primary education, physical education and sport, early education, or social education course) and sex, produced large effects sizes in all cases. The present research, the psychometric instrument was designed using the Delphi method. Content validity of the scale was analyzed. A panel of 7 experts used existing literature [38] in order to establish variable names. It is worthwhile to mention that prior studies have focused on analyzing psychological factors or learning-related factors, yet few studies exist which encapsulate both factors and are adapted to the current state of confinement. Thus, it is hugely important to be able to offer a reliable and empirically tested instrument in order to continue advancing. We find ourselves in a situation from which we would all like to learn how to improve in all senses and find a way in which to be better prepared. Additional analysis conducted on the questionnaire included exploratory factor analysis (EFA) and instrument reliability. These analyses were also carried out using the previously presented statistical programs. All elements were found to be reliable. Next, confirmatory factor analysis (CFA) was performed to confirm the model through examination of acceptable indices (CFI and TLI) [40, 43] . Additionally, analysis of content validity demonstrated consistency with the scale used in relation to the majority of proportions produced by the developed instrument. A novel characteristic of the elaboration and validation of this instrument is the inclusion of elements, specific to the confinement context, centered on learning environments and psychological factors, in addition to student values [33] [34] [35] [36] . These aspects are included in the consideration of a necessary tool for the evaluation and improvement of university education for future teachers. In order to carry out the present study, we analyzed the inter-relation between sex and factors which affect learning environments in adaptive contexts in accordance with different groups (university students undertaking a Primary Education degree, university students undertaking an Early Education degree, university students undertaking a Social Education degree, and university students undertaking a Physical Activity and Sports Sciences degree). All participants were in the last year of their course, thus undertaking teaching placements. ANOVA testing demonstrated significant differences and large effect sizes in relation to the frequency of participant responses, with respect to learning environments and psychological factors as a function of group and sex. A total of 75.25% of the participants reported that, when faced with a problem, they are able to resolve it through tools available in their PLE (chats, email, Facebook, Tuenti, etc.). Current means of communication enable new learning systems to be established via existing channels, permitting young people to develop their social, educational, and personal interaction. In recent years, Western society has experienced significant changes due to the generalized use of information and communication technology, as well as its increased use amongst adolescents [57] . In total, 83.5% consider themselves able to specify goals, establishing where they want to get to. Further, 78.75% considers that they have developed stronger ties with family and friends during confinement. This corroborates the idea extolled in current literature about the family [58] [59] [60] , educational setting [61] [62] [63] , and place of work [64] [65] [66] , with these being considered essential for individual's learning development. It is highlighted that 71.87% of individuals suffered from frequent headaches during confinement, whilst 69.02% have felt bored, sad, and the need to cry, etc. These symptoms mirror those detected in other studies of the immediate impact of the COVID-19 pandemic on mental health or quality of life [67] [68] [69] . Psychological factors have been most strongly established in relation to social education students, followed by those undertaking early education and primary education studies. Those in sports courses were seen to be the least affected. This may indicate that these students are protected from boredom and sadness by being in permanent contact with physical activity and sport. This has been established in various research studies that suggest that belonging to a sporting environment [70] [71] [72] helps individuals in their critical development, including Castro et al.'s conclusions on their study in which they highlight that a task-involving climate and engagement in physical activity are both associated with lower levels of life stress and higher levels of academic performance [73] . Likewise, prior research [74, 75] has demonstrated the importance of psychological needs to the development and wellbeing of individuals. This has strong implications for educational science, motivation, and social development adapted to specific context [76] . Analysis through the ANOVA test demonstrated significant differences and varied effect sizes in relation to participants' response frequency regarding variables pertaining to learning environment and psychological factors, as a function of sex and the educational course being undertaken. Thus, differences were found with regard to sex when examining the variables, 1, 2, 4, 6, 10, 11, 12, 14, 15, 17, 18, 19, 24, and 25 . Females were found to exhibit more problematic psychological factors, especially those undertaking a social education degree. Within the consideration of degree specialty, all variables except for 10, 12, and 13 emerged, with males embarking on physical education and sports courses exhibiting better development of their personal learning environment (PLE). Such development predicts better future success. On the other hand, the group pertaining to those undertaking social education exhibited suffering greater psychological problems during the development of their professional practice in confinement. The data demonstrate that learning environments different according to the degree subject being studied. Students undertaking the degrees of Primary and Social education report greater difficulties and being overwhelmed more often than others. In the case of Social Education, this course is directed towards disadvantaged contexts, with students focusing on parents in difficult economic situations who, as stated by Goedhart et al. [77] , are largely influenced by parenthood, poverty, low literacy levels, poor education, and little experience of the digital society, regardless of migration history. This explains the fact that students undertaking this degree also report greater difficulty when acting in this new age of learning. The same was also seen, unfortunately, with primary education students. It may be relevant that a large proportion of children are still found in parts of the country who do not find it easy to access the internet. Some families may share a computer, while others may not have a computer at all. Associations, the government, companies, and educational systems must be engaged to find ways of providing all students with computers and tablets. In this way, we will facilitate the learning of all young people, despite the precarious situation of some families [3] . It is not new that digitalized society today demands that specialized social services continually adapt to the changing needs of users and transformations in society itself. In the future, responding to these needs will help parents to work with their children in the technological setting and in settings, such as the present one, in other words, pandemics, health crises, etc. This is important as these are all settings in which students find themselves to be disadvantaged [77] . The present research has also uncovered other aspects. For instance, university students have had to incorporate themselves into a complicated adaptive system. In this sense, they have responded with autonomy and have adjusted well, though effects can be seen at a number of levels. In this sense, work demands are described as physical, psychological, social, or organizational aspects of work which require sustained effort or physical and/or psychological (cognitive and emotional) skills [30] . Work demands are not necessarily negative, but they can provide a source of stress when excessive effort is required by employees to meet them [31] . Females are found to be more affected by headaches, sadness, boredom, wanting to cry, etc. This confirms our second objective by identifying groups at risk of suffering depression during confinement [27] . It is necessary to highlight some limitations of the present study. Firstly, the sample should be extended to include all centers for university education, not only in Spain, but also throughout Europe. We also emphasize the need to conduct more studies capable of providing evidence about the effect of factors in contexts that are adaptive but do not involve confinement. It will be useful to identify the individuals and social principles required for this concept to come to life. Another of the limitations experienced by the present study was due to difficulties in accessing the sample as a result of the situation described throughout the study. This complicated participant involvement as it could not be conducted in-person; however, it is important to note that data collection was still completed within an acceptable time-frame.@story_separate@From the present study, we conclude that we have developed a good (internal consistency and factorial validity) tool, thus fulfilling the first study objective. In this sense, we have expanded upon results obtained regarding the advantages of the designed tool. Through provision of this instrument, the present research also favors learning environments and positive psychological factors. This can be appreciated in the four analyzed groups as significant differences were reflected between the various items associated with the learning environment and psychological factors in adaptive confinement contexts. Hyun-Joo et al. [78] state that depressive symptoms in teachers not only influence the quality of their teaching practice but also their work-related wellbeing, including their professional motivation and stress. Likewise, Kyriacou [79] established that stress in teachers can be defined as the experience of unpleasant and negative emotions, resulting from some aspects of their work [31] . Previously conducted research studies conducted by Ecker et al. [80] demonstrate that social ambiguity and anxiety conditions arise during periods of crisis or pandemics. These may include malaise and sadness. According to Altena et al. [81] , sleep pressure and homeostatic drive are key for sleeping well, thus avoiding headaches and sadness. Boredom can be tackled by engaging in physical activity during the day (but not late at night), with this also improving sleep quality [82] . This conclusion is reiterated in the present group of Physical Activity and Sport Science students who, being more accustomed to exercise, most effectively dealt with the psychological issues that arose throughout the study. During the COVID-19 pandemic, following news updates for more than 3 h a day has been associated with higher levels of anxiety, with this having negative repercussions in comparison to those who less exposed themselves to news updates in relation to COVID-19 [83] . A study conducted by Yu and Yu [84] reports that the majority of research studies on students' participation and the success of electronic learning, in which the impact of students' attitudes has been observed, ultimately focused on the commitment of students to using the system. When a student's understanding of learning is incorporated as a part of system design, it is more likely that the resultant system will adapt to individual needs. In conclusion, the pandemic provides an opportunity for young people to develop and perfect their resilience and adaptability, enabling them to appreciate the value of social responsibility and personal sacrifice in order to protect the most vulnerable. More research is needed into online replacements for face-to-face lessons. It is also necessary to provide training to teachers so that they can prepare for change in extreme situations, such as that which we are currently living [85] . It is crucial that we validate young people's experiences during this global crisis and listen to their creative solutions, in order to tackle this new reality and connect with each other. We must up-skill so that students can use these new skills to create a connected society that is characterized by solidarity; in this way, we will emerge equipped in this changed world [86] . The conclusion reached herer is that the results of the present study will permit future multi-dimensional analyses to be conducted [87] . The critical alpha level was adjusted for multiple testing to reduce the type I error (α). Thus, the α-value was divided by the number of pair comparisons for each ANOVA.","The present research was carried out in Spain during the COVID-19 pandemic following emergency school closures in an attempt to avoid the spread of infection. As a result, university students undertaking the final year of education degrees (teaching placements) have been obliged to deliver their teaching from home, adapting their teaching contexts to learning in virtual settings. A novel instrument was designed and validated in order to analyze the impact of learning environments and psychological factors in university students during a period of teaching placements. This took place in an adaptive context (state of confinement). Associations were determined between learning environments and psychological factors in adaptive contexts, in relation to the group to which they belonged (whether undertaking a degree in primary education, physical education and sport, early education or social education), and sex. The present study used a Delphi method, alongside a descriptive and quantitative analysis. The data demonstrate that learning environments differ according to the degree studied. The four analyzed groups revealed significant differences in relation to learning environments and psychological factors in adaptive confinement contexts. The subjects of Primary and Social Education were seen to be related with a greater possibility of being overwhelmed and reporting difficulties. Those more used to physical exercise showed more positive psychological indices. Females reported more negative responses. The conclusion reached is that the results of the present research will enable future additional multi-dimensional analysis to be conducted."
"In Dec-2019, coronavirus infection occurred in Wuhan, China and since then this virus has impacted millions of people across the world [1] . WHO on Jan-30-2020 declared a global health emergency and coronavirus as a pandemic [2] . Several cases from across the world which includes USA, Europe, Thailand, Australia were reported in the Feb-2020. This coronavirus is named as SARS-CoV-2, a new family of SARS-COV by International Committee on Taxonomy of Viruses [3] . This coronavirus disease transmits from human to human causing rapid growth in infected patients. Due to this COVID-19 infected patients had increased across all parts of the world and the patient infected from this virus suffers from acute respiratory syndrome that includes fever, cough, chest pain and several other respiratory problems [4] [5] . However, there are cases reported in which people have shown no symptoms but were infected by COVID-19 [6] . To detect coronavirus, there is Reverse Transcription Polymerase Chain Reaction (RTPCR) test available. In these tests, specimens from lower and upper respiratory organs like nasal, sputum or nasal aspirate are collected from the person suspected to be infected by COVID-19 by health specialist. But this test has limitations like the sample collection process is manual and depends on cooperation of patient and skills of specialists, which may impact the accurate diagnosis of the virus. Also, this testing process is very time consuming and rate of detection is also very low. Due to these issues, repeated test are required to be performed for accurate diagnosis [7] [8] . The present testing methodology has limitations of accuracy and processing time, therefore, there is a need for rapid detection of individuals suffering from COVID-19 so that infected patients can receive quick care and treatment. Studies have shown that radiological images like X-ray or CT images can be used for the detection of COVID-19 [9] . These researches have shown the benefits of using radiological images for detection of COVID-19. However, in such case, there will be need for health specialists to read these images to identify the patients. The diagnosis of disease through radiological images can be augmented with the help of machine learning models, which can help health specialist reduce subjectivity and time taken in diagnosis. Therefore, diagnosis through machine learning models of high accuracy is required so that the authorities feel encouraged to use these models in order to get the accurate and rapid results [10] . Many researchers have proposed various AI based models for rapid detection of COVID-19 infected patients by either using X-rays or CT images. Wang et al. [11] proposed a deep learning based AI diagnostic model that uses CT images and obtained accuracy of 79.3%. Another model proposed by Xu et al. [12] that classifies healthy, COVID-19, Influenza-A viral-based pneumonia cases using CT images and claims accuracy of 86.7%. These studies use nonpublic datasets for testing their AI based model. Wang et al. [13] proposed an approach where public dataset of SARS-CoV-2 X-ray images are used and achieved an accuracy of 92.4%. Few more research studies have been done for the detection of COVID-19 using X-ray images [14] [15] [16] [17] . In all these studies pre-processed dataset is used. Another approach proposed by Ucar et al. [18] where deep learning model is designed with Bayes optimization and public dataset with pre augmentation is used to reduce the data imbalance. Ismael et al. [19] proposed a CNN model to detect the COVID-19 cases using chest Xray images. Hussain et al. [20] proposed a deep learning model for COVID-19 detection using chest X-ray images. The major contribution of this study is to develop a self-learning model for rapid and real time detection of coronavirus infected individuals. This model will work as an automated tool that can be used to assist medical professionals in improving the COVID-19 diagnosis accuracy. In this framework, X-ray images are pre-processed in which step in which input X-ray images are prepared into an acceptable size and format required by the model. This includes reading an image, resizing, and augmentation. Augmentation is done for imbalanced dataset where images are artificially created by creating different combinations of images by rotation, flipping, shear and adding noise. After pre-processing we have applied segmentation of images by clustering them into similar groups. We have used K-mean clustering approach which is more common and utilized for real world data sets [21] . In the next step feature extraction is performed on the clustered dataset collected from k-means clustering. It is the process of capturing the relevant informative data from an image and build the feature set-in coarse-grained manner. Feature extraction process will generate different features by describing the characteristics of the chest x-ray image processed. These features may contain the dominant and nondominant characteristics of an image and these irrelevant and redundant features might impact the classification accuracy and computation time of the classifier. Therefore, there is a need for a feature selection approach which will only choose the relevant and optimized features for classification and this make the entire system more efficient. We have used a novel feature selection approach that uses differential evolution algorithm(DE) [22] hybridized with particle swarm optimization (PSO) [23] . The optimized feature set is used in support vector machine (SVM) classifier. Our aim is to achieve higher accuracy in diagnosis of coronavirus infected individuals using X-ray images in real time, so optimized features and SVM helps in achieving higher accuracy, even with limited size of data set. SARS-CoV-2 is a global pandemic which spreads rapidly from human to human and so data set from x-ray images with large number of features are available, but this creates difficulty in classifying the data using standalone classifier i.e. without proper features. Therefore, there is a need for feature optimization approach that could remove the irrelevant features and, also help in dimensionality reduction by filtering the less informative features, which would lead to improvement in the accuracy of classifier. The addition of feature selection process makes the model more robust and less complex during classification computation. Recent studies show that the evolutionary approaches are amongst the popular techniques for feature selection as they are suitable for solving complex optimization problems [24] . Xue et al. [25] performed a detailed review on various evolutionary approaches used for feature selection. Recently PSO and its variant have been adopted for feature selection problems. Zhang et al. [26] proposed an approach based on multi objective PSO for optimization of costbased feature selection. Xue et al. [27] proposed another variant of PSO for optimization of large feature set to improve the classification accuracy. Engelbrecht et al. [28] proposed a set based PSO variant for feature selection optimization. These solutions show the advantages of PSO in feature selection but still problem in finding optimal feature set occurs when data has large number of features. In recent years, differential evolution algorithm is also introduced for optimizing feature set specially in medical domain. Mazaheri et al. [29] proposed an automated tool for detecting abnormal cardiac functions. DE, PSO algorithms are used as a feature selection approach to achieve higher accuracy. Vivekananda et al. [30] proposed a variant of DE for optimization of feature selected for cardiovascular disease. Zhang et al. [31] proposed a variant of DE for solving the multi-objective feature selection problem. However, feature selection is still a problem specially with datasets having large number of features and very less work has been done for optimizing feature set obtained from X-ray images. In order to optimize the feature selection in our framework, we have introduced a novel approach by hybridizing Differential evolution algorithm with Particle swarm optimization. In this approach, PSO is used to enhance the convergence speed and DE has been used to improve the population diversity so that optimal feature set can be selected with precision. The procedure starts with 2 ⁄ ⁄ mutation strategy with archival approach and therefore each generation will be able to search in larger space and avoid the premature convergence. Lately, PSO strategy is used in the evolution process to speed up the convergence. In addition to this we have also adopted the parameters tuning during the evolution process. The coordination of changing mutation strategy and parameters tracking and tuning during evolution process help in improving performance of our proposed approach. Further the optimized feature set is then used in SVM [32] classifier for accurately detecting the COVID-19 positive and negative cases. SVM has recently received greater consideration in designing machine learning model as it possesses the generalization ability even with relatively smaller data sets, which is not the case with other types of classifiers. The objective of ANN model is to reduce the sum of square error among target label and therefore the performance of ANN is largely dependent on size and quality the training set. However, in SVM the margin among different classes is maximized and therefore its performance is not impacted by the rare training data set [33] . Also, SVM uses kernel function that helps SVM to classify the non-linear objects. The proposed framework model is different from previous designs in three ways: First, most of the previous models are using non-public data set or with small set of public data set whereas our model is tested with relatively large public data set available [13] . Moreover, we have applied data augmentation in order to solve the class imbalance problem with dataset. Second difference is in classifier approach. All the previous model uses CNN classifier that uses supervised learning algorithm and therefore performance is dependent on training data. There is a need to artificially augment the data in order to develop the accurate model. Our framework is developed on three step process in which initially data pre-processing is done and data is clustered using K-means clustering [21] and then feature extraction is done. This K-means clustering is unsupervised learning algorithm and there is no need to supervise the model. K-means clustering subgroups the data based on the Euclidian distance without any prior training. It is efficient yet simple approach. This is an important step to understand the underlying patterns in an image by subdividing them into clusters as per the characteristics. Third difference is the addition of feature selection step. This is an important step as the processed data from preprocessing step have large feature set and it is important to optimize the feature set so that higher classification accuracy is achieved. To achieve that we are proposing a novel hybridization approach based on differential evolution algorithm and particle swarm optimization for feature selection. In this hybridization approach we have updated the DE mutation strategy with PSO and then in crossover approach the best particles are chosen with sigmoid function. This collaboration between mutation and crossover strategy provides optimized feature subset to SVM classifier. Utilizing this framework, we have achieved higher accuracy using chest X-ray images and detect individuals suffering from coronavirus in real time. The proposed framework is tested on large public data set of chest X-ray images and compared with other state of art approaches. The propose approach is evaluated on seven parameters as number of features optimized, accuracy, correctness, completeness, F-score, training time and classification time. We have applied k-fold cross-validation method in order to ensure the reliability of our classifier and strengthen the simulation results. These results are compared with classical SVM classifier. We have also compared the results with DE-SVM and PSO-SVM. Performance of our proposed approach is also compared with eight recently proposed models as Wang et al. [13] , Li et al. [14] , Afshar et al. [15] , Farooq et al. [16] , Chowdhury et al. [17] , Ucar et al. [18] , Ismael et al. [19] , Hussain et al. [20] . Experimental results show that our proposed model has superior performance than other approaches. We have also performed nonparametric Friedman's test for evaluating the statistical significance of superiority of our proposed model. The test shows that our proposed model achieves highest ranking among all other algorithms. Therefore, statistical test also confirms the superiority of our proposed model. This paper is further organized into four sections. Preliminary approaches are discussed in section 2; Proposed framework is discussed in section 3. Section 4 showcase the experimental results and comparative analysis. Conclusions and future work are discussed in section 5.@story_separate@This section discusses the preliminary algorithms that are used in our framework. We have used Support vector machine (SVM), Differential evolution (DE) and Particle swarm optimization (PSO) algorithms. A supervised classification algorithm SVM [32] is better suited for solving classification problems. In SVM, the main objective is to look for a hyperplane in dimensional space in order to classify the data set. A non-linear function is set as ( ) where is the training set and * ( ) + = 0 represents the classifier hyperplane. A decision function is defined as: ( ) = ( * ( ) + ). In this equation, represents the orientation and represents the related displacement position. Equation for hyperplane classification can be represented as: where ℎ and are the training label and training data respectively. For each = 1,2, … where n represents the training set size, ∈ ℎ ∈ {+1, −1}. is capacity constant, is a non-negative variable also known as slack variable. This slack variable is an important attribute that demonstrate the violations of margin by sample . The characteristics of linear and non-linear classifiers are almost same but with a difference of the Lagrange formulation in non-linear. So now the formulation of the equation 1 re-represented as: where is the support value, if 0 ≤ ≤ , then is represented as the support vector (SV), ( , ) = ( ) * ( ) is the kernel fucntion [34] . DE [22] is a population-based metaheuristic approach which is stochastic in nature. DE has been applied in many domains for solving different optimization problems which are complex in nature like medical image processing [35] [36], Feature selection [37] [31] . DE begins by population initialization as is the candidate solution. This process is followed by mutation, crossover and selection operation as shown below: Mutation strategy in DE named as "" −⁄ "" ⁄ can be represented as: Where is the scaling factor, 1 , 2 3 are mutually exclusive random values in range [1, ] . is the population size and Number of generations is represented as . Crossover operation is performed in order to improve the population diversity for target vector. Crossover rate is applied in order to generate new trail vector as , +1 . This operation is described as below. where crossover probability is represented as is the random number and the value is in range [0,1]. In this operation, fitness value of each individual vector is compared, and best optimized values are selected based on greedy selection. Thus, the target vector is defined as. Where objective function ( ) with k= 1, 2, . . . . . . . is the population size. This process is repeated until stopping criteria is met. Kennedy and Eberhart [23] in the year 1995 introduced a novel technique based on swarm behaviour termed as Particle Swarm Optimization (PSO). In this algorithm = ( 1 , 2 , 3 … . ) shows the position and = 1 , 2 , … … … , is the velocity for the particle in search space of dimension . Every particle in search space maintains its local and global best position as and respectively. PSO update its position ( ) and velocity ( ) for each iteration. Initially PSO was introduced for solving continuous optimization problems but later as there were multiple discrete optimization problems; like feature selection, PSO was augmented to binary PSO (BPSO) [38] . In BPSO position ( ), and global and local best ( ) can only take 0 and 1 values. Therefore, for BPSO the velocity calculation is updated as: where 1 , 2 , 1 and 2 are acceleration constants. In a generation , For Particle , represents the velocity in dimension . represents the Inertia weight that specifies the effect of previous velocity. ( , ) and ( , ) represents the local and global best values. The proposed framework for detecting COVID-19 is discussed in this section. In this framework, data is pre-processed in which input images are prepared into an acceptable size and format required by the model. This process is feature extraction in which image features like shape, size etc. are extracted followed by feature selection process for feature optimization. Finally, the optimized feature subset is forwarded to classifier for detecting the COVID-19 impacted patient. A novel Hybrid Differential evolution algorithm based on PSO with SVM is proposed to detect the coronavirus infected individuals by classifying their chest X-ray images. The architecture framework of our proposed model is shown in figure 1. This proposed model is trained end to end and Chest X-ray image are required as input to diagnose the individual as Covid-19 positive or negative in real time without any manual intervention. Our framework follows the 3-step process. 1. Data pre-processing step in which input X-ray image data is prepared into an acceptable size and format required by the model. This includes reading an image, resizing, and augmentation. In section 3.3, we have discussed about the datasets and pre-processing approach used in this study. After the pre-processing image segmentation is required to identify the similar grouping of objects known as clustering. Clustering is a crucial step, as it is an important forerunner for the feature extraction. Clustering is performed on unsupervised learning having no class information. In this process data with similar attributes are grouped together. We have used K-means clustering technique as it is generally used in overlapping clusters which is common case in real datasets. The detailed discussion on clustering analysis is done in section 3.4. Further, feature extraction process is applied to find out the characteristics of objects within an image. These characteristics or objects like shape and colour can be used to define an object. Section 3.1 discusses the feature extraction process used in this study. 2. Feature extraction process will generate different features by describing the characteristics of the chest x-ray image processed. These features may contain the dominant and non-dominant characteristics of an image and these irrelevant and redundant features might impact the classification accuracy and computation time of the classifier. Therefore, there is a need for a feature selection approach which will only choose the relevant and optimized features for classification and this make the entire system more efficient. We have used a novel approach for feature selection-based hybrid differential evolution algorithm with PSO for feature optimization. 3. Finally, Feature subset obtained from step 2 will be used by SVM classifier for classification. The step 1 is a data pre-processing step. The training and testing of the proposed model for detecting COVID-19 has been performed using image dataset as mentioned in [13] . The images during training phase are clustered based on ""Euclidian"" distance using K-means clustering approach with k = 2. The pseudo code for K-means clustering used in our model is shown in Table  1 . Calculate the Euclidean distance among each data and cluster. 6. Store clustered image into the region with minimum Euclidean distance. 7. Until coverage criteria In the next step feature extraction is performed on the segmented dataset collected from K-means clustering. Feature extraction is the process of capturing the relevant informative data from an image and build the feature setin coarse-grained manner. It is like a screening process for identifying useful features. Feature extraction is useful for large dataset as it reduces the data dimensionality by obtaining the new features and remove repeated or redundant data. All the details around these feature types are stated in [39] . Table 2 showcase the procedure for feature extraction. In our model we have extracted following features. Color features are most important features calculated from an image. Color features add more information and helps in getting content information from an image. There are various methods, but we are discussing few. Mean: Mean value of image is calculated as: Standard Deviation: SD is the calculation of inhomogeneity in an image. Texture features are also extracted and for that we have used a well-known grey level co-occurrence matrix (GLCM) [40] . Contrast, Correlation, Energy, Homogeneity etc. are the features extracted using GLCM approach. Energy: Sum of square elements is captured in GLCM and is the uniformity in image regions. If the image pixel value is high the value of energy is also high. Entropy: Entropy is the measure of randomness in an image. Contrast: Measured for an image as the intensity measurement among pixels Correlation: Measurement of correlation among the pixels. Homogeneity: calculate the similarity among pixels. where, is the mean of GLCM. is the gray level count in an image. 2  is the calculation of variance of intensities of all pixels. The next step is feature selection. In this step all the feature set collected after data pre-processing is optimized based on our hybrid differential evolution algorithm based on PSO. This is an important step as it reduces the complexity of the classifier by optimizing the feature, selecting only relevant features and thus improving the classifier's accuracy. The implementation process of our feature selection and classification is shown in Table 3 . In this approach, we have used PSO for population initialization, then velocity and position of the particle is updated from its current position. In the next step, DE is applied for local search. This balances the exploitation and exploration capabilities of both the algorithms and thus improves the efficiency and prevents the problem of trapping into local optima. Further the optimized feature set are sent for classification using SVM classifier.  where 1 , 2 , 1 and 2 are acceleration constants. In a generation , For Particle , represents the velocity in dimension . represents the Inertia weight that specifies the effect of previous velocity. ( , ) and ( , ) represents the local and global best values. ( ) is the sigmoid function. As shown in Table 3 , decision making system starts with hybrid DEPSO algorithm for feature selection. The algorithm starts with initialization of population where features set obtained from COVID-19 image data set of Chest X-rays are set. The hybrid DE-PSO algorithm is applied to optimize the feature set by removing the irrelevant features. A new feature threshold constraint is added to validate the redundancy relevance, duplicity and performance of fitness function. The fitness function is defined as.  where, is the threshold constraint in range [0,1]. In the above equation is the relative importance of features and 1 − is the relative importance of error rate in classification. Since number of features are always important than the classification accuracy, the value of should be ≤ 1 − . In our proposed feature selection approach based on hybrid DEPSO, the computation complexity lies in the selection of mutation and crossover strategy using sigmoid function. Also, on the parameter self-adjusting strategy in each iteration, the computational complexity of selection strategy is represented as (( × + × + ) × ) . The self-adjusting strategy has the complexity of ( × × × ) where, N is the population sizes, D is dimension and is the maximum iteration and is the count of objectives . Therefore, the computational complexity of our feature selection algorithm (DEPSO) is (( × ) × ) + ( × ). As we have used SVM as a classifier and classifier's accuracy is dependent on training data and feature set. Therefore, the complexity of SVM classifier during training is ( 2 + 3 ) and for prediction ( ) , where is the training sample, is the number of features, is the support vector count. This is due to the fact that during the training, classical SVM classifier needs to evaluate the kernel matrix represented as ( , ). Currently RT-PCR test is performed to detect the COVID-19 infected individual. Lower and upper respiratory specimens like nasal, sputum or nasal aspirate are collected from the person suspected to be infected by COVID-19 by health specialist. But this test has limitations like the sample might malfunction by mistake and this impact the accurate diagnosis. Also, the test process is very time consuming and rate of detection is also very low. Radiological images like chest X-ray images can be used as an alternative for detection of COVID-19 infected individual. Therefore, in this study chest Xray images available as public dataset are used in our model. We have collected the COVID-19 chest X-ray images from [13] and [41] . Pneumonia infected patient's X-ray images [42] are also used so that our model can be effectively prepared and tested. Total 13975 X-ray images are available as public dataset. This data has 8066 normal, 5551 Pneumonia and 358 COVID-19 chest X-ray images. The sample X-ray images are shown in Fig. 2. (a) (b) (c) Figure 2 . Chest X-ray images (a) Normal (b) Pneumonia (C) COVID-19 Feature selection and classification from imbalance data impact the performance of any machine learning model. There are different strategies for handling the imbalance data [43] . This study showcases the impact of imbalance data on the performance of classifier. Inspired from these studies we have conducted a systematic approach by resizing all the images to 227 × 227 pixels. Next is to get the mirror image by flipping each image. In the next step performing shearing, adding noise, decreasing, and increasing the brightness by ±30 pixels on both original and flipped image. Since we have limited Covid-19 x-ray images, we perform this augmentation process on Covid-19 x-ray images. Figure 3 shows that sample operation performed, and different images obtained after augmentation process. By doing this, we obtain 24 variants of same image. After this pre-processing of image dataset, we get an acceptable number of Covid-19 x-ray images.  In an unsupervised learning, clustering plays a very important role. The aim of clustering is to find the interesting pattern in an unlabeled data and group them together. Various clustering techniques are suggested and proposed by researchers [44] . As there are no absolute criteria for choosing the best clustering technique available and the clustering technique mostly dependent of the problem. From the literature we see that there is a manual approach in which clusters are defined for the dataset. Other approach is known as Overlapping clustering, in this technique data is clustered on fuzzy sets based on some membership value. The other approach is hierarchical clustering technique. This algorithm starts by creating clusters of similar objects and finally each object is grouped into the distinct clusters and final clusters will have similar objects. For this study we have used 2 most widely used clustering techniques as K-means and expectation-maximization (EM) with Gaussian mixture model (GMM-EM) [45] clustering technique. Table 4 shows the accuracy comparison results of K-means and GMM-EM approach. The results show that K-means clustering is able to correctly classify 87.42% of features whereas GMM-EM is able to achieve 85.4532% accuracy. The results show that K-means clustering is showing better results in comparison to GMM-EM and therefore, we have opted k-mean algorithm as a clustering approach in our proposed model. For calculation of ""K"" in K-means clustering we have used Elbow method. The basic idea in calculating the value of ""K"" using elbow method is to run the clustering algorithm on various values from the dataset and then calculate the sum of square error. This square error is the square of the distance between each value. ""Euclidian distance"" is used to calculate this distance. Every observation of the data values fit to nearest mean value cluster. All these centers choose the clusters as per the density and centroid. As shown in Figure 4 for value of K=2 there is an ""elbow point"", therefore we have used this value for clustering the image data. Image pre-processing is an important step for better clustering of images, we have applied Watershed transform of gradient magnitude as shown in Figure 5 . This helps in separating the touching objects from image. Figure 5 . Image pre-processing for K-means clustering We have applied k-fold cross-validation method [46] in order to ensure the reliability of our classifier and strengthen the simulation results. In this approach we have used 10-fold cross-validation by randomly dividing the 10 set of training and testing samples. Each combination is executed independently for calculating the accuracy and other parameters as mentioned below. To measure the performance of our model, we have considered following parameters.  Computation time: Total time spent in calculation.  Classification accuracy:  : is calculated to measure the test's accuracy. where , , , are the correctly classified class, opposite class classified, incorrectly classified and misclassified class. are correctness and completeness.  Friedman's test: Non-parametric test for statistical analysis of the results. For evaluation the performance of our proposed model, the experiment is performed using MATLAB with system configuration as 2.11 GHz, Intel ® Core™ i7-8650U and 16GB RAM. The parameters used for DEPSO algorithm is mentioned in Table 5 . In the evolution stage setting up the right parameters is very important as performance is dependent on these control parameters, however choosing right parameters is a difficult process. In our approach values are adjusted in real time by monitoring the evolutionary process of each individual. During the process of evolution if any individual stagnates then the values need to be readjusted. In literature there is no guideline to set the values of control parameters, instead the random selection of values by trial and error is considered as the better option [47] . Since we have use DE and PSO algorithm in our model for feature selection and these algorithms are stochastic in nature, so accuracy is calculated by running our program over 100 iteration for 30 runs. To evaluate the performance of our proposed model we have also implemented SVM, DE with SVM (DE-SVM), PSO with SVM(PSO-SVM) classifier. We have also compared our proposed model's efficiency with 8 recently proposed approaches (detailed mentioned in Table 6 ) in literature for COVID-19 detection. In the preprocessing step data is split into 3 set as training, validation, and testing. This formation of split data is packaged as training data:80%, validation and testing data as 10% each. This validation data is required to better make the error prone objective function. Now with the separate test data set, all the images are resized to 227 × 227 pixel and the input data is reshuffled in order to reduce the overfitting's negative impact. Table 5 shows the distribution of data and classes. All the images are pre-processed as in step 1 and 230 features are extracted from each image. These feature set are put for feature selection process using our hybrid DEPSO algorithm. Finally, the optimized feature set are sent to classifier for classification. Experimental results shown in Table 7 showcase the proposed algorithm performance with different values of in fitness function. From the table we can see that in all the cases there is a reduction in features but with = 0.15, our proposed algorithm captures the smaller number of features with better classification accuracy as compared to other values. Our proposed approach obtains 99.35 of average accuracy in 40 runs and best accuracy of 100%. These results also show the impact of relevance and redundancy on the performance of classier. Therefore, it is important to choose the correct value of . We have applied k-fold cross-validation method in order to ensure the reliability of our classifier and strengthen the simulation results. For our experiment we have used k as 10 and so 10 sets of equal sized training and test data samples are created. Further 9 sets are used for training and 1 is used for testing the model. We have repeated this process 10 times by applying data set on both training and testing stage. The average testing results are calculated with training and classification time and shown in Table 8 . Training time is the time spent in training a classifier on 10-fold cross-validation. Classification time is the time spent in predicting the Covid-19 positive and negative cases. The results show that DESVM is able to optimize the feature set and selects 116 features, PSOSVM selects the 112 optimized feature set and our proposed algorithm is able to optimize maximum and select 106 feature set. These optimized feature results also show the impact on classifier's accuracy. We have also calculated the computational complexity of our algorithm. As we can see from the table the total time for training is 11 sec which is less as compared with DESVM and PSOSVM classifiers but more than SVM classifier. Similarly, the classification time complexity is also less than 1 seconds. The results show that our proposed hybrid approach working fast as compared to other evolutionary variants but slow in comparison to SVM classifier. This is due to feature selection step added in our framework and features subset selection from larger extracted feature set takes time but will results in fine tuning of classifier by reducing the complexity .Results also indicate that our feature selection approach is able to get more optimized feature set. This shows that adding the feature selection approach only improves the computational complexity of our classifier. These results show that our proposed algorithm is giving better performance as compared to other classifier in predication of COVID-19 positive and negative cases. We have also compared our proposed approach performance with 8 recently proposed models. Experimental results are shown in Table 9 . From the results, we can see that the model proposed by Chowdhury et al. [17] is giving better results in terms of accuracy and correctness in comparison to other state of art algorithms. Almost similar performance is shown by the diagnosis model proposed by Ucar et al. [18] . If we compare both these models with our proposed approach, the proposed model with DEPSOSVM is showing better results with 99.34% of accuracy as compared with all the other approaches. These results show our proposed model is giving more accurate results as compared to other models. Experimental results show that our proposed model is showing superior performance then other approaches. There are two reasons for the same. In our framework the initial step is to pre-process the images by applying K-means unsupervised learning algorithm which is best suited for creating a self-learning model. The second reason is the feature selection step. We have added a novel feature selection approach in which differential evolution algorithm is hybridized with PSO. This hybridization helps swarm to acquire population diversity and avoiding local optima convergence. This is due to our mutation strategy that helps algorithm to maintain the population diversity and to improve the local and global search ability by utilizing DE mutation strategy at initial and PSO strategy at the later stage. DE helps in adding population diversity and PSO enhances the convergence and accuracy. Following this process, optimized feature set are collected which are then put into SVM classifier to gaining better classification accuracy particularly on the larger population and complex solution set. In our approach, DE has been used to maintain the constant parameter value for every evolution, but individual parameter can dynamically get the optimized performance in each iteration. Every dataset is different and complex so need a dynamic strategy to choose the parameter for each iteration and this will improve the overall efficiency of the algorithm. Therefore, in our approach, parameters are self-adjusted based of the status. For example, if any individual parameter becomes stationary in consecutive generations, our model will readjust them by random values as: where , , are the scaling factor and min and max constant values of scaling factor respective ly. , , represents the crossover rate, max and min constant values of crossover rate for , +1 in generation . rand (1, D) is the random values in range [1, D} and D is the size (samples, 2). The min and max values for scaling factor are 0.8 and 1.0 and crossover rate are 0.8 and 1.0. The impact of these control parameters is crucial and therefore the values are chosen by trial and error. For handling the population diversity and premature converge nce problem, we have used a novel mutation operation to produce child generation followed by crossover with particles. These generated offspring have their position updated. Throughout the iteration these new offspring update their own best position in comparison to other generated offspring. As shown in Figure 6 , we have created the confusion matrix of our proposed framework in testing. In the figure, 1 represent the COVID data, 2 for the normal and 3 is for the Pneumonia data. Our propose d model is able to detect all the COVID-19 infected chest X-ray images of the patients. Out of 459 samples, there is only 3 cases where misclassification happened. If we check for the error rate, it is .007 % for normal x-ray images and .01% for pneumonia cases. This shows the robustness and sustainability of our model. We have also captured the results using box plot as shown in Figure 7 for good understanding. We have also performed non-parametric Friedman's test for evaluating the statistical performance of our proposed model. The null hypothesis is set as: For the same dataset, results Q is tested for the provided p value ( −1 2 > ), where T is test statistics [48] . For testing performance metrics is applied on accuracy, fitness and . Test statistics results and ranks for various approaches are shown in Table 10 and 11 respectively. For this experiment, confidence level ( ) is taken as 0.5. From Table 10 we can observe the difference between various approaches are significant and so this null hypothesis is rejected. Ranking order of various approaches are given in Table 11 . Lower the value, higher is the ranking and so our proposed model achieves highest ranking among all other algorithms. Therefore, statistical results also confirm the superiority of our proposed model. Friedman's non-parametric test results shows that there is a significa nt difference between the comparative algorithm, but we are not able to establish the interrelation between the algorithms in comparison. García et al. [49] and Derrac et al. [50] has suggested a post-hoc analysis for × comparison of multiple algorithms. Their studies suggested a non-parametric test should be conducted to determine whether there is any significant difference among the algorithms in comparison. Once this is established that there is a significant difference among the algorithms then post-hoc analysis is performed to detect which pair of algorithms are significantly different. Post-hoc test are usually performed to control the type-1 error also known as family wise error rate (FWER) [51] . In a pairwise multip le comparison tests, FWER refers to the probability of rejecting at least one null hypothesis. With the Friedman test, the Bonferroni test is usually a suggested approach which adjust the p-values and controls the FWER [52] . But this approach is very conservative and there are modificatio ns made to the original process [53] [54] . We have used Holm's test to determine which of these algorithms are different in × comparison. This Holm's test is also known as modified Bonferroni process and works on sequentially rejective step down approach for calculating the adjusted p-value [53] . This post-hoc analysis is based on the significa nt value of . For this experiment we have used .05. We have applied post-hoc analysis to further strengthen the statistica l analysis and to showcase that there is a significant difference between the proposed algorithm and rest of the algorithms in comparison. We have used Bonferroni-Holm process for this analysis. Table 12 shows the results from post-hoc analysis that includes Z-score, p-value(unadjusted), Holm's coefficient adjustment and adjusted p-value. The results are compared with proposed model and other 4 algorithms. From the results it is evident that proposed model shows the significant difference in performance in comparison to other algorithms. Therefore, post-hoc analysis results also confirms the superiority of our model. @story_separate@SARS-CoV-2 also known as COVID-19 is a global pandemic. This virus transmits from human to human and spreads very rapidly. Therefore, there is a need for rapid detection of individuals suffering from COVID-19 so that infected patients should receive quick care and treatment. The current testing approach is full of limitations and require manual intervention from health specialist. Therefore, an alternative approach is required which should be quick, real time in response, giving accurate results and minimal manual intervention should be required. In this study, we have proposed a new framework which is a self-learning model, giving accurate results without manual intervention. This model can be used for real time detection of individuals suffering from COVID-19. This framework works on 3 step process in which 1 st step is data pre-processing. In this step, chest X-ray image is first clustered by using unsupervised K-means algorithm and then features are extracted. In the 2 nd step, feature selection is performed using a novel differential evolution algorithm based on PSO. The large feature set obtained after feature extraction are optimized by removing irrelevant features. The optimized feature set is then put into SVM classifier to fine tune the classification process and get the better accuracy in terms of identification of COVID-19 positive and negative cases. The proposed framework is tested on large public data set of chest X-ray images and compared with other state of art approaches. Our approach is performing superior as compared to other approaches and giving better accuracy, correctness, completeness and . We have also compared the computation time with SVM and with classical DE and PSO algorithm. Our proposed approach is giving better optimized feature set in less time as compared with classical DE and PSO. We have also performed Friedman's nonparametric test for statistical analysis and our model is performing better as compared to other approaches. This shows that our model is robust and sustainable learning model and has a great potential to be used as an automation tool for detecting the COVID-19 infected individuals in real time. The proposed model can be used public places like shopping mall, Metro, school/colleges, Airports, Railways entry points to detect the individuals infected from COVID-19. In future we want to extend this work and test our model on larger set of data and evaluate other evolutionary approaches.","For Covid-19 suspected cases, it is critical to diagnose them accurately and rapidly so that they can be isolated and provided with required medical care. A self-learning automation model will be helpful to diagnose the COVID-19 suspected individual using chest X-rays. AI based designs, which utilizes chest X-rays, have been recently proposed for the detection of COVID-19. However, these approaches are either using non-public database or having a complex design. In this study we have proposed a novel framework for real time detection of coronavirus patients without manual intervention. In our framework, we have introduced a 3-step process in which initially K-means clustering, and feature extraction is performed as a data pre-processing step. In the second step, the selected features are optimized by a novel feature optimization approach based on hybrid differential evolution algorithm and particle swarm optimization. The optimized features are then feed forwarded to SVM classifier. Empirical results show that our proposed model is able to achieve 99.34% accuracy. This shows that our model is robust and sustainable in diagnosis of COVID-19 infected individual."
"The emergence and global spread of the 2019 novel coronavirus (COVID-19) has imposed a significant mental health burden on communities around the world. Many of the psychiatric manifestations of COVID-19 are a consequence of psychological stressors, such as fear of illness and death, prolonged social isolation, and uncertainty and fear about the future. However, a growing body of evidence suggests that the virus itself can precipitate psychosis among infected individuals [1] . Emerging neuropsychiatric sequelae of COVID-19 include encephalopathy, anxiety, depression, mania, and trauma-related disorders [2] . The potential for the virus to induce psychosis is of particular interest given the association with acute suicidal/homicidal ideation and other severe perceptual and behavioral disturbances. Much is yet to be discovered about the biological mechanisms, presentation, treatment, and long-term outcomes of COVID-related psychotic illness. A connection with psychosis has been described in other strains of coronavirus, including the species responsible for severe acute respiratory syndrome (SARS-CoV). Common symptoms observed in SARS-related psychosis include persecutory delusions, auditory hallucinations of gossip, suicidal thoughts and behavior, and sleep disturbances [3] . One survey of recently discharged SARS patients found that disease severity-as measured by chest radiograph on admission, maximum oxygen requirement, need for ICU care, and length of hospital stay-was an independent predictor of new onset psychosis and behavioral problems in both the acute and convalescent stages of illness [4] . Compared with SARS patients without psychiatric complications, SARS patients with new onset psychosis had higher rates of family history of psychiatric illness, as well as higher rates of concurrent SARS infection in family members [3, 5] . This data suggests that personal vulnerability and psychosocial stressors may contribute, in part, to the psychosis associated with coronavirus infection. Furthermore, these findings argue against the etiological theory that SARS-related psychosis is simply a result of corticosteroid therapy. Another study found that patients with new onset psychosis have a significantly higher seroprevalence of IgG antibodies against four human coronavirus strains (229E, HKU1, NL63, and OC43) compared with non-psychiatric controls [6] . These findings suggest that coronavirus exposure may be a risk factor for development of psychosis in susceptible individuals. Psychosis caused by viral infection has been associated with other novel infectious disease outbreaks. One study reviewing literature from the H1N1 influenza, Ebola, SARS, Middle East Respiratory Syndrome (MERS), and COVID-19 outbreaks estimated that 0.9 to 4% of people exposed to a virus during an epi-or pandemic develop psychosis or psychotic symptoms, significantly higher than the median incidence rate of .015% for psychosis in the general population [7] . Researchers also found that low doses of atypical antipsychotics, particularly aripiprazole, are effective in treating psychosis associated with viral infection. Several case reports have recently been published describing patients with no psychiatric history who developed acute psychosis in the setting of positive diagnostic testing for COVID-19 [8] . Common themes observed in these patients include severe anxiety, agitation, suspiciousness, and auditory hallucinations. None of the patients displayed any of the typical respiratory or constitutional symptoms associated with COVID-19 but they did show signs of systemic inflammation as evidenced by elevated C-reactive protein (CRP) and other inflammatory markers. Here, we report the case of a patient who presented with disorganized behavior and paranoia leading to a suicide attempt in the context of positive serological testing for COVID-19 antibodies (IgG).@story_separate@Mr. C, a 52-year-old male with medical history of obstructive sleep apnea on home CPAP with no significant psychiatric history, presented to our emergency department (ED) with acute altered mental status and mutism. As per family account Mr. C had been ""off"" for 1 week, with decreased speech and paranoid delusions that he was the cause of the ""coronavirus pandemic."" The ED visit was precipitated by the onset of mutism. His vitals were 99.2°F, blood pressure 181/125, pulse 120, and respiratory rate 20. Based upon his initial presentation and vitals, a code stroke was activated. A noncontrast head computerized tomography (CT) and magnetic resonance imaging with diffusion weight imaging was negative for acute pathology. However, his blood work was significant for elevated liver transaminases along with acute inflammatory markers (erythrocyte sedimentation rate = 40, Creactive protein = 1.5, and D-dimer = 1003). His COVID-19 PCR was negative. His urine analysis was indicative of dehydration, with positive ketone and high specific gravity. In the setting of elevated D-dimer, the patient underwent a chest CT scan to rule out pulmonary embolism, which was negative; however, he was found to have multifocal pneumonia. Mr. C received intravenous antibiotics including ceftriaxone and azithromycin along with lorazepam 2 mg IV push × 2 doses. He was subsequently admitted to the observational unit for psychiatry consult. At that time, his psychotic and catatonic symptoms appeared to have resolved. He reported that two of his colleagues with whom he rides had tested positive for COVID-19. This led to him becoming anxious and feeling overwhelmed. There were no features of catatonia. He was subsequently discharged home. Mr. C returned 2 days later to the psychiatric emergency room complaining of worsening agitation, anxiety, paranoia, and mutism. He received haloperidol 5 mg IM and lorazepam 2 mg IM prior to formal evaluation. He was found to be disorganized, irritable, and with select mutism. As per history from the family, he awoke that morning stating: ""Today I should die!"" and attempted to cut his neck with a knife. Mr. C was subsequently admitted to the inpatient psychiatric ward and was started on fluoxetine 20 mg po once daily, olanzapine 5 mg po BID, and lorazepam 1 mg po BID. In the inpatient psychiatric unit, Mr. C was found to be isolated, irritable, and attempted to abscond. He remained tachycardic and Medicine was consulted and recommended that he be transferred to the Medicine service for re-testing of COVID-19. He had a subsequent negative PCR for COVID-19 (second test) and psychiatric CL service was consulted. His lorazepam was increased to 2 mg po BID but he remained irritable and attempted to cut his wrist with a plastic knife from his breakfast tray. After he was cleared by Medicine, he was transferred back to the inpatient psychiatric ward. Mr. C remained paranoid but was agreeable to electroconvulsive therapy (ECT). He underwent a total of 6 ECT treatments which led to his overall clinical improvement with no further thoughts of suicide. His discharge medications included olanzapine 2.5 mg oral QHS, sertraline 100 mg po once daily, clonazepam 0.25 mg BID, and trazadone 50 mg po qhs. Mr. C underwent IgG antibody testing for COVID-19 3 weeks after discharge and was found positive. He continued follow-up on the outpatient psychiatric and remained symptom-free as of 4 weeks post-discharge. From the patient's perspective, it was a very confusing experience. Several weeks after hospital discharge, he was unable to recall specific details or strong emotions related to hospitalization. This case shows the potential for a coronavirus-associated inflammatory trigger to precipitate psychosis in seropositive patients. Although it is possible that excessive fear and anxiety related to the pandemic may have contributed to this patient's psychotic symptoms, the role of viral exposure in the development of his psychosis must be explored. The connection between COVID-19 and new onset psychosis was first observed in China, the country with the earliest documented cases of the virus. A retrospective chart review in the city of Xuzhou showed a 10% increase in psychosis among first time psychiatric outpatients in January 2020 compared with averaged data from January 2017-2019 [9] . There was also a 25% rise in psychosis in late January 2020 versus early January 2020, with linear regression analysis revealing a strong positive relationship between psychosis incidence and number of confirmed COVID-19 cases. The study also found that mean age of first episode psychosis increased significantly from 39 (2017-2019) to 50 (2020), suggesting that age is a major risk factor for COVID-related new onset psychosis. Our patient, a 52-year-old male, is illustrative of the demographic changes highlighted in the Xuzhou study. The fact that elderly individuals have the highest risk of contracting and dying from the disease may explain the heightened psychological vulnerability of this population to the effects of the virus. Recent reports of COVID-induced psychosis describe a clinical and laboratory presentation similar to that seen in our patient [8] . One case is of a 30-year-old male with no psychiatric history who presented with several days of severe anxiety, auditory hallucinations, psychogenic polydipsia, and suicidality. On exam, he was responding to internal stimuli and believed he was being followed. Psychosis resolved after 4 days of low-dose quetiapine. The second case describes a 34-year-old female with a history of panic disorder who was evaluated for paranoia, disorganized behavior, and perseverating on strange somatic sensations, such as migratory paresthesia and the feeling of a fire burning within her body. This patient required a more complex treatment regimen of benzodiazepines, antipsychotics, and antidepressants. The final case describes a 33-year-old male with opioid use disorder who presented with first episode psychosis, including intense agitation, persecutory delusions, and auditory hallucinations. His symptoms improved with low-dose quetiapine. Many parallels can be drawn between these cases. In all three, the patients tested positive for COVID-19 but were physically asymptomatic with none of the respiratory, constitutional, or gastrointestinal symptoms typically seen with the disease. They also denied any history of anosmia or ageusia. All three patients were found to have elevated CRP, as well as elevated ferritin in the first patient. The pattern of psychotic symptoms seems to be similar across all cases, with most patients-including the one described in this reportpresenting with extreme anxiety, agitation, paranoia, auditory hallucinations, and suicidal ideation. Also like our patient, all three were fully alert and oriented on initial presentation despite their disorganized thought and behavior. This, in addition to the absence of any fluctuations in consciousness, makes the diagnosis of delirium less likely. Our patient also had elevated inflammatory markers on admission, including high CRP and ESR levels. Furthermore, our patient did not report any fever, chills, cough, sore throat, dyspnea, muscle aches, or fatigue-symptoms that are generally associated with COVID-19. Thus, it seems that patients who are prone to developing psychosis due to SARS-CoV-2 may be less vulnerable to the respiratory and systemic complications commonly caused by the virus. First established in the late nineteenth century, the theory that microbial agents are etiologically linked to psychosis has received a new wave of scientific support in recent years [10] . One study found that patients with new onset psychosis had significantly higher serum and/or CSF IgG titers for at least one of the six viruses under investigation (cytomegalovirus, HSV1, mumps, measles, varicella zoster, Japanese encephalitis virus) compared with non-psychiatric controls. Many of the psychotic patients also had a diagnostic (four-fold) change in viral antibody titers over the 2-week study period, indicating active viral infection [11] . A number of case reports have been published describing persecutory delusions, poor self-care, vivid auditory and visual hallucinations, food refusal, and insomnia following infection with the mosquito-borne dengue virus and Zika virus [12] [13] [14] . Psychiatric complications associated with these two flaviviruses seem to follow a similar pattern with onset of psychosis occurring approximately 1 week after resolution of viral symptoms (e.g., fever, rash, myalgia) and excellent response to atypical antipsychotics. Untreated HIV infection has also been associated with new onset psychosis [15] . The risk of psychosis in these patients is shown to be positively correlated with HIV viral load and negatively correlated with CD4 count [16] . Symptoms in these patients generally improve with low-dose antipsychotics and initiation of antiretroviral therapy. Additional viral infections shown to be associated with acute psychosis include H1N1 influenza, Borna disease virus, and measles virus [17] [18] [19] . Many of the patients described in the cases above had no recall of their psychotic episode after recovery. Our patient, too, denied any recollection of his hospital course or the events surrounding his hospitalization. This sort of retrograde amnesia following resolution of psychosis has been described in many cases of brief psychotic disorder, with the patient losing all memory of the entire psychotic period [20] . Several pathological mechanisms have been proposed to explain the neuropsychiatric sequelae of COVID-19, including new onset psychosis. Given that neurotropism and neuroinvasive potential has been demonstrated in many strains of coronavirus, it is possible that direct viral infiltration into the central nervous system (CNS) is responsible for the neuropsychiatric manifestations of COVID-19 [1] . It is believed that coronaviruses can migrate from the respiratory tract to the brain via retrograde axonal transport from the olfactory bulb [21] . Another possible route involves hematogenous dissemination into the CNS via infected blood leukocytes. In mouse models, the human respiratory coronavirus strain OC43 (HCoV-OC43) is shown to have a preferential tropism for infecting neurons versus other neural cells (e.g., oligodendrocytes, astrocytes, microglia) [22] . Mice inoculated with HCoV-OC43 developed signs of acute encephalitis secondary to neuronal apoptosis. These mice were found to have behavioral abnormalities with persistence of viral RNA in the brain for several months. These findings suggest that respiratory viruses with neuroinvasive potential can induce neuronal cell death and consequent psychosis in vulnerable individuals. Another proposed mechanism for COVID-related psychosis involves dysregulation of cytokine networks. Peripheral activation of proinflammatory cytokines (e.g., interleukin (IL)-6, tumor necrosis factor (TNF)-alpha, IL-8, IL-10, IL-2R) in response to COVID-19 infection may contribute to neuroinflammation via increased permeability and compromised integrity of the blood-brain barrier [8] . Immunological triggers have long been shown to play a role in the pathogenesis of psychotic illness, including the psychosis associated with HIV infection and other viruses [23, 24] . All four of the patients with COVID-related psychosis discussed here presented with elevated CRP. This acute phase reactant has been implicated in the development of psychotic disorders, with 28% of schizophrenia patients showing high CRP levels [25] . Interestingly, the serotonin antagonist cinanserin, a drug originally developed to treat schizophrenia, has also proven effective in inhibiting replication of coronavirus strains SARS-CoV and HCoV-229E. This suggests a common neuropathological mechanism underlying both schizophrenia and the psychosis associated with coronavirus infection [26] . A third possible mechanism of psychosis in COVID-19 patients may be related to the severe sensory deprivation associated with hospital isolation measures. This can occur during at home quarantine, or subsequent isolation protocols in a single hospital room with minimal direct human contact. Similar cases of acute psychosis have been described in prisoners in solitary confinement and in experimental sensory deprivation. However, this does not seem to be the case with Mr. C, who was already psychotic when he presented to the hospital, and was previously living with his family. The case of Mr. C demonstrates just one potential cause of increased suicide risk during the COVID-19 pandemic. Psychosis-associated suicidal behavior appears to be a rare, but severe neuropsychiatric sequelae of acute viral infection. However, several additional risk factors for suicide during the COVID-19 pandemic have been described recently. [27] Excessive apprehension about the spread and fatality of disease compounded by overexposure to media coverage can precipitate suicidal ideation and behavior in vulnerable individuals. Mass quarantine and physical distancing measures, while epidemiologically beneficial for slowing contagion, also carry severe psychological consequences that cannot be ignored. Moreover, growing stigma and social rejection of infected patients and their families may lead to guilt, anger, and alienation that further exacerbate psychological distress. Domestic violence, alcohol consumption, unemployment, and financial insecurity are additional risk factors for suicide that have risen in prevalence due to the COVID-19 pandemic. Finally, patients with mental illness and those who are acutely suicidal may have reduced access to the resources and care they need. Successful suicide prevention during the pandemic requires targeted interdisciplinary interventions in order to mitigate the impact of these multiple risk factors. Conflict of Interest The authors declare that they have no conflict of interest. Ethical Approval At Stony Brook University, a single case report does not require IRB review and approval since it does not meet their definition of research. Additional information can be found on the Stony Brook University IRB website in their Statement of Purpose, or provided if requested. Informed Consent The patient signed a consent authorizing the writing and publication of this case report.@story_separate@New onset psychosis is a not so common described symptom of COVID-19 infection with potential lethal consequences, which needs aggressive and early management in order to decrease morbidity and mortality.","The COVID-19 pandemic is associated with different types of stressors: fear of infection, financial burden, and social isolation. Additionally, COVID-19 infection seems to increase the risk for neuropsychiatric symptoms including psychosis. We present a case of a 52-year-old male with no previous psychiatric history who developed severe paranoia leading to a suicide attempt. He was successfully treated with a combination of milieu treatment, pharmacotherapy, and electroconvulsive therapy. We add to the nascent literature that COVID-19, as other coronaviruses, can increase the risk for severe psychosis and suicidal behavior."
"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection has spread worldwide rapidly since its emergence in Wuhan in China in early December 2019 [1] . The SARS-CoV-2 epidemic was declared a public health emergency of international concern by the World Health Organization (WHO) on January 30, 2020 [2] . To date, over 2,000,000 patients have been diagnosed with coronavirus disease-2019 (COVID- 19) globally. The cumulative number of laboratory-confirmed cases has been reported to be over 660,000 in the United States, 180,000 in Spain, 170,000 in Italy, and 80,000 in China [3]. SARS-CoV-2 was identified as a diverse clade derived from severe acute respiratory syndrome coronavirus (SARS-CoV) and Middle East respiratory syndrome coronavirus (MERS-CoV) and was reported as the cause of COVID-19 [4] . The clinical characteristics of adult patients with COVID-19 have been revealed in recent studies and mainly include fever, cough, dyspnea, and radiographic findings of pneumonia [5] [6] [7] . However, information on pediatric patients is limited. This case series describes the clinical and epidemiological features of 34 pediatric patients on the basis of epidemiological, demographic, laboratory, and radiological data and aims to contribute to a comprehensive understanding of the characteristics of COVID-19.@story_separate@a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 available data; 78%). In addition, significant increases in the levels of lactate dehydrogenase and α-hydroxybutyrate dehydrogenase were detected in 28 patients (among 34 patients with available data; 82%) and 25 patients (among 34 patients with available data; 74%), respectively. Patchy lesions in lobules were detected by chest computed tomographic scans in 28 patients (82%). Ground-glass opacities, which were a typical feature in adults, were rare in pediatric patients (3%). Rapid radiologic progression and a late-onset pattern of lesions in the lobules were also noticed. Lesions in lobules still existed in 24 (among 32 patients with lesions; 75%) patients that were discharged, although the main symptoms disappeared a few days after treatment. All patients were discharged, and the median duration of hospitalization was 10.00 (8.00-14.25 ) days. The current study was limited by the small sample size and a lack of dynamic detection of inflammatory markers. Why was this study done? • Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection has spread rapidly worldwide. • Early identification and intervention are necessary for effective control of the epidemic in both adults and children; however, the information on clinical and epidemiological characteristics in pediatric patients was limited. What did the researchers do and find? • We collected and analyzed the clinical data of 34 pediatric patients with coronavirus disease-2019 (COVID- 19) in 4 hospitals in China from January 27 to February 23, 2020. • We described the clinical and epidemiological characteristics of the patients and focused on the features of initial symptoms, radiological findings, and outcomes. • In contrast to that observed in adult patients, higher proportion of fever, vomiting, and diarrhea were noticed on admission in pediatric cases. Patchy shadows with a high density were common in lobule lesions, whereas the typical features of ground-glass opacities seen in adults were rare in pediatric cases. • A late-onset pattern of lobule lesions was revealed on the basis of chest computed tomographic scans. The clinical presentations were not as severe as the signs observed in the computed tomography (CT) images, and the recovery of lesions in lobules lagged behind that of the main symptoms.  This retrospective, observational study was approved by the institutional review board (IRB) of the Affiliated Taihe Hospital of Hubei University of Medicine (ethical approval no. 2020KY01). Suspected patients with clinical and/or radiological features of pneumonia were quarantined prior to SARS-CoV-2 nucleic acid detection according to WHO guidelines for cases with suspected infection [8] as well as the instructions from the Pediatric Branch of the Hubei Medical Association for pediatric cases [9] . Specifically, suspected cases of SARS-CoV-2 infection should meet 1 of the following criteria [10] : (1) at least 1 clinical symptom, including fever, expectation, tachypnea, lethargy, poor feeding, cough, vomiting, and diarrhea; (2) chest radiologic abnormalities consistent with viral pneumonia. Diagnosis was confirmed by the SARS-CoV-2 nucleic acid test with samples from respiratory tract swabs. Admitted children with laboratory-confirmed SARS-CoV-2-positive results from 4 hospitals in West China from January 27 to February 23, 2020, were included. The clinical type of disease (S1 Table) was assessed for each patient according to the recommendation of the National Health Commission of the People's Republic of China (NHC) [10] . Patients were discharged when all the following criteria were met [10] : (1) fever had recovered for at least 3 days; (2) upper respiratory symptoms were alleviated; (3) the exudative lesion was alleviated significantly according to radiological evidence; (4) negative results were obtained for SARS-CoV-2 nucleic acid detection in 2 consecutive tests performed with an interval of 24 hours. The final follow-up visit was completed by March 16, 2020. Assent was gained from school-aged children, and written informed consent was provided by their parents or guardians prior to data collection. There was no prespecified protocol prior to the current study. The clinical process and data analysis plan are shown in Fig 1.  Samples were taken from nasopharyngeal or throat swabs for SARS-CoV-2 detection. SARS-CoV-2 RNA was detected by real-time reverse transcription polymerase chain reaction (RT-PCR) (S1 Text) in accordance with the recommendation of the NHC [11] . The results of SARS-CoV-2 nucleic acid detection were analyzed by following the manufacturer's instructions. Cases with negative results were double checked by resampling and retesting with an interval of 24 hours and could be confirmed when negative results were obtained in 2 consecutive tests. A series of laboratory tests were conducted, including hematological, serum biochemical, acute-phase protein, and erythrocyte sedimentation rate (ESR) testing. In particular, samples from nasopharyngeal or throat swabs were tested for common respiratory pathogens,  including influenza A and B virus, respiratory syncytial virus, adenovirus, parainfluenza virus, Epstein-Barr virus, and Mycoplasma pneumoniae, using RT-PCR assays with established methods. Patients underwent chest computed tomography (CT) scans. The radiologic assessments were conducted in Taihe Hospital, which was a treatment center for COVID-19 designated by local municipal government. The images were stored in picture archiving and communication systems (PACS) and reviewed by 2 experienced pediatric radiologists independently. A third radiologist reviewed all CT findings for confirmation. The medical records of the included patients were accessed by the study team for data collection. Clinical data were extracted, including demographic data, medical history, epidemiological history, underlying diseases, clinical symptoms, signs, laboratory findings, radiological characteristics, treatments, and outcomes. In particular, exposure history was investigated if the patients met any of the following criteria [10] : (1) travel history in Wuhan or neighboring areas or other areas with persistent local transmission within 14 days prior to disease onset; (2) a SARS-CoV-2 infection diagnosis in the child's family or caregivers; (3) close contact with people who might have or with confirmed SARS-CoV-2 infection or patients with unexplained pneumonia; and (4) children who were associated with a cluster outbreak. In addition, mixed infection was defined as the concurrent infection of a patient with 2 or more pathogens. Two researchers from the Institute of Drug Clinical Trials of Taihe Hospital cross-checked the collected data to ensure quality control and communicated with attending doctors or other healthcare providers if they had any questions. This study was reported based on a STROBE checklist (S1 STROBE Checklist). Descriptive statistics were determined using SPSS software (version 20.0, IBM, https://www. ibm.com/analytics/spss-statistics-software, Armonk, NY, USA). No imputation was made for missing data. Categorical variables are presented as number and frequency rates. Continuous variables are presented as the median and interquartile range (IQR). In this study, 57 suspected pediatric patients were screened, among whom 34 patients with confirmed COVID-19 were enrolled (Fig 1) , including 14 male patients (41%) and 20 female patients (59%). The first patient was diagnosed with SARS-CoV-2 infection on January 27, 9 days after his father was diagnosed with COVID-19. There were 21 cases (62%) that were diagnosed after 15 February, and an uptrend of daily confirmed cases was observed until the cutoff date of our recruitment phase (Fig 2) . The median age was 33 (IQR 10.00-94.25) months with a range of 1 to 144 months. Eighteen patients (52%) had exposure to residents of Wuhan. In addition, 13 (38%) patients had close contact with family members with COVID-19, and 16 (48%) patients were noted to be without a history of exposure to an identified source. In particular, mixed infections of other respiratory pathogens were reported in 16 patients (47%), including M. pneumoniae (26%), influenza B virus (18%), influenza A virus (9%), respiratory syncytial virus (6%), Epstein-Barr virus (6%), parainfluenza virus (3%), and adenovirus (3%). Comorbidities were reported in 6 patients (18%). With respect to the initial symptoms and signs, fever (76%) and cough (62%) were the most frequently complaints. Meanwhile, expectoration (21%), tachypnea (9%), vomiting (12%), and diarrhea (12%) were reported as well. Patients in our study presented mild (18%) or moderate (82%) forms of disease, and moderate cases were predominant (96%) in 23 patients who were not older than 72 months (Table 1) . On admission, hematological tests indicated that the lymphocyte count was increased in 17 patients (50%), although the median value (3.19, 1.73-4.34) was within the normal range. Concerning the findings of blood biochemistry, prealbumin (median 138.65 mg/L) was decreased significantly in 25 patients (among 32 patients with available data; 78%), whereas a substantial increase was detected in serum amyloid A (SAA) for 17 patients (among 20 patients with available data; 85%) and high-sensitivity C-reactive protein (hs-CRP) for 17 patients (among 29 patients with available data; 59%). In addition, a noticeable increase was observed in lactate dehydrogenase (LDH) for 28 patients (among 34 patients; 82%) and in α-hydroxybutyrate dehydrogenase (α-HBDH) for 25 patients (among 34 patients; 74%). However, the results for creatine kinase (CK) and creatine kinase-MB (CK-MB) were normal for all patients ( Table 2) . No other significant findings were observed in routine blood coagulation tests or urine and stool tests. The results of the electrocardiogram (ECG) exam were normal in all patients during hospitalization. During hospitalization, laboratory tests were reviewed 7 days after admission. The levels of SAA, hs-CRP, and prealbumin had recovered within 7 days posttreatment for all patients with abnormalities at baseline. The median duration for recovery was 7.00 (7.00-10.00) days for LDH and 8.00 (7.00-10.00) days for α-HBDH. The proportion of patients who recovered in LDH and α-HBDH were 86% (for 24 patients) and 84% (for 21 patients), respectively. Lesions in lobules that were characterized by patchy shadows of high density were indicated by chest CT scans in 28 patients (82%) on admission. A ground-glass opacity with patchy shadows was observed in 1 case (3%) in our study (Table 3) . Both unilateral lesions (41%) and bilateral lesions (41%) were detected in the patients with radiological findings. Notable lesion progression was detected in 18 (among 28 patients with lesions on admission; 64%) patients during hospitalization (Patient 1 in Fig 3) . Moreover, a late-onset pattern in the chest CT images was observed in 4 cases (among 34 patients; 12%). These patients had normal initial CT images on admission; however, lesions in lobules emerged in 4-5 days thereafter (Patient 2 in Fig 3) . There were only 2 cases (among 34 patients; 6%) without emergence of lesions during hospitalization. Antiviral treatments were employed according to the recommendation of the NHC [10] for mild and moderate cases. All patients received interferon-α nebulization twice a day. Ribavirin was given to 15 (44%) patients twice a day. In addition, 20 (59%) patients received traditional Chinese medicine. Antibiotics were given to 11 patients with an initial diagnosis of bacterial pneumonia on admission before detection of SARS-CoV-2 infection and were withdrawn after confirmation of COVID-19. Nine patients received antibiotic therapy because of concerns about viral-bacterial mixed infections during hospitalization. Azithromycin was given to 9 patients with M. pneumonia infection. Corticosteroid (15%) and oxygen inhalation supportive therapy (9%) were also employed (Table 3) .  All patients were discharged once the main symptoms disappeared and the SARS-CoV-2 tests became negative. However, lesions in lobules recovered in only 8 patients. The lesions still existed in 24 patients (among 32 patients with lesions; 75%) when they were discharged (Fig 4) . The duration of fever was 3.00 (2.00-4.00) days, similar to that of cough (4.00 days, 2.00-7.00). The duration of hospitalization was 10.00 (8.00-14.25) days for all patients. A shorter duration of hospitalization was indicated in mild cases (8.00 days, 7.00-9.50) than in moderate cases (10.50 days, 8.00-15.00) ( Table 4 ). Along with the rapid spread of SARS-CoV-2 infection, the pediatric cases of COVID-19 gradually increased. The morbidity of COVID-19 in children was reported as 0.9% in China [1], 1.2% in Italy [12] , and 5% in the USA [13] . However, the clinical and epidemiological characteristics of pediatric patients have not yet been determined clearly. Here, we report the clinical and epidemiological features of 34 pediatric patients with COVID-19 aged from 1 to 144 months. Patients experienced mild or moderate disease forms in the current study. Most patients suffered from fever and cough, which recovered within 3.00-4.00 days after treatment. The progression pattern of the lesions in lobules was revealed by chest CT scan, and the lesions  still existed in the majority of patients when discharged. Unlike other reports, the typical feature of ground-glass opacity observed in adults was rare in pediatric patients based on our data. Substantial increases were detected in SSA, hs-CRP, LDH, and α-HDBD, all of which recovered promptly after treatment. The current study found that all the patients presented mild or moderate COVID-19 disease, which was consistent with the results of previous studies [14, 15] . It was also reported that 94% of cases were identified as asymptomatic (4%), mild (51%), or moderate (39%) among 2,143 confirmed and suspected pediatric patients in China [14] . The underlying mechanisms of milder disease presentation in children compared with adults has been a topic of research, and several hypotheses have been raised based on the current understanding of COVID-19. One possible explanation may be related to a reduced inflammatory response due to the less well-developed immune system in children than in adults [16] . However, a substantial increase in hs-CRP was detected in 59% of cases in our study, which was similar to that observed in adult cases (61%) [1] . This finding suggested that an immunological response that was similar to that in adults occurred in the pediatric population in neighboring areas of Wuhan, which did not support the immature immune system theory. Serum inflammatory marker detection  was not performed in our study because of the limitation of the retrospective study design, and such detection could be helpful to address this controversial issue in the future. The other theory originated from the observation that younger children experienced milder disease courses. Children of younger age tend to have many viral infections, and it is possible that repeated viral exposure strengthens the immune system when it responds to SARS-CoV-2 [17] . Correspondingly, mixed infection was detected in 16 (47%) patients with other pathogens, including M. pneumoniae, influenza A and B virus, respiratory syncytial virus, Epstein-Barr virus, parainfluenza virus, and adenovirus. However, all these pathogens were tested to be negative in 10 pediatric cases from Guangzhou [18] . Stratified analysis according to age range was performed to determine the correlation between age and mixed infection, if any, as well as the impact of mixed infection on the clinical type of disease. As a result, mixed infection (62% in 13 patients) was most common in children aged between 12 and 72 months, and 12 moderate cases (92% in 13 patients) were identified in this subgroup. It was suggested that mixed infection did not increase protection to ameliorate the disease course of COVID-19 based on our data. In addition, children with moderate disease aged below 72 months accounted for 79% of all moderate cases, suggesting that preschool children were more prone to developing SARS-CoV-2 infection. According to our current data from the chest CT images, patchy shadows were detected in 82% of patients on admission, which was in accordance with previous reports in adults (86%) [1] and children (65%) [15] . Lesions in lobules were characterized with patchy shadows of high density in most cases (97%). Ground-glass opacity was rare (3%) in the current study, although it was common in pediatric cases from Wuhan (33% in 171 cases) [15] and Guangzhou (50% in 10 cases) [18] , as well as in adults (56%) [19] . Notably, the proportion of patients with a history of exposure was 52% in current study, whereas the proportion was 90% in 171 cases from Wuhan [15] and 100% in 10 cases from Guangzhou [18] . Thus, exposure status might attribute partially to the discrepancy of proportions in pediatric cases between current study and previous studies. Further study was needed to reveal the correlativity between viral load of SARS-CoV-2 and exposure status to identify the underlying reason for the discrepancy. The time course of lung changes was revealed in adult patients [20] ; however, the course of progression remained elusive in pediatric cases. Notably, severe progression of lesions in lobules was noticed within 7 days after admission in the current study and even sometimes appeared 4-5 days after admission. However, the clinical presentations were not so severe as the signs shown in CT images. Rapid radiologic progression was also reported, with a peak at approximately 2 weeks after onset [21] in adult cases. In addition, a late-onset pattern of lesions was detected in some cases, because the lesions were indicated by the CT scan after approximately 7 days after symptom onset, which was similar to that observed in other report for adults (6-12 days) [22] . Nonetheless, our findings suggest that close monitoring for pediatric patients should be performed because of the severe progression of lesions in lobules and the late-onset pattern seen in some cases. The level of SAA was found to be increase in a high percentage (for 17 patients among 20 patients with available data; 85%) of patients undergoing the test and was a sensitive marker correlated with the extent of pneumonia in SARS patients [23] . The levels of hs-CRP and SAA recovered dramatically within 7 days after treatments. The correlation of SAA and SARS-CoV-2 infection remains to be investigated in pediatric patients. Consistent with previous reports in adults [1, 6] and children [24] , the levels of LDH and α-HBDH were increased without any symptoms or signs of myocardial impairment. With respect to the initial symptoms, fever was identified in 26 children (76%) in our study; however, it presents in only 44% of adult patients on admission [1] . In addition, vomiting (12%) and diarrhea (12%) also present on admission and were more common in children than in adult patients (5% for vomiting and 4% for diarrhea) [1] . Comorbidities were found in 6 patients (18%) in the current study, which was similar to that observed in adult patients with mild symptoms (21%) [1] . The therapeutic strategy was based on antiviral therapies, which was in alignment with the recommendations of the NHC [10] . All the patients had recovered from the main symptoms when discharged. A negative SARS-CoV-2 detection result was achieved in 10.00 (8.00-14.25) days. Lesions in lobules still existed in 75% of patients, although great improvements were shown in CT scans after treatments. An association of the radiologic findings with mortality was revealed in adult patients [19] . However, it was not suggested to utilize CT scans for prognosis prediction in mild and moderate cases because no definitive correlation was found between radiologic imaging and the course of the disease in our study. Our study also adds new information to existing reports on epidemiological characteristics. A considerable percentage of pediatric patients (48%) was noticed to have an unidentified source of infection, whereas up to 72% of nonresidents of Wuhan had contact with residents of Wuhan [1] . The unanticipated findings suggested that the reference value of exposure history to epidemic areas for the early identification of SARS-CoV-2 infection should be considered carefully for pediatric patients during the rapid development of epidemics. The correlation of exposure history with disease severity could be investigated in a future study with a larger population. In accordance with the present studies [14, 25] , family cluster transmission was found to be common in our pediatric patients. There have been few reports of the infection dynamics from pediatric patients to their caregivers, although transmission from adults to children has been identified with confirmed evidence. Children may become potential spreaders in the explosive stage of the outbreak, which was attributed to a high prevalence of asymptomatic infection and milder disease in the pediatric population [25] . Thus, a close monitoring and tracking system involving hospitals and communities was utilized to track the transmission between pediatric patients and their caregivers. However, no evidence was shown regarding the transmission route from pediatric patients to their caregivers and closecontact family members. The patient population in the current study is representative of pediatric cases diagnosed and treated in West China. However, the interpretation of our findings was limited by the small sample size and retrospective study design. The underlying reasons for the lower risk of the severe form of COVID-19 in children remain elusive because of a lack of dynamic detection of the viral load of SARS-CoV-2 and inflammatory markers. Further information about these issues would help us to obtain a broader view of COVID-19.@story_separate@Our data systemically presented the clinical and epidemiological features, as well as the outcomes, of pediatric patients with COVID-19. Stratified analysis was performed between mild and moderate cases. The findings offer new insight into early identification and intervention in pediatric patients with COVID-19. This case series described the clinical and epidemiological characteristics of pediatric patients with COVID-19. Our data presented the clinical features of pediatric patients to facilitate early identification and intervention in suspected patients. Notwithstanding the relatively limited number of samples, our findings offer valuable insight into the early diagnosis and epidemic control of COVID-19 in children.","BACKGROUND: As of April 18, 2020, over 2,000,000 patients had been diagnosed with coronavirus disease-2019 (COVID-19) globally, and more than 140,000 deaths had been reported. The clinical and epidemiological characteristics of adult patients have been documented recently. However, information on pediatric patients is limited. We describe the clinical and epidemiological characteristics of pediatric patients to provide valuable insight into the early diagnosis and assessment of COVID-19 in children. METHODS AND FINDINGS: This retrospective, observational study involves a case series performed at 4 hospitals in West China. Thirty-four pediatric patients with COVID-19 were included from January 27 to February 23, 2020. The final follow-up visit was completed by March 16, 2020. Clinical and epidemiological characteristics were analyzed on the basis of demographic data, medical history, laboratory tests, radiological findings, and treatment information. Data analysis was performed for 34 pediatrics patients with COVID-19 aged from 1 to 144 months (median 33.00, interquartile range 10.00–94.25), among whom 14 males (41%) were included. All the patients in the current study presented mild (18%) or moderate (82%) forms of COVID-19. A total of 48% of patients were noted to be without a history of exposure to an identified source. Mixed infections of other respiratory pathogens were reported in 16 patients (47%). Comorbidities were reported in 6 patients (18%). The most common initial symptoms were fever (76%) and cough (62%). Expectoration (21%), vomiting (12%), and diarrhea (12%) were also reported in a considerable portion of cases. A substantial increase was detected in serum amyloid A for 17 patients (among 20 patients with available data; 85%) and in high-sensitivity C-reactive protein for 17 patients (among 29 patients with available data; 59%), whereas a decrease in prealbumin was noticed in 25 patients (among 32 patients with available data; 78%). In addition, significant increases in the levels of lactate dehydrogenase and α-hydroxybutyrate dehydrogenase were detected in 28 patients (among 34 patients with available data; 82%) and 25 patients (among 34 patients with available data; 74%), respectively. Patchy lesions in lobules were detected by chest computed tomographic scans in 28 patients (82%). Ground-glass opacities, which were a typical feature in adults, were rare in pediatric patients (3%). Rapid radiologic progression and a late-onset pattern of lesions in the lobules were also noticed. Lesions in lobules still existed in 24 (among 32 patients with lesions; 75%) patients that were discharged, although the main symptoms disappeared a few days after treatment. All patients were discharged, and the median duration of hospitalization was 10.00 (8.00–14.25) days. The current study was limited by the small sample size and a lack of dynamic detection of inflammatory markers. CONCLUSIONS: Our data systemically presented the clinical and epidemiological features, as well as the outcomes, of pediatric patients with COVID-19. Stratified analysis was performed between mild and moderate cases. The findings offer new insight into early identification and intervention in pediatric patients with COVID-19."
"COVID-19 has drastically disrupted the personal and professional lives of billions of citizens globally and forced governments throughout the world to quickly adapt to a new reality characterized by increasing mortality rates, lockdowns, social distancing, and teleworking (Oldekop et al., 2020) . The first wave of the pandemic overwhelmed public health systems worldwide, posing a threat not only to those directly infected and suffering, but to society at large (Weible et al., 2020) . Governments face enormous challenges in dealing with the virus, adopting new policies, supporting vulnerable communities and individuals, making progress on sustainable development goals, and finding new ways to achieve results under intense pressure (Barbier & Burgess, 2020; Naidoo & Fisher, 2020) . Scholars have long argued that government response during a crisis needs to be coordinated with and supported by other actors, such as citizens, civil society including community and nongovernmental organizations, and other network partners (Kapucu, 2006) . Collaboration among government, volunteers, and community groups can be considered a form of coproduction (Goodwin, 2019; Ostrom, 1972) . Following Elinor Ostrom's seminal work, coproduction can be defined as ""the process through which inputs used to provide a good or service are contributed by individuals who are not 'in' the same organization"" (Ostrom, 1996 (Ostrom, , 1073 . Coproduction usually refers to the direct involvement of citizen ""lay actors"" (Nabatchi, Sicilia, & Sancino, 2017, 769) with government in voluntarily providing public services that create value for their communities (McGranahan, 2015; Ostrom, 1996) . Coproduction can involve citizens and community groups, who are better aware of local conditions and help to assure that interventions reflect specific needs and customs (Ostrom, 1990, 92) . Volunteering is a key component of coproduction, as coproducing volunteers actively provide relevant public services to their own communities, typically without tangible compensation (Nabatchi et al., 2017) . Working with volunteers and voluntary groups to provide community services has the potential to fill acute gaps and prevent public agencies from being overwhelmed during crisis events, such as COVID-19. Yet a main barrier to public volunteerism is government capacity to effectively utilize volunteers and to match volunteer coproducers with appropriate tasks (Gazley & Brudney, 2005) . Digital platforms (e.g., mobile apps) can play a key role in addressing this barrier, helping to marshal efforts and resources to ameliorate the effects of the pandemic. Communication-related mobile apps help overcome existing geographical, temporal, and organizational barriers (Lember, Brandsen, & Tõnurist, 2019) and scale the coproduction process by reaching more participants more quickly with up-to-date information (Meijer, 2012) , while supporting non-pharmaceutical interventions such as social distancing that aim to reduce contact rates in times of contagion (Ferguson et al., 2020; Oldekop et al., 2020) . In China, after the initial outbreak of COVID-19 in Wuhan, the pandemic rapidly spread as the country began its most important annual holiday, the Spring Festival (Chen, Yang, Yang, Wang, & Bärnighausen, 2020) . Following swiftly on the pandemic's heels was a wave of volunteers, often recruited via mobile apps, to support and extend official efforts, engage in urgent on-the-ground tasks ranging from emergency transport and the delivery of food, masks, and medicine to vulnerable populations, and provide logistical support for frontline medical staff. In recent years, China's government has come to realize the value of leveraging civil society organizations to deliver social services, meet public needs, and strengthen its own legitimacy (Moore, 2019; Schwarz, Eva, & Newman, 2020) . As a result, volunteerism in China has gradually gained momentum since the 2008 Sichuan Earthquake, the 2008 Beijing Olympics, and the 2010 Shanghai World Expo (Cheung, Lo, & Liu, 2012) . As noted by Wu, Zhao, Zhang, and Liu, 2018, 1206) , ""the Chinese government has been a primary mobilizer of citizens' volunteer participation,"" often through community organizations assisting the state on local service delivery. This is an example of top-down and state-driven coproduction (Li, Hu, Liu, & Fang, 2019) that differs from the bottom-up coproduction frequently found in the global South (Castán Broto & Neves Alves, 2018; Mitlin, 2008) . In China, volunteer networks are operated by community organizations yet endorsed by government which initiates the process through long-term relationships with civil society and legitimates volunteer action. Scholars state that ""the evidence base for coproduction is relatively weak"" (Nabatchi et al., 2017, 766) and ""there has been little quantitative empirical research on citizen coproduction"" (Bovaird, Stoker, Jones, Löffler, & Roncancio, 2016, 48) . To close this research gap, we analyzed usage data from 85,699 COVID-19 volunteers gathered through China's leading volunteering digital platform from January to February 2020, as the first wave of the pandemic peaked in China. We then conducted a more individualized survey among a sample of 2,270 of these COVID-19 volunteers followed by semi-structured interviews with 14 senior managers of civil society organizations in charge of coordinating the service activities in Zhejiang Province. This mixed methods approach involving three levels of data acknowledges the importance of methodological diversity in pursuit of a robust understanding of the research questions. Our study makes two contributions to theory and practice. First, the volunteer dynamics seen here in terms of swift ramping up and switching over to COVID-19 suggest a ""crowding out"" or redeployment effect of experienced volunteers in response to the crisis. Second, China's recent experience illustrates how community organizations and citizen volunteers can work together with public sector agencies at a local level. Their experience speaks to one of the classic challenges of coproduction: How to create sustainable cooperation between government and citizens that continues beyond a particular crisis, such as COVID-19, and forms enduring relationships to address future challenges (Lam, 1996) . Despite these contributions, our study does have some limitations. The limited time frame and single-country focus restrict generalizability of the findings; instead, we aim to provide a useful base for future studies in multiple country settings, possibly with multiple rounds of data collection over time. The remainder of this article is structured as follows: The next section details the methods used in collecting quantitative and qualitative data from volunteers on the frontlines of the pandemic in China. Section 3 analyzes the results, including volunteering trends and demographics during the peak, the role of experience and preparation, and the collaborative relationship of government, volunteers, and civil society. Finally, we interpret the findings through the lens of coproduction theory and make recommendations for the future.@story_separate@We gathered the original digital data for this study from 85,699 volunteers working from January 21 to February 22, 2020-the period when the COVID-19 pandemic emerged, peaked, and subsided in eastern China. Existing data were collected via the 'ZYH' (ZhiYuanHui, meaning ""volunteering together"") volunteer app, focusing on usage, overall volunteering patterns and aggregated demographic information (see sections 3.1. and 3.3.). As a mobile platform for smartphone users, ZYH is the most popular app for volunteers and a range of civil society organizations in China, operating in all 31 provinces. Its key functions include volunteer recruitment posts, a search function for individuals to find and join volunteer projects, and a social media element allowing participants to share their experiences. While not specifically launched for COVID-19, the app soon came to be used for pandemic-related volunteering in January 2020. We then hosted an electronic survey through the ZYH app for individual volunteers from this larger user group. A total of 5,000 randomly selected COVID-19 volunteers received a survey invitation automatically generated by the ZYH system. The survey resulted in a respondent sample of 2,270 volunteers, a response rate of 45%, and provided more individualized information about their efforts, such as perceived effectiveness and experience (see sections 3.1.2., 3.2., and 3.3.). Finally, one-on-one semi-structured interviews lasting approximately 20-30 minutes were conducted by one of the authors with 14 local civil society leaders who have played an important role in recruiting and deploying volunteers, using ZYH, during this time period. This provided information on volunteers and government collaboration from an organizational perspective (see sections 3.3. and 3.4.). Applying purposive sampling, we interviewed one civil society leader from each of 11 sub-provincial and prefecture-level cities, along with three additional leaders interviewed from the hardest-hit cities (i.e., Hangzhou, Wenzhou, and Taizhou). These cities are valuable examples because each subprovincial or prefecture-level city encompasses a large metropolitan area with three to six million people, including an urban core and surrounding area of smaller cities, towns and villages. Our findings reveal numerous details about the rise in volunteer numbers, characteristics and experience of the volunteers, as well as government volunteer relations. Digital usage data from the ZYH app (N=85,699) over the span of one month (January 21 -February 22, 2020) provides a snapshot of volunteering in the eastern province of Zhejiang over the timeline of the pandemic. During this time period, these volunteers contributed a total of 3,544,780 volunteer hours averaging out to 41.36 hours per person on COVID-related efforts. i The daily volunteering rate began slowly and then grew robustly in response to the infection rate (see Figure 1 ). On January 21, the number of COVID-19 related volunteers working through the app in the region was just 9 among total ZYH volunteers of 12,111. As the virus took hold in central China's Hubei Province, the capital city of Wuhan entered lockdown on January 23, with 16 more Hubei cities locking down by January 25 (Leung, Wu, Liu, & Leung, 2020) . At the same time, volunteering in the east reached a low ebb as the Spring Festival or Lunar New Year, the most important Chinese holiday, began (Chen et al., 2020) . As the virus swept east into Zhejiang, the daily volunteer rate rose: from 522 COVID-19 volunteers on January 26 to 18,553 on February 5. The city of Wenzhou in eastern Zhejiang locked down February 2, followed by semi-lockdowns across 50 major cities. Daily rates of volunteering grew as pandemic conditions worsened: by the time infections peaked on February 7, more than 20,000 volunteers per day were involved in Zhejiang relief efforts. 2 The daily volunteering rate peaked at 29,772 on February 12 and remained above 20,000 through February 22, as the curve began to flatten and gradual re-opening began in Wenzhou and other hard-hit areas. [ Figure 1 here] Based on digital use data, Figure 2 highlights the volunteer focus on COVID-19 rather than other social issues during the peak of the pandemic. Early in the crisis, prior to January 24, COVID-related volunteers constituted less than 1% of total daily volunteers. The proportion of COVID-19-related volunteers rose swiftly from 4% on January 25 to 25% on January 27 to 50% on January 30 before peaking close to 88% of the volunteers on February 10. As the infection rate slowly subsided, the proportion of COVID-19 volunteers to total daily volunteers remained above 80% through February 22. [ Figure 2 here] The volunteer survey data (N=2,270) further illuminates this trend. While some new volunteers joined due to the pandemic, the majority had previously enlisted for other causes. More than three-fourths (76.3%) of the surveyed volunteers were registered on ZYH before the pandemic (e.g., for environmental protection or elderly care) and shifted their focus to COVID-19, suggesting that the urgency of the pandemic ""crowded out"" other social issues. Viewed more positively, this crowding out represents redeployment of volunteer resources in a crisis. Redeployment occurred at both organizational and individual levels, as noted in the qualitative interviews with civil society leaders. For instance, one community group that orginally supported special needs children expanded to offering pandemic-related support for this population and their families during the outbreak. Another organization that originally had focused on ridesharing adapted its efforts to provide emergency patient transport, material delivery, rescue, and logistics. The crowding-out effect -or redeployment -matters not only to those causes that are temporarily abandoned but also to the process of coproduction. While coproduction is a voluntary effort on the part of individuals and organizations, a top-down approach led by the state (Li et al., 2019) has agenda-setting power to focus attention during a crisis, attracting and coordinating voluntary coproduction efforts in the public interest. Successful coproduction can also leverage long-term relationships among existing volunteers and local community groups (Joshi & Moore, 2004; Mitlin & Bartlett, 2018) , who can rapidly redeploy from one issue to another while utilizing local knowledge and previous expertise in the face of a public crisis. As seen in the survey sample (N=2270), volunteers came from a broad range of occupational backgrounds. This included private firms and entrepreneurs (19.2%), freelancers and not employed (18.3%), and public institutes such as health, science, and education (15.9%). While 10.8% of survey respondents stated they were mobilized by a leadership figure, 85.8% stated they volunteered on their own initiative, indicating a strong voluntary motive for the great majority. Regarding gender, over the entire period (January 21 to February 22), the proportion of male volunteers was somewhat higher than that of females (55% vs. 45%), based on the digital usage data and in contrast with the findings in other contexts showing women's higher volunteering rates (Parrado, Van Ryzin, Bovaird & Löffler, 2013) . This may be due to school closures, as well as China's Spring Festival (January 25-26), when female family members are often preoccupied with household tasks and holiday preparations. As the pandemic worsened, the proportion of females volunteers increased, with 52-55% males remaining. A further observation pertains to the experience and midlife stage of volunteers. During the pandemic, senior citizens could not be expected to volunteer, given the health risks involved. As a result, the average age of volunteers during the first wave was 40-42 years old, and this trend was consistent every day and night from mid-January to mid-February. This finding fits with volunteering patterns in other contexts such as the US and the UK, where well-qualified midlife citizens play a key role, particularly in community services (Wilson, 2012) . However, the real value of age is rooted in experience. Participants' experience enhances professionalized service delivery, a key feature of coproduction, and a growing trend in volunteerism generally. Both the survey and qualitative interviews provide insights regarding experience. Among survey respondents, those volunteers who had been registered longer on the ZYH app between 2015 and 2020, gaining volunteer experience, had a higher level of perceived effectiveness in terms of whether they believed the volunteering helped control the pandemic (based on an ANOVA of effectiveness score by ZYH registration year: F(5/2265)=3.202, p<.007). In addition, interviews with civil society leaders show they valued midlife volunteers for their experience gained through employment or previous crisis volunteering. One leader observed: ""There are a total of 50 of our backbone volunteers. Many of them came out with me [before]. We are now 35 to 40 years old and have experienced a lot … including typhoons and earthquakes. They are very experienced in all aspects, and they have become our main backbone"" [R10]. Other leaders commented, ""Volunteers are in their 30s, 40s, and 50s. They are basically local people"" [R2]; ""We have participated in most of the disaster relief in China. Our team has rich experience and training"" [R9]. This finding extends earlier work suggesting that the decision to coproduce is strongly influenced by the human capital and knowledge of citizens (Alford, 2009 ) and that older citizens are often more likely to collaborate with the public sector than their younger counterparts (Parrado et al., 2013) . Scholars note that successful coproduction requires citizen competence such as experience and professional skills in order for individuals to feel confident contributing (Van Eijk & Steen, 2014) . In this way, coproduction taps into citizen resources as part of a portfolio of strategies to achieve broader public goals (Alford, 2009 ). Many of the Zhejiang COVID-19 volunteers provided service through civil society organizations that have long-term relationships with regional and local governments to provide specific types of services to members of their own communities during times of need. Working at the city and county level, these organizations helped to organize the service, Examples such as these demonstrate how volunteer activity is coordinated by community groups at the behest of government agencies, which initiate requests through local networks of local organizations. This reflects a top-down version of coproduction that Li and colleagues termed ""state-led coproduction"" (2019, 250) in which the state retains control over critical components, setting priorities, and providing legitimacy. This approach contrasts sharply with the instances of bottom-up coproduction frequently found in the global South (Mitlin & Bartlett, 2018) . Nevertheless, the provision of pandemic-related services has become more participatory in China, extending citizen involvement to areas previously reserved primarily for the government, due to necessity as well as policies encouraging volunteerism. While bottom-up forms of coproduction are an important strategy for grassroots organizations to increase political power (Castán Broto & Neves Alves, 2018; Mitlin, 2008) , top-down state-led coproduction is useful during public crises that require swift, decisive action at the center as well as engagement of local communities to respond effectively.@story_separate@This study generates lessons from the frontline of COVID-19 in China, based on digital data from 85,699 volunteers along with 2,270 survey respondents and interviews with 14 community leaders, with relevance for other countries combating the global pandemic (Oldekop et al., 2020) . The results illustrate a key role for experienced volunteers who were able to swiftly deploy, or redeploy, to address the emerging crisis. A collaborative approach leveraging networks among public agencies, community organizations, and citizen volunteers allowed rapid mobilization to meet urgent demand for public services. These findings from Zhejiang Province provide empirical evidence of citizen coproduction through volunteering in east Asia, which has previously been neglected in the research (Bovaird et al., 2016; Ma & Wu, 2020) . On a conceptual and practical level, the study provides useful insights into top-down, state-led coproduction implemented through long-term relationships among local agencies, organizations and people. The localization of crisis response contrasts sharply with the expanding phenomenon of overseas volunteering (Meneghini, 2016) that uses professionals or youth from one country (usually from the global North) to carry out activities in another country (usually in the global South) for a limited period of time. It also diverges from primary reliance on government or international development organizations typically associated with crisis response. Instead, these COVID-19 volunteers in China were members of the communities they served who were able to understand local norms, relationships, and dialects, applying competences on the ground close to home. As Ostrom (1996 Ostrom ( , 1083 predicted, ""coproduction rapidly spills over to other areas."" In our study, coproduction involving local volunteers and groups guided by government not only addressed COVID-19 but enhances capacity for swift ramping-up to fill gaps in services when future crises occur. Despite the positive results, citizen volunteerism should not be considered a panacea for meeting public needs (Bovaird, 2007) , or an opportunity for states to abrogate responsibility (McLennan et al., 2016) , engage in cost-shifting, or divert additional burden to vulnerable groups (Mitlin & Bartlett, 2018) . Such efforts are unlikely to result in sustained development or citizen engagement. Going forward, coproduction is likely to become increasingly relevant. As the longterm effects of COVID-19 hit governments, there will be a growing need to involve citizen volunteers and community groups in capacity building (Moreno, Noguchi, & Harder, 2017) . As noted by Weible and colleagues (2020, 236) , ""The pandemic calls on citizen coproduction in the realization of policy goals on an unprecedented scale."" Our findings offer a springboard for future research, to consider the potential of integrating experienced local volunteers, working through community organizations and public agencies, more systematically to meet societal needs.","The COVID-19 pandemic created a critical need for citizen volunteers working with government to protect public health and to augment overwhelmed public services. Our research examines the crucial role of community volunteers and their effective deployment during a crisis. We analyze individual and collaborative service activities based on usage data from 85,699 COVID-19 volunteers gathered through China’s leading digital volunteering platform, as well as a survey conducted among a sample of 2,270 of these COVID-19 volunteers using the platform and interviews with 14 civil society leaders in charge of coordinating service activities. Several results emerge: the value of collaboration among local citizens, civil society including community-based groups, and regional government to fill gaps in public services; the key role of experienced local volunteers, who rapidly shifted to COVID-19 from other causes as the pandemic peaked; and an example of state-led coproduction based on long-term relationships. Our analysis provides insight into the role of volunteerism and coproduction in China's response to the pandemic, laying groundwork for future research. The findings can help support the response to COVID-19 and future crises by more effectively leveraging human capital and technology in community service delivery."
"Since early 2020, the SARS-CoV-2 virus has rapidly spread all over the world, leading governments to take national measures to protect the population's health. The World Health Organization (WHO) officially declared the global Covid-19 pandemic on March 11, 2020 . Since the first confirmed case, more than 63 million Covid-19 infections have been identified and more than 2,000,000 people have died over the globe (as of February 1, 2020) [1] . In addition to the high rate of Covid-19-related deaths, some collateral damages to physical and mental health during the imposed lockdown have been identified, such as increased anxiety, depression, or stress [2, 3] . In France, stage 3 was reached on March 14, 2020 (corresponding to the free circulation of the Covid-19 virus on national territory), and a national lockdown was imposed 3 days later for a total of 55 days, in attempts to prevent the spread of the Covid-19 virus. All primary and secondary schools were completely closed and all the teaching activities were conducted virtually. As a direct consequence, physical activity (PA) and sedentary behaviors (SB) have been negatively affected, which has been associated with impaired well-being, mental, physical, and metabolic health [4] [5] [6] [7] [8] . In several countries, surveys have been conducted to evaluate the exact impacts of this lockdown on movement behaviors, collectively observing a drastic decrease of the physical activity level (PAL) altogether with an increased time spent sedentary [4] [5] [6] 8, 9] . In France, the National Observatory for Physical Activity and Sedentary Behaviors (ONAPS), conducted a major survey that revealed that both initially active and inactive individuals (did or did not meet the PA recommendations) were negatively impacted by this lockdown [9] . Although the majority of studies have been conducted among adults, some results are available among children and adolescents. A Canadian study conducted among 1,472 parents of children and youth aged 5-17 years showed than only 4.8% (2.8% girls, 6.5% boys) of children (5-11 years) and 0.6% (0.8% girls, 0.5% boys) of youth (12-17 years) have reached the recommendations for a healthy lifestyle (24h movement guidelines) during this lockdown [10] . According to this research group, having parents who encourage and are involved in PA [10, 11] , having a domestic animal that needs to be walked [10] , having an environment and neighborhood favoring PA [12] have been key determinants. This survey also revealed an increase in screen time among the youngest children [10] [11] [12] and determined the parents' ability to restrict screen time as the major factor associated with this progression [11] . Similar results have been observed among 12-year-olds (n=113) [13] Spanish youth ages 3 to 16 years (n=860) [14] ; adolescents from Bosnia-Herzegovina (n=688, 15-18 years old) [15] , and youth from Egypt [16] . While Pombo et al. obtained similar results regarding the effect of the lockdown of Portuguese children's PA level (n=2,159; mean age of 13 years), the authors also found that the access to a large outdoor area, having at least one parent who did not have to work from home, or sharing the house with other kids were strong positive predictors of PA during the lockdown [17] . Based on the data from the French national survey conducted in about 28,000 individuals from all ages (ONAPS Covid-19 Survey; [9] ), the present paper assessed the effect of the Covid-19-related lockdown on the movement behaviors (PA and SB), and their determinants, of French children and adolescents. Importantly, these effects are analyzed considering the initial PA (active vs. inactive) and sedentary (high vs. low) profiles of the participants.@story_separate@As previously detailed (global ONAPS Covid-19 survey; [9] ), an expert committee (composed of representative the public health, academic and scientific, governmental, medical and collectivity areas) was gathered by the ONAPS and the French Ministry of Sports, to determine at the national level, key indicators to identify, understand and evaluate the changes induced by this lockdown on the population's PA and SB. Different questionnaires following the same internal structure have been developed for children between the age of 6 and 10 years and for adolescents (11-17 years old) . The questionnaires and their methodology have been adapted and inspired from the IPAQ [18] and ONAPS-Q (in progress) questionnaires in adults and YRBSS (Youth Risk Behavior Surveillance System) investigation in children and adolescents [19] . Briefly, the internal structure of the questionnaires have been developed using the same type of questions and structure of possible answers (for instance: time being active over a period of 7 days; screen time per day; etc.). Geographical, socio-demographic, and health status information were first requested before properly addressing the participants' behaviors in terms of PA levels, sitting time and screens time. The participants were also asked to indicate whether they increased or decreased their time devoted to PA and SB compared with their lockdown down habits. Concerning PA, participants are consider as initially inactive if they did not engage in at least 5 hours and 30 minutes per week of moderate to vigorous PA (5 hours and 30 minutes being the highest range proposed in by questionnaire). Concerning SB we used the recommendations thresholds like not exceed 2h/day of screen time [11] . More precisely, the participants were asked to declare their (or their children's) PA and sedentary habits at the time of the lockdown (when they completed the questionnaires) and retrospectively, what they were doing before the lockdown. Parents of children below 10 years of age were asked to fill out the questionnaires while older children and adolescents completed the questionnaire themselves. The final version of these questionnaires resulted from a back-and forth consultation between the members of the expert committee, until a consensus was reached. The survey was made available online at the ONAPS website (http://www.onaps.fr/) on April 1 st , 2020 (after 15 days of lockdown). Social media platforms were used to promote the survey regularly until May 6 th , 2020, the date at which the survey was closed. Social media (Facebook, LinkedIn for example) and other networks were used for its promotion. Several types of online media were used to disseminate the survey, targeting different kinds of professional, associative, demographical and geographical networks and areas. In the context of the Covid-19 lockdown, particular efforts were deployed to reach a large and representative sample. To do so, several types of online media were used to disseminate the survey, targeting different kinds of professional, associative, demographical and geographical networks and areas. On a regular basis (April 6 th , 16 th , 24 th , 28 th , May 6 th (the last day of the lockdown)), the operational office of the ONAPS made relaunches in order to optimize the success of the questionnaires. The survey was closed 36 days after it officially started (on May 6 th ), one week before the end of the lockdown. This work received ethical agreement from the appropriate authorities (Committee for the Protection of Persons Sud est VI. reference 2020 / CE 27). The survey was administered online using the LimeSurvey software version 2.67.3. Data were collected anonymously and none of the provided answers allowed any potential for participant identification. Of the 22,895 properly completed questionnaires, 1,588 concerned children ages 6 to 10 years old and 4,903 were completed by adolescents (11-17 years old). Three indicators (physical activity levels, sitting time and screen time) have been transformed into quantitative data by taking the central value of each class (example: less than 30 minutes per week were encoded as 15 minutes of PA per week). Originally we had chosen to propose qualitative values in order to avoid inconsistent values and data entry errors. Data were then gathered into an Excel sheet before being analyzed by the biostatistician team (CL, BP). Statistical analysis was performed separately for children and adolescents using Stata software (version 15; StataCorp, College Station, Texas, USA). All tests were two-sided, with a Type I error set at 0.05. All variables were categorical and presented as number of subjects and percentages. The factors associated with the evolution before/during lockdown (increase, similarity, decrease) of the three indicators (PA level, sitting time, and screen time) were studied by chi-squared tests. Data were collected among 6,491 children and adolescents (57.6% female). One-quarter (24.5%) of the sample was between the ages of 6 to 10 years (46.2% female), while 75.5% of responses were from youth between the ages of 11 to 17 years (61.2% female).  A total of 42.0% of children and 58.7% of adolescents reported decreased PA during the lockdown, compared to 21.3% of children and 21.8% of adolescents maintained a similar volume of PA, and 36.7% of children and 19.6% of adolescents declared increased their PA. The proportion of participants who increased, decreased or did not change their PAL during the lockdown was significantly associated with gender in adolescents (p<0.001) but not in children (p=0.10). The table 1 presents the proportions of children and adolescents who declared increased, decreased or unchanged overall level of PA depending on gender and initial level of PA. As depicted in table 1, being physically active before lockdown was associated with the change in PA level during lockdown in both age groups (p<0.001). A total of 45.6% of children and 65.9% of adolescents who were initially active admitted a decrease of their level of PA during lockdown. Fortyeight percent of children and 53.7% of adolescents who were initially inactive declared a decrease of their PA during lockdown. A total of 49.0% and 33.0% of initially inactive children and adolescents respectively, increased their PA level during lockdown. Of note, the fact that our questionnaire could not identify PAL above 5h30min per week, explains the absence of initially active children and adolescents who increased their PAL. The geographic location (rural, suburban, urban) of the accommodation was significantly associated with the children and adolescent's PA during the lockdown (p<0.001), while the housing condition (access to an outdoor area or not) was associated with PA changes in children only (p<0.001 in children and p=0.13 in adolescents). As presented in table 2, PA decreased among 35.2% of children who lived in rural areas, decreased among 46.7% of children who lived in suburban areas, and decreased among 47.9% of children who lived in urban areas. Access to an outdoor area moderated the change in PA levels of children, such that 64.2% reported a decrease in PA when they did not access to an outdoor area, compared to a decrease in PA among only 37.8% who had individual outdoor area access (p<0.001). According to our results, the initial level of sitting time in children was associated with their PAL changes during lockdown while their initial screen time did not affect their PAL during lockdown (p=0.04 and p=0.95 respectively). In adolescents, pre-lockdown screen time (p<0.001) and sitting time (p=0.01) was associated with their PAL changes. A total of 32.8% of children who didn't exceeded the 6h/day of sitting increased their PAL and 37.6% among those whose daily sitting time was higher than 6h/day. Based on our results, as presented in the table 3, not exceeding sitting time recommendations (<6h/day) before the lockdown was associated with the sitting time during lockdown t of both children and adolescents (p<0.001). Concerning children and adolescents who respected the recommendations of 6h/day of sitting time before lockdown, they mainly declared an increase of their sitting time during lockdown (71.7% and 72.1% respectively), while among those who exceeded the 6h/day of sitting time before lockdown, only 28.5% of children and 19.9% of adolescents admitted an increase of their sitting time. The initial screen time of children and adolescents was also associated with their sitting time during the lockdown (p<0.001). A total of 40.1% children and 44.3% adolescents who were exposed to screens <2h/day declared an increase of their sitting time against respectively 18.3% and 17.6% for those who were exposed to screens >2h/day before the lockdown (p<0.001 for both children and adolescents). Table 3 , the housing area (urban, suburban, rural) of adolescents and children was significantly associated with the evolution of their sitting time before and during lockdown (p<0.001). More children who lived in urban areas declared an increased sitting time during lockdown (41.0%) than those who lived rural areas (30.5%) (p<0.001). The access to an outdoor area has been found significantly related to the sitting time modifications during the lockdown in children (p<0.001) and adolescents (p=0.004). Indeed, higher proportion of children (p<0.001) and adolescents (p=0.04) who have no access to an outdoor admitted an increased sitting time during lockdown (59.3% and 32.2% respectively) than those who had access to an individual backyard (33.5% and 25.3% respectively). While only 1.4% of children and 3.2% of adolescents admitted to decrease their screen time during the lockdown, 62.0% of children and 68.9% of adolescents reported an increased screen time. As displayed in table 4, adherence to screen time recommendations before lockdown (<2h/day) influenced changes in screen time during lockdown in both children and adolescents (p<0.001). A higher proportion of children and adolescents who complied with the recommendations before lockdown reported an increase of their screen time (65.0% and 78.7% respectively) compared to those who exceeded the 2h/day of screen time before the lockdown (respectively 47.8% and 64.8%). According to our results, the PAL before lockdown was significantly associated with the screen time of adolescents during lockdown (p<0.001) but not in children (p=0.62). A total of 64.2% of initially inactive adolescents before the lockdown reported an increase of their screen time during lockdown against 75.8% of the initially active ones (p<0.001). Meeting the sitting time recommendations (<6h/day) before the quarantine was significantly associated with the screen time during lockdown in children (p=0.02) and adolescents (p<0.001). A higher proportion of adolescents who had a sitting time >6h/day before the lockdown declared an increase of their screen time during lockdown (70.3%) compared to those who showed a sitting time <6h/day before the lockdown (57.6%) (p<0.001). The housing area of children was significantly associated with their screen time during the quarantine (p=0.002), but not in adolescents (p=0.10). All of them declared an increase of their screen time during the lockdown but the higher proportion of children and adolescents who lived in urban areas reported an increase of their time spent in front of screen (respectively 66.4% and 70.6%) compared 56.7% and 67.4% of those who live in the countryside respectively. Access to outdoor areas was significantly associated with changes in screen time for both children and adolescents (p=0.01 and p=0.002, respectively). Higher proportion of children and adolescents who had not access to an outdoor before the lockdown admitted to increase their screen time (Table   4 ). The global pandemic of Covid-19 led to lockdown of the national and international population. A large number of regional and national surveys have been carried out during and following this lockdown to assess its impact on individual movement behaviors, collectively describing an overall decline in PA levels, combined with an increased time devoted to SB, particularly screen time. Since most of these surveys have been conducted in adults, less is known regarding the impact of this quarantine on movement behaviors in children and adolescents. In that context, based on the French National ONAPS Covid-19 Survey, the present work evaluated the effect of the quarantine on PA and SB of children (aged 6 to 10 years old) and adolescents (11-17 years old). In line with national and international statistics [20, 21] , a large proportion of the children and adolescents who composed our sample were identified as inactive before the lockdown (75.0% of children and 59.3% of adolescents). Considering the strong associations between health and healthy movement behaviors [22, 23] , the situation was already alarming in youth before the institution of social and physical restrictions. Based on the current results, 42% of children and 58.7% of adolescents reported a decrease in PA during the lockdown, which was particularly pronounced among adolescents girls (59.7%). These results are in line with what has been observed in other countries such as Spain [13, 14] , Bosnia-Herzegovina [15] , Egypt [16] or Canada [10] [11] [12] among others. Gilic et al. estimated that 50% of their Bosnian adolescents reached PA recommendations before the lockdown, dropping to only 24% during the lockdown [15] . Interestingly, our results are the first to evaluate the effect of this Covid-19-related lockdown stratified by the initial (prelockdown) level of PA in youth. Our results show that this drastic global decline in PA during this particular period affected both initially active and inactive children and adolescents. Indeed, high proportions of both active (45.6% in children and 65.9% in adolescents) or inactive (40.8% of children and 53.7% of adolescents) youth reported a decrease in PA levels. Importantly, our survey also highlight that none of the children and adolescents initially (before the lockdown) identified as inactive, reported an increase of their PA during this lockdown. While our results clearly highlight that initially inactive youth might be particularly concerned by the deleterious effects of such lockdown, they also show that a higher initial level of PA of children and adolescents might not prevent them from decreasing their PA during the lockdown. Indeed, some may argue that they have ""more to lose"" when it comes to declines in PA. While some authors previously underlined the role of the parental encouragement [10, 11] or a family's neighborhood [12] to avoid such a decrease in PA, our results also identified the living conditions (rural-urban) of the accommodation and the access to outdoor facilities as primary influences. High proportions of children (47.9%) and adolescents (63.5%) living in urban areas or whose accommodation did not allow access to outdoor facilities (64.2% and 63.8%, respectively), declared a significant decrease in PA as a result of stay-at-home orders.. These results are in line with those from Zenic et al., who also described adolescents living in urban areas as more prone to reduce their PA levels during the lockdown when compared with their counterparts living in rural areas [24] . Our findings also align with results from Canada, identifying the access to outdoor (as parks) as influences on PA during periods of home lockdown [12] . Although our results show that 22% of children and 27.9% of adolescents admitted to increase their sitting time during the French lockdown, they also underline an alarming increase in screen time among 62% and 68.9% of children and adolescents, respectively. This finding is in line with previously published results from other counties showing an increase of the time exposed to screens [10] [11] [12] [13] [14] , which is at least partly attributable to the immediate transition to home-based virtual schooling. This was true among Chinese youth, with an increase in screen time of more than 4 hours per day reported during the lockdown [25] . Moreover, Pietrobelli and colleagues underlined that while 60.3% of the Italian children and adolescents already exceed the screen time recommendations, 68.9% of adolescents with obesity increased screen time during the first Covid-19-related lockdown [26] . As for PA, our results also underline that this increased sitting and screen time affects children and adolescents independently of previously meeting recommendations for time spent in SB. Interestingly, sitting and screen time were also similarly increased regardless of initial PA levels. As already noted for PAL, our results reinforce the important role of the living conditions on both sitting and screen time during the lockdown, with children from urban areas most affected. Similarly, higher proportions of both children and adolescents who had no or limited access to outdoor areas reported an increase in sitting and screen time. indicates that our sample might be slightly different of the general French population concerning PA in children (25% of active against 67% in the ESTEBAN survey), while closer among adolescents (40% vs. 30%) [27] and widely different concerning screen time in children, (25% who do not exceed 2h/day against 55% do not exceed 3h/day in ESTEBAN survey) and adolescent (41% against 74%) [27] . These differences can be explained by the threshold used to identify participants as active or inactive (5h30min per week of PA in the present work against 7h/week for the general recommendations), the evolution of screen time recommendations (2h/day and 3h/day) and the retrospective nature of the data collected. The threshold used for PA (5h30min /week) is one of the main limitation of the present work that is due to the internal construction of the survey, and that must be considered when interpreting our results. Concerning living conditions, large differences were observed between the proportion of children and adolescents who lived in urban areas (34.6% against 21.1%) and rural areas (44.4% against 57.4% of adolescents), which can be explained by the different number of respondents (1586 children and 4895 adolescents). The lack of information regarding the geographical situation of the participants, and the lack of anthropometric information, also compose some limitations of the present analysis. Finally, the retrospective nature of the estimation of the participants' physical activity level and sedentary time before the lockdown composes another important limitation of the present analysis that must be considered. This work has been funded through the partnership between the French ONAPS and the Minister of Sports. The authors have no conflict of interest to disclose. Data are presented as number of subjects (row percentages).@story_separate@In line with previously published results in other countries, the present result confirm the negative impact of the first Covid-19-related lockdown period on movement behaviors in children and adolescents. Our study reinforces the need to orient future public health policies towards improving the accessibility of outdoor facilities, particularly in urban areas, in order to encourage greater physical activity. It also indicates that such a period of isolation has deleterious effects on both physical activity and sedentary behaviors among youth, regardless of whether or not they were previously meeting public health guidelines. Finally, there is a need for more informative and preventive public health strategies clearly warning the population that every child, regardless of age or usual movement behaviors, may be negatively impacted by physical and social restrictions.","INTRODUCTION: In France March 14, 2020 a national lockdown was imposed in France for 55 days to prevent the spread of the Covid-19 and all schools were closed. This study aimed to investigate the effects of home confinement as a result of lockdown on the activity (physical activity and sedentary behaviors), and their determinants, on French children (6-10 years) and adolescents (11-17 years). METHODS: The National Observatory for Physical Activity and Sedentary behaviors launched an online survey from April 1(st), to May 6(th), 2020 using popular social networks and websites. It compared the level of physical activity (PA), sitting and screen time before and during the lockdown and identified the impact of the initial PA (active vs. inactive), sedentary (high vs. low) profiles of the participants and the housing conditions. RESULTS: 6,491 children were included in this study. Initially active children and adolescents decreased their PA more than those initially inactive (p>0.001), while those who met the sitting time recommendations increased more their sitting time during lockdown (p<0.001). The same applies to screen time (p<0.001). Live in urban was associated with a decrease of PA (p<0.001), an increase of their sitting time (p<0.001) and children's screen time (p=0.002) during lockdown. CONCLUSION: This study showed the deleterious effects of confinement caused by lockdown on physical activity and sedentary behaviors. Housing conditions were associated with lifestyle behaviors over this period of lockdown. Future public health policies should consider these results."
"In January 2020, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) was identified as the infectious agent causing an outbreak of viral pneumonia in Wuhan, China. It was soon established that droplet-based human to human transmission was occurring, and on March 11, 2020 , the World Health Organization characterized coronavirus disease 2019 (COVID-19) as a pandemic. As of this article's submission date, COVID-19 has infected more than 44.9 million people, causing more than one million deaths. A pandemic-scale outbreak creates tremendous socioeconomic burden due to thwarted productivity, a spike in healthcare expenses, and irreparable loss of human lives 1, 2 . Furthermore, implementation of social and physical isolation measures has caused many countries to declare states of emergency and lockdowns with border closures. SARS-CoV-2 is the seventh identified human coronavirus and the third novel one to emerge in the last 20 years. It is a single-stranded positive sense RNA genome of about 30,000 nucleotides that encodes ~27 proteins and four structural proteins. A surface-expressed spike protein mediates receptor binding and membrane fusion with host cells, and the virus interacts with the angiotensin converting enzyme 2 (ACE2) receptor to gain entry into cells 3 . ACE2 mRNA is present in almost all human organs, but the receptor is particularly highly expressed on the surface of lung alveolar epithelial cells and enterocytes of the small intestine, thereby allowing a preferential accumulation of the virus in these organs 4 . The incubation period of SARS-CoV-2 ranges from about 3-17 days, and COVID-19 diagnosis cannot be made based on symptoms alone as, most are nonspecific and may be confused for more common ailments. The more serious sequelae of infection includes acute respiratory distress syndrome (ARDS) and sepsis caused by the cytokine storm from the immune response to infection, which is believed to be the leading cause of mortality in COVID-19 patients 5 . Screening for COVID-19 is done via nucleic acid testing by RT-PCR (specimens from both upper and lower respiratory tracts) and pulmonary CT scans. The viral load in naso-or oro-pharyngeal swabs is the key clinical biomarker of COVID-19 and also the key clinical endpoint of pharmacological intervention. Although several antiviral and immunomodulatory drugs are being used for symptomatic treatment and viral load reduction, there are still no proven therapeutics for COVID-19 to date. To explore novel and effective therapeutic targets, we require a better understanding of the pathogenesis of COVID-19, particularly of virus-host interactions 6 . This will also enable more efficient disease management strategies, such as deriving prognostic information from viral load kinetics, and quantification of the effects of the immune system in controlling the disease. With limited studies on the in vivo dynamics of SARS-CoV-2, a mathematical modeling approach can be an excellent, complementary tool for investigating viral-host interactions and simulating pathogenesis in order to better understand disease progression and evaluate treatment strategies. Indeed, the application of mathematical modeling and quantitative methods has been instrumental in our understanding of viral-host interactions of various viruses, including influenza, HIV, HBV, and HCV 7 . These kinetic models have been developed for various spatial scales, including molecular, cellular, multicellular, organ, and organism. By analyzing viral load kinetics, these models have deepened our understanding of the fundamentals of virus-host interaction dynamics, innate and acquired immunity, mechanisms of action of drugs, and drug resistance [8] [9] [10] [11] [12] . 21 . Although also a target cell-limited model, by only including upper and lower respiratory tract compartments, this model omits key biological mechanisms involved in the complete immune response, and is thus unable to provide deeper insights into the system-wide dynamics and interplay of disease response. In order to improve upon the existing models, we have developed a multiscale semi-mechanistic model of viral dynamics, which, in addition to capturing virus-host interactions locally, is also capable of simulating the whole-body dynamics of SARS-CoV-2 infection, and is thereby capable of providing insights into disease pathophysiology and the typical and atypical presentations of COVID-19. Importantly, using our modeling platform, we can identify treatment strategies for effective viral load suppression under various clinically relevant scenarios. We note that while the modeling platform is developed for SARS-CoV-2, we also expect it to be applicable to other viruses that have shared similarities in mechanisms of infection and physical dimensions. In January 2020, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) was identified as the infectious agent causing an outbreak of viral pneumonia in Wuhan, China. It was soon established that droplet-based human to human transmission was occurring, and on March 11, 2020 , the World Health Organization characterized coronavirus disease 2019 (COVID-19) as a pandemic. As of this article's submission date, COVID-19 has infected more than 44.9 million people, causing more than one million deaths. A pandemic-scale outbreak creates tremendous socioeconomic burden due to thwarted productivity, a spike in healthcare expenses, and irreparable loss of human lives 1, 2 . Furthermore, implementation of social and physical isolation measures has caused many countries to declare states of emergency and lockdowns with border closures. SARS-CoV-2 is the seventh identified human coronavirus and the third novel one to emerge in the last 20 years. It is a single-stranded positive sense RNA genome of about 30,000 nucleotides that encodes ~27 proteins and four structural proteins. A surface-expressed spike protein mediates receptor binding and membrane fusion with host cells, and the virus interacts with the angiotensin converting enzyme 2 (ACE2) receptor to gain entry into cells 3 . ACE2 mRNA is present in almost all human organs, but the receptor is particularly highly expressed on the surface of lung alveolar epithelial cells and enterocytes of the small intestine, thereby allowing a preferential accumulation of the virus in these organs 4 . The incubation period of SARS-CoV-2 ranges from about 3-17 days, and COVID-19 diagnosis cannot be made based on symptoms alone as, most are nonspecific and may be confused for more common ailments. The more serious sequelae of infection includes acute respiratory distress syndrome (ARDS) and sepsis caused by the cytokine storm from the immune response to infection, which is believed to be the leading cause of mortality in COVID-19 patients 5 . Screening for COVID-19 is done via nucleic acid testing by RT-PCR (specimens from both upper and lower respiratory tracts) and pulmonary CT scans. The viral load in naso-or oro-pharyngeal swabs is the key clinical biomarker of COVID-19 and also the key clinical endpoint of pharmacological intervention. Although several antiviral and immunomodulatory drugs are being used for symptomatic treatment and viral load reduction, there are still no proven therapeutics for COVID-19 to date. To explore novel and effective therapeutic targets, we require a better understanding of the pathogenesis of COVID-19, particularly of virus-host interactions 6 . This will also enable more efficient disease management strategies, such as deriving prognostic information from viral load kinetics, and quantification of the effects of the immune system in controlling the disease. With limited studies on the in vivo dynamics of SARS-CoV-2, a mathematical modeling approach can be an excellent, complementary tool for investigating viral-host interactions and simulating pathogenesis in order to better understand disease progression and evaluate treatment strategies. Indeed, the application of mathematical modeling and quantitative methods has been instrumental in our understanding of viral-host interactions of various viruses, including influenza, HIV, HBV, and HCV 7 . These kinetic models have been developed for various spatial scales, including molecular, cellular, multicellular, organ, and organism. By analyzing viral load kinetics, these models have deepened our understanding of the fundamentals of virus-host interaction dynamics, innate and acquired immunity, mechanisms of action of drugs, and drug resistance [8] [9] [10] [11] [12] . 21 . Although also a target cell-limited model, by only including upper and lower respiratory tract compartments, this model omits key biological mechanisms involved in the complete immune response, and is thus unable to provide deeper insights into the system-wide dynamics and interplay of disease response. In order to improve upon the existing models, we have developed a multiscale semi-mechanistic model of viral dynamics, which, in addition to capturing virus-host interactions locally, is also capable of simulating the whole-body dynamics of SARS-CoV-2 infection, and is thereby capable of providing insights into disease pathophysiology and the typical and atypical presentations of COVID-19. Importantly, using our modeling platform, we can identify treatment strategies for effective viral load suppression under various clinically relevant scenarios. We note that while the modeling platform is developed for SARS-CoV-2, we also expect it to be applicable to other viruses that have shared similarities in mechanisms of infection and physical dimensions.@story_separate@We have developed a semi-mechanistic mathematical model to simulate the whole-body biodistribution kinetics of SARS-CoV-2 following infection through the nasal route (Figure 1 ; Methods: Model development). The model was formulated as a system of ordinary differential equations (Equations 1-40) that describe cellular-scale viral dynamics, whole-body transport and excretion of viruses, and innate and adaptive immune response to predict the viral load kinetics of SARS-CoV-2 in the respiratory tract, plasma, and other organs of the body. SARS-CoV-2 exhibits ACE2 tropism 22 , therefore the organs included in the model were chosen based on the presence of ACE2 receptor expressing cells in their tissues [23] [24] [25] . Specifically, the key processes described by the model include infection of ACE-2 expressing susceptible cells by SARS-CoV-2 (also referred to as target cells), production of new virions by infected cells, death of infected cells due to cytopathic effect, transport of virions from the site of infection to other organs of the body, hepatobiliary excretion of the virions, and key processes in the innate and adaptive immune response against the virus and infected cells to clear the infection. Note that in the absence of a thorough understanding of the mechanistic underpinnings of viral shedding in the feces 26 , and a growing evidence of liver damage in COVID-19 patients 27, 28 , we assumed bile production rate as the rate limiting step in the hepatobiliary excretion of the virus into the feces. While some of the parameters of the model were known a priori (Table 1) , the remaining parameters were estimated through nonlinear regression using published in vivo 29 and clinical 30 data. Specifically, from published experimental data for hamsters 29 , we first calibrated a reduced version of the model (referred to as Reduced model; Equations 1-23) that comprises all compartments and interferon (IFN)-mediated innate immunity, but lacks adaptive immunity (bottom half of Figure 1 ; also see workflow in Figure 2 ). The parameters of the reduced model characterize cellular-scale viral dynamics, IFN-mediated immunity, inter-compartment viral transport, and hepatobiliary excretion of the virus from the mononuclear phagocytic system (MPS). The estimated parameters were then used in the complete version of the model (referred to as Full model; Equations 1-40), which also includes adaptive immunity, to calibrate the remaining parameters using nonlinear regression with clinical data 30 . The models were solved numerically in MATLAB as an initial value problem, using the built-in stiff ODE solver ode15s. Calibrating parameters of the reduced model As shown in Figure 3 , the numerical solution of the reduced model for whole-body viral kinetics, IFN kinetics, and target cell population kinetics in hamsters satisfies the initial conditions, and is in good agreement with the available in vivo data 29 for viral and IFN kinetics (Pearson correlation coefficient R between experimental data and model fits is > 0.97, p < 0.0001, Figure S1a) . The corresponding parameter estimates are given in Table 2 . Based on findings in the in vivo study by Chan et al. 29 that the adaptive immune response in test animals was not triggered during the first seven days post-infection, it is reasonable to use the reduced form of the model to estimate the unknown parameters, rather than using the full model at this point. The model solution (Figure 3) shows the kinetics of ACE2-expressing target cells (solid orange lines) and their infected counterparts (dashed orange lines) in every compartment. These infected cells can produce new virions that will in turn infect other healthy target cells. Because we are . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 3, 2020. using a target-cell limited modeling assumption 9, 18 , the healthy target cells that become infected by the virus are not replaced by new healthy cells, and as seen in Figure 3 , the target cells were observed to deplete within 48 h post infection. The viral load kinetics (blue curve) is primarily governed by the interplay of new virion production, distribution of the virions between compartments, viral elimination by alveolar and MPS macrophages, hepatobiliary excretion of viruses from the body, cytopathic death of infected cells, and suppression of viral production due to IFN produced by infected cells 9 , which is shown in Figure 3i . As the infected cell population tapers, the IFN concentration will also decrease to the pre-infection baseline value. In our model, infected cells of the respiratory tract are the source of IFN following infection, the lack of which has been found to be the underlying cause of life-threatening COVID-19 due to uncontrolled viral replication in the absence of IFN regulation [31] [32] [33] . Of note, the plasma compartment (Figure 3h ) of the model does not contain any target cell population and thus its viral load kinetics is only governed by the influx and outflux of viruses from various compartments. However, in the full model, the neutralization of viruses by antibodies will also be considered in the plasma compartment, as discussed in the next section. Plasma flow is the key mechanism of viral transport and systemic spread of infection in the body 34 , but due to lack of established mechanistic underpinnings of these processes, we instead use phenomenological rate constants to characterize viral transport. Based on the estimated characteristic times (1-24 h) of the vascular transport processes (shown in Figure 1 and presented as rates in Table 2 ), it can be inferred that viral transport is permeability-limited and not perfusionlimited, i.e., capillary permeability and vascular surface area govern the rate of extravasation of virions from blood vessels into tissue interstitium to reach the target cells, and thus viral transport is not exclusively governed by the plasma flow rates into the organs. This is consistent with the in vivo behavior of nanomaterials of comparable size [35] [36] [37] [38] [39] [40] , and is in contrast to the perfusion ratelimited kinetics of smaller lipophilic molecules. The variability in characteristic times of vascular transport can be explained by differences in the permeability of capillary endothelium due to differences in pore sizes of endothelial fenestrae 41 . For instance, the blood brain barrier seems to resist transport of virus to the brain, thereby leading to an estimated characteristic time of influx of 1 day, which is ~twenty-times longer than the estimated characteristic time of influx to the MPS (1.25 h) that contains large sinusoidal pores in its microvasculature. Of note, the non-vascular transport processes have relatively longer characteristic times that can be attributed to resistance to transport offered by mucus or degradation caused by pH, among other factors. Once the parameters discussed in the previous section were estimated, they were then used in the full model to calibrate the remaining parameters (see Table 3 ) relevant to the innate and adaptive immune system using published clinical data (n = 4 untreated patients) 30 . Due to the uncertainty associated with the duration between day of infection and onset of symptoms (referred to as incubation period), a shifting parameter was included in the calibration routine. Numerically, the time points corresponding to the data were shifted units of time. As shown in Figure 4 , the model correctly represents the initial conditions of the variables and predicts an incubation period of ~6 days (indicated by red arrow in Figure 4a ), which is comparable to published literature 42 . Also, assuming nasal route as the route of infection, the numerical solution for URT at time = 0 suggests exposure to a viral load of ~10 7 copies/mL. The clinical data shows the viral load kinetics in the upper (Figure 4a ) and lower respiratory tract (Figure 4b) , the IFN kinetics (Figure 4i) , the . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 3, 2020. ; effector CD8 + (CD8 * ) and activated CD4 + (CD4 * ) cell population kinetics (Figure 4k) , and the total neutralizing antibody kinetics (Figure 4l) . As shown in Figure 4 , the full model solution fits the data well (Pearson correlation coefficient R > 0.98, p < 0.0001, Figure S1b) , and was able to predict the kinetics of viral load in the remaining compartments by using the viral dynamics and transport parameters estimated from the in vivo data (through calibration of the reduced model). The model predicts that the viral load in extrapulmonary organs and plasma persists for ~17-20 days post onset of symptoms, consistent with published studies 43 , and is thus comparable to the duration of viral detection in URT and LRT. Therefore, it can be also inferred that nasopharyngeal swabs can safely provide an indication of the infection status of the patients. The model also shows the kinetics of naïve lymphocytes (Figure 4j ) and antibody producing plasma cells (Figure 4k ) in the lymphatic compartment, which is represented as a common compartment for the entire body. Importantly, in close agreement with published literature 44, 45 , the model predicts that the systemic concentration of antibodies persists above the detectable limit for >100 days post onset of symptoms, following which it may no longer be detectable ( Figure   4l ). This finding suggests the lack of indefinite antibody protection against reinfection 46 , and highlights the need for vaccine boosters to achieve long-lasting immunity 47 . We note that the data used in the above calibrations was obtained under conditions where neither the animals nor the patients were given any pharmacological treatment. Hence, the data are appropriate to calibrate the effects of the immune components and other physiological processes in distributing and eliminating the viral load. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) While URT and LRT are the preferred sites to detect the presence of SARS-CoV-2, it is important to note, and as is evident from the model predictions, that the viral load in non-pulmonary organs can attain comparable levels, and can thus explain the non-respiratory symptoms observed in some COVID-19 patients 28, 48, 49 . Following transport of the virus from respiratory tract to blood or via gastrointestinal tract to blood, organs that have a significant population of ACE2 expressing cells may become infected by the virus, leading to the extrapulmonary manifestations of COVID-19 that may include symptoms such as diarrhea and impaired renal-, hepatic-, cardiovascular-, or neurological-functions. To investigate the effects of the cellular and humoral arms of innate and adaptive immunity on viral load kinetics in the body, we individually switched off these components and simulated the whole-body viral kinetics for up to the time when viral load fell below the detectable limit 18 of 10 2 copies ml -1 . This numerical experiment is meant to mimic the effect of compromised immunity due to an underlying condition in a virtual patient undergoing no antiviral treatment. As seen in the viral kinetics in Figure 5 , when one or all of the immune components were shut down, the viral concentration in all the compartments was higher than the baseline (dashed dark red line). Further, it can be inferred that IFN is the primary mechanism of controlling viral load in the URT ( Figure 5a ) and GI (Figure 5c ), while macrophages (alveolar macrophages, Kupffer cells, and splenic macrophages) play a predominant role in limiting infection in the LRT, MPS, plasma, and other organs, followed by IFNs (Figures 5b, 5d-5h) . Findings in the literature support the above observations as follows. Lack of IFNs can lead to excessive viral production 33 and cause lifethreating COVID-19 in patients deficient in functional IFNs due to, for example, the occurrence . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint of loss-of-function mutations in genes governing IFN-mediated immunity 32 or auto-antibodies against IFNs 31 . Further, FABP4+ alveolar macrophages were observed to be largely absent in patients with severe COVID-19, but were a predominant macrophage in patients with mild disease 50 , indicating the major role of FABP4+ alveolar macrophages in controlling infection as also shown previously for patients with chronic obstructive pulmonary disease (COPD) 51 . We assume a constant supply of macrophages in the lungs and MPS in our model, but a deleterious effect of infection on these immune cells cannot be ruled out, and further experimental evidence is necessary to model the cell population kinetics appropriately 52 . Further, the model reveals that the effect of adaptive immunity (antibodies and CD8 * cells) is not significant in controlling infection, but it does not necessarily rule out the therapeutic potential of exogenously administered antibodies or novel cell-based therapies (e.g. T cell therapy). All the above scenarios abstractly represent real-world underlying conditions (e.g. cancer, diabetes, autoimmune diseases) in patients that lead to varying degrees of immunosuppression, thus highlighting the importance of an individual's immune status in regulating viral kinetics. In the absence of immune responses, the only plausible mechanism that brings the viral load down is hepatobiliary excretion of the virus through the MPS, but our results show it takes several weeks before the viral load falls below the detectable value of 10 2 copies ml -1 . Note that upon shutting down IFN-and macrophage-mediated immunity or total immunity, the viral load grew beyond clinically observed values in the literature (~10 12 copies/ml), therefore we set an upper bound at 10 12 copies/ml to keep the results clinically meaningful. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. Treatment over a combination of the two parameters, i.e., IFN and viral production rates, can be more efficient than monotherapy in suppressing viral load, as also suggested by clinical studies 54, 55 . While cytopathic death rate and viral production rate play major roles in governing the clearance time of viruses ( clear ), IFN production rate is relatively less significant. Further, transport processes play a significant role in governing both total viral load and time to clear the load. Specifically, the transport of virus from URT to LRT ( 1 ) affects viral load in URT, and blood to MPS via the hepatic artery ( ) and MPS to blood via the hepatic vein ( ) govern the clearance time from plasma, which should also affect the viral clearance of other organs connected to plasma. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. are important parameters in governing the kinetics of viral load in LRT and plasma, respectively. Finally, the total viral load in LRT is also affected by pulmonary absorption ( 1 ), i.e. by the rate of transport of viruses from LRT to plasma. Up to this point, we have demonstrated that the model was able to reproduce viral kinetics that were consistent with experimentally measured values and produce observations consistent with published literature. We next sought to examine whether this tool can make predictions that might allow clinicians to design an effective therapy for patients, helping to optimize and personalize their treatment regimen. As a numerical experiment, we tested three treatment scenarios in controlling infection: a hypothetical antiviral agent, interferon therapy, and antiviral agentinterferon combination therapy. Further, the effects of the timing of therapy initiation ( ) were also tested, i.e., starting therapy on the day of onset of symptoms ( = onset ), and starting therapy 5 days post onset of symptoms ( = onset + 5). To quantify treatment effectiveness, we compared the viral load kinetics in three compartments, namely, URT, LRT, and plasma in simulations spanning a period of four weeks. We simulated therapy with a hypothetical antiviral agent that has the same mechanism of action as Remdesivir 56 , i.e. interference with RNA-dependent RNA polymerase. For this, 200 mg loading dose (≡initial plasma concentration 0 = 5 M, assuming a molecular weight of 800 g/mol and a volume of distribution of 50 L), followed by 100 mg daily maintenance doses for 9 additional . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint days, via intravenous injection were simulated to mimic the pharmacological intervention. Treatment was started at one of the two time points previously mentioned. As a simplification, assuming one-compartment pharmacokinetics for the hypothetical drug with elimination rate constant Cl = 1 −1 , we use the plasma concentration kinetics as a surrogate for tissue concentration kinetics of the drug. The plasma concentration ( ) is thus given by, Hence, the injection times are = , + 1, … , + 9, and we define this set of times as . The antiviral agent acts by inhibiting the production rate of virus from infected cells in the body,  We simulated treatment with interferon beta-1a, with and without the hypothetical antiviral agent (discussed above). For this, four subcutaneous injections (Dose = 44 µg each) of interferon beta-. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ;  1a were administered every other day starting at one of the two time points previously mentioned. The plasma concentration kinetics of interferon beta-1a I ( ) is obtained by solving the following equation: Hence, the injection times are = , + 2, … , + 6, and we define this set of times as . The . Figure 7d -f, interferon beta-1a therapy significantly reduces the viral load, and the effect is comparable to the hypothetical antiviral agent. Also, an early initiation of therapy leads to a lesser total viral load and a faster reduction in viral load. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint Combination therapy Finally, we tested the effect of combination therapy with the hypothetical antiviral agent and interferon beta-1a on viral load kinetics (plasma concentration kinetics in the inset of Figure 7g ). Figure 7g -i, the combination therapy leads to a faster reduction in viral load compared to the effect of antiviral agent and interferon beta-1a alone, such that the viral load seems to fall below the detection threshold 2-3 days earlier. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint with a physiologically-based pharmacokinetic model to build an in-silico platform that can be used to simulate disease progression and a more complete pharmacokinetics of various test drugs and novel formulations. In each organ compartment, we consider the kinetics of three populations. The first is the . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint The rate of change of total infected cell population within an organ is a function of three mechanisms. The first is an increase due to freshly infected healthy cells by viral particles, the second is death due to cytopathic effect of viral infection, proportional to the number of infected cells and characterized by the rate constant 1 , and the third is due to the interaction between effector CD8 + cells (concentration denoted by CD8 * ( )) and the infected cells. The cytotoxic effect is measured in terms of the death rate constant CD8 . It is important to note that in the reduced form of the model, infected cell death due to effector CD8 * cells is not included. In our model description, all activated immune cells are indicated with an asterisk (e.g., CD8 * ), while inactive or Naïve populations are indicated by standard naming conventions (e.g., CD8 + ). The concentration of viral particles in each organ compartment is influenced by different factors, some of which are organ-specific. However, in all organ compartments, the rate of change of viral particles is proportional to the number of infected cells with virus production constant , but is inversely proportional to the concentration of IFN, denoted IFN( ). IFN is part of the innate immune response that acts by suppressing the viral production rate of infected cells, and is controlled by the effectiveness constant . In all compartments, viral particles may be neutralized due to the aggregation of antibodies on their surface proteins. The antibody concentration is represented by Ab( ), and the destruction rate of viral particles due to antibodies is denoted by Ab . Of note, neutralization of virus by antibodies is not incorporated in the reduced form of the model. Lastly, the viral load can also be reduced by tissue resident macrophages in the lungs (alveolar macrophages) and MPS (Kupffer cells and splenic macrophages) that engulf the viral particles and destroy them. The rate of removal of viral particles by macrophages is given by ϕ . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint We introduce the system of ordinary differential equations that governs the concentration kinetics as follows. Mechanisms particular to each compartment are discussed after each set of equations. Equations for the URT: which is quantified through the pulmonary absorption coefficient 1 . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. Additionally, as discussed above, viral particles from the URT are transported to the GI tract at a rate 2 . Equations for the MPS: is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. Given that the size of the SARS-CoV-2 virus is ~100 nm, we assume that renal excretion is not feasible 58 . Therefore, the viral kinetics in kidneys is dependent on the standard mechanisms and is affected by influx via the renal arteries ( ) and outflux via the renal veins ( ). Equations for the Brain: While the blood brain barrier may be deterrent to the establishment of infection in the brain, we have included the brain compartment due to the lack of evidence for the former 59 is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint The equation for the plasma compartment incorporates all the outgoing fluxes of viral particles through arteries ( , , CO , CA ) and the incoming fluxes via veins ( , , CO , ). Also, the viral load from LRT in equation (6) gets added to plasma at rate 1 . Lastly, similar to all the previous compartments, viral particles can be neutralized by antibodies at a rate Ab . The model up to this point is the reduced model, and the only equation that captures the immune system is equation (7). This equation describes the change of concentration of IFN, which is part of the innate immune system. However, the adaptive immune system should activate to properly mount a full immune response. The equations that follow provide the remaining elements to initiate and maintain a humoral and cell-mediated adaptive immune response to make up the full model. if the difference is large, the denominator is equally large, and the ratio is close to one. This allows a near constant modulation rate that only acts whenever the population of macrophages is far from equilibrium. This reequilibration rate is denoted by APC . The APC population is also impacted by the interaction between APCs and invading viral particles. This causes the population of APCs to . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; Furthermore, each of these lymphocytes can be promoted to its activated state, which we denote with an asterisk, * . This conversion takes place when activated APCs interact with naïve lymphocytes, presenting them fragments of the ingested viral particles. The transformation rate from the naïve state to the activated one is represented by the constant , where indicates the cell type. For the case of CD4 + and CD8 + , we use the common rate T . The concentration of activated lymphocytes can fluctuate due to two mechanisms. One is the conversion of naïve cells, which was already discussed. The second is due to death caused by a variety of factors like exhaustion or apoptosis, and is expressed through the death constant . B cells, however, follow a different mechanism, which we discuss later. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint The final equation in the model describes the rate of change of antibody concentration, Ab( ). The sole contributors to the production of antibodies are short-lived and long-lived plasma cells. The corresponding production rates are given by P S and P L , respectively. We consider two mechanisms by which antibodies can be consumed or eliminated. One is the loss of antibodies due to their interaction with viral particles in a given compartment with rate constant Ab . The second is the elimination of antibodies by other factors independent of the viral load, e.g., degradation or clearance from tissues, which occurs at rate constant Cl Ab . A summary of the parameters used in the model is given in Tables 1-3. Once the full set of parameters for the model has been defined and fixed for the conditions corresponding to Figure 4 , we proceed to identify the relative effect of each parameter on the viral kinetics. This is done by systematically perturbing one or multiple parameters and comparing the outcomes between the perturbed state and the original state. To quantify the differences between the two states we introduce the following 6 criteria. The first three refer to the area under the curve The next three denote the total time required for the viral load in the URT, LRT, and Plasma compartment to reduce to < 10 2 viral copies per mL, i.e., 2 in log base 10 units. The last comparison criterion is the antibody titer at day 30 in the body, i.e., Ab( = 30). In the next two . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint subsections we compare each of the 6 criteria using global sensitivity analysis (GSA), applied to the 31 parameters. Local sensitivity analysis only allows one parameter to change at a time, and thus may not be suitable for analyzing complex biological systems. We performed global sensitivity analysis (GSA 36, 54, 55 ; i.e., multiple parameters can be varied simultaneously) to obtain a further understanding of the relationship between parameters and their combined effects on the model outputs of interest. Specifically, in our analysis, all parameters were perturbed at the same time, and we assume a uniform distribution for each parameter. The range of values of each sample was PR ± 99%(PR), where PR is the reference value of a given parameter. To ensure a complete sampling of the full parameter space we used a Latin hypercube sampling scheme. Subsequently, each sample was used to recompute the kinetics, from which we extract the 6 criteria mentioned above. In total, 10 batches of 5000 samples each were computed. Then, the data were subjected to a multivariate linear regression analysis to produce an impact factor, which we label as the sensitivity index (SI). Lastly, the sensitivity indices were ranked by means of a one-way ANOVA and a Tukey's test. The higher the SI, the more significance a parameter holds. A detailed description of the GSA workflow can be found in 38, 60, 61 . All analyses were performed in MATLAB R2018a. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint Figure 2 . Modeling workflow. In the first step, the reduced model uses the hamster data to fit parameters corresponding to viral dynamics, transport coefficients, and innate immunity. Subsequently, the more complex full model uses the previously estimated parameters and clinical data to estimate the remaining parameters pertaining to the adaptive and innate immune responses. Lastly, simulations are generated to make predictions, and statistical analyses are performed to extract useful information. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; bound at 10 2 copies ml -1 and 10 4.6 pg ml -1 is imposed to represent the detectable limit of viral load . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint and antibodies, respectively; dashed blue line indicates the limit of detection. Once the viral load or antibodies go below the detection limit, a vertical line is used to indicate the time of occurrence of this event. The triangular markers represent clinical data presented as mean ± SD (n = 4 patients). Pearson correlation coefficient between observed and fitted values is R > 0.98 (see Figure   S1b ). . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. Insets in a,d,g) show plasma concentration kinetics of the pharmacological agent/s for the treatment regimen that begins on the day of onset of symptoms. A lower bound at 10 2 copies ml -1 is imposed to represent the detectable limit of viral load in the body (black . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint horizontal line); once the viral load goes below the detection limit, a vertical line is used to indicate the time of occurrence of this event. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint Reequilibration rate of naïve CD8 cells cell⋅mL 1 ⋅d 1 -0.0045 62, 63 Reequilibration rate of naïve B cells cell⋅mL 1 ⋅d 1 -1.75 76 Reequilibration rate of naïve CD4 cells cell⋅mL 1 ⋅d 1 -0.0027 63, 62 Baseline IFN production rate IFN units⋅ mL -1 ⋅d -1 38.8 1.37 29, 30 Degradation rate of IFN d -1 24 24 77 Healthy tissue parameters Initial concentration of target cells in URT cells⋅mL -1 10 6.9 10 6.7 72, 78, 79 Initial concentration of target cells in LRT cells⋅mL -1 10 6.9 10 6.7 Initial concentration of target cells in GI cells⋅mL -1 10 7.4 10 6.9 80 Initial concentration of target cells in MPS cells⋅mL -1 10 6.8 10 6.6 81, 82, 83 Initial concentration of target cells in heart cells⋅mL -1 10 6.5 10 6.3 Initial concentration of target cells in kidneys cells⋅mL -1 10 7.1 10 6.9 Initial concentration of target cells in brain cells⋅mL -1 10 5.9 10 5.7 Viral dynamics parameters Initial concentration of viral load in URT virus⋅mL -1 10 5.7 Table 3 29 Clearance rate of antibodies d -1 -0.04 10 Hepatobiliary excretion rate d -1 2.68 0.15 89 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint Table 2 . List of model parameters estimated from fitting the reduced model to in vivo data. Note: Characteristic times corresponding to the transport parameters are shown in Figure 1 . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint Transition rate of naïve CD8 into CD8 * or CD4 into CD4 * mL⋅cell -1 ⋅d -1 0.0061 Transition rate of naïve B cells into B * mL⋅cell -1 ⋅d -1 0.029 Transition rate of B * into short-lived plasma cells mL⋅cell -1 ⋅d -1 564.8 Transition rate of B * into long-lived plasma cells mL⋅cell -1 ⋅d -1 0.36 Production rate of antibodies from short-lived plasma cells. antibody⋅cell -1 ⋅d -1 0.59 Production rate of antibodies from long-lived plasma cells. antibody⋅cell -1 ⋅d -1 1.34 Antibody loss rate due to viruses mL⋅virus -1 ⋅d -1 0.0013 Elimination rate of viruses due to antibodies mL⋅antibody -1 ⋅d -1 0.0085 Death rate of infected cells due to CD8 * mL⋅cell -1 ⋅d -1 0.0037 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 3, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint We have developed a semi-mechanistic mathematical model to simulate the whole-body biodistribution kinetics of SARS-CoV-2 following infection through the nasal route (Figure 1 ; Methods: Model development). The model was formulated as a system of ordinary differential equations (Equations 1-40) that describe cellular-scale viral dynamics, whole-body transport and excretion of viruses, and innate and adaptive immune response to predict the viral load kinetics of SARS-CoV-2 in the respiratory tract, plasma, and other organs of the body. SARS-CoV-2 exhibits ACE2 tropism 22 , therefore the organs included in the model were chosen based on the presence of ACE2 receptor expressing cells in their tissues [23] [24] [25] . Specifically, the key processes described by the model include infection of ACE-2 expressing susceptible cells by SARS-CoV-2 (also referred to as target cells), production of new virions by infected cells, death of infected cells due to cytopathic effect, transport of virions from the site of infection to other organs of the body, hepatobiliary excretion of the virions, and key processes in the innate and adaptive immune response against the virus and infected cells to clear the infection. Note that in the absence of a thorough understanding of the mechanistic underpinnings of viral shedding in the feces 26 , and a growing evidence of liver damage in COVID-19 patients 27, 28 , we assumed bile production rate as the rate limiting step in the hepatobiliary excretion of the virus into the feces. While some of the parameters of the model were known a priori (Table 1) , the remaining parameters were estimated through nonlinear regression using published in vivo 29 and clinical 30 data. Specifically, from published experimental data for hamsters 29 , we first calibrated a reduced version of the model (referred to as Reduced model; Equations 1-23) that comprises all compartments and interferon (IFN)-mediated innate immunity, but lacks adaptive immunity (bottom half of Figure 1 ; also see workflow in Figure 2 ). The parameters of the reduced model characterize cellular-scale viral dynamics, IFN-mediated immunity, inter-compartment viral transport, and hepatobiliary excretion of the virus from the mononuclear phagocytic system (MPS). The estimated parameters were then used in the complete version of the model (referred to as Full model; Equations 1-40), which also includes adaptive immunity, to calibrate the remaining parameters using nonlinear regression with clinical data 30 . The models were solved numerically in MATLAB as an initial value problem, using the built-in stiff ODE solver ode15s. Calibrating parameters of the reduced model As shown in Figure 3 , the numerical solution of the reduced model for whole-body viral kinetics, IFN kinetics, and target cell population kinetics in hamsters satisfies the initial conditions, and is in good agreement with the available in vivo data 29 for viral and IFN kinetics (Pearson correlation coefficient R between experimental data and model fits is > 0.97, p < 0.0001, Figure S1a) . The corresponding parameter estimates are given in Table 2 . Based on findings in the in vivo study by Chan et al. 29 that the adaptive immune response in test animals was not triggered during the first seven days post-infection, it is reasonable to use the reduced form of the model to estimate the unknown parameters, rather than using the full model at this point. The model solution (Figure 3) shows the kinetics of ACE2-expressing target cells (solid orange lines) and their infected counterparts (dashed orange lines) in every compartment. These infected cells can produce new virions that will in turn infect other healthy target cells. Because we are . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 5, 2020. using a target-cell limited modeling assumption 9, 18 , the healthy target cells that become infected by the virus are not replaced by new healthy cells, and as seen in Figure 3 , the target cells were observed to deplete within 48 h post infection. The viral load kinetics (blue curve) is primarily governed by the interplay of new virion production, distribution of the virions between compartments, viral elimination by alveolar and MPS macrophages, hepatobiliary excretion of viruses from the body, cytopathic death of infected cells, and suppression of viral production due to IFN produced by infected cells 9 , which is shown in Figure 3i . As the infected cell population tapers, the IFN concentration will also decrease to the pre-infection baseline value. In our model, infected cells of the respiratory tract are the source of IFN following infection, the lack of which has been found to be the underlying cause of life-threatening COVID-19 due to uncontrolled viral replication in the absence of IFN regulation [31] [32] [33] . Of note, the plasma compartment (Figure 3h ) of the model does not contain any target cell population and thus its viral load kinetics is only governed by the influx and outflux of viruses from various compartments. However, in the full model, the neutralization of viruses by antibodies will also be considered in the plasma compartment, as discussed in the next section. Plasma flow is the key mechanism of viral transport and systemic spread of infection in the body 34 , but due to lack of established mechanistic underpinnings of these processes, we instead use phenomenological rate constants to characterize viral transport. Based on the estimated characteristic times (1-24 h) of the vascular transport processes (shown in Figure 1 and presented as rates in Table 2 ), it can be inferred that viral transport is permeability-limited and not perfusionlimited, i.e., capillary permeability and vascular surface area govern the rate of extravasation of virions from blood vessels into tissue interstitium to reach the target cells, and thus viral transport is not exclusively governed by the plasma flow rates into the organs. This is consistent with the in vivo behavior of nanomaterials of comparable size [35] [36] [37] [38] [39] [40] , and is in contrast to the perfusion ratelimited kinetics of smaller lipophilic molecules. The variability in characteristic times of vascular transport can be explained by differences in the permeability of capillary endothelium due to differences in pore sizes of endothelial fenestrae 41 . For instance, the blood brain barrier seems to resist transport of virus to the brain, thereby leading to an estimated characteristic time of influx of 1 day, which is ~twenty-times longer than the estimated characteristic time of influx to the MPS (1.25 h) that contains large sinusoidal pores in its microvasculature. Of note, the non-vascular transport processes have relatively longer characteristic times that can be attributed to resistance to transport offered by mucus or degradation caused by pH, among other factors. Once the parameters discussed in the previous section were estimated, they were then used in the full model to calibrate the remaining parameters (see Table 3 ) relevant to the innate and adaptive immune system using published clinical data (n = 4 untreated patients) 30 . Due to the uncertainty associated with the duration between day of infection and onset of symptoms (referred to as incubation period), a shifting parameter was included in the calibration routine. Numerically, the time points corresponding to the data were shifted units of time. As shown in Figure 4 , the model correctly represents the initial conditions of the variables and predicts an incubation period of ~6 days (indicated by red arrow in Figure 4a ), which is comparable to published literature 42 . Also, assuming nasal route as the route of infection, the numerical solution for URT at time = 0 suggests exposure to a viral load of ~10 7 copies/mL. The clinical data shows the viral load kinetics in the upper (Figure 4a ) and lower respiratory tract (Figure 4b) , the IFN kinetics (Figure 4i) , the . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 5, 2020. ;  effector CD8 + (CD8 * ) and activated CD4 + (CD4 * ) cell population kinetics (Figure 4k) , and the total neutralizing antibody kinetics (Figure 4l) . As shown in Figure 4 , the full model solution fits the data well (Pearson correlation coefficient R > 0.98, p < 0.0001, Figure S1b) , and was able to predict the kinetics of viral load in the remaining compartments by using the viral dynamics and transport parameters estimated from the in vivo data (through calibration of the reduced model). The model predicts that the viral load in extrapulmonary organs and plasma persists for ~17-20 days post onset of symptoms, consistent with published studies 43 , and is thus comparable to the duration of viral detection in URT and LRT. Therefore, it can be also inferred that nasopharyngeal swabs can safely provide an indication of the infection status of the patients. The model also shows the kinetics of naïve lymphocytes (Figure 4j ) and antibody producing plasma cells (Figure 4k ) in the lymphatic compartment, which is represented as a common compartment for the entire body. Importantly, in close agreement with published literature 44, 45 , the model predicts that the systemic concentration of antibodies persists above the detectable limit for >100 days post onset of symptoms, following which it may no longer be detectable ( Figure   4l ). This finding suggests the lack of indefinite antibody protection against reinfection 46 , and highlights the need for vaccine boosters to achieve long-lasting immunity 47 . We note that the data used in the above calibrations was obtained under conditions where neither the animals nor the patients were given any pharmacological treatment. Hence, the data are appropriate to calibrate the effects of the immune components and other physiological processes in distributing and eliminating the viral load. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) While URT and LRT are the preferred sites to detect the presence of SARS-CoV-2, it is important to note, and as is evident from the model predictions, that the viral load in non-pulmonary organs can attain comparable levels, and can thus explain the non-respiratory symptoms observed in some COVID-19 patients 28, 48, 49 . Following transport of the virus from respiratory tract to blood or via gastrointestinal tract to blood, organs that have a significant population of ACE2 expressing cells may become infected by the virus, leading to the extrapulmonary manifestations of COVID-19 that may include symptoms such as diarrhea and impaired renal-, hepatic-, cardiovascular-, or neurological-functions. To investigate the effects of the cellular and humoral arms of innate and adaptive immunity on viral load kinetics in the body, we individually switched off these components and simulated the whole-body viral kinetics for up to the time when viral load fell below the detectable limit 18 of 10 2 copies ml -1 . This numerical experiment is meant to mimic the effect of compromised immunity due to an underlying condition in a virtual patient undergoing no antiviral treatment. As seen in the viral kinetics in Figure 5 , when one or all of the immune components were shut down, the viral concentration in all the compartments was higher than the baseline (dashed dark red line). Further, it can be inferred that IFN is the primary mechanism of controlling viral load in the URT ( Figure 5a ) and GI (Figure 5c ), while macrophages (alveolar macrophages, Kupffer cells, and splenic macrophages) play a predominant role in limiting infection in the LRT, MPS, plasma, and other organs, followed by IFNs (Figures 5b, 5d-5h) . Findings in the literature support the above observations as follows. Lack of IFNs can lead to excessive viral production 33 and cause lifethreating COVID-19 in patients deficient in functional IFNs due to, for example, the occurrence . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint of loss-of-function mutations in genes governing IFN-mediated immunity 32 or auto-antibodies against IFNs 31 . Further, FABP4+ alveolar macrophages were observed to be largely absent in patients with severe COVID-19, but were a predominant macrophage in patients with mild disease 50 , indicating the major role of FABP4+ alveolar macrophages in controlling infection as also shown previously for patients with chronic obstructive pulmonary disease (COPD) 51 . We assume a constant supply of macrophages in the lungs and MPS in our model, but a deleterious effect of infection on these immune cells cannot be ruled out, and further experimental evidence is necessary to model the cell population kinetics appropriately 52 . Further, the model reveals that the effect of adaptive immunity (antibodies and CD8 * cells) is not significant in controlling infection, but it does not necessarily rule out the therapeutic potential of exogenously administered antibodies or novel cell-based therapies (e.g. T cell therapy). All the above scenarios abstractly represent real-world underlying conditions (e.g. cancer, diabetes, autoimmune diseases) in patients that lead to varying degrees of immunosuppression, thus highlighting the importance of an individual's immune status in regulating viral kinetics. In the absence of immune responses, the only plausible mechanism that brings the viral load down is hepatobiliary excretion of the virus through the MPS, but our results show it takes several weeks before the viral load falls below the detectable value of 10 2 copies ml -1 . Note that upon shutting down IFN-and macrophage-mediated immunity or total immunity, the viral load grew beyond clinically observed values in the literature (~10 12 copies/ml), therefore we set an upper bound at 10 12 copies/ml to keep the results clinically meaningful. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. Treatment over a combination of the two parameters, i.e., IFN and viral production rates, can be more efficient than monotherapy in suppressing viral load, as also suggested by clinical studies 54, 55 . While cytopathic death rate and viral production rate play major roles in governing the clearance time of viruses ( clear ), IFN production rate is relatively less significant. Further, transport processes play a significant role in governing both total viral load and time to clear the load. Specifically, the transport of virus from URT to LRT ( 1 ) affects viral load in URT, and blood to MPS via the hepatic artery ( ) and MPS to blood via the hepatic vein ( ) govern the clearance time from plasma, which should also affect the viral clearance of other organs connected to plasma. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. are important parameters in governing the kinetics of viral load in LRT and plasma, respectively. Finally, the total viral load in LRT is also affected by pulmonary absorption ( 1 ), i.e. by the rate of transport of viruses from LRT to plasma. Up to this point, we have demonstrated that the model was able to reproduce viral kinetics that were consistent with experimentally measured values and produce observations consistent with published literature. We next sought to examine whether this tool can make predictions that might allow clinicians to design an effective therapy for patients, helping to optimize and personalize their treatment regimen. As a numerical experiment, we tested three treatment scenarios in controlling infection: a hypothetical antiviral agent, interferon therapy, and antiviral agentinterferon combination therapy. Further, the effects of the timing of therapy initiation ( ) were also tested, i.e., starting therapy on the day of onset of symptoms ( = onset ), and starting therapy 5 days post onset of symptoms ( = onset + 5). To quantify treatment effectiveness, we compared the viral load kinetics in three compartments, namely, URT, LRT, and plasma in simulations spanning a period of four weeks. We simulated therapy with a hypothetical antiviral agent that has the same mechanism of action as Remdesivir 56 , i.e. interference with RNA-dependent RNA polymerase. For this, 200 mg loading dose (≡initial plasma concentration 0 = 5 M, assuming a molecular weight of 800 g/mol and a volume of distribution of 50 L), followed by 100 mg daily maintenance doses for 9 additional . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint days, via intravenous injection were simulated to mimic the pharmacological intervention. Treatment was started at one of the two time points previously mentioned. As a simplification, assuming one-compartment pharmacokinetics for the hypothetical drug with elimination rate constant Cl = 1 −1 , we use the plasma concentration kinetics as a surrogate for tissue concentration kinetics of the drug. The plasma concentration ( ) is thus given by, Hence, the injection times are = , + 1, … , + 9, and we define this set of times as . The antiviral agent acts by inhibiting the production rate of virus from infected cells in the body,  We simulated treatment with interferon beta-1a, with and without the hypothetical antiviral agent (discussed above). For this, four subcutaneous injections (Dose = 44 µg each) of interferon beta-. CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ;  1a were administered every other day starting at one of the two time points previously mentioned. The plasma concentration kinetics of interferon beta-1a I ( ) is obtained by solving the following equation: Hence, the injection times are = , + 2, … , + 6, and we define this set of times as . The . Figure 7d -f, interferon beta-1a therapy significantly reduces the viral load, and the effect is comparable to the hypothetical antiviral agent. Also, an early initiation of therapy leads to a lesser total viral load and a faster reduction in viral load. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint Combination therapy Finally, we tested the effect of combination therapy with the hypothetical antiviral agent and interferon beta-1a on viral load kinetics (plasma concentration kinetics in the inset of Figure 7g ). Figure 7g -i, the combination therapy leads to a faster reduction in viral load compared to the effect of antiviral agent and interferon beta-1a alone, such that the viral load seems to fall below the detection threshold 2-3 days earlier. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint with a physiologically-based pharmacokinetic model to build an in-silico platform that can be used to simulate disease progression and a more complete pharmacokinetics of various test drugs and novel formulations. In each organ compartment, we consider the kinetics of three populations. The first is the . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint The rate of change of total infected cell population within an organ is a function of three mechanisms. The first is an increase due to freshly infected healthy cells by viral particles, the second is death due to cytopathic effect of viral infection, proportional to the number of infected cells and characterized by the rate constant 1 , and the third is due to the interaction between effector CD8 + cells (concentration denoted by CD8 * ( )) and the infected cells. The cytotoxic effect is measured in terms of the death rate constant CD8 . It is important to note that in the reduced form of the model, infected cell death due to effector CD8 * cells is not included. In our model description, all activated immune cells are indicated with an asterisk (e.g., CD8 * ), while inactive or Naïve populations are indicated by standard naming conventions (e.g., CD8 + ). The concentration of viral particles in each organ compartment is influenced by different factors, some of which are organ-specific. However, in all organ compartments, the rate of change of viral particles is proportional to the number of infected cells with virus production constant , but is inversely proportional to the concentration of IFN, denoted IFN( ). IFN is part of the innate immune response that acts by suppressing the viral production rate of infected cells, and is controlled by the effectiveness constant . In all compartments, viral particles may be neutralized due to the aggregation of antibodies on their surface proteins. The antibody concentration is represented by Ab( ), and the destruction rate of viral particles due to antibodies is denoted by Ab . Of note, neutralization of virus by antibodies is not incorporated in the reduced form of the model. Lastly, the viral load can also be reduced by tissue resident macrophages in the lungs (alveolar macrophages) and MPS (Kupffer cells and splenic macrophages) that engulf the viral particles and destroy them. The rate of removal of viral particles by macrophages is given by ϕ . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint We introduce the system of ordinary differential equations that governs the concentration kinetics as follows. Mechanisms particular to each compartment are discussed after each set of equations. Equations for the URT: which is quantified through the pulmonary absorption coefficient 1 . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. Additionally, as discussed above, viral particles from the URT are transported to the GI tract at a rate 2 . Equations for the MPS: is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. Given that the size of the SARS-CoV-2 virus is ~100 nm, we assume that renal excretion is not feasible 58 . Therefore, the viral kinetics in kidneys is dependent on the standard mechanisms and is affected by influx via the renal arteries ( ) and outflux via the renal veins ( ). Equations for the Brain: While the blood brain barrier may be deterrent to the establishment of infection in the brain, we have included the brain compartment due to the lack of evidence for the former 59 is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint The equation for the plasma compartment incorporates all the outgoing fluxes of viral particles through arteries ( , , CO , CA ) and the incoming fluxes via veins ( , , CO , ). Also, the viral load from LRT in equation (6) gets added to plasma at rate 1 . Lastly, similar to all the previous compartments, viral particles can be neutralized by antibodies at a rate Ab . The model up to this point is the reduced model, and the only equation that captures the immune system is equation (7). This equation describes the change of concentration of IFN, which is part of the innate immune system. However, the adaptive immune system should activate to properly mount a full immune response. The equations that follow provide the remaining elements to initiate and maintain a humoral and cell-mediated adaptive immune response to make up the full model. if the difference is large, the denominator is equally large, and the ratio is close to one. This allows a near constant modulation rate that only acts whenever the population of macrophages is far from equilibrium. This reequilibration rate is denoted by APC . The APC population is also impacted by the interaction between APCs and invading viral particles. This causes the population of APCs to . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ;  Furthermore, each of these lymphocytes can be promoted to its activated state, which we denote with an asterisk, * . This conversion takes place when activated APCs interact with naïve lymphocytes, presenting them fragments of the ingested viral particles. The transformation rate from the naïve state to the activated one is represented by the constant , where indicates the cell type. For the case of CD4 + and CD8 + , we use the common rate T . The concentration of activated lymphocytes can fluctuate due to two mechanisms. One is the conversion of naïve cells, which was already discussed. The second is due to death caused by a variety of factors like exhaustion or apoptosis, and is expressed through the death constant . B cells, however, follow a different mechanism, which we discuss later. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint The final equation in the model describes the rate of change of antibody concentration, Ab( ). The sole contributors to the production of antibodies are short-lived and long-lived plasma cells. The corresponding production rates are given by P S and P L , respectively. We consider two mechanisms by which antibodies can be consumed or eliminated. One is the loss of antibodies due to their interaction with viral particles in a given compartment with rate constant Ab . The second is the elimination of antibodies by other factors independent of the viral load, e.g., degradation or clearance from tissues, which occurs at rate constant Cl Ab . A summary of the parameters used in the model is given in Tables 1-3. Once the full set of parameters for the model has been defined and fixed for the conditions corresponding to Figure 4 , we proceed to identify the relative effect of each parameter on the viral kinetics. This is done by systematically perturbing one or multiple parameters and comparing the outcomes between the perturbed state and the original state. To quantify the differences between the two states we introduce the following 6 criteria. The first three refer to the area under the curve The next three denote the total time required for the viral load in the URT, LRT, and Plasma compartment to reduce to < 10 2 viral copies per mL, i.e., 2 in log base 10 units. The last comparison criterion is the antibody titer at day 30 in the body, i.e., Ab( = 30). In the next two . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint subsections we compare each of the 6 criteria using global sensitivity analysis (GSA), applied to the 31 parameters. Local sensitivity analysis only allows one parameter to change at a time, and thus may not be suitable for analyzing complex biological systems. We performed global sensitivity analysis (GSA 36, 54, 55 ; i.e., multiple parameters can be varied simultaneously) to obtain a further understanding of the relationship between parameters and their combined effects on the model outputs of interest. Specifically, in our analysis, all parameters were perturbed at the same time, and we assume a uniform distribution for each parameter. The range of values of each sample was PR ± 99%(PR), where PR is the reference value of a given parameter. To ensure a complete sampling of the full parameter space we used a Latin hypercube sampling scheme. Subsequently, each sample was used to recompute the kinetics, from which we extract the 6 criteria mentioned above. In total, 10 batches of 5000 samples each were computed. Then, the data were subjected to a multivariate linear regression analysis to produce an impact factor, which we label as the sensitivity index (SI). Lastly, the sensitivity indices were ranked by means of a one-way ANOVA and a Tukey's test. The higher the SI, the more significance a parameter holds. A detailed description of the GSA workflow can be found in 38, 60, 61 . All analyses were performed in MATLAB R2018a. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint Figure 2 . Modeling workflow. In the first step, the reduced model uses the hamster data to fit parameters corresponding to viral dynamics, transport coefficients, and innate immunity. Subsequently, the more complex full model uses the previously estimated parameters and clinical data to estimate the remaining parameters pertaining to the adaptive and innate immune responses. Lastly, simulations are generated to make predictions, and statistical analyses are performed to extract useful information. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020. 10.30.20215335 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; bound at 10 2 copies ml -1 and 10 4.6 pg ml -1 is imposed to represent the detectable limit of viral load . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint and antibodies, respectively; dashed blue line indicates the limit of detection. Once the viral load or antibodies go below the detection limit, a vertical line is used to indicate the time of occurrence of this event. The triangular markers represent clinical data presented as mean ± SD (n = 4 patients). Pearson correlation coefficient between observed and fitted values is R > 0.98 (see Figure   S1b ). . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. Insets in a,d,g) show plasma concentration kinetics of the pharmacological agent/s for the treatment regimen that begins on the day of onset of symptoms. A lower bound at 10 2 copies ml -1 is imposed to represent the detectable limit of viral load in the body (black . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint horizontal line); once the viral load goes below the detection limit, a vertical line is used to indicate the time of occurrence of this event. . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint Reequilibration rate of naïve CD8 cells cell⋅mL 1 ⋅d 1 -0.0045 62, 63 Reequilibration rate of naïve B cells cell⋅mL 1 ⋅d 1 -1.75 76 Reequilibration rate of naïve CD4 cells cell⋅mL 1 ⋅d 1 -0.0027 63, 62 Baseline IFN production rate IFN units⋅ mL -1 ⋅d -1 38.8 1.37 29, 30 Degradation rate of IFN d -1 24 24 77 Healthy tissue parameters Initial concentration of target cells in URT cells⋅mL -1 10 6.9 10 6.7 72, 78, 79 Initial concentration of target cells in LRT cells⋅mL -1 10 6.9 10 6.7 Initial concentration of target cells in GI cells⋅mL -1 10 7.4 10 6.9 80 Initial concentration of target cells in MPS cells⋅mL -1 10 6.8 10 6.6 81, 82, 83 Initial concentration of target cells in heart cells⋅mL -1 10 6.5 10 6.3 Initial concentration of target cells in kidneys cells⋅mL -1 10 7.1 10 6.9 Initial concentration of target cells in brain cells⋅mL -1 10 5.9 10 5.7 Viral dynamics parameters Initial concentration of viral load in URT virus⋅mL -1 10 5.7 Table 3 29 Clearance rate of antibodies d -1 -0.04 10 Hepatobiliary excretion rate d -1 2.68 0.15 89 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint Table 2 . List of model parameters estimated from fitting the reduced model to in vivo data. Note: Characteristic times corresponding to the transport parameters are shown in Figure 1 . . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint Transition rate of naïve CD8 into CD8 * or CD4 into CD4 * mL⋅cell -1 ⋅d -1 0.0061 Transition rate of naïve B cells into B * mL⋅cell -1 ⋅d -1 0.029 Transition rate of B * into short-lived plasma cells mL⋅cell -1 ⋅d -1 564.8 Transition rate of B * into long-lived plasma cells mL⋅cell -1 ⋅d -1 0.36 Production rate of antibodies from short-lived plasma cells. antibody⋅cell -1 ⋅d -1 0.59 Production rate of antibodies from long-lived plasma cells. antibody⋅cell -1 ⋅d -1 1.34 Antibody loss rate due to viruses mL⋅virus -1 ⋅d -1 0.0013 Elimination rate of viruses due to antibodies mL⋅antibody -1 ⋅d -1 0.0085 Death rate of infected cells due to CD8 * mL⋅cell -1 ⋅d -1 0.0037 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted November 5, 2020. ; https://doi.org/10.1101/2020.10.30.20215335 doi: medRxiv preprint@story_separate@In summary, we have developed a semi-mechanistic mathematical model that predicts the whole- Through global sensitivity analysis, we identified the key mechanisms that control infection and can be used as potential therapeutic targets for pharmacological intervention. Finally, we tested the potential of such therapeutic targets by simulating clinically relevant treatment options and identified the importance of the timing of treatment initiation, and the effects of various therapies to suppress infection effectively and immediately. As a limitation of the model, it is important to note that due to lack of clinical data for the viral load kinetics in extrapulmonary compartments, we had to rely on the transport parameters estimated from in vivo data, and the model predictions for the extrapulmonary compartments could not be clinically validated. As clinical knowledge of the disease and its mechanisms improves, we will continue to fine-tune the model and integrate it . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. In summary, we have developed a semi-mechanistic mathematical model that predicts the whole- Through global sensitivity analysis, we identified the key mechanisms that control infection and can be used as potential therapeutic targets for pharmacological intervention. Finally, we tested the potential of such therapeutic targets by simulating clinically relevant treatment options and identified the importance of the timing of treatment initiation, and the effects of various therapies to suppress infection effectively and immediately. As a limitation of the model, it is important to note that due to lack of clinical data for the viral load kinetics in extrapulmonary compartments, we had to rely on the transport parameters estimated from in vivo data, and the model predictions for the extrapulmonary compartments could not be clinically validated. As clinical knowledge of the disease and its mechanisms improves, we will continue to fine-tune the model and integrate it . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.","Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a pathogen of immense public health concern. Efforts to control the disease have only proven mildly successful, and the disease will likely continue to cause excessive fatalities until effective preventative measures (such as a vaccine) are developed. To develop disease management strategies, a better understanding of SARS-CoV-2 pathogenesis and population susceptibility to infection are needed. To this end, physiologically-relevant mathematical modeling can provide a robust in silico tool to understand COVID-19 pathophysiology and the in vivo dynamics of SARS-CoV-2. Guided by ACE2-tropism (ACE2 receptor dependency for infection) of the virus, and by incorporating cellular-scale viral dynamics and innate and adaptive immune responses, we have developed a multiscale mechanistic model for simulating the time-dependent evolution of viral load distribution in susceptible organs of the body (respiratory tract, gut, liver, spleen, heart, kidneys, and brain). Following calibration with in vivo and clinical data, we used the model to simulate viral load progression in a virtual patient with varying degrees of compromised immune status. Further, we conducted global sensitivity analysis of model parameters and ranked them for their significance in governing clearance of viral load to understand the effects of physiological factors and underlying conditions on viral load dynamics. Antiviral drug therapy, interferon therapy, and their combination was simulated to study the effects on viral load kinetics of SARS-CoV-2. The model revealed the dominant role of innate immunity (specifically interferons and resident macrophages) in controlling viral load, and the importance of timing when initiating therapy following infection."
"The basic mechanism of autophagy is the sequestration of the structure that has to be degraded by large cytoplasmic double-membrane vesicles called autophagosomes. The current model is that autophagosomes are formed by expansion and sealing of a small cistern known as the phagophore or isolation membrane ( Figure 1 ) [1] [2] [3] [4] [5] . Once complete, they fuse with the mammalian lysosomes or plant and yeast vacuoles to expose their cargo to the hydrolytic interior of these compartments for degradation. In mammalian cells, this event is preceded by the fusion with vesicles of the endocytic pathway and/or endosomes, to form amphisomes ( Figure 1 ) [6] . The metabolites generated in the lysosomes/vacuoles are subsequently transported in the cytoplasm and used as either an energy source or building blocks for the synthesis of new macromolecules. The phagophore is generated at a specialized site known as the phagophore assembly site or preautophagosomal structure (PAS) [1] [2] [3] [4] [5] . At this location, the key actors of this pathway, the autophagy-related genes (ATGs), mediate the formation of the phagophore and its expansion into an autophagosome. Sixteen Atg proteins compose the conserved core Atg machinery that catalyses the formation of autophagosomes in all eukaryotes. The rest of the Atg proteins are organism-specific and most of them are involved in either the regulation of autophagy or dictating the specificity during selective types of autophagy. Autophagy has been considered for long time a nonselective process for bulk degradation of either long-lived proteins or cytoplasmic components during nutrient deprivation. Recent evidences, however, have revealed the existence of numerous types of selective autophagy used by the cell to specifically eliminate unwanted structures including organelles and invading microorganisms [7] . Under specific conditions, autophagosomes can thus exclusively sequester and degrade mitochondria (i.e., mitophagy), peroxisomes (i.e., pexophagy), endoplasmic reticulum (ER) (i.e., ER-phagy or reticulophagy), endosomes/lysosomes, lipid droplets (i.e., lipophagy), secretory granules (i.e., zymophagy), cytoplasmic aggregates and complexes (i.e., aggrephagy), ribosomes (i.e., ribophagy), invading pathogens (i.e., xenophagy) and so forth. Because of its ability to rapidly eliminate unwanted structures, autophagy participates in a multitude of physiological processes essential to maintain cellular and organismal homeostasis such as the adaptation to starvation, cell differentiation and development, degradation of aberrant structures, turnover of superfluous or damaged organelles, tumorsuppression, innate and adaptive immunity, lifespan extension, and type II programmed cell death [10] [11] [12] [13] . As Phagophores are the initial precursor structure of this transport pathway. These membrane cisterns are formed at the PAS by the Atg machinery, which also catalyzes their expansion into autophagosomes through the acquisition of extra lipid bilayers. During this latter event, the growing phagophore sequesters cytoplasmic components or specific structures depending on the autophagyinducing conditions. The closure of the expanding phagophore leads to the formation of a double-membrane vesicle called an autophagosome, which contains the cargo targeted for degradation. The Atg machinery is then released from the surface and the complete autophagosomes, which initially fuse with endosomal compartments generating amphisomes. While the cargo material starts to be already turned over in the amphisomes, the exposure to hydrolases by fusion with lysosomes to form autolysosomes allows its complete degradation into basic metabolites such as amino acids and sugars, which are transported in the cytoplasm and used as an energy source or building blocks for the synthesis of new macromolecules. Adapted from [8, 9] . a result, a defect or an impairment in this pathway leads to severe illnesses including neurodegenerative, cardiovascular, chronic inflammatory, muscular and autoimmune diseases, and some malignancies. Crucially, it has also been shown that autophagy could be a potential therapy to prevent or cure particular diseases, including specific types of tumors, muscular dystrophies, neurodegenerative disorders, and selected infections [14] [15] [16] [17] [18] [19] . Yeast ATGs are in blue while the mammalians counterparts, which in few cases comprise few paralogues, are in red. The WIPI's is a protein family which comprises 4 members: WIPI1, WIPI2, WIPI3, and WIPI4 [20] . Three of them have been shown to be involved in autophagy [20] [21] [22] . The LC3's is a protein family that comprise 6 proteins: LC3A, LC3B, LC3C, GABARAPL1, GABARAPL2, and GABARAPL3 [23] . All of them associate with autophagosomes [23, 24] . The yeast Atg1 complex contains two subunits, Atg29 and Atg31, which do not have homologues in high eukaryotes. In contrast, the mammalian complex possesses a component, Atg101, which is not found in yeast.@story_separate@proteins, that is, how these factors assemble, rearrange, and expand membranes into an autophagosome. Although the exact molecular role of the core Atg proteins remains unknown, they have been classified into five Atg functional groups principally based on interactions: the Atg1/Ulk kinase complex, the Atg9 cycling system, the autophagy-specific phosphatidylinositol 3-kinase (PtdIns3K) complex I, and the two ubiquitin-like conjugation systems ( Figure 2 ). Atg1 is a serine/threonine protein kinase that has a key role in autophagy induction [25] . Different proteins associate to form a complex with Atg1. In yeast, this kinase is associated with Atg13, Atg17 and two nonconserved subunits, Atg29 and Atg31, while ULK1 and ULK2, two mammalian redundant Atg1 homologues, associate with mATG13 and FIP200, the counterparts of Atg13 and Atg17, respectively, and the nonconserved component ATG101 (Figure 2 ) [26] [27] [28] [29] [30] [31] . The signaling cascade centered on the serine/threonine kinase mammalian target of rapamycin (mTOR) promotes cell growth and anabolism in presence of nutrients [32] . This pathway inhibits autophagy through direct modulation of the Atg1/ULK complex. In nutrient rich conditions, mTOR is associated with the Atg1/ULK complex via ULK1 or ULK2 and it maintains mATG13 phosphorylated [31, [33] [34] [35] [36] . Under nutrient deprivation, mTOR dissociates from this complex provoking a dephosphorylation of ULK1 and ULK2 necessary for the activation of their kinase activity and subsequent phosphorylation of FIP200, mATG13, and ULK1/2 itself [35] . All these modifications are necessary to initiate autophagy. Complex I. This complex is formed by Vps34/hVPS34, Vps15/p115, Atg6/BECLIN1, and Atg14/ ATG14L (Figure 2 ), and it is essential for the generation of PtdIns3P on autophagosomal membranes and for the progression of autophagy [37] [38] [39] . The role in autophagy of this lipid, which is found on the surface and interior of autophagosomes [40, 41] , remains unclear. Nevertheless, one function is to recruit factors such as Atg18 to the PAS and possibly also to the phagophore. The formation of PtdIns3P depends on the activity of PtdIns3 kinase class III hVPS34, which is present on the surface of various organelles [42] . Atg14 is a subunit of the autophagy-specific PtdIns3K complex both in yeast and in mammals. There are at least two different Vps34-containing complexes in yeast [43] , which, in addition to Vps34, Vps15, and Atg6/Vps30, also possess specific subunits: Atg14 and Vps38. These two last components direct the PtdIns3K complexes to specific locations where they generate the PtsIns3P pools essential for autophagy and endosomal trafficking, respectively. A similar situation also appears to be present in mammalian cells, with UVRAG being the homologue of Vps38 [38] . In mammalian cells, the PtdIns3K complex I also controls autophagy induction. When BECLIN1 self-associates or binds to BCL-XL/BCL-2, the lipid kinase activity of hVPS34 is inhibited as BECLIN1 is not part of the complex [37, 44, 45] . Upon nutrient deprivation, the JNK1 signaling pathway phosphorylates BCL-2 leading to its dissociation from BECLIN1, which permits this protein to interact with the PtdIns3K complex I stimulating PtdIns3P synthesis and autophagy induction [45, 46] . In parallel, autophagy positive regulators such as AMBRA1 and BIF-1 promote BECLIN1 association to hVPS34 [47] [48] [49] . Cycling System. Atg9 is another protein that is found at an early stage of the PAS formation and it is the only integral membrane protein among the core Atg machinery [50] . It possesses six conserved transmembrane domains with the two cytoplasm-oriented termini, and it is essential for autophagy [51, 52] . Mammalian Atg9 (mATG9) localizes to the trans-Golgi network (TGN) in fed cells and partially to the late endosomes [52] . Upon autophagy induction by starvation, mATG9 relocates to the site where autophagosomes are generated, possibly the PAS and/or phagophores [52, 53] . It has recently been shown, however, that mATG9 positive membranes do interact dynamically with the autophagosomal intermediate rather than becoming integral part of them [53] . Similarly, yeast Atg9 is located at the PAS and in several cytoplasmic structures, which are likely to be directly derived from the Golgi [54] [55] [56] . The high mobile cytoplasmic structures are probably 30-60 nm vesicles, while the less mobile appear to be constituted by clusters of vesicles and tubules [56] , which have been named Atg9 reservoirs [54] and have also been observed in mammalian cells [53] . As in mammalian cells, yeast Atg9 also cycles between the cytoplasmic pools and the PAS but it seems to arrive at the early stage of the formation of this structure and to be retrieved when an autophagosome is formed [54, 56] . Several factors regulate Atg9 trafficking including the Atg1/ULK and PtdIns3K complexes [52, 57] . Two other core Atg proteins, Atg2 and Atg18, are involved in Atg9 cycling. In particular, they appear to mediate Atg9 retrieval from the PAS [57, 58] . In yeast, Atg2 and Atg18 form a cytoplasmic complex [59] . While the formation of this complex does not require PtdIns3P, the presence of this lipid at the PAS is necessary for its recruitment to this site [59] . This is achieved through the capacity of Atg18 to directly bind PtsIns3P [59] . Mammals possess 4 Atg18 homologues: WDrepeat protein interacting with phosphoinositides 1 (WIPI1), WIPI2, WIPI3, and WIPI4 [20] . Three of them, WIPI1, WIPI2, and WIPI4 have been implicated in autophagy [20] [21] [22] . Recently, two mammalian Atg2 homologs, Atg2A and Atg2B, have been identified and both are required for autophagy [58] . Interestingly, human WIPI4 interacts with Atg2A and Atg2B as well as Caenorhabditis elegans EPG-6/WIPI4 with ATG2 [21, 60] . These observations suggest that WIPI4/EPG-6 and yeast Atg18 overlap in their role in autophagy by carrying out the functional interconnections with Atg2 [58] . The elongation of the phagophores and the completion/sealing of autophagosomes appear to rely on the function of these two ubiquitin-like systems ( Figure 2 ). Atg12, an ubiquitinlike molecule, is covalently conjugated to Atg5 through the activity of Atg7 and Atg10, an E1-and an E2-like enzyme, respectively [23, [61] [62] [63] . The Atg12-Atg5 complex subsequently associates with Atg16 forming a large oligomer that localizes to both the PAS and the phagophore via Atg16 [64] . The function of the Atg12-Atg5·Atg16 oligomer in autophagy is unclear, but it seems that it acts as an E3 ligase for the generation of the lipidated form of Atg8/LC3 [65] . Atg8 is a second ubiquitin-like protein participating in autophagy. While yeast has only one copy of Atg8, mammalian cells have 6 homologues and all are involved in autophagy [23, 24, 62] . Atg8 is posttranslationally processed by the specific cysteine protease Atg4, which cleaves its Cterminal amino acids exposing a glycine residue. Through another ubiquitylation-like reaction mediated by Atg7 and the E2-like enzyme Atg3, Atg8 is covalently conjugated to phosphatidylethanolamine (PE). This lipidation promotes Atg8 recruitment and association with autophagosomal membranes [23, [61] [62] [63] . In contrast to the rest of the Atg proteins, which are mainly present on the surface of autophagosomes, Atg8 is found inside and outside these vesicles. When an autophagosome is completed, Atg4 cleaves the Atg8-PE pool on the surface releasing Atg8 back in the cytoplasm for reuse. Atg8 has been shown to be essential for autophagosome formation possibly by mediating tethering and fusion of membranes [66, 67] . These data, however, are controversial [68] . What is clear is that the Atg8 population associated with autophagosome inner membrane is essential for the selective sequestration of specific cargoes and together with them it is degraded in the lysosome/vacuole lumen (see above). In addition to the Atg proteins, additional factors play a crucial role in the autophagosome biogenesis especially in high eukaryotes. Important ones include AMBRA1 [47, 48] , DFCP1 [69, 70] , and VMP1 [70, 71] . The detailed discussion of the role of these proteins as well as their functional relationship with the different Atg functional groups is not the subject of this review, and they have been extensively presented elsewhere [1] [2] [3] [4] [5] . Almost all the Atg proteins are cytosolic and associate to form the PAS by interacting with other Atg components and/or lipids upon autophagy induction [3, 50, 72] . Most of the studies about the PAS have been done in yeast and they have revealed that the core Atg proteins assemble following a hierarchical order and form this autophagosomal precursor [3, 50, 72] . Recent evidences have shown that the PAS and the principles of this ordered recruitment are conserved in mammals [70] . While these works have proposed a model where one Atg protein is at the top of the hierarchical recruitment cascade, studies on the selective elimination of either mitochondria or Salmonella indicate that the Atg proteins can be grouped into clusters, which independently assemble to form the PAS [73] [74] [75] . Interestingly, these clusters mirror almost entirely the organization in functional groups of the Atg proteins. One of the enigmas in the field of autophagy is the origin of the lipid bilayers composing autophagosomes. Several cellular compartments, including the ER, Golgi, endosomes, and the plasma membrane, have been implicated as the possible source of the autophagosomal membranes by a series of recent studies [76] [77] [78] . This apparent discrepancy between the different reports could be due to the ability of cells to derive the membranes from the most suitable reservoirs depending on the tissues and conditions triggering autophagy. Thus in a tissue under a specific stress, autophagy would be supplied with membranes from an organelle that could guarantee the delivery of a large amounts of lipids [76] [77] [78] . An alternative option would be that the diverse Atg functional clusters that come together to generate the PAS (and the phagophore) are associated to membranes derived from different compartments explaining why endosomes, the plasma membrane, and the Golgi have all been shown to contribute to the formation of the early autophagosomal intermediates [76] . This model would also explain the involvement of proteins mediating membranes fusion such as the SNAREs in the early stages of autophagosome biogenesis [68, 79] . Thus in addition to unveiling the molecular function of each Atg protein, the challenge for the future will be to understand the mechanism underlying the integrated interaction between the different Atg functional groups, which will probably also be key in uncovering the events leading to the assembly of the autophagosomal membranes and possibly identify new mechanisms for the regulation of autophagy. The major amount of lipids, however, is required for the expansion of the phagophore into an autophagosome. The current idea is that the ER plays a central role in this event because growing phagophores have been observed in close proximity of this organelle [69, 80, 81] . Contact sites between these two compartments have been detected [80, 81] and therefore it has been postulated that transfers could occur by direct lipid translocation from the ER to the nascent autophagosome. It remains to be proven whether this unidirectional passage of lipids between these two organelles indeed exists and how this is achieved. Autophagosomes are ready to fuse with the lysosome/vacuole once the vesicle membranes are sealed and the Atg machinery is disassembled and released back in the cytoplasm for reuse [72, 82] . Evidence for this latter event has been provided by the observation that Atg8/LC3, an ubiquitin-like protein that is covalently conjugated to autophagosomal membranes through a reversible linkage to phosphatidylethanolamine (PE), is not found on the surface of complete vesicles while it is abundantly detected on phagophores and nascent autophagosomes [83] . Accordingly, failure to release Atg8 form the autophagosome surface by Atg8-PE delipidation leads to an impairment of autophagy [84, 85] . Recently, it has been revealed that the turnover of phosphatidylinositol-3-phosphate (PtdIns3P), a lipid generated at the PAS and involved in the recruitment of Atg proteins to this location, is key in the disassembly of the Atg machinery from the surface of yeast autophagosomes [86] . This event is a requisite for the fusion of these carriers with the vacuole [86] indicating that the cell possesses a regulatory factor to avoid premature and potentially harmful fusion of incomplete double-membrane vesicles with the vacuole/lysosome. It remains to be identified this factor (or factors) that is able to sense the autophagosome completion and thus trigger PtdIns3P turnover, the Atg4-mediated processing of Atg8-PE, and the release of the rest of the Atg machinery. Autophagy can be induced by numerous environmental and cellular stresses. As a result several signaling molecules and cascades have been shown to be involved in the modulation of this pathway [4, 8, 87] . Biochemical and pharmacological experiments have highlighted the upstream effector role of Atg1/Ulk1 and PtdIns3K complexes in the transduction of these signals into the initiation of autophagosome biogenesis. Atg9 also appears to participate in the regulation of autophagy [88, 89] . The best-characterized regulator of autophagy is mTOR and as already introduced above it represses this pathway by principally blocking the activity of the Atg1/ULK1 complex through direct phosphorylation [4, 8, 87] . The activity of mTOR is stimulated by a variety of anabolic inputs that include the energy and nutrient status of the cell as well as the presence of amino acids and growth factors. Conversely, mTOR is inhibited when amino acids are scarce, growth factor signaling is reduced and/or ATP concentrations fall, and this results in a derepression of autophagosome biogenesis. The energy-sensing AMP-activated protein kinase (AMPK) and glucose-sensing protein kinase A (PKA) also regulate the Atg1/ULK1 complex by direct phosphorylation [90] [91] [92] . The molecular details of these regulations and the cross-talk between them remain to be elucidated. Numerous molecules including interferon γ (IFNγ), tumor necrosis factor α (TNFα), and vitamin D, but also receptors such the toll-like receptors (TLRs) or the pattern recognition receptors (PPRs) have been shown to regulate autophagy as well [13, [93] [94] [95] . It is largely unknown how this is achieved but understanding these signaling mechanisms could have the added value of providing the knowledge essential for the development of either treatments or drugs for autophagy-based therapies to cure of specific diseases [14] . Some of the open questions regarding autophagy regulation have accurately been discussed in a recent compendium [96] . In addition to the core Atg machinery, the selective types of autophagy rely on specific cargo-recognizing autophagy receptors that assure the cargo sequestration into autophagosomes. Autophagy receptors are defined as proteins being able to interact directly with both the structure that has to be specifically eliminated by autophagy and the pool of the Atg8/LC3 protein family members present in the internal surface of growing autophagosomes [7, 97] . This latter interaction is in most of the cases mediated through a specific sequence present in the autophagy receptors and commonly referred to as the LC3-interacting region (LIR) motif [98] . It has recently been shown that particular proteins possessing this motif including Atg1/Ulk1 are also directly turned over by autophagy without the necessity of having an autophagy receptor [30] . The autophagy receptors for the selective degradation of several complexes and organelles have been identified but others such as those for the specific turnover of the ER and ribosomes are still elusive [7, 97] . One emerging theme is that structures targeted for destruction are ubiquitinylated and a series of autophagy receptors such as p62/SQSTM1 and NBR1 with an ubiquitin-banding domain and a LIR motif, promote their sequestration into autophagosomes [7, 97, 98] . While these molecules preferentially recognize short ubiquitin chains [99] , it is still unclear why they do not bind other cellular components carrying the same types of posttranslational modification. Central in understanding these specific elimination processes will be the identification of the E3 ligases and their eventual adaptors involved in marking the autophagy cargoes with ubiquitin. SMURF1 and STING appear to belong to these two classes of proteins [100, 101] . The investigation of proteins like these will provide information about how the cell senses and regulates the degradation of unwanted structures by autophagy. Atg30 and Atg32 are two yeast autophagy receptors involved in pexophagy and mitophagy, respectively, which do not use the ubiquitin system to bind the targeted cargo but nevertheless their study has provided insights into possible mechanisms that could also be used by the E3 ligases [102] [103] [104] . These proteins are present on the surface of peroxisomes and mitochondria, respectively, and under mitophagy and peroxisome-inducing conditions they get phosphorylated by signaling cascades activated under these conditions [102, 105, 106] . The phosphorylation of Atg30 and Atg32 promotes the association and recruitment of Atg11, which in turn triggers the assembly of the Atg machinery mediating the formation of a double-membrane vesicle around the organelle [102] [103] [104] . Atg30 is present in Pichia pastoris but not in Saccharomyces cerevisiae, which uses a different molecule for perxophagy, that is, Atg36 [107] . Atg30 is a soluble protein that becomes phosphorylated when pexophagy is stimulated. This modification leads to its recruitment onto the peroxisome surface and its subsequent biding to Atg11 results in a selective engulfment of peroxisome by autophagosomes [107] . Pathway. For a long time autophagy has been considered a degradative transport route but recent discoveries have begun to change this view. The yeast cytosol-to-vacuole transport (Cvt) pathway is a biosynthetic selective type of autophagy that delivers a subset of hydrolases into the vacuole [108] . Shortly after synthesis, the proform of these hydrolases assembles into a large cytoplasmic oligomer, which is subsequently sequestered into a double-membrane vesicle that fuses with the vacuole. In the vacuole, the resident proteases cleave the profragment of the hydrolases composing the oligomer leading to both their activation and the disassembly of this structure [108] . For long the transport function of the Cvt pathway has been considered an exception in the field of autophagy. Recently it has been shown that the extracellular delivery of the cytosolic Acyl coenzyme-A-(CoA-) binding protein in the yeast Pichia pastoris and Saccharomyces cerevisiae (ACBP), and the social amoebae Dictyostelium discoideum (AcbA), which occurs under starvation conditions, is not mediated by the secretory pathway [109, 110] . The used unconventional transport route depends on the ATG and the Golgi ReAssembly and Stacking Protein (GRASP/Grh1) [109, 110] , suggesting that autophagosomes could be the hallmark of this type of unconventional secretion. This notion is supported by work in yeast S. cerevisiae that has revealed that when this new transport route is triggered by starvation, Grh1 is recruited to membranous structures that are positive for Atg8 and Atg9 [111] , and morphologically and molecularly resemble to precursor structures involved in autophagy [54] . Interestingly, the unconventional secretion of cytosolic IL-1β and HMGB1 by macrophages upon their stimulation with either starvation or lipopolysaccharides-(LPS-) treatment also requires the ATG and GRASP55, one of the paralogues of GRASP/Grh1, indicating that this process could be conserved among eukaryotes [112] . Additionally, autophagosomes expel engulfed material, mostly of plasma membrane origin, by fusing with the plasma membrane during the last stages of reticulocytes maturation into erythrocytes (intracellular turnover is not possible because lysosomes are absent in these cells) [113] . Finally, it has been hypothesized that picornaviruses exploit autophagosomes to secrete their newly synthesized virions [114] and while it was assumed that these viruses were somehow hijacking and diverting these carriers, one emerging possibility could be that they take advantage of an existing type of autophagy mediating the extracellular delivery of specific cytosolic components. Under ER stress conditions that activate the unfolded protein response (UPR), yeast cells expand their ER volume to probably accommodate newly synthesized chaperones and to buffer the accumulation of unfolded proteins under UPRinducing conditions. This phenomenon is accompanied by the formation and accumulation of autophagosomes that are densely and selectively packed with ER membranes [115] . Very surprisingly, the ER sequestration into autophagosomes and not its degradation is the crucial step allowing the cell to survive under these stress conditions [115] . While it remains totally unknown the fate of these autophagosomes, these data highlight the possibility that in specific situations autophagosomes could be persistent organelles rather than transport carriers, a notion somehow reminiscent with those infections where pathogens subvert autophagy to use autophagosomes as a platform for their intracellular replication [116] . A completely new research area is the study of those forms of autophagy that do not require all the components of the core Atg machinery, which until recently were believed to be the absolute requirement for the generation of autophagosomes [117, 118] . One of the first reports describing one of these alternative processes of autophagy showed that when cells are subjected to particular stresses such as the treatment with the cytotoxic compound etoposide, they can form autophagosomes out of the Golgi and perform autophagymediated protein degradation in an ATG5-, ATG7-, ATG9-, and ATG16-independent way [119] . Nonetheless this pathway still requires ULK1/Atg1, FIP200/Atg17, BECLIN1/Atg6, and hVPS34/Vps34 [119] . BECLIN1, however, has been shown to be dispensable for autophagy in several situations, most of which involved treatment of cells with proapoptotic compounds such as the neurotoxin 1-methyl-4-phenylpyridinium, staurosporine, MK801, resveratrol, and Z18 [120] [121] [122] [123] [124] . The autophagy-specific PtdIns3K complex I controls autophagy induction and BECLIN1 can be part of it. When BECLIN1 self-associates or binds to Bcl-XL/Bcl-2, the lipid kinase activity of hVps34 is inhibited as BECLIN1 is not part of this complex [37, 44, 45] . Upon nutrient deprivation, the JNK1 signaling pathway phosphorylates Bcl-2 leading to its dissociation from BECLIN1, which permits this protein to interact with the PtdIns3K complex I stimulating PtdIns3P synthesis and autophagy induction [45, 46] . Because the BECLIN1-independent types of autophagy still entirely or partially require the generation of PtdIns3P [121, 125, 126] , one possibility is that PtdIns3K complex I is stimulated in a different way under conditions that trigger this alternative pathway. A lot still need to be understood about the mechanism of these unconventional types of autophagy and future studies will also tell us why the cell utilizes them. One of the principal assumptions of the field of autophagy has been that the Atg proteins are involved in autophagosome biogenesis exclusively. Studies on the role of autophagy in immunity, especially in the context of specific viral and bacterial infections, have revealed a different picture. There are now several experimental findings showing that individual Atg proteins or Atg functional groups can also be part of other processes. The ERAD tuning is a transport pathway out of the ER that mediates the rapid turnover of specific ERAD factors in the endosomal system [127] [128] [129] . In the ER SEL1L, a single transmembrane protein cargo receptor, binds and sorts these ERAD factors into vesicles called EDEMosomes [130] . The cytoplasmic tail of SEL1L binds to the nonlipidated form of LC3, that is, LC3-I, and as a result the EDEMosomes are LC3-I-positive [128, 130] . This notion of an unconventional use of LC3 by the ERAD tuning, which does not depend on an intact Atg machinery, has been reinforced by the observation that ATG5 and ATG7 are not involved in this pathway [128, 131] and the end product of the two autophagy conjugation systems to which these two proteins belong to, that is, lipidated Atg8/LC3 also known as LC3-II [62] , is not present on the EDEMosomes [128] . The molecular function of LC3-I in the ERAD tuning is unclear and one hypothesis is that it acts as an adaptor to a not yet identified vesicle protein coat. Alternatively, the capacity of LC3 to associate with microtubules [132] could permit the EDEMosome to traffic following routes traced by the cytoskeleton. Coronavirus (CoV) cell infection is characterized by the formation of reticulovesicular networks of double-membrane vesicles (DMVs) and convoluted membranes, onto which replication-transcription complexes are associated. Studies with the mouse hepatitis virus (MHV), a CoV, have revealed that the ATG5 and ATG7 gene products are not required for the formation of the virus-induced DMVs and accordingly LC3-II is not present on these structures [131, 133] . In contrast LC3-I decorates the MHV-induced DMVs and the depletion of this protein blocks virus replication [131] . What has been shown is that CoV hijack the ERAD tuning by probably coopting SEL1L because this receptor also localizes to the MHV-induced DMVs and the virus replication is severely impaired when it is depleted [130] . Interestingly, the Equine Arteritis Virus (EAV), a member of the arterivirus virus family that belongs to the Nidovirales order like the CoV, is also hijacking the LC3-I-positive membranes of the ERAD tuning to replicate in host cells [134] . Finally and similarly to CoV, LC3-I (but not LC3-II) is associated to and essential for the formation of the intracellular inclusions of the Chlamydia trachomatis [135] . The generation of the C. trachomatis inclusions also does not require an intact Atg machinery [135, 136] but it remains unknown whether this bacterium is subverting the ERAD tuning as well. Brucella abortus ensures its intracellular survival by forming the Brucella-containing vacuoles (BCVs), which traffic from the endocytic compartment to the ER where this bacterium proliferates [137] . The replication of Brucella in the ER is followed by conversion of the BCVs into compartments with autophagic features that have been named autophagic BCVs (aBCVs) [138] . The aBCVs formation is essential for both the intracellular life cycle and cell-tocell spreading of Brucella, and requires proteins involved in the induction of autophagosome biogenesis such as ULK1, BECLIN1 and ATG14L, and the PtdIns3K activity [138] . The generation of the aBCVs, however, does not require proteins of the two conjugation systems like ATG5, ATG16L1, ATG4B, ATG7, and LC3B [138] . It remains to be understood whether this microbe is either subverting part of the Atg machinery or exploiting a pathway that uses a subset of the Atg proteins. A somehow opposite situation is observed in osteoclasts. These cells resorb bone tissue by removing its mineralized matrix and breaking up the organic bone principally composed by collagen [139] . For this resorption, the osteoclasts form specialized plasma membrane protrusions, the ruffled borders, which are opposed to the surface of the bone tissue [139] . The acidification of this bone-osteoclast resorptive microenvironment and the deposit of proteases such as cathepsin K is achieved through the fusion of tissue-specific secretory lysosomes with the plasma membrane. It has been revealed that Atg proteins, which are part of the two conjugation systems including ATG5, ATG7, ATG4B, and LC3, play an important role in the fusion of these secretory lysosomes with the plasma membrane and subsequent formation of the ruffled border [140] . This process very likely does not represent a situation like the ones described above where autophagosomes fuse with the plasma membrane because secretory lysosomes are single membrane vesicles and their cargo is not cytoplasmic. It will be interesting in the future to determine whether ATG belonging to other Atg functional groups are also involved in this type of secretion. A similar process involving the two Atg conjugation systems in organelle fusion has also recently been characterized in phagocytic cells and termed LC3-associated phagocytosis (LAP). In macrophages and other cell types uptaking apoptotic and necrotic cells, but also yeast or latex beads-conjugated LPS, LC3 is rapidly recruited to phagosomes in a manner that depends on ATG5, ATG7, BECLIN1, and hVPS34 [141] [142] [143] . Work in C. elegans on the same process has also implicate Atg18/WIPI [144] . While it is unclear whether BECLIN1 and hVPS34 are recruited as part of the autophagy-specific PtdIns3K complex I, what has been shown is that LAP does not require ULK1 and FIB200 revealing that the Atg1/ULK complex does not participate in this pathway [141, 142] . The translocation of LC3 onto phagosomes during LAP is not due to the fusion of autophagosomes with phagosomes as it has been observed for example during the killing of Mycobacterium [145] , indicating a probable direct conjugation of LC3 to the limiting membrane of this latter organelle [142, 143] . Interestingly, LC3 association to phagosomes promotes their fusion with lysosomes leading to a rapid acidification and enhanced killing of the ingested organism [141] [142] [143] . Another documented case where it has been shown that cells have the capacity to use a portion of the Atg machinery (as part or not of another pathway) is the IFNγ-mediated antiviral response in macrophages [146] . In particular, it has been shown that the direct antiviral activity of IFNγ against murine norovirus, which involves an inhibition of the formation of the membranous cytoplasmic replication complexes of this virus, depends on the ATG5-ATG12 conjugate, ATG7 and ATG16L1, but not on the induction of autophagy, fusion between autophagosomes and lysosomes, and the degradative activity of lysosomes [146] . In addition, this response does not require the Atg8/LC3-processing protein ATG4B indicating that it uses just one of the two conjugation systems. It remains unclear how Atg5-Atg12 and Atg16L1 are carrying out their antiviral action, but interestingly Atg16L1 is detected on the norovirus replication complexes indicating that these proteins could affect the organization of the membranes harboring them and/or the replication machinery. Few questions still have to be answered in our way to understand the contribution of these Atg proteins in the direct IFNγ-mediated antiviral response. First, it must be determined whether ATG4B is substituted by one or more of its homologues (e.g., ATG4A, ATG4C, and ATG4D) before excluding the participation of the second conjugation system. Second, it will be interesting to analyze whether components of the other Atg functional groups are involved in this response.@story_separate@The study of autophagy has attracted a lot of interest in the past years because of its multiple physiological and pathological implications. While major advances have been achieved in understanding the regulation, the mechanism, and the cellular roles of this versatile transport pathway, the new discoveries have unveiled new interesting aspects and their in-depth exploration will keep researchers busy for the next few decades. With the increasing number of laboratories starting to investigate autophagy in tissues, organisms, and diseases so far unexplored, it is easy to predict that the future will be full of surprises and autophagy will continue to astonish us for some time.","Macroautophagy (hereafter autophagy) is currently one of the areas of medical life sciences attracting a great interest because of its pathological implications and therapy potentials. The discovery of the autophagy-related genes (ATGs) has been the key event in this research field because their study has led to the acquisition of new knowledge about the mechanism of this transport pathway. In addition, the investigation of these genes in numerous model systems has revealed the central role that autophagy plays in maintaining the cell homeostasis. This process carries out numerous physiological functions, some of which were unpredicted and thus surprising. Here, we will review some of the questions about the mechanism and function of autophagy that still remain unanswered, and new ones that have emerged from the recent discoveries."
"The recent outbreak of coronavirus disease 2019 caused by the 2019 novel coronavirus (SARS-CoV-2) is one of the most serious threats to the human race in this millennium. There appears to be a large variability among countries in the risk of infection and mortality by this virus 1 . For example, Japan, which has close physical and social distance from China, is one of the first countries that recorded the first case in the earliest phase of this pandemic. As of March 30th, while many governments have 'locked-down' numerous cities and even the entire country, the Japanese government still keeps applying mild measures to mitigate the spread of the virus. The citizens have simply been 'advised' to stay home. Nevertheless, most people in Japan, with the notable exception of Tokyo metropolitan, are currently working as usual. Surprisingly, despite such a liberal measure taken and relatively low number of PCR tests conducted, Japan is ranked at 117 th and 69 th among 199 countries and regions 1 , as of March 28th, regarding the number of cases per 1 million population and the number of deaths per 1 million population, respectively. Also, there seem to be visible differences in COVID-19 prevalence and mortality between countries in Western Europe and Eastern Europe. There are many potential geographical, social, and biological factors, such as temperature, humidity, life expectancy, average income, social norms, and ethnical genetic background, that could potentially explain such variabilities among countries, but it remained fully explored. In case they are successfully identified, such information could potentially contribute to the mitigation of the spread of the virus. Some vaccines (e.g., measles and Bacillus Calmette-Guérin (BCG) vaccines) are associated with a lower risk of illness and death from other disorders [2] [3] [4] . A systematic review of epidemiological studies provided evidence for the non-specific beneficial effects of BCG vaccine on all-cause mortality 5, 6 . Induction of cytokines associated with trained immunity is proposed to underly such protection against non-related viral infections 7 . Researchers in four countries will soon start a clinical trial of BCG vaccine on this disease, based on the proposed beneficial effect of BCG 4 . Interestingly, a blogger noticed that there might be a correlation between the administration of BCG vaccine in each country and the extent to which the spread of COVID-19 occurs 8 . In this study, we evaluated the hypothesis that BCG vaccination has some protective effect against COVID-19 by utilizing publicly available datasets through linear regression modeling. Among the potentially confounding factors, we assessed two factors, life expectancy and the average . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint temperature of the countries. We also tried to evaluate the potential effect of BCG vaccination policy on the growth rate of COVID-19, controlled by the onset of its propagation in each country.@story_separate@The data on COVID-19 and life expectancy were retrieved on March the 28 th from ""COVID-19 CORONAVIRUS PANDEMIC"" page 1 and ""Life Expectancy of the World Population"" page 9 in worldmeter website. The average temperature data were retrieved from ""List of cities by average temperature"" page 10 in Wikipedia. Average temperature of each country was obtained by averaging those of the cities in each country. The raw data on which our analyses are based is attached as Supplementary Three sets of linear regressions were run. The dependent variables (DVs) were the rate of total cases per one million population (Model 1), the rate of death per one million population (Model 2), and the ratio between these two variables (Model 3). The country's BCG policy was the independent variable (IV) of interest. In accordance with the BCG world atlas 12 , this variable had three levels: Group A, the country currently administers the BCG; Group B, the country used to administer the BCG and currently does not; and Group C, the country has never administered the vaccine. The country's life expectancy and mean temperature (°C) in February and March 2020 were added as control variables in all the models in order to rule out potentially confounding effects. In fact, infection rates and mortality rates may have been influenced by the subject's age (i.e., the older, the more vulnerable) and climate conditions (i.e., the higher the temperature, the less contagious the virus). Finally, the Order Quantile (ORQ) normalization transformation was used to standardize the continuous variables. Beyond meeting the statistical assumption of linear modeling (normalization), this procedure is also useful to mitigate potentially confounding effects of outliers. This study included 136 countries or regions for which complete data about total cases per one million population, life expectancy, and temperature were available (Model 1). The data regarding total deaths per one million population and deaths/cases ratio were available for 91 countries (Models 2 and 3). All the analyses were run with the R software 13 , and the graphs were produced by using the package ggplot2 14 . The ORQ transformation was performed with the . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint bestNormalize R package 15 . Finally, the rsq R package was employed to calculate partial R 2 statistics (i.e., unique variances) 16 . Descriptive statistics of each variable (e.g., means, medians, and quantiles) are retrievable from the R codes provided online. Regarding total cases per one million population, the linear model showed a statistically significant effect for both Group B (b = 0.6483, p = .0002) and Group C (b = 0.8666, p = .0025; as compared to Group A). Temperature was barely significant (Figure 1a ; b = -0.1232, p = .0424). As anticipated, life expectancy was significant (Figure 1c Again, since life expectancy was a strong predictor in the model, we reran the analyses only with those countries with a life expectancy higher than 78 (n = 40). The pattern of results was the same. There was a statistically significant effect for . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. While based on a rough classification, this analysis was useful to explore the potential impact of the country's onset of the virus on our findings. The Group A countries significantly tend to be classified in lower growth group compared to Groups B and C countries (as a single group) with all the 68 countries with known BCG policy (Figure 3b ; Chi-squared test: p = 0.0002; B and C groups were combined for this test). As in the linear regression models, given that life expectancy may affect growth rate, we also conducted a Chi-squared test after excluding the countries that had a shorter life expectancy (≤78 years old, n = 40), and found that the difference remained significant after the exclusion (Figure 3c ; Chi-squared test: p < 0.0001; B and C groups were combined for this test), where pvalue became even smaller adjusting life expectancy despite the decrease of sample number. Both the analyses thus showed that Group A countries tended to exhibit a . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint lower growth rate compared to Groups B and C countries regardless of their life expectancy. Associations of BCG policy with COVID-19 after controlling two major confounding factors In this study, we have shown that the countries that currently adopt universal BCG vaccination programs (Group A) have, compared to the other countries, a lower number of cases and deaths per one million people. The countries that no longer recommend BCG vaccination for everyone (Group B) and those that have never had universal BCG vaccination programs (Group C) reports more cases and deaths. We have also evaluated the impact of two potentially confounding factors, the country's life expectancy and the average temperature in February and March 2020. Crucially, the effects of BCG groups on the two dependent variables remain significant, even when the country's life expectancy and temperature are controlled for. The amount of variance explained by BCG vaccination is about 12.50% and 20% for cases and deaths per one million population, respectively. The percentage of explained variance is greatly increased when only countries with a life expectancy above 78 years are considered (about 20% and 38% for cases and deaths, respectively). Also, only Group C appears to play a role in the deaths/cases ratio and explains little more than 3% of the observed variance. This latter result may suggest that, unlike cases and deaths per one million population, the death rate is weakly affected by the type of BCG vaccination policy adopted by the country. We thus hypothesize that the protective effect of the vaccine, if any, may consist of a significant reduction of the spread of the virus rather than a reduced mortality rate. It is also possible that the vaccine prevents progression of the disease after infection, since only the persons with severe symptoms tend to be able to receive PCR tests in many of the countries at present. This hypothesis requires additional empirical corroboration. Finally, in line with the results of the linear regression analysis, the Chi-squared analyses highlight that BCG vaccination policy appears to affect how quickly this virus spreads. Taken together, these results suggest that the overall impact of BCG vaccination on the COVID-19related cases and deaths is, at the very least, non-negligible and worth of further empirical investigation. . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint We have reported that a large part of the variance in the two dependent variables is explained by life expectancy, while the effect of temperature seems to be marginal at best. This is not surprising, considering the fact that age is a major risk factor in COVID-19 18, 19 . Life expectancy is highly correlated with the income level of individuals 20 and countries 21 , which would also be related to the quality of medical care that people can receive. If life expectancy is controlled, higher income and quality of medical care may decrease the risk and mortality of diseases in general, which is expected to decrease the positive effect of life expectancy on the risks in COVID-19. Considering the highly significant contribution of life expectancy on the risks, we could consider that the income level or the quality of medical care cannot be the confounding factor that explains the association between BCG vaccination and the risks in COVID-19. Regarding the tight relationships between age and mortality in COVID-19 18, 19 , BCG protection may wane with time since vaccination 22 , and it could be potentially contributing to the higher mortality in aged populations to some extent. These possibilities need to be examined by further analyses. As seen, the average temperature in countries exhibits a small and sometimes even non-significant negative correlation with the risks of COVID-19 infection and mortality. That said, we have not assessed the effect of humidity, which we plan to do in the near future, since absolute humidity is considered to be associated with influenza infection 23,24 . However, it is unlikely that absolute humidity significantly affects the results. In fact, absolute humidity does not seem to play any major role in the transmission rates of the COVID-19 25 . Moreover, absolute humidity and temperature are usually highly correlated, and it is thus unlikely that humidity may play a major role in explaining the spread of the COVID-19 if the temperature does not. We are still in the midst of the pandemic, during which the virus keeps spreading in most of the countries (except for China, where the rise has nearly been stopped). Also, the role of the observed between-country differences concerning the date of the spread of the COVID-19 is still unclear. In brief, the current state of affairs might change quickly and, therefore, our findings should be interpreted with caution. That being said, we have found a highly significant difference among the BCG groups of the slope of increase of the cases in log scale, that is, adjusted by the . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. Potential mechanisms BCG, originally developed against tuberculosis, is hypothesized to develop 'frontline' immunity, training it to respond non-specifically to certain viruses with greater intensity 7, 3, 4 . This idea is supported by clinical and epidemiological studies, which showed that BCG appeared to lower overall mortality in children 5,2,6 . BCG, which can remain alive in the human skin for several months, triggers not only specific memory B and T cells, but also stimulates the innate blood cells for a prolonged period 7 . In a randomized placebo-controlled study, it was shown that author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint policies, and culture/life style (e.g., shaking hands and hugging, wearing masks, and washing hands). Some of these elements might affect the observed relationships between COVID-19 indices and BCG vaccination policy by affecting both the susceptibility to SARS-CoV-2 and BCG vaccination policy in an indirect manner. These and other factors need to be examined in future studies (or even before formal publication of this manuscript in a journal with peer review; see ""production note"" below). As outlined above, we have employed a rough classification for the statistical test for the relationship between BCG groups and the growth curve of COVID-19 in each country with a limited number of observations ( Figure 3a) . Obviously, it would be preferable to use continuous data to produce a more accurate estimation of the impact of BCG vaccination policy on how quickly the virus spreads. Also, examining variables such as BCG strain 26 and the timing and the number of vaccinations (including the ones for other diseases) would be worth some attention. These variables might be easier to be examined in those countries where mandatory BCG vaccination was terminated by investigating the history of vaccination of COVID-19 patients and their symptoms and condition severity. In our study, we used the data that are publicly available from several websites (see Method and results section), which have not been validated by any official institutions (to the best of our knowledge). Therefore, further analyses are recommendable once the data's reliability has been certified. It may also be worth looking into the relationship between the age of BCG vaccination and the risk of infection and severity /mortality in COVID-19 patients 18, 19 . An SNP in IL-1b (IL1B; rs16944) was found to affect the trained immunity response induced by BCG 7 , and it is of interest to evaluate the association of this SNP and the protective effect of BCG vaccine against SARS-CoV-2. We thank Yoko Kagami, and Harumi Mitsuya for their assistance in inputting the data and making Figures, Mamoru Tejima for letting us know the existence of potential correlation, and Hideo Hagihara, Tomoyuki Murano, Hironori Funabiki and Shinichi Nakagawa for useful discussions. We also thank Tomoko Tatsumi for helping us drafting the R codes. The authors declare that there is no conflict of interest regarding the publication of this article. We welcome the contributions from readers of any data related to variables of interest (including potentially confounding factors), which might be considered as a collaboration. It is preferable that data contributed be sorted by country name and in excel format (as in our dataset; See Supplementary Table 1 ). Using the same naming convention for the name of the countries as those in supplementary table 1 is also helpful for us to carry out analyses quickly. The data we'd like to add to the excel file includes, but not limited to, When you provide us data, specify where you obtained data so that we can confirm the data. We look forward to collaborating with you in this war against COVID-19. . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . Shaman . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint Figure 2 : Effect of BCG vaccination policy on COVID-19 a. The boxplot of total cases per one million population sorted by BCG Group in countries with life expectancy higher than 78 years. Groups B and C (no current BCG vaccination) show a significantly higher rate of cases of COVID-19 compared to Group A (countries currently implementing BCG vaccination). Groups B and C (no current BCG vaccination) show a significantly (p = .0024 and p = .0326) higher rate of cases of COVID-19 compared to Group A (countries currently implementing BCG vaccination). b. The boxplot of total deaths per one million population sorted by BCG Group in countries with life expectancy higher than 78 years. Groups B and C (no current BCG vaccination) show a significantly higher rate of cases of COVID-19 compared to Group A (countries currently implementing BCG vaccination). Groups B and C (no current BCG vaccination) show a significantly (p = .0011 and p < .0001) higher rate of deaths from COVID-19 compared to Group A (countries currently implementing BCG vaccination). . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint Figure 3 : BCG vaccination policy and COVID-19 growth rate a. Categorial classification of growth rate of cases in 70 countries. A, B, or C designates BCG group and l, m, or h designates low, middle or high growth rate. ""?"" indicates that information is lacking. Countries marked by asterisk have average life expectancy below 78 years. b. Table for 68 countries on BCG vaccination groups and growth rate. c. Table for 40 countries on BCG vaccination groups and growth rate, by excluding the countries whose life expectancy is below 78 years.@story_separate@The present study reports significant associations of BCG vaccination with prevalence and mortality from COVID-19 in 136 countries, even when the country's life expectancy and average temperature are controlled for. Together with the previous studies showing potential non-specific protection of BCG, we believe that further studies examining this hypothesis are warranted. In countries with no mandatory BCG vaccination at present, policymakers involved in health service . CC-BY 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20048165 doi: medRxiv preprint may consider, with careful evaluation of its safety, increasing/implementing BCG vaccination during this outbreak of COVID-19, at least for the categories of people who are currently receiving the vaccination in other countries.","There is some evidence that tuberculosis vaccine bacillus Calmette-Guérin (BCG) has non-specific beneficial effects against non-related infections. Here, we examined the possible association between BCG vaccination with prevalence and mortality by COVID-19 by using publicly available data of COVID-19 in 199 countries/regions and the BCG World Atlas. By using linear regression modeling, we found that the number of total cases and deaths per one million population were significantly associated with the country's policy concerning BCG vaccine administration. The amount of variance in cases and deaths explained by BCG vaccination policy ranged between 12.5% and 38%. Importantly, this effect remained significant after controlling for the country's life expectancy and the average temperature in February and March 2020, which themselves are significantly correlated with the cases and deaths indices, respectively. By contrast, the ratio between deaths and cases was weakly affected. This latter outcome suggested that BCG vaccination may have hindered the overall spread of the virus or progression of the disease rather than reducing mortality rates (i.e., deaths/cases ratio). Finally, by roughly dividing countries into three categories showing high, middle, or low growth rate of the cases, we found a highly significant difference between the slope categories among the BCG groups, suggesting that the time since the onset of the spread of the virus was not a major confounding factor. While this study potentially suffers from a number of unknown confounding factors, these associations support the idea that BCG vaccination may provide protection against SARS-CoV-2, which, together with its proven safety, encourages consideration of further detailed epidemiological studies, large-scale clinical trials on the efficacy of this vaccine on COVID-19, and/or re-introduction of BCG vaccination practice in the countries which are currently devoid of the practice."
"At the current rates of warming, the world is likely to reach 1.5 • C above pre-industrial levels between 2030 and 2052 [1] . A rapidly changing climate is expected to exacerbate risks to human health [2] through direct (e.g., extreme heat), indirect, or ecosystem-mediated (e.g., malnutrition, or vector-borne disease risk), and socially-mediated (e.g., displacement) pathways [3] . This complexity of pathways makes difficult the attribution of health outcomes to climate change [4] and therefore can make actions challenging to develop and implement. The magnitude of climate-driven health impacts depends on the climate adaptation and mitigation actions taken now. Such actions must reflect a systems-based understanding of how the health and other sectors affect climate-driven health effects. Unless policy actions reflect this understanding, efforts to improve and sustain health will be undermined. The relationship between climate change and health and well-being can be non-linear and involve time delays and feedbacks [5, 6] . These complex, dynamic interactions can lead to health and well-being outcomes which are hard to predict and lead to unintended consequences. This calls for a systems approach [7] [8] [9] to address climate change and health together [10] . Systems thinking brings a coherent approach to inform climate change actions by requiring a consistent, rigorous evaluation for every proposed mitigation or adaptation action, including the impacts, tradeoffs of, and unintended effects on both health and climate especially on vulnerable and marginalized groups. There are several reasons why this approach adds practical value for informing needed actions on climate mitigation, adaptation and health. First, the use of a systemic approach can help clarify causal relationships including direct and indirect pathways between climate change and health, the strength of the relationships, which groups are differentially impacted and why, and any feedback loops which can affect these relationships in positive and negative ways. Second, this understanding helps to identify actions to prevent or reduce harm to both climate and health without ultimately undermining health due to unrecognized tradeoffs or unintended side effects. Third, a systems approach can help identify intervention points that target upstream anthropogenic drivers of health and well-being as well as their social and economic determinants rather than focus solely on the symptoms of health problems (Box 1). At a time when resources are limited and climate policy ambitions are flagging, country actions should aim to meet multiple objectives at the same time, so addressing health and its climate-related drivers together makes sense. For example, because of their common causes, integrated, cross-sectoral action tackling climate change and air pollution can provide significant benefits in reducing health risks in the near term at the local level [11] , mitigating climate change and potentially increasing energy savings [12] . Such multiple benefits-based policies can be opportunities to maximize efficiencies and increase the effectiveness of investments to ""ensure health and well-being"" (United Nations Sustainable Development Goal (SDG) 3) and ""take urgent action to combat climate change"" (SDG 13). Box 1. Developing a systems-based understanding of climate-driven health challenges and actions to address them. Business as usual: • What are the two-way effects (positive and negative) between climate and health? What is the magnitude of the effects? This commentary article describes how a systems approach to climate and health underpins the three key elements needed for effective health and non-health collaboration and actions to address the climate and health nexus: understanding multisectoral impacts of human-driven climate change, assessment of climate and health benefits and costs of policies, and skills for working cross-sectorally to share information and coordinate policy actions. The following sections describe the use of existing tools, assessment processes and strategic framing which could be used in complementary ways to apply a systems-based approach to support climate and health actions. The content is derived from selected examples and our collective country experiences but without a comprehensive literature review.@story_separate@Climate and health actions require cross-sector collaboration through shared understanding of the impacts of climate change on health and other sectors as well as the application of this understanding to inform assessments (e.g., health impact, vulnerability, cost-effectiveness/cost-benefit) which can in turn inform strategic climate and health actions. Building shared understanding of climate change and health can be facilitated through the use of human health indicators [13] . For example, this can begin with a shared understanding of climate-health relationships involving direct and indirect pathways (including socially-mediated pathways), within a framework and methods for the identification of indicators (e.g., Causal Loop Diagrams, based on Systems Thinking [14] which cover the spectrum of problem identification, setting problem solving objectives, development, implementation, and evaluation of interventions. The Lancet Countdown on health and climate change [15] identifies relevant indicators updated annually across climate change impacts on health, risk exposures, vulnerability factors, adaptation, planning, and resilience; mitigation and health co-benefits; economics; and, political engagement. As has been noted, climate and health indicators that more explicitly integrate environmental sustainability and development are needed to achieve the SDG targets [16] . Systems Thinking is already used in the health sector, supporting a variety of public health issues (see for instance [17, 18] ). Systems Thinking is also used in other sectors, informing planning exercises in areas such as green economy, green growth, and climate adaptation [19] . Systems Thinking brings the advantage of helping to clearly identify the dynamics underlying a system, which can then help identify effective interventions for positive impact. While most of the systems thinking and system dynamics applications available to date are customized and applied in niche planning processes, this article presents the opportunity to build on and extend previous systems-based work to integrate health more explicitly in projects and policy assessments on climate and health actions; and, to use systems thinking and systems dynamics more extensively beginning with a baseline systems understanding of climate and health (Box 1). This understanding takes into account the drivers affecting the climate-health relationship including feedbacks, tradeoffs and unintended side effects across multiple sectors. Addressing these systems questions can help identify interventions to benefit climate and health while at the same time reveal other issues that should be addressed in designing solutions which can benefit all key stakeholders involved (i.e., equity). As such, this systems understanding of climate and health should underpin the use of key tools like Health Impact Assessment (HIA). Using a systems-based understanding of climate-driven health challenges as described in Box 1, HIA can be an important tool to identify, and make recommendations on, actions which benefit both climate and health. HIA is a tool which when used early in the development stage of a project or policy process helps identify likely health impacts. HIA features broad stakeholder engagement and reducing social disparities, paying special attention to the health impacts on vulnerable groups and how they may be affected [20] . In addition to quantitative data, the HIA process incorporates qualitative information which can help characterize pathways of health risk vulnerability. HIA results in evidence-based recommendations to prevent and control health risks and/or promote any health benefits. HIA can also be conducted during policy implementation and for evaluation. As the understanding of the complex and dynamic relationship between climate and health continues to grow, the prospective HIA process presents a promising opportunity for applying an updated systems-based understanding of climate and health, integrating information across disciplines and sectors, with relevant indicators in order to help identify climate-driven impacts, tradeoffs of, and unintended effects on, health. Such an understanding should inform actions needed now to address climate and health. For example, the HIA's scoping stage, where relevant health impacts are identified, could set the spatial and temporal boundaries of a climate-associated health concern. For example, concerns about air pollution would consider local and urban-rural (ground-level ozone, PM 2.5 ), country-wide (PM 2.5 ), and transboundary (PM 2.5 ) scale effects which could in turn inform potential climate mitigation actions and take into account the groups most vulnerable to exposure-children, women, the elderly, outdoor workers, those with chronic respiratory conditions, and people living in poverty [21] . Such an HIA could result in recommendations on mitigation actions which target the common cause of both climate change and short-lived air pollutants such as ground-level ozone-a missed opportunity for nearer-term realization of health benefits locally (see [11] ). HIA can identify likely health impacts of projects and inform health systems responses. HIA of the Don Sahong Hydropower Project in Lao People's Democratic Republic (PDR) identified a greater risk of dengue due to greater availability of Aedes aegypti mosquito breeding sites created by land disturbance associated with the project [22] . Dengue mortality is already on the increase [23] in the Asia Pacific region, and by 2030, climate change is estimated to contribute to shifts in the geographic range of dengue-transmitting mosquitoes [24] . These geographic, spatial scale and time estimates should inform a full HIA so as to inform health systems planning, prevention and control of infectious diseases among the most vulnerable-children, pregnant women, the elderly, and those with limited access to health services [25] . In addition to risk assessment, HIA should be used to inform the design and scale of climate and health adaptation actions including green infrastructure-based strategies. For example, local leaders in the state of Georgia in the United States applied HIA to a green street project which was aimed at reducing stormwater runoff and flooding. The HIA resulted in the city's decision to increase the scale of the green street project by threefold in order to capture the health benefits of walkability and reduced heat island effect [26] . Similarly, to reduce the intensity of urban heat islands (UHI) in megacities in the Asia region, HIA should guide the design and implementation of climate adaptation actions across different physical contexts given that UHI intensity varies by extent of economic activity, city geographic size, amount of built up area density, and season [27] . HIA could inform how interventions, such as greenspace and green walls, could be effective in reducing surface temperature [28] and importantly, the appropriately scaled site of implementation (e.g., urban street canyon, building, and neighborhood). Moreover, such strategies could be modeled to estimate UHI health impacts when implemented, singly or in combination with other sectoral approaches (e.g., energy efficiency, urban forestry, and low carbon transport). Across the Association of Southeast Asian Nations (ASEAN) region, HIA is being used to support sustainable development based on the recognition that health is a cross-cutting issue amidst rapid economic integration. HIA has been included in the Environmental Impact Assessment of projects in Lao PDR, Cambodia and Malaysia. HIA has been codified in national governance [29] and is a shared priority for regional action with progress regularly reported [30] . In the environmental health context, Thailand is the lead ASEAN country focal point on HIA. Through the development of a HIA practitioners' training manual, Thailand is developing and promoting HIA to strengthen capacity at country level across the region. To this end, the ASEAN Environmental Health and HIA Network was established to share performance indicators and best practice [31] . The next phase of HIA work in the region is to implement improved knowledge sharing mechanisms (e.g., curricula) to reach the broad range of HIA stakeholders-the public and private sectors, academia, and civil society. Quantified health impacts can facilitate collaboration between health and other sectors on climate and health. A healthy human capital base is fundamental to sustaining economic growth and development [32] . Improved understanding of health impacts, positive and negative, of climate policies is necessary to include in decision making on strategies to achieve climate and health goals. A systems-based understanding of climate-health relationships and HIA can inform the estimation of health impacts and associated costs calculated in terms of health care treatment, lost work productivity, and GDP [33] Quantification of the costs and benefits to health associated with action and inaction can support priority-setting and selecting among climate-health actions under consideration. Health risks that are identified could be managed proactively through preventive measures which include increasing awareness of climate change-health relationships among the health workforce; improved health information systems for integrated risk monitoring and early warning; and greater financing [34] . Quantification of health and environmental impacts can support policymaking by providing economic bottom line estimates for costing of climate actions and informing cost-effectiveness analyses of policies for achieving climate and health objectives. In fact, the quantification of health impacts can serve two purposes: it highlights the economic cost of side effects, originating from policies and projects that do not take into account health outcomes; and, it highlights the extent to which climate adaptation and mitigation projects can reduce and avoid health costs. The quantification of these two impacts and related economic valuation can inform decision making by estimating the net societal value of a given project, equally weighing benefits and avoided costs. This will make it more difficult, and certainly undesirable, to ignore the role of human health in project conceptualization and policy formulation. The potential health benefits of climate actions as expressed in avoided/reduced costs to economic and social development could make policy actions and projects more financially viable to investors, or attract different investors, those vulnerable to the impacts often unaccounted for, in both the private and public sectors. Quantification of climate and health effects depends on the strength of their causal relationship. While attribution can be complicated, there are climate and health relationships that have been studied with high confidence [see3]. Quantified health effects could significantly increase visibility of climate change-health issues for the finance sector as well as for the public interest. This could be key to facilitating greater cooperation between health, environment, finance and other sectors. Several analyses have shown the economic rationale for taking climate actions including for health cost savings. Climate mitigation efforts to meet the Paris Agreement in transport and power generation which reduce air pollution could exceed the costs of implementation by a factor of 1.4 to 2.45 in China and India, respectively, with savings of trillions of dollars in worker productivity and health care expenses globally [35] . Interventions of transport mode shifts which facilitate physical activity and healthier lifestyles could lead to even greater cost savings associated with noncommunicable diseases [36] . An evaluation of a market based regulatory program to reduce greenhouse gas emissions at the subregional level in the United States estimated cost savings of avoided adverse children's health outcomes related to annual average secondary PM 2.5 reduction in the range of $191 to $350 million between 2009 and 2014 [37] . Reducing deforestation can have potential health as well as climate mitigation benefits. It can limit the emergence of zoonotic diseases such as severe acute respiratory syndrome (SARS) associated coronaviruses like SARS-CoV-2. Such measures can be taken at a cost that is significant orders of magnitude less than the costs that COVID-19 disease has already imposed in morbidity, mortality, and loss of GDP while producing social benefits from reduced greenhouse gas emissions [38] . There are many methodologies for estimating the health benefits of actions taken in non-health sectors, and they may also include associated economic cost savings and damages [39] [40] [41] . However, there are important differences when quantifying the health benefits of climate mitigation or adaptation which can complicate generalizations about health impacts and associated economic costs. Notable considerations in estimated quantified costs associated with health impacts include methodological differences in the type of health outcome measured; how the health outcome is quantified; assumptions made about the risk exposure-health response function; uncertainties about confounding factors; the spatial and temporal scales considered; and, the specific policy scenarios modeled [42] . Together with the use of health indicators, HIA, and health quantification, strategic framing of climate and health can further support how a systems-based approach can be applied to climate and health actions. The SDGs are a strong global framework for identifying strategies which exploit synergies between climate change and health related SDGs [43] . By taking advantage of countries' flexibility in the means of implementation to achieve the SDGs, there are opportunities to build on the SDGs commitment to identify health and non-health sector strategies to reach targets in an integrated way [44] -specifically, improving health by addressing its upstream human-driven environmental drivers. For example, using clean energy for household cooking is a good public health intervention to reduce indoor air pollution (SDG 3) while providing access to other forms of energy (SDG 7). There is a gap between recognition of climate-health relationships and policy action to address them. In a review on health in the Nationally Determined Contributions (NDCs) [45] , 86 of the assessed 184 countries recognized the impacts of climate change on health (especially vector-and water-borne diseases as well as food security), but only 10 countries out of 184 included evidence or policies on climate change's impacts on health in their NDCs, and only 3% of NDCs highlighted the health benefits of climate actions. When resources are limited, policy actions should aim to meet multiple objectives especially when the objectives are mutually reinforcing. In addition to the SDGs and the Paris Agreement, other country level commitments or frameworks should be built upon to maximize efficiencies in achieving climate and health goals at the same time. These include the Health in All Policies (HiAP) country framework and Universal Health Coverage (UHC). With the premise that health is affected by all public policies, the Health in All Policies (HiAP) country framework highlights multisectoral collaboration to improve health and health equity [46] . Strategic coordination of health and other sectors affecting health could result in actions which achieve efficiencies in energy use, climate change, and health together, with significant cost savings [47] . Our proposed systems-based approach to climate and health involves the health sector working with other sectors which influence health. Integrating health, climate change and social determinants of health is necessary to achieve health goals in a more holistic and equitable way by targeting environmental drivers and social determinants so as not to ultimately undermine health. Collaboration between health and other sectors can be facilitated by the HIA tool and HiAP framework, underpinned by a systems-based understanding which should appreciate the depth of knowledge and experience of partners working in non-health sectors. Capacity development among health and non-health sectors on climate-health understanding and methods for cross-sector engagement should be strengthened. Given the urgency to act on climate change, especially with a health lens, policymakers should take advantage of HiAP's principles of cross sector collaboration on country-led climate actions. A systems approach brings coherence to building understanding of climate change and health relationships and applying that understanding to policy actions which benefit both climate and health while minimizing adverse tradeoffs and unintended side effects including disproportionate impacts on vulnerable groups which may have gone unrecognized without such an approach. At a minimum, the systems approach can help to highlight these issues so that they can be addressed early. Achieving UHC is one of the primary policy goals of the World Health Organization [48] . However, many regions of the world with the highest vulnerability to climate change are also those with the lowest levels of UHC coverage [49] . UHC cannot be achieved without addressing climate change because population health is affected by climate change, and the health system itself contributes to climate change, responsible for 4.4% of global carbon emissions [50] . Climate-driven health outcomes should be included in the essential health services coverage by way of workforce training on climate-health relationships, financing, and increasing resilience of health care service delivery which may be disrupted during climate related events (e.g., storms, and flooding). These can bolster UHC to more effectively address context-specific climate driven health effects which are already being experienced and which are expected to worsen over time. In addition to the project-level HIA, the National Health Adaptation Plan (NHAP) (see [13] ) should be developed and used to directly inform climate adaptation policies. The NHAP is intended to integrate health in adaptation planning by identifying vulnerabilities in the health system as well as opportunities to increase the resilience of health systems to climate change. Having in place an NHAP is an indicator of a country's readiness to identify and respond to climateassociated health events (see [23] ). The World Health Organization identified vulnerability and adaptation assessment as one of the key components of a country level operational framework for climate resilient health systems (see [34] ). In the climate and health context, a systems-based HIA can take the form of vulnerability and adaptation assessment [51] that is designed to build a baseline understanding of climate and health (Box 1) so as to use that understanding to inform interventions to reduce climate-driven health risks. In addition to assessing current vulnerabilities and impacts on health, the systems-based HIA process should consider the vulnerability of other sectors (e.g., food) and the health impacts of that vulnerability [ibid] . HIA, updated to incorporate a systems-based understanding of climate and health can address risk factors of vulnerable groups as well as the capacity of the people, institutions and resources of existing health systems to prepare for and adapt to climate-driven health challenges. Because NHAP and HIA both prioritize cross-sector cooperation and reducing health inequities, they are consistent with, and therefore should be used to advance the implementation of, the country's HiAP goals. A systems-based understanding of climate change and health-i.e., the human drivers affecting their relationship including feedbacks, tradeoffs, and unintended side effects across societal, environmental, and economic domains-can help identify interventions to benefit climate and health while at the same time reveal other issues that should be addressed in designing solutions to benefit all key stakeholders involved. For example in 2015, approximately 100,000 deaths across Singapore, Malaysia, and Indonesia were attributed to fires which were set to clear peatlands for palm oil production ( Figure 1) . 2015 was an El Nino year which created drought conditions, and with the drier conditions, peat provided abundant fuel. The fires burned more intensely and for a longer period of time, releasing significant carbon emissions as well as harmful health pollutants such as fine particulate matter which moved downwind towards population centers [52, 53] . The estimated adult mortality (and health care costs) associated with specific fire events justify the need for peatlands protection and enforcement of fire prevention. To date, combined efforts to restore peatlands and rewet degraded peatlands have been missed opportunities to prevent the further release of locked-up carbon and to enhance the function of peatlands as important carbon sinks, contributing to climate mitigation efforts globally [54] . Notably, the benefits and costs of peatland protection are not equally borne. Farmers' livelihoods must be considered [55] as part of such potential nature-based solutions possibly through payment for ecosystem services, subsidies, and other incentives. Legend: As described by Sterman [56] , causal loop diagrams (CLDs) include variables and arrows (called causal links), with the latter linking the variables together with a sign (either + or −) on each link, indicating a positive or negative causal relation (see Box 1) . A causal link from variable A to variable B is positive if a change in A produces a change in B in the same direction. A causal link from variable A to variable B is negative if a change in A produces a change in B in the opposite direction. Circular causal relations between variables form causal, or feedback, loops. There are two types of feedback loops: reinforcing (R) and balancing (B). The former can be found when an intervention in the system triggers other changes that amplify the effect of that intervention, thus reinforcing it [57] . The latter, balancing loops, tend towards a goal or equilibrium, balancing the forces in the system [ibid]. Nature-based solutions are an emerging area of research which has the potential to both improve health and reduce greenhouse gas emissions. For example, forests not only support water filtration [58] but also provide wild foods which contribute to dietary diversity [59, 60] . Conserving forest cover in close proximity to communities was associated with approximately 7% reduced stunting in young children across 25 low-and middleincome countries, comparable to the median effect of traditional interventions such as providing micronutrient supplements and food fortification [61] . The quantified potential of forest conservation as a public health intervention in rural areas could capitalize on high population coverage due to the large numbers of nutrition insecure groups who live there, suggesting that health nutritionists and conservation practitioners could collaborate to include protecting forest cover as part of the toolbox of interventions to improve the health of vulnerable populations while also maintaining forests' carbon sink role. In addition to identifying interventions to address the climate-health nexus, a systemsbased understanding can help to highlight disproportionate health impacts on vulnerable populations, amid the variation in types of predominant health impacts of climate change within and across countries and regions [62] . Within a given geography, climate-driven health effects will vary by equity aspects related to age, gender, income, livelihoods, and capacity to successfully address them [63] . Projects must be responsive to community needs, and climate actions must be context-specific for there to be successful implementation. These can be achieved through an inclusive approach to building a systems-based understanding of climate change and health to help identify disproportionately affected groups and how they could be impacted over time. For example, a systemic approach applied to a large infrastructure investment for hydropower in Cambodia revealed that local populations in the northern provinces of the country would be affected both positively and negatively by the project. Positive outcomes included improved access to education and health, via the construction of roads and new facilities. On the other hand, there were estimates of reduced access to resources, such as water and fish, possibly leading to poorer nutrition and negative impact on livelihoods [64, 65] . The relationship between climate and health is not trivial, especially for investors. Climate change cannot be predicted with certainty, which reduces the interest of private investors in climate adaptation due to the lack of a revenue stream or a clear trend of avoided costs. On the other hand, the cost of climate adaptation is too high for most governments which already struggle to maintain operational existing infrastructure, especially in low and middle-income countries [66] . As a result, in order to invest in an area with high financial risk, but with the potential to generate benefits across a multitude of economic actors, a new approach to financing is required. Such an approach has to combine the ""high risk-high reward"" perspective of private investors with the need to provide basic services (often not economically viable) by governments and donors. There are innovative financing tools which can complement public funds and public sector strategies (e.g., taxes, and loans) to address climate and health actions. For example, parametric or index-based insurance instruments can support climate adaptation in the health sector by reducing the impacts of extreme weather events on health and also increasing funding for health-related assets. This type of insurance monetizes climate risks and therefore can increase the financial viability of investments aimed at reducing these risks. Index-based insurance offers payouts even when there is no physical damage, when a pre-determined set of parameters such as weather conditions of a certain type and severity occur [67] . Payouts are made relatively quickly, as compared with traditional insurance, to fund emergency responses as well as for investments to improve climate resilience. For example, to address food security regularly threatened by drought, Mauritania was one of the earliest purchasers of parametric insurance through which it was given an estimated premium of US$ 1,394,000 for a total guaranteed cover of US$ 9,000,000 for the agricultural season from July through November 2014. After the next drought, Mauritania was eligible for a payment of approximately US$ 6,326,000 which was paid out in January 2015. The Mauritanian government used the quickly distributed funds to reduce the impact of drought and to protect livelihoods by providing 50,000 vulnerable households with 50 kg of rice and 4 L of oil each over 4 months. These measures also reduced stress-driven migration and the distressed sale of livestock [ibid] . In this way, parametric insurance could be an important tool to incentivize resilience planning as part of a proactive preventive approach to health system preparedness for climate adaptation especially in high-risk areas. The tool is flexible enough to adapt to local needs and context by modifying the specific climate parameters that trigger payment. A systems-based understanding of climate change and health is critical across all stages of the policy or project process-from problem conceptualization, design to implementation, and evaluation. This has important implications for the development of policies as well as project proposals aimed at the climate and health nexus. Achieving a shared understanding on the central role that human health plays in dynamics triggered by climate change and their socio/economic consequences is not trivial. We are surrounded by complexity, driven by the growing interconnection of social, economic and environmental dynamics of change. Regardless of how challenging it may be, our capacity to plan must adapt to such growing complexity if we want to maximize the societal value of investments, increase economic resilience and achieve national and global development targets (e.g., SDGs). We have the knowledge and tools to tackle such complexity. Communication and knowledge integration are of critical importance. We have developed great depth of knowledge on health and climate change, and in many other related fields. Experts must come together, using a multi-disciplinary and multistakeholder approach, because no one has all of the knowledge required, and communicate about the critical interrelationships between climate and health. When this integration takes place, especially in the context of project development and policy formulation, the complexity can be greatly reduced. Systems thinking is a method that aims to simplify complexity and bring a coherent approach to inform climate change actions by requiring a consistent, rigorous evaluation for every proposed mitigation or adaptation action, including the impacts, tradeoffs of, and unintended effects on, both health and climate especially on vulnerable and marginalized groups. Box 1 summarized how systems thinking can support understanding of climate change-health relationships and identifying actions based on that understanding. A systems-based approach brings practical value to addressing the climate-health nexus because it can help clarify causal relationships, the strength of the relationships, which groups are differently impacted and why, and any feedback loops which can affect these relationships in positive and negative ways. Importantly, for identifying intervention actions, a systems-based approach can help to prevent or reduce harm to both climate and health without undermining health due to unrecognized tradeoffs or unintended side effects. In the COVID-19 recovery period, the use of relatively limited resources should be maximized to achieve interrelated economic, environmental and health goals concurrently. Actions which benefit both climate and health are opportunities to maximize efficiencies, by reducing costs and generating new benefits. This increases the financial viability of investments, especially from a societal perspective, where a single investment may result in several beneficiaries across sectors, and over time. To apply systems thinking for climate and health actions, cross-sector collaboration between health and non-health sectors is a key element. This can be facilitated through the complementary use of existing tools, assessment processes and strategic framing of climate and health actions to meet related country and global commitments. Within countries charged with developing climate actions as well as the organizations (e.g., funders, and accredited entities) which support them, the systems-based approach must be the common starting point. Donors should require a systems-based assessment in project proposals. Specifically, funders such as The Green Climate Fund (GCF) should require health in all climate mitigation and adaptation projects, making clear how health plays a role in the dynamic interplay across economic, environmental and societal domains. Donors, bilateral and multilateral development banks, as well as governments should mandate the use of HIA. For country climate adaptation and mitigation project developers, HIA should be used as a good governance tool. As the scientific study on climate change and health continues to advance, spatial scale and time relevant climate-health inter-relationships, feedbacks, and tradeoffs among health and non-health sectors need to be reflected in the HIA. This baseline understanding should then inform potential climate mitigation/adaptation interventions which minimize adverse effects especially on vulnerable or marginalized groups. Further research is necessary to advance a systems-based approach to inform actions at the climate-health nexus. Practically, new research is required every time a systems approach is used because any given context is unique if we consider how social, economic, and environmental drivers of change interact with one another. Further, research is needed on specific topics to generate the evidence base that can be further tested, customized and validated during project conceptualization and policy formulation. For instance, we need an improved understanding of how climate change interacts with other environmental changes to affect health, given the potential for negative synergistic interactions [68] . Nature-based solutions is an area that is ripe for study [69] particularly for evaluating and quantifying the potential of actions to meet health objectives [70] . While research studies may not have been originally designed to demonstrate both health and climate benefits, their findings could inform potential nature-based solutions which could be implemented with field partners at the appropriate spatial scale and evaluated through implementation research [71] . Simulation models could be used to forecast outcomes across sectors and for many economic actors, strengthening development planning (see [19] ). Selection of targets and indicators relevant to health are key considerations for designing and measuring the effectiveness of climate mitigation and adaptation (see [44] ). Moreover, HIA recommendations should focus on the upstream human-driven environmental and social determinants of health so as to avoid the adverse effects to be borne by the most vulnerable groups and the costs of health externalities to be transferred to the health sector [72] . The mandatory use of HIA early in the climate mitigation/adaptation project development process can socialize the viability and sustainability of projects which include appropriate and measurable health indicators and avoided/reduced costs to economic and social development by recognizing health (see [22] ). From a more practical perspective, donors including the Green Climate Fund should request that project developers prepare a climate and health cost-benefit assessment for every proposed project. This is critical, especially for low and middle-income countries, to create value for money for public investments (see [66] ). Integrating health in all projects and in all policies will allow for maximizing the performance of several sectors and indicators of performance, simultaneously, as decisionmakers could recognize that their decisions may lead to extra health costs. This can be achieved by avoiding the emergence of future costs (e.g., via increased health care-related infrastructure resilience to climate change), and by creating additional benefits (e.g., via increased labor productivity). Practically, value for money for every investment improves if health is explicitly considered in the project planning stage. In this article, we propose a systems-based understanding as the basis for a coherent approach to climate and health-specifically, by using health impact assessment, quantification of climate-driven health impacts, and strategic framing in a complementary way to support climate and health actions. The content of this commentary article is derived from selected examples and our collective country experiences but without a comprehensive literature review. There is a need for more case studies which build on available systemsbased applications in health and other sectors which affect health. In addition, an extensive review of the literature may be helpful for providing more examples of how the HIA tool and HiAP framework could be used to apply the proposed systems-based understanding and to inform specific guidelines on actions which benefit climate and health.@story_separate@The health and environment sectors are impacted by policies made across sectors which can determine the health and well-being of people and the socio-ecological system on which it depends. A systems-based approach to climate and health can be operationalized by first understanding the systemic two-way health and well-being impacts of humandriven climate change; feedback loops triggered by climate-health relationships; how and why there are disparities in health and well-being impacts; and, which groups are the most vulnerable. This paper describes the value of, and how to apply, the systems-based approach to address the climate and health nexus. This does not begin with a blank slate. Already existing tools such as HIA can be used strategically to inform climate and health understanding and actions while also advancing the SDGs and prominent country goals such as Health in All Policies (HiAP), and strengthening health systems for Universal Health Coverage (UHC). Donors and project/country partners can play important roles to incentivize and support the development of science-based actions which reflect systems thinking. Quantified health impacts should be used in cost-effectiveness or cost-benefit assessments of policies, supporting the financial viability of climate actions and as a result attracting traditional and innovative financing instruments. At the same time, the strategic consideration of health in climate mitigation and adaptation strategies must be enabled by governance structures and the capacity to work cross-sectorally, as part of a continuing effort to improve the resilience of health systems. The strategic, practical steps described in this paper should serve as 2021 United Nations Climate Change Conference (COP-26) entry points for a more concrete process to take climate and health action.","Multiple sectors—health and non-health—can determine the health and well-being of people and the condition of the socio-ecological environment on which it depends. At the climate and human health nexus, a systems-based understanding of climate change and health should inform all stages of the policy process from problem conceptualization to design, implementation, and evaluation. Such an understanding should guide countries, their partners, and donors to incorporate health in strategic climate actions based on how health is affected by, and plays a role in, the dynamic interactions across economic, environmental, and societal domains. A systems-based approach to sustainable development has been widely promoted but operationalizing it for project level and policy development and implementation has not been well articulated. Such an approach is especially valuable for informing how to address climate change and health together through policy actions which can achieve multiple, mutually reinforcing goals. This commentary article describes strategic steps including the complementary use of health impact assessment, quantification of health impacts, and linking climate and health actions to national and global policy processes to apply a systems-based approach for developing climate mitigation and adaptation actions with human health benefits."
"Viral infections are the most frequent infectious diseases and are common triggers for constituting major health and socio-economic harms (Meo et al., 2020) . In late December 2019, an earlier named novel coronavirus (2019-nCoV), currently named as coronavirus (COVID-19) emerged from Wuhan, China, resulted in a challenging outbreaks in many regions in China and expanding globally. Human infections with coronavirus COVID-19 have raised great public health apprehension globally. In the third millennium, three major threatening infectious diseases outbreaks happened. Following the outbreak of SARS-CoV in 2002 (Zhong et al., 2003) and the MERS-CoV in 2012 , the novel Coronavirus ""COVID-19"" has emerged globally and has threatened the entire world. The coronaviruses are zoonotic infections, can be transmitted from animal to animal, animal to human, and human to human (Li et al., 2020; World Health Organization 2020) . The Covid-2019 first appeared in the last week of December 2019. The infection cases were originated from bats, snakes, seafood among people living in or visiting Wuhan, China and human-to-human transmission has also been confirmed (World Health Organization, 2020; Wang et al., 2020; Callaway and Cyranoski, 2020) . The biological and epidemiological trends in the prevalence and mortality rate are changing daily. Initially, China bears the large burden of the diseases, whereas the incidence is gradually increasing in other countries mainly the Europe and United States of America. Despite recent efforts to understand the novel Coronavirus COVID-19, the science community, researchers and general population would like more information about the current biological and epidemiological situations. This study aimed at investigating the mutable biological and epidemiological trends in the prevalence and mortality outbreaks of coronavirus COVID-19 infections.@story_separate@Scientific Information (ISI) Web of Science on the trends in the prevalence and mortality due to infection outbreaks. The results show rising trends in the transmission, prevalence and mortality rate due to coronavirus COVID-19. During the period of December 29, 2019 through March 31, 2020, it has infected 750890 people worldwide, resulting in 36405 deaths with a mortality rate of 4.84%. The infections were more frequent among male gender with above 60 years of age. The mean growth rate index for total number of cases from January 23 to March 31, 2020 was 1.20 and growth rate index for mortality rate was 1.12. There was a positive association between the prevalence and mortality rate (R 2 =0.996). The novel coronavirus COVID-19 is highly contagious and has affected a large number of people worldwide. It is still spreading with mutable prevalence and mortality outbreak trends. The global health officials have taken priority measures to prevent the further outbreaks of this emerging pathogen across the globe. However, the rising number of cases and mortality risk estimates are demonstrating that enhanced public health mediations, good hygienic conditions, social distancing and movement limitations may control the COVID-19 epidemics. Key Words: Biological trends, Coronavirus, Covid-2019, 2019-nCoV, Prevalence, Outbreak. This study was conducted in the Department of Physiology, College of Medicine, King Saud University, Riyadh, Saudi Arabia. We obtained data on biological and epidemiological trends, global number of confirmed cases, and number of deaths due to Coronavirus COVID-19 infections all around the world. The data were obtained from the World Health Organization (WHO), Centers for Disease Control and Prevention (CDC), and reports from various countries and their allied ministries to the WHO. We also obtained data from search engines including (Worldometer-Coronavirus). Moreover, we also reviewed the literature published in the Institute of Scientific Information (ISI) Web of Knowledge, Thomson Reuters, Pub-Med, Medline, and appropriate findings were recorded. We assessed the growth factor, a factor by which quantity multiplies itself over time; daily cases divided by cases on the previous day. A growth factor more than 1.0, indicates an increasing pattern, whereas values between 0-1.0 show a decline pattern (Worldometer-Coronavirus). In this study the information on the biological and epidemiological trends on global prevalence and mortality due to novel Coronavirus Covid-2019 infections was obtained from the World Health Organization, Worldometer-Coronavirus, the Centers for Disease Control and Prevention and reports from various countries and their allied ministries to the WHO; hence ethical approval was not required. The data were recorded and analyzed, and the results were expressed in numbers and percentages. The regression analysis was performed; and a p-value <0.05 was considered significant. These results are established from the available information at the time of publication originating from the mentioned sources. The data were interpreted with carefulness however, the outbreak is evolving rapidly and there is swift change in the numbers. The global number of cases and number of deaths due to novel coronavirus COVID-19 infection are presented in Table I (Table 1 ). In these contents COVID-19 highly effected the various countries including United States of America, Italy, France, Spain, Germany, Switzerland, and Iran ( Figure 1) . However, the highest mortality rate was found in Italy, Spain, United Kingdom, France and Iran ( Figure 5 ). The outbreak of novel coronavirus Covid-2019 started on December 29, 2019. The results shows rising trends in the transmission, prevalence and mortality rate due to coronavirus Covid-2019. In this study, we also analyzed the daily cases and death growth factors of the coronavirus Covid-2019. It was identified that during the January 22 to March 31, 2020 the growth factor of the number of cases worldwide was 0.28 to 6.96 (Mean 1.20) and the growth factor of death rates was 0.51 to 2.17 (Mean 1.12). There was a positive association between the prevalence and mortality rate (R 2 =0.996). It showed a mutable change in both the daily case growth factor and mortality rate (Figure 3 ). Coronavirus infection is an emerging global health concern and has infected a significant portion of the world's population. In this study, we investigated the biological and epidemiological trends in the prevalence and mortality due to outbreaks of novel coronavirus COVID-19 infection. The COVID-19 infection is expanding over 198 countries and territories, infected 750890 people, has caused 36405 (4.84%) deaths during the period December 29, 2019 to March 31, 2020 (Table I) . The coronavirus Covid-2019 infection is rapidly transmitted, the disease is still in its spreading phase with predictions of infection expand to over one people globally. We have derived the estimates of the ongoing COVID-19 epidemic and found that still the mean growth factor for number of cases and mortality rate is more than 1.0. It is highly contagious because of its biological characteristics (Meo et al., 2020) . It is a zoonotic disease with person-to-person transmission through droplet or contact transmission (Wu et al., 2019) . Infected people can transmit the disease before they present clinical symptoms (Rothe et al., 2020) . This is the main reason that the disease could swiftly spread from Wuhan, China to various corners of the globe. More recently, the epicenter of the diseases appears to have shifted from Wuhan, China to the European world and mainly Italy, and United States of America (World Health Organization, 2020). Many countries including China, Italy, Saudi Arabia, New Zealand, Poland, Ireland, Denmark, Spain, France have cancelled international flights and implemented the world's largest and most restrictive quarantines policies to minimize the further transmission and disease burden. For the prevention of the spread of the disease, these countries are not permitting people to enter or leave the country without strict screening of the passenger for Covid-2019 infection at airports. (Quilty et al., (2020) evaluated the usefulness of thermal passenger screening for COVID-19 infection at airports exit and entry points. The authors found that effectiveness of entry screening was dependent on the effectiveness of the exit screening at the destination. The authors identified that 46% of the infected travelers were not detected, because of the incubation period, and asymptomatic or subclinical cases (Chan et al., 2020) . (Quilty et al., 2020) also reported that airport screening is unlikely to detect a sufficient proportion of COVID-19 infected travelers. The screening is intended to be a barrier for preventing infected people from entering into the country; however, evidence of its effectiveness remains limited. These are reasons that health officials are still unable to control the spread of this contagious disease. The transmission of the disease is closely linked to the asymptomatic and infected people and those visiting the countries with COVID-19 pandemic. (Figure 4) . The disease is still spreading with mutable prevalence and mortality outbreak trends. Researchers Supporting Project Number (RSP-2019/47), King Saud University, Riyadh, Saudi Arabia. The authors declare that they have no conflict of interests.  Callaway, E., Cyranoski, D., 2020. @story_separate@The epidemiological trends show that novel coronavirus COVID-19 is highly contagious and has affected 750890 people, with a mortality rate of 4.84%. The number of cases were proportional to the number of deaths. There was a great fluctuation in the biological and epidemiological trends both in the growth factor of number of cases and the mortality rates. Global health officials have taken high priority measures to prevent the further outbreaks of this emerging pathogen across the globe, but still the coronavirus COVID-19 is swiftly spreading with mutable biological trends. The rising number of cases and mortality risk estimates are demonstrating the dire need for enhanced public health mediations, good hygienic conditions, social distancing and movement limitations to control the COVID-19 epidemics.","The novel coronavirus (Covid-19) infection outbreak has posed a major threat to international health system and economy. This study is aimed at investigating the biological and epidemiological trends in the prevalence and mortality due to outbreaks of novel coronavirus (COVID-19) infections. The data on the global outbreak of COVID-19, were obtained from World Health Organization (WHO), Worldometer, Centers for Disease Control and Prevention (CDC), and research institutes. The information was also recorded from research documents published in global scientific journals indexed in Pub Med and Institute of Scientific Information (ISI) Web of Science on the trends in the prevalence and mortality due to COVID-19 infection outbreaks. The results show rising trends in the transmission, prevalence and mortality rate due to coronavirus COVID-19. During the period of December 29, 2019 through March 31, 2020, it has infected 750890 people worldwide, resulting in 36405 deaths with a mortality rate of 4.84%. The infections were more frequent among male gender with above 60 years of age. The mean growth rate index for total number of cases from January 23 to March 31, 2020 was 1.20 and growth rate index for mortality rate was 1.12. There was a positive association between the prevalence and mortality rate (R(2)=0.996). The novel coronavirus COVID-19 is highly contagious and has affected a large number of people worldwide. It is still spreading with mutable prevalence and mortality outbreak trends. The global health officials have taken priority measures to prevent the further outbreaks of this emerging pathogen across the globe. However, the rising number of cases and mortality risk estimates are demonstrating that enhanced public health mediations, good hygienic conditions, social distancing and movement limitations may control the COVID-19 epidemics."
"The World Health Organisation (WHO) was alerted on the 31st of December 2019 by Chinese authorities of a series of pneumonia-like cases in the city of Wuhan [1] . The Chinese Centre for Disease Control and Prevention identified this infection as a novel coronavirus infection on Jan 7, 2020 and on Feb 11, 2020 , the WHO announced a new name for the pandemic disease as 2019-new coronavirus disease . Symptoms of the infection had included fever, malaise, dry cough, shortness of breath and respiratory distress [2] . Studies from Europe, China, and USA on COVID-19 have consistently shown that older age and comorbidity are major risk factors for adverse outcomes and mortality. Although most reported COVID-19 cases in China were mild (81%), approximately 80% of deaths had occurred among adults population older than 60 years of age; only one (0.1%) death had occurred in a person under 19 years of age [3] [4] [5] . J o u r n a l P r e -p r o o f 5 Data from MERS-CoV and SARS-CoV, indicate that infection in pregnancy tends to be severe and associated with adverse neonatal outcomes, including increased risk of miscarriage, fetal growth restriction, and preterm birth [6] [7] [8] [9] . Data from the UK [10] of more than 400 pregnant patients hospitalised with COVID-19 suggest an increased potential for adverse maternal outcomes in pregnant patients hospitalised with confirmed COVID-19 infection; while the risk of an intrauterine vertical transmission is inconclusive . Royal college of Obstetrics and Gynaecology recommends that delivery in COVID-19 patients should be determined primarily by obstetric indication and recommends against routine separation of affected mothers and their babies [11] . Our study aims to provide additional emerging information for maternity and neonatal services planning their response to COVID-19.@story_separate@Prospective clinical information was collected at the time of presentation to the maternity unit from February 2020 to April 2020 inclusive. For each patient, a proforma was attached to the clinical note which was completed at each stage of the hospital stay. Telephone follow-up of maternal recovery and neonatal conditions were carried out by community midwives following hospital discharge for completion, and was recorded on electronic maternal notes [Badgernet maternity information system]. The infection was confirmed based on positive RT-PCR results supplemented by clinical symptoms, chest x ray, chest computed tomography (CT) information. RT-PCR for SARS-CoV-2 nucleic acid was used to determine COVID-19 in suspected infection from both maternal and neonatal nasopharyngeal samples. Sample collection, processing, and laboratory testing followed guidance from Public Health England [12] . (Table 1) . Mean age of patients was 29 [16;40] years, 4/23 (17.3%) were admitted to intensive care unit (ICU), 3/23 (13%) required mechanical ventilation, and 1/23 (4.3%) required ECMO-Extracorporeal membrane oxygenation (ECMO). Comorbidities were diabetes mellitus 4/23 (17.3%), Asthma 2/23 (8.7%), preeclampsia 2/23 (8.7%). One pregnant woman had hypertension, one had Anti-S antibodies, one had well-controlled hyperthyroidism, and hepatitis B. One patient died from basilar artery thrombosis, a co-existing pulmonary embolism, and complicated by diabetic ketoacidosis during ICU admission (Table 1) In our cohort of 23 women, we had 19 pregnant women with confirmed COVID-19 in their 3 rd trimester delivering 20 neonates (18 singleton, and 1 set of twins), and 4 women with confirmed COVID-19 in their second trimester. Of the later, one had missed miscarriage at 13 weeks' gestation, while one developed acute pyelonephritis with consequent acute kidney injury. Of the 19 patients who delivered, 7/19 (36.4%) were preterm. The gestation at delivery J o u r n a l P r e -p r o o f 7 varied from 29 weeks to 36 weeks with mean of 33.1 weeks' gestation. Four of these patients were preterm delivery following preterm pre-labour rupture of membrane (PPROM). Three patients required early delivery due to development of maternal severe adult respiratory distress syndrome; two were at 31 weeks' gestation and another at 35weeks' gestation. The majority had caesarean deliveries 16/19 (68.4%) ( Table 1 ). 13/16 (81%) had an emergency Csections while 3/16 (11.8%) had an elective C-sections. Indications for the C-sections included pathological CTG (2), failure to progress (4), PPROM including subsequent unsuccessful induction of labour (3), maternal request (2) and severe sepsis (2) ( Table 1) . Two of these patients were admitted to ICU, intubated and ventilated prior to delivery. Pre-eclampsia occurred in 2/19 of patients (10.5%), one of whom progressed to develop liver dysfunction, HELLP and DIC. For 6/19 (31.6%) patients there were concurrent complaint of reduced fetal movement (RFM) but only one of whom had a pathological antenatal cardiotocograms (CTG) at her 40 weeks' gestation presentation (Table 1) . In our cohort, we had one maternal death of a 29-year-old Asian patient with a history of poorly controlled type-2 diabetes. She was admitted with pyrexia and severe breathlessness requiring 100% oxygen. Her infection was complicated by diabetic ketoacidosis. She was delivered by an emergency C-section under general anaesthetic. She was started on amoxicillin and thromboprophylactic dose of enoxaparin. Although she was extubated initially, she had to be reintubated after 4 days due to worsening respiratory function. Her CT pulmonary angiogram confirmed pulmonary embolism, and showed bilateral solid pulmonary consolidations which was consistent with COVID-19. Her CT head showed basilar artery thrombosis. Following multidisciplinary discussion including the neurosurgical team into her care, end of life care was commenced before she passed away soon thereafter. Neonatal outcomes J o u r n a l P r e -p r o o f 8 In terms of fetal and neonatal outcomes, the majority 19/20 (95%) did not require resuscitation with 1 minute Apgar scores of 8 -9, and 5 minute Apgar scores of 9-10. One new-born, who was delivered at 35 weeks by emergency C-section to black African patient due to severe COVID-19 respiratory symptoms requiring ventilation, had low Apgar score of 3 and 5, at 1 and 5 minutes respectively following delivery ( Table 1 ). The baby was resuscitated with positive oxygen pressure following delivery, intubated and transferred to a special care baby unit (SCBU). The baby was extubated on day 3 and subsequently was discharged from hospital without further adverse, either mother or infant outcomes reported to date. Nasal swabs were performed to screen for COVID-19 in seven infants 7/19 (37%) who were delivered to mothers with severe symptoms (one test was not performed as guidance for not routinely performing screening test on the neonates born to COVID-19 patient was changed to routine screening soon after the data collection started). The swabs were taken on day 0, and day 3 following delivery. All 7 infants were started on antibiotics following delivery whilst awaiting swabs results. Additional neonatal pharyngeal swab testing was taken based on index of suspicion, there were four neonates where these additional swabs were taken. All neonatal swabs were, however, negative for COVID-19. None of the infants presented any respiratory symptoms as of the submission of the manuscript. The immune function of pregnant patients is relatively suppressed during pregnancy. At the same time, physiological changes during pregnancy will also expose pregnant patients to a higher risk, which will lead to a more adverse outcomes [13, 14] . It is reported in the literature that pregnant patients infected with SARS-CoV, and MERS-CoV indeed have more adverse outcomes (spontaneous miscarriage, intrauterine growth restriction and premature delivery); the J o u r n a l P r e -p r o o f 9 mortality rate of pregnant patients is as high as 25% compared to 10% in ordinary infected people [15, 16] . Recently, Chen et al. [5] , and Zhu et al. [17] reported that the perinatal infection COVID-19 may have adverse effects on new-borns, but compared with SARS-CoV, the adverse mother-to-child outcomes are fewer. Analyses of our prospectively collected data of a cohort of pregnant patients infected with COVID-19 in their second and third trimester seems to bear these. Of all patients presenting in the 2 nd or 3 rd trimester, most cases had mild manifestation with eight severe cases. Chest imaging including CT and x ray examination showed typical patchy solid consolidation consistent with COVID-19 pneumonia in 20/23 (87%) of the patients. Three of the severe cases progressed to requiring intubation and ventilation. All three were in the 3rd trimester. In our cohort, there was a relatively higher rate of preterm birth, preeclampsia, and C-section. 7/19 (37%) of the patients who acquired the infection in the 3rd trimester had preterm delivery, which remains higher compared to the national rate of preterm delivery (7.3%) [18] . Furthermore, the rate of C-section in our cohort was 16/19 (84%) which is significantly higher than the national C-section rate in the UK (26.2%) [19] . Out of all patients 2/19 (10.5%) had severe preeclampsia compared to (1-2%) risk in general population [19] , out of which one patient developed HELLP and DIC. One pregnancy with confirmed COVID-19 infection in the third trimester had a neonate with intrauterine growth restriction.  We are acknowledging that our study is limited by the small sample size, and incomplete information on the outcome of the infants beyond the end date of data collection, however, our findings are important for understanding the characteristics of the disease in pregnant patients, and their infants. The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.@story_separate@Although our cohort of 23 patients with confirmed COVID-19 was relatively small in absolute numbers, we have prospectively collected data for the three months' period covered. The incidence of COVID-19 in our cohort mirrored the national UK trend. There is a relatively higher rate of preterm birth, preeclampsia, and C-section for patients with COVID-19 but vertical transmission including development of severe neonatal COVID-19 complications seemed reassuringly rare. Our findings can provide an additional guidance to enhance prenatal counselling of patients with COVID-19 infection during pregnancy.","OBJECTIVE: To study the effect of COVID-19 on pregnancy and neonatal outcomes. STUDY DESIGN: Prospective cohort study in a large tertiary maternity unit within a university hospital with an average annual birth of over 10,000 births. We prospectively collected and analysed data for a cohort of 23 pregnant patients including singleton and multiple pregnancies tested positive for COVID-19 between February 2020 and April 2020 inclusive to assess the effect of COVID-19 on pregnancy, and neonatal outcomes. RESULTS: Twenty-three pregnant patients tested positive for COVID-19, delivering 20 babies including a set of twins, with four ongoing pregnancies at the time of manuscript submission. 16/23 (70%) whom tested positive were patients from Asian (Indian sub-continent) background. The severity of the symptoms ranged from mild in 13/23 (65.2%) of the patients, moderate in 2/23 (8.7%), and severe in 8/23 (34.8%). Four out of total 23 COVID-19 pregnant patients (17.4%) developed severe adult respiratory distress syndrome complications requiring ICU support, one of whom led to maternal death 1/23 (4.3%). 11/23 (48%) of the patients had pre-existing co-morbidities, with morbid obesity 5/23 (21.7%) and diabetes 4/23 (17.4%) being the more commonly represented. Of the 23 pregnant patients 19 were in their third trimester of pregnancy and delivered; 7/19 (36.8%) had preterm birth, 3/19 (15.8%) developed adult respiratory distress syndrome before delivery, and 2/19 (10.5%) had pre-eclampsia. 16/19 (84%) of patients delivered by C-section. Out of the 20 new-borns, 18 were singletons with a set of twin. CONCLUSION: COVID-19 is associated with high prevalence of preterm birth, preeclampsia, and caesarean section compared to non-COVID pregnancies. COVID-19 infection was not found in the newborns and none developed severe neonatal complications."
"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a betacoronavirus and the infectious agent that causes coronavirus disease (COVID-19), a respiratory infection with systemic involvement. The first documented COVID-19 case occurred in Wuhan, China [1] at the end of 2019. Initially, cases were only recorded in Hubei province; however, the COVID-19 outbreak rapidly evolved and was soon characterized as a pandemic by the World Health Organization (WHO) [2] . The first COVID-19 case in Greece was confirmed on 26 February 2020, marking the start of the first pandemic wave in the country, which began in March and lasted until May 2020. During the summer months, some touristic areas within the country recorded a small increase in cases. By 31 August 2020, Greece had reported 8986 laboratory confirmed cases of SARS-CoV-2 infection in the general population and 266 related deaths [3] . The recorded cumulative incidence of COVID-19 in Greece until 31 August was estimated at 87.2 cases per 100,000 population, and the mortality at 2.6 deaths per 100,000 population. The second pandemic wave in Greece began in October 2020. In an effort to manage the pandemic, countries have applied different strategic interventions with varying levels of success [4] . Extensive diagnostic testing and subsequent interventions are considered essential for controlling and interrupting SARS-CoV-2 transmission. A gradual deterioration of the epidemiological situation in Greece resulted in the implementation of a strict lockdown on 23 March 2020, requiring all residents to limit non-essential movement with minimal exceptions. Beginning on 4 May 2020, public health measures were gradually lifted, with retail/trade businesses the first to reopen, followed by the reopening of schools. As of 1 July 2020, Greece opened its points of entry to tourists. Measuring host immune response to SARS-CoV-2 infection is an indirect method for detection of COVID-19 beyond the first 2 weeks of illness onset [5] . Considering both the insufficient number of molecular tests conducted and that the majority of individuals infected with SARS-CoV-2 display mild symptoms or remain completely asymptomatic, serological diagnosis is becoming an important tool to understand the extent of COVID-19 in the community. Furthermore, serological diagnosis allows for the identification of individuals who are immune and potentially ""protected"" from becoming infected. The duration of antibody response, particularly in asymptomatic or mild infections is not yet known. Many scientific articles support the idea of antibodies waning and falling below the threshold of seropositivity approximately two to three months after COVID-19 diagnosis [6, 7] . According to the Centers for Disease Control and Prevention (CDC), approximately 2 months after an antibody test, 28% of seropositive individuals seroreverted to below the threshold of positivity. Thus, point seroprevalence studies could face challenges related to interpretation of results. Conducting repeated serosurveys on a monthly basis using the same sampling methodology could be considered a supplementary surveillance tool. This seroepidemiological study began in March 2020 and has been repeated at monthly intervals. Results from the first two months have been published elsewhere [8] , while here we report on the results from May to August 2020. The aims of the present seroepidemiological study are to provide an assessment of the extent of COVID-19 spread in the community through estimation of prevalence of SARS-CoV-2 IgG antibodies in the Greek population by sex, age group and geographical area; to identify regional, sex and age differences throughout the entire course of the pandemic; and to assess the infection fatality rate (IFR) and compare it to the case fatality rate (CFR). Finally, this serosurvey intends to provide evidence regarding potential under-diagnosis of COVID-19 in Greece. @story_separate@The study was designed as a cross-sectional survey and repeated at monthly intervals. We used the leftover sampling methodology in order to collect serum samples (residual sera from the general population) [9] . A geographically stratified sampling plan based on regional units (NUTS level 3) was applied in order to produce a representative sample, taking into consideration age group (0-29, 30-49, 50-69, and ≥70 years) and sex. The required sample size was determined to be 380 serum samples from each of the 13 NUTS level 2 regions and the sample size for each regional unit (NUTS level 3) from the corresponding region was calculated according to population distribution. However, the actual number of collected samples differed from the pre-determined number of samples above. The leftover serum samples were collected from a nationwide laboratory network, including both private microbiological laboratories as well as microbiological and biochemical laboratories of public hospitals. A total of 36 laboratories participated. The samples were derived from individuals who visited the laboratories for routine screening and reasons unrelated to COVID-19. The majority of private laboratories, particularly in large urban areas, were closed due to the summer holidays in August 2020, resulting in more challenging sample collection. The presence of anti-SARS-CoV-2 IgG antibodies was determined using the ABBOTT SARS-CoV-2 IgG assay, a chemiluminescent microparticle immunoassay (CMIA), with the ARCHITECT i2000SR analyzer (Abbott, Illinois, United States). Anti-spike IgG antibodies are used as a marker of prior SARS-CoV-2 infection. As already stated, the method was validated in our laboratory. We used 305 pre-COVID-19 samples (obtained in 2017) as negative controls and 94 samples from patients with positive SARS-CoV-2 PCR and different symptom durations. The kit displayed 84.0% sensitivity (95% confidence interval (CI): 76.6-91.5) and 99.7% specificity (95% CI: 98.2-100). Given that there were not vaccines during the study period (May to August 2020), all positive samples for IgG anti-SARS-CoV-2 were provoked by natural infection. The statistical analysis applied is identical to the analysis applied for samples between March and April 2020 [8] . Initially, we determined an unweighted relative frequency of all patient characteristics (age, sex and area of residence): this is the crude seroprevalence (S1). The weighted proportions of positive tests in the countrywide sample were based on the sex and age distribution within each regional unit (NUTS level 3) and the population of each regional unit, according to the most recent census conducted in 2011 (S2) [10] . We also adjusted the weighted proportion (S2) of positive tests to account for the accuracy (sensitivity and specificity) of the laboratory test (S3) [11, 12] . Since reported COVID-19 cases were by definition outside the sampling framework, the seroprevalence was corrected, taking into consideration the number of reported cases per month in accordance with the National Public Health Organization (NPHO) (S4). Therefore, we added the cases reported in March, April and May to the estimated S3 seroprevalence in order to calculate the S4 for May, while to calculate the S4 for June we added the reported cases from March to June, and so forth. We calculated the S1, S2, S3 and S4 seroprevalence of IgG antibodies by month and also calculated the CFR and IFR by month. CFR is the ratio of the number of deaths attributed to COVID-19 and reported to the NPHO, divided by the number of cases reported to the NPHO; IFR is the ratio of deaths divided by the number of estimated individuals infected with SARS-CoV-2. The estimation of infected individuals was the product of the seroprevalence and population of regional units where confirmed cases were identified according to NPHO [13] . The 95% CI for weighted data were estimated using normal approximation of binomial distribution and effective sample size, rather than the collected sample size (further explained below). It should be noted that clusters of cases from refugee camps and from a cruise ferry -which were not considered community cases (302 cases in total) -were excluded from analysis for CFR and IFR. The 95% CI for CFR was calculated using normal approximation of binomial distribution. The 95% CI for IFR was calculated using the corresponding 95% CI of the S1, S2, S3 and S4 seroprevalence. Comparison of two proportions was carried out with the 'N-1' chi-squared test [13] . In order to calculate how many SARS-CoV-2 infections correspond to one reported case, we estimated the average S3 seroprevalence and corrected it by the estimated 28% seroconversion according to CDC. For all analyses, a 5% significance level was set. Since the number of collected samples from each regional unit was not proportional to the regional unit's population, we calculated an effective sample size based on each regional unit's population proportion, according to 2011 census data. This was done using target weighting. The target sample size for a regional unit i is t i , and the actual sample size for the regional unit i is a i . The weighting factor for the regional unit i is calculated with the following formula: The weighted sample size (w i ) for the regional unit i is calculated as follows: (2) For k regional units and a countrywide target sample size of n t , the country-wide effective sample size (n e ) is calculated with the following formula: This can also be written as: The samples were anonymized leftover serum samples. Each sample had a unique code and the required data-sex, age, residence and date of blood sampling-were recorded. Health staff from the participating laboratories requested written consent statements from the involved individuals. The research protocol was approved by the ethical committee of the Faculty of Medicine, University of Thessaly, Greece (No. 2116). A total of 20,110 samples were collected for the four month period between May and August 2020, of which 11,481 (57%) were obtained from females. Regarding the age distribution of collected samples, 4375 (21.8%) belonged to the ""0-29"" age group, 5957 (29.6%) to the ""30-49"" age group, 5328 (26.5%) to the ""50-69"" age group and 4547 (22.6%) to individuals "">70"" years of age. Figure 1 displays the geographic distribution of collected leftover samples. A total of 6,054 samples were collected from the Peloponnese region, followed by 3501 from Attica, 1795 from Thessaly, 1748 from Crete, 1510 from Western Greece, 1215 from Eastern Macedonia and Thrace, 1207 from Epirus, 1058 from Western Macedonia, 1011 from Central Macedonia, 677 from Central Greece, 188 from South Aegean and 146 from the Ionian Islands. For each sample, age, sex, residence and date of blood sampling were recorded. Figure 1 displays the geographic distribution of collected leftover samples. A total of 6,054 samples were collected from the Peloponnese region, followed by 3501 from Attica, 1795 from Thessaly, 1748 from Crete, 1510 from Western Greece, 1215 from Eastern Macedonia and Thrace, 1207 from Epirus, 1058 from Western Macedonia, 1011 from Central Macedonia, 677 from Central Greece, 188 from South Aegean and 146 from the Ionian Islands. For each sample, age, sex, residence and date of blood sampling were recorded. Of the 20,110 collected serum samples, 89 (0.44%) were found positive for anti-SARS-CoV-2 IgG antibodies. According to the monthly distribution of samples, S1 seroprevalence for anti-SARS-CoV-2 IgG antibodies was as follows: 0.44% in May, 0.37% in June, 0.49% in July and 0.52% in August (Tables 1-4 ). The adjusted results for age, sex, population (S2) and additionally, for accuracy of the laboratory test (S3) are presented in Tables  1-4 . After the addition of NPHO data, S3 seroprevalence was modified and S4 was calculated as 0.35% in May, 0.19% in June, 0.25% in July, and 0.35% in August (Tables 1-4 ). Of the 20,110 collected serum samples, 89 (0.44%) were found positive for anti-SARS-CoV-2 IgG antibodies. According to the monthly distribution of samples, S1 seroprevalence for anti-SARS-CoV-2 IgG antibodies was as follows: 0.44% in May, 0.37% in June, 0.49% in July and 0.52% in August (Tables 1-4 ). The adjusted results for age, sex, population (S2) and additionally, for accuracy of the laboratory test (S3) are presented in Tables 1-4 . After the addition of NPHO data, S3 seroprevalence was modified and S4 was calculated as 0.35% in May, 0.19% in June, 0.25% in July, and 0.35% in August (Tables 1-4 ). Table 3 . Anti-SARS-CoV-2 IgG antibody seroprevalence, Greece, July 2020 (n = 5959). Throughout the study period, the two younger age groups presented the highest seroprevalence. Specifically, in May 2020 the highest seroprevalence was observed in the ""0-29"" year age group with S4 = 0.82%, while in June, July and August 2020 the highest seroprevalence was estimated in the ""30-49"" year age group with S4 = 1.02%, 0.47%, and 0.82%, respectively (Tables 1-4, Figure 2 ). During the first two months of the study period, higher seroprevalence was estimated in large urban areas (Attica region and the regional unit of Thessaloniki) as compared to the rest of the country. In large urban areas, the S4 was calculated as 0.47% and 0.46% in May and June respectively, while in the rest of the country the S4 was calculated as 0.16% and 0% for the corresponding months (May: difference = 0.31%, p = 0.039; June: difference = 0.46%, p < 0.0001) (Tables 1 and 2 ). However, in July 2020 the S4 was calculated as 0.29% in large urban areas and 0.21% for the rest of the country, with no statistically significant difference estimated (p = 0.570). Due to an insufficient number of samples collected from large urban areas in month of August, due to closures of many microbiological laboratories during summer holidays, seroprevalence was not calculated separately based on areas by population density. The S4 was higher among females as compared to males in May and June (May: females: S4 = 0.58% VS males: S4 = 0.10%, June: females: S4 = 0.34%, VS males: S4 = 0.02%) (Tables 1 and 2); however, this difference was reversed during July and August (July: females: S4 = 0.23% VS males: S4 = 0.27%, August: females: S4 = 0.12% VS males: S4 = 0.58%) (Figure 3) . The difference between sexes observed in August (0.46%) is of borderline statistical significance (p = 0.052). Additionally, seroprevalence in each age group was calculated separately for each sex (Table S1 ). During the first two months of the study period, higher seroprevalence was estimated in large urban areas (Attica region and the regional unit of Thessaloniki) as compared to the rest of the country. In large urban areas, the S4 was calculated as 0.47% and 0.46% in May and June respectively, while in the rest of the country the S4 was calculated as 0.16% and 0% for the corresponding months (May: difference = 0.31%, p = 0.039; June: difference = 0.46%, p < 0.0001) (Tables 1 and 2 ). However, in July 2020 the S4 was calculated as 0.29% in large urban areas and 0.21% for the rest of the country, with no statistically significant difference estimated (p = 0.570). Due to an insufficient number of samples collected from large urban areas in month of August, due to closures of many microbiological laboratories during summer holidays, seroprevalence was not calculated separately based on areas by population density. The S4 was higher among females as compared to males in May and June (May: females: S4 = 0.58% VS males: S4 = 0.10%, June: females: S4 = 0.34%, VS males: S4 = 0.02%) (Tables 1 and 2) ; however, this difference was reversed during July and August (July: females: S4 = 0.23% VS males: S4 = 0.27%, August: females: S4 = 0.12% VS males: S4 = 0.58%) (Figure 3) . The difference between sexes observed in August (0.46%) is of borderline statistical significance (p = 0.052). Additionally, seroprevalence in each age group was calculated separately for each sex (Table S1 ). Vaccines 2021, 9, x 9 of 13 Summarizing the above results, for the months of May and June, statistically significant difference was observed between the two sexes (May p = 0.003 and June p < 0.001) and between large urban areas and rest of the country (May = 0.039 and June p < 0.001) with females and large urban areas presented higher seroprevalence. These differences were not observed in July. In August, a borderline no statistically significant difference was calculated (p = 0.052) between males and females, with S4 = 0.58% in males and 0.12% in females. Tables 1-4 present the monthly CFR and IFR. A gradual decline in CFR was observed, while IFR remained below 0.2% each month during the study period, presenting a slight difference from month to month. Between May and August 2020, 126 deaths were reported according to data from the NPHO. Consequently, the CFR for this 4-month period was calculated as 1.89% and the corresponding IFR as 0.47% (Table 5) . Table 5 . Anti-SARS-CoV-2 IgG antibody seroprevalence, IFR, CFR, Greece, May-August 2020. A total of 5094 new cases were reported between May and August 2020 in the general population, excluding the Attica region. By using the average S3 seroprevalence for this time period and increasing it by 28% (the percentage of seropositives that seroconvert), according to the CDC it was estimated that each case reported by the NPHO corresponded to 4.9 SARS-CoV-2 infections in the general Greek population (95% CI: 2.1-7.8). Summarizing the above results, for the months of May and June, statistically significant difference was observed between the two sexes (May p = 0.003 and June p < 0.001) and between large urban areas and rest of the country (May = 0.039 and June p < 0.001) with females and large urban areas presented higher seroprevalence. These differences were not observed in July. In August, a borderline no statistically significant difference was calculated (p = 0.052) between males and females, with S4 = 0.58% in males and 0.12% in females. Tables 1-4 present the monthly CFR and IFR. A gradual decline in CFR was observed, while IFR remained below 0.2% each month during the study period, presenting a slight difference from month to month. Between May and August 2020, 126 deaths were reported according to data from the NPHO. Consequently, the CFR for this 4-month period was calculated as 1.89% and the corresponding IFR as 0.47% (Table 5 ). A total of 5094 new cases were reported between May and August 2020 in the general population, excluding the Attica region. By using the average S3 seroprevalence for this time period and increasing it by 28% (the percentage of seropositives that seroconvert), according to the CDC it was estimated that each case reported by the NPHO corresponded to 4.9 SARS-CoV-2 infections in the general Greek population (95% CI: 2.1-7.8). Our results demonstrate low seroprevalence of anti-SARS-CoV-2 IgG antibodies in Greece during the first wave of the pandemic. This finding supports hypotheses regarding the effectiveness of the timely implementation of public health measures. In March and April 2020, the serosurvey results were calculated as S4 = 0.02% and 0.25%, respectively [8] . In Figure 4 , we summarize our previous and current serosurvey results, in addition to presenting the monthly cases according to NPHO data. A peak in seroprevalence was observed in May 2020; this peak can be explained as representing the proportion of individuals infected with SARS-CoV-2 during the first pandemic wave between March to May 2020. Consequently, an increase in seroprevalence would be expected in May, as compared to March and April 2020. Figure 4 becomes more remarkable, taking into consideration the different public health measures implemented during this period. From 23 March 2020 a national lockdown had been imposed, which was gradually lifted beginning 4 May 2020, with a requirement for masks to be worn in areas of intense crowding (such as on means of public transport, at supermarkets, hospitals etc.). Furthermore, on 18 May mobility between regional units within the country was permitted. Between mid-May to June, schools gradually reopened with senior classes the first to commence. In late May, eating establishments were reopened and starting from 1 July 2020, the entry of tourists into Greece from all countries was permitted. Vaccines 2021, 9, x 10 of 13 Our results demonstrate low seroprevalence of anti-SARS-CoV-2 IgG antibodies in Greece during the first wave of the pandemic. This finding supports hypotheses regarding the effectiveness of the timely implementation of public health measures. In March and April 2020, the serosurvey results were calculated as S4 = 0.02% and 0.25%, respectively [8] . In Figure 4 , we summarize our previous and current serosurvey results, in addition to presenting the monthly cases according to NPHO data. A peak in seroprevalence was observed in May 2020; this peak can be explained as representing the proportion of individuals infected with SARS-CoV-2 during the first pandemic wave between March to May 2020. Consequently, an increase in seroprevalence would be expected in May, as compared to March and April 2020. Figure 4 becomes more remarkable, taking into consideration the different public health measures implemented during this period. From 23 March 2020 a national lockdown had been imposed, which was gradually lifted beginning 4 May 2020, with a requirement for masks to be worn in areas of intense crowding (such as on means of public transport, at supermarkets, hospitals etc.). Furthermore, on 18 May mobility between regional units within the country was permitted. Between mid-May to June, schools gradually reopened with senior classes the first to commence. In late May, eating establishments were reopened and starting from 1 July 2020, the entry of tourists into Greece from all countries was permitted. A cumulative effect of seropositivity would be conventional, increasing even with lower positivity rates over the following months. However, the seroprevalence in June is lower than the seroprevalence in May. This finding has been documented by corresponding seroepidemological studies reflecting antibody waning [6, 14] . Our positive results reflect mainly mild or asymptomatic cases, since confirmed COVID-19 cases that occurred during the same month were excluded from the sampling A cumulative effect of seropositivity would be conventional, increasing even with lower positivity rates over the following months. However, the seroprevalence in June is lower than the seroprevalence in May. This finding has been documented by corresponding seroepidemological studies reflecting antibody waning [6, 14] . Our positive results reflect mainly mild or asymptomatic cases, since confirmed COVID-19 cases that occurred during the same month were excluded from the sampling framework. It is widely supported that both anti-SARS-CoV-2 antibody titers and their duration of detection are correlated with the severity of clinical presentation [15] . Mild COVID-19 cases develop antibodies in a lower titer and for a shorter time period. The halflife of anti-SARS-CoV-2 antibodies has been calculated as 106 days [7] and, subsequently, several of them end in ""serosilent"" infections. As mentioned above, the CDC suggests that, approximately 2 months after the first detection of antibodies, nearly one of four seropositive individuals seroconverted below the threshold of positivity [6] . This documented waning of antibodies following infection decreases the sensitivity of antibody detection throughout the months. Considering this, the observed decrease of seroprevalence in June 2020 can be justified by both the reduced spread of SARS-CoV-2 in the community and the simultaneous seroconversion of seropositive individuals infected in March and April 2020. This decrease in seroprevalence raises concerns related to long-term immune response. A few reports exist that describe cases of reinfection; however, this occurrence is extremely rare [16] . In the following months between July and August 2020, a small increase in seroprevalence was observed. This finding may be explained by the unrestricted movement of citizens during this period and increased travel due to summer holidays. During the summer months, it is well-recognized and customary for the general Greek population to travel from large urban areas to areas throughout the rest of the country. This ""pattern of mobility"" may offer an explanation for our second remarkable finding, regarding the diminished differences in seroprevalence between these two areas. In May and June 2020, the calculated seroprevalence was higher in large urban areas compared to the rest of the country, while almost the same seroprevalence was estimated in July 2020 for both areas. This finding reflects the spread of SARS-CoV-2 in non-urban areas due to population movement for summer holidays, after the remaining movement restrictions were lifted for the general population on 25 May 2020 Individuals from large urban areas where higher SARS-CoV-2 spread had been observed travelled to their holiday destinations throughout the rest of country, where the susceptible local populations were at risk of becoming infected. This ""population movement"" resulted in a lessening of seroprevalence differences between the two areas. Unfortunately, a sufficient number of samples from large urban areas for August 2020 were unavailable. However, the existence of a difference in seroprevalence between large urban areas and the rest of the country will be further examined in the following months, as the collection of samples continued from September 2020 onward according to the established methodology. In contrast to our previous results presenting a simultaneous increase in seropositivity with increasing age, seroprevalence between May and August 2020 was primarily higher in the ""30-49"" year age group [8] . This finding could be attributed to the fact that Greece's workforce is largely comprised of individuals in this age group and, furthermore, increased mobility is associated with this subset of the population due to their more active participation in recreational activities. Considering the above factors and that younger age groups that become infected with COVID-19 typically experience mild disease, may offer an explanation for the high seroprevalence observed in this age group [17] . Continuous communications campaigns provided by public health authorities regarding the protection of elderly populations likely influenced the behavior of elderly individuals after restrictive public health measures were lifted. This protective behavior could be considered as a reason for the low seroprevalence observed in the "">70"" year age group. The results of the next months will enrich the discussion of this issue. Throughout the months, an increase in seroprevalence in males compared to females can be observed. This finding is consistent with data from the NPHO (55.6% of cases refer to males). Interpretation of this result must also consider that males comprise a large majority of the workforce in Greece and tend to participate more actively in recreational activities. Both findings related to age, group and sex are consistent with the results of a published systematic review and meta-analysis, which included preprints or peer-reviewed articles up to 14 August 2020. Higher seroprevalence is calculated in males compared to females. Moreover, in this review the ""20-49"" year age group shows the highest prevalence, followed by the ""50-65"" year age group [18] . A total of 2310 COVID-19 cases were reported by the NPHO up to 30 April 2020, and it was calculated that one reported COVID-19 case corresponded to ten SARS-CoV-2 infections in the Greek general population [8] . For the following months, the corresponding factor decreased to 4.9. This reduction is justified by an increase in the number of tests conducted and therefore, increased detection of COVID-19 cases. A similar ratio of approximately 4 was identified when comparing the estimated CFR with the IFR for this four-month period. It should be noted that the delay of death could not be accounted for in the current estimation. The leftover sampling methodology could be considered a limitation of the study, as non-random convenient sampling may affect the representativeness of samples collected. A limitation of the leftover sampling methodology is the difficulty related to collection of clinical information. Using this methodology, it was therefore not possible to correlate clinical status with positive samples. Sample collection was also challenging due to summer closures of many microbiological laboratories, primarily in August 2020. Not all areas were covered by the sampling network. This methodology has several advantages including ease of sample collection. Furthermore, this methodology allows for repeated monthly sample collection, enabling follow up of the course of the pandemic and immunity levels of the general population on a rolling basis.@story_separate@Our study presents low seroprevalence in Greece during the period from May to August 2020, a finding which renders the Greek population extremely vulnerable to SARS-CoV-2 infection. The ""30-49"" year age group appears to have been most affected during this period, since this subset of the population is characterized by the highest mobility levels and most actively participates in recreational activities. The differences in seroprevelance between large urban areas and other areas throughout the country lessened, and towards the end of the study period, a higher seroprevalence in males was observed. As was expected, a lower IFR was calculated compared to CFR. The waning of anti-SARS-CoV-2 IgG antibodies is supported by our serosurvey results. Supplementary Materials: The following are available online at https://www.mdpi.com/article/ 10.3390/vaccines9050504/s1, Table S1: S1 and S1 adjusted for Se & Sp in each age group for each sex separately. Informed Consent Statement: Informed consent was obtained from all subjects involved in the study.","A serosurvey of IgG antibodies against SARS-CoV-2 was conducted in Greece between May and August 2020. It was designed as a cross-sectional survey and was repeated at monthly intervals. The leftover sampling methodology was used and a geographically stratified sampling plan was applied. Of 20,110 serum samples collected, 89 (0.44%) were found to be positive for anti-SARS-CoV-2 antibodies, with higher seroprevalence (0.35%) observed in May 2020. The highest seroprevalence was primarily observed in the “30–49” year age group. Females presented higher seroprevalence compared to males in May 2020 (females: 0.58% VS males: 0.10%). This difference reversed during the study period and males presented a higher proportion in August 2020 (females: 0.12% VS males: 0.58%). Differences in the rate of seropositivity between urban areas and the rest of the country were also observed during the study period. The four-month infection fatality rate (IFR) was estimated to be 0.47%, while the respective case fatality rate (CFR) was at 1.89%. Our findings confirm low seroprevalence of COVID-19 in Greece during the study period. The young adults are presented as the most affected age group. The loss of the cumulative effect of seropositivity in a proportion of previous SARS-CoV-2 infections was indicated."
"i. COVID-19 Virus Coronaviruses (CoV) are a large family of viruses that cause illness ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS-CoV) and Severe Acute Respiratory Syndrome (SARS-CoV). CoV are zoonotic, meaning they are transmitted between animals and people. Coronavirus disease (COVID-19) is a new strain that was discovered in 2019 and has not been previously identified in humans [1] . COVID-19 is a respiratory infection with common signs of infection that include respiratory symptoms, fever, cough, shortness of breath and breathing difficulties. In more severe cases, infection can cause pneumonia, severe acute respiratory syndrome, kidney failure and death. ii. Flattening the Curve On March 11, 2020 the World Health Organization (WHO) declared COVID-19 to be a pandemic [2] . In their press conference, they were clear that pandemic was not a word they used lightly or carelessly or to cause unreasonable fear. They were also clear to highlight that this is the first pandemic to ever be caused by a coronavirus and that all countries can still act to change its course. Public health and healthcare experts agree that mitigation is required in order to slow the spread of COVID-19 and prevent the collapse of healthcare systems. On any given day, health systems in the United States run close to capacity [3] and so every transmission that can be avoided and every case that can be prevented has enormous impact. iii. Identifying Vulnerable People The risk of severe complications from COVID-19 is higher for certain vulnerable populations, particularly people who are elderly, frail, or have multiple chronic conditions. The risk of death has been difficult to calculate [4] , but a small study [5] of people who contracted COVID-19 in Wuhan suggests that the risk of death increases with age, and is also higher for those who have diabetes, disease, blood clotting problems, or have shown signs of sepsis. With an average death rate of 1%, the death rate rose to 6% for people with cancer, high blood pressure and chronic respiratory disease, 7% for people with diabetes, and 10% for people with heart disease. There was also a steep age gradient; the death rate among people aged 80+ was 15% Identifying who is most vulnerable is not necessarily straightforward. More than 55% of Medicare beneficiaries meet at least one of the risk criteria listed by the CDC [6] . People with the same chronic condition don't have the same risk, and simple rules can fail to capture complex factors like frailty [8] which makes people more vulnerable to severe infections.@story_separate@Since real world data on COVID-19 cases is not readily available, the CV19 Index was developed using close proxy events. A person's CV19 Index is measured in terms of their near-term risk of severe complications from respiratory infections (e.g. pneumonia, influenza). Specifically, 4 categories of diagnoses were chosen from the Clinical Classification Software Refined (CCSR) [11] classification system: • RSP002 -Pneumonia (except that caused by tuberculosis) • RSP003 -Influenza • RSP005 -Acute bronchitis • RSP006 -Other specified upper respiratory infections Machine learning models were created that use a patient's historical medical claims data to predict the likelihood that they will have an inpatient hospital stay due to one of the above conditions in the next 3 months. The data used was an anonymized 5% sample of the Medicare claims data from 2015 and 2016. This data spanned the transition from ICD-9 to ICD-10 on October 1st, 2016. The data set used to create the model was created by identifying all living members above the age of 18 on 9/30/2016. Only fee -for-service members were included because medical claims histories for other members are not reliably complete. We then excluded all members who had less than 6 months of continuous eligibility prior to 9/30/2016. We also excluded members who lost coverage within 3 months after 9/30/2016, except for those members who lost coverage due to death. Table 1 below summarizes the population selection. The final data set is split 80/20% into train and test sets, with 1,481,654 people in the training set and 369,865 in the test set. The prevalence of the proxy event within the final population was 0.23%. . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted March 21, 2020. Exclude members who lose coverage in the next 3 months not due to death. The labels for the prediction task were created by identifying all patients who had an inpatient visit with an admission date from 10/1/2016 through 12/31/2016 with a primary diagnosis from one of the listed categories. A 3 month delay was imposed on the input features to the model, so that no claims after 6/30/2016 were used to make the predictions. This 3 month delay simulates the delay in claims processing that usually occurs in practical setting and enables the model to be used in realistic scenarios. We highlight a few approaches to building models to help identify individuals who are vulnerable to complications to respiratory infections. All 3 approaches described are machine learning methods created using the same data set. We have chosen 3 different approaches that represent a tradeoff between accuracy and ease of implementation. For individuals who have access to data, but not the coding background to adopt our model, we hope that the simple model can be easily ported to other systems. For a more robust model, we create a Gradient boosted tree leveraging age, gender, and medical diagnosis history. This model has been made open sourced, and can be obtained from github (https://github.com/closedloop-ai/cv19index). Finally, we have created a third model that uses an extensive feature set generated from Medicare claims data along with linked geographical and social determinants of health data. This model is being made freely available through our hosted platform. Information about accessing the platform can be found at https://cv19index.com. The first approach is aimed at reproducing the high level recommendations coming from the Center for Disease Control (CDC) website [7] for identifying those individuals who are at risk. They identify risk features as: • Older adults • Individuals with Heart disease • Individuals with Diabetes • Individuals with Lung disease To turn this into a model, we extract International Classification of Diseases, Version 10 (ICD-10) diagnosis codes from the claims and aggregate them using the Clinical Classification Codes Revised (CCSR) categories. We create indicator features for the presence of any code in the CCSR category. The mapping between the CDC risk factors and the CCSR codes are described in 3 . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted March 21, 2020. -0.020 CCSR:RSP016 age X Pneumonia 0.010 n/a age X Other and ill-defined heart diseas 0.003 n/a age X Heart failure 0.009 n/a age X Acute rheumatic heart disease 0.003 n/a age X Coronary atherosclerosis and other heart disease 0.011 n/a age X Pulmonary heart disease -0.000 n/a age X Chronic rheumatic heart disease -0.001 n/a age X Diabetes mellitus with complication 0.007 n/a age X Diabetes mellitus without complication 0.009 n/a age X Chronic obstructive pulmonary disease and bronchiectasis 0.013 n/a age X Other specified and unspecified lower respiratory disease 0.006 n/a Table 2 . We start with these features as they give us an ability to quantify the portion of the at risk population that are encapsulated by the high level CDC recommendations. In addition to the conditions coming from the recommendations of the CDC, we will look at features that our other modeling efforts surfaced as important and avail those features to the model as well. We also provide gender, age in years, as well as an interaction term between age and the diagnostic features. This simple data set is used to train a logistic regression model [9] . In addition to the CCSR Codes, Table 2 additionally includes iv. Gradient Boosted Trees Our more robust approach uses gradient boosted trees. Gradient boosted trees are a machine learning method that use an ensemble of simple models to create highly accurate predictions [9] . The resulting models demonstrate higher accuracy. The drawback to these models are that they are significantly more complex, however, ""by hand"" implementations of such models is impractical. Here, we create two variations of the models. The first, is a model that leverages similar information as our logistic regression model. A nice feature of Gradient Boosted Trees is they are fairly robust against learning features that are excentricities of the training data, but do 4 . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted March 21, 2020. . https://doi.org/10.1101/2020.03.16.20036723 doi: medRxiv preprint We additionally built a model within the ClosedLoop platform. The ClosedLoop platform is a software system designed to enable rapid creation of machine learning models utilizing healthcare data. The full details of the platform are outside the bounds of this paper, however, using the platform allows us to leverage engineered features coming from peer reviewed studies. Examples are social determinants of health, and the Charlson Comorbidity Index [12] . We chose not to include these features within the open sourced model, because the purpose of the open sourced version is to be as accessible as possible for the greater healthcare data science community. We quantify the performance of our models using metrics that are standard within the data science community. In particular, we visualize the performance of our model using a Receiver Operation Characteristic graph, see Figure 1 . Additionally, the metrics quantifying the effectiveness of our models are in Table 3 . As you can see, the performance of both Gradient Boosted Tree models are very similar. The ROC curve demonstrates that even as the decision threshold increases, the percentage of the potentially affected population increases at roughly the same rate. Similarly, the Logistic Regression model has similar performance at low alert rates. We can see that at a 3% alert rate, the difference in sensitivity is only .02. The performance at higher alert rates experiences a significant performance disadvantage, however, for most interventions this would be at alert rates higher than is practical. . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted March 21, 2020.  There are two ways of accessing the models that we are providing. The first, is to access our open sourced version of our model. As stated, we have released an open sourced version of the model, available at https://github.com/closedloop-ai/cv19index. This model is written in the Python programming language. We have included synthetic data for the purpose of walking individuals through the process of going from tabular diagnosis data to the input format specific for our models. We encourage the healthcare data science community to fork the repository, and adapt it to their own purposes. We encourage collaboration from the open sourced community, and pull requests will be considered for inclusion in the main branch of the package. For those wishing to use our models within our platform, we are providing access to the COVID-19 model free of charge. Please visit https://closedloop.ai/cv19index for instructions on how to gain access. The copyright holder for this preprint this version posted March 21, 2020.  . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 21, 2020.  . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 21, 2020. . https://doi.org/10.1101/2020.03.16.20036723 doi: medRxiv preprint@story_separate@. CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.","COVID-19 is an acute respiratory disease that has been classified as a pandemic by the World Health Organization. Information regarding this particular disease is limited, however, it is known to have high mortality rates, particularly among individuals with preexisting medical conditions. Creating models to identify individuals who are at the greatest risk for severe complications due to COVID-19 will be useful to help for outreach campaigns in mitigating the diseases worst effects. While information specific to COVID-19 is limited, a model using complications due to other upper respiratory infections can be used as a proxy to help identify those individuals who are at the greatest risk. We present the results for three models predicting such complications, with each model having varying levels of predictive effectiveness at the expense of ease of implementation."
"Lockdown, stay-at-home, and school closure policies in response to the spread of the novel coronavirus and its associated disease, COVID-19, have the potential to exacerbate the risk of food insecurity that low-income households face. They may reduce or eliminate both income streams available to some households and programs designed to relieve child food insecurity. The National School Lunch Program (NSLP), for example, is the second largest food and nutrition assistance program in the United States (US) (Gundersen and Ziliak 2018; Guthrie and Ralston 2019) , feeding 84% of low-income, food-insecure households with school-age children (Ralston et al. 2017) . Most studies of the NSLP and such similarly designed feeding programs such as the School Breakfast Program (SBP) find that they are associated with significantly lower rates of food insecurity for households with children, as well as improved diet quality and academic performance (Ralston et al. 2017; Gundersen and Ziliak 2018) . Thus, there is concern that when schools close, the nutrition and food security of children fed through these programs may be threatened. When schools closed due the pandemic, federal funding and relaxation of rules that ensure reimbursement to school districts, states, and other food service providers proliferated (USDA FNS 2020). However, there has been no federal mandate that schools offer food service during closures or federal guidance on best practices to simultaneously encourage continued participation by families and reduce the spread of COVID-19. Thus, school districts, which are not trained to design effective policy, have had to decide if and how to implement summer feeding funds despite concerns that summer feeding programs only reach 17% of children who usually receive free or reduced-price meals during the school year (Feeding America 2019). In addition, summer feeding programs do not follow the same strict nutritional standards as the NSLP, in part because they have not been updated since 2000 (Hopkins and Gunther 2015) . Accordingly, local governments and their partners quickly developed their own programming and policies, resulting in a diverse patchwork of emergency feeding programs to support children and families across the US. The policies and programs that were adopted and/or expanded by cities has potential consequences that are not well understood across the food system. These concerns recently led an interdisciplinary network of food system researchers to map the complex food system of five different urban areas across the US. We looked across projects to examine what the cities were doing to support emergency food service provision to children and families in need and indicators associated with the effectiveness of local approaches. We focus on families with school-aged children, given that they are particularly vulnerable (Gundersen and Ziliak 2018) and that food insecurity among children is associated with increased risks of birth defects, anemia, lower nutrient intakes, cognitive problems, and aggression and anxiety (Gundersen and Ziliak 2014) . To explore the impact on families, we conducted semistructured interviews and focus groups with key informants who are involved with COVID-related emergency food service provision, particularly for households with K-12 aged children. We find that the lack of clear guidelines about the role of the NSLP and SBP in supporting continued feeding programs resulted in each school district and city making different decisions about their response. Our results point to several indicators of effectiveness of local approaches, including (i) cross-sector collaboration, (ii) adaptable supply chains, and (iii) addressing gaps in services to increased-risk populations. 1 We make two contributions to the literature on pandemic food-assistance response. First, we document local responses to the pandemic specifically aimed at supporting households with K-12-aged children after school closures. Second, taking advantage of our research networks' recent urban food system mapping, we draw upon existing community relationships to provide an overview of policy and programming consequences across types of emergency food intervention to understand what may impact the effectiveness of different strategies in supporting emergency food provision to children and families in need. This article proceeds as follows. First, we present a brief review of causes and consequences of food insecurity and the effectiveness of the four largest food assistance programs prepandemic, followed by a review of selected national food assistance programs introduced or modified to address pandemic-related issues. Next, we discuss our methods, including providing more context on the five urban areas included in our study. Results and discussion are organized by themes that emerged based on interviews and focus groups, which help to characterize indicators of the effectiveness of different approaches. We end with conclusions and questions for future research.@story_separate@An extensive review of the causes and consequences of food insecurity and the ability of food assistance programs to mitigate it in the prepandemic US can be found in Gundersen and Ziliak (2018) . Particularly important for the current pandemic, sharp changes in asset levels negatively influence food security. Negative income shocks, income volatility, and job loss have been experienced at unprecedented scale during the pandemic and are all associated with food insecurity (Ribar and Hamrick 2003; Heflin, Corcoran, and Siefert 2007; Leete and Bania 2010; Gjertson 2016) . Additionally, households at a high risk of homelessness (Gundersen et al. 2003 ) and households that have chaotic meals and meal-planning efforts (Fiese et al. 2016 ) also experience food insecurity at an elevated rate. Food assistance programs have been found to decrease food insecurity (Gundersen, Kreider, and Pepper 2017) . The four largest food assistance programs in the US, in terms of value, are the Supplemental Nutrition Assistance Program (SNAP); the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC); the NSLP; and the SBP. • SNAP provides benefits that can be used to purchase most foods (there are a few exceptions, such as prepared foods) based on net income and household size. 2 Participation in SNAP has been found to decrease the prevalence of food insecurity in households with children by at least six percentage points (Gundersen and Ziliak 2018) . • WIC provides supplemental food, nutrition education, and health care referrals to low-income infants, children, and pregnant, postpartum, and breastfeeding women (Oliveira and Gundersen 2001) . WIC has been found to reduce the prevalence of child food insecurity by about 3.6 percentage points (Kreider, Pepper, and Roy 2016) . • NSLP and SBP provide free and reduced-price lunches and breakfasts to households that meet income eligibility and have children enrolled in an NSLP or SBP school. Meals must meet national dietary standards of healthfulness. The NSLP has been found to decrease food insecurity among households with children in school by 2.3% to 9% (Gundersen, Kreider, and Pepper 2012) . Under pandemic conditions, including school closures, the U.S. Department of Agriculture Food and Nutrition Service (USDA FNS) has provided significant flexibility to states across its 15 nutrition programs (USDA FNS 2020). 3 This lack of a cohesive approach has enabled diverse approaches to meeting the changing needs of low-income households with children, but it has also led to a heterogeneity of local policies and program implementation by authorities who have had to rely solely on their limited resources and experiences to design policy responses. The Families First Coronavirus Act (FFCA) provides supplemental federal funding for the WIC program, commodity assistance, and nutrition waivers for schools (USDA FNS 2020d). Examples of waivers in the FFCA include the Community Eligibility Provision (USDA FNS 2020e), the Meal Pattern Flexibility Provision (USDA FNS 2020c), and the congregate meal waiver (USDA FNS 2020b). The first allows school districts to feed anyone who comes to get food from one of its feeding programs, regardless of documented need. The National Meal Pattern waiver, which creates flexibility for what food is distributed, allows a school district that has trouble accessing fruit one week to provide different options without risking the loss of its meals' reimbursable status. The congregate meal waiver enables the Summer Food Service Program and NSLP Seamless Summer Option sponsors to serve meals in noncongregate settings, enabling school food authorities to offer grab-andgo style meals, deliver meals, distribute meals for multiple days, and offer meals for parents or custodians to pick up without children present. There are concerns, however, that even though additional funding is allocated for these programs, guidelines on how to use the funds effectively are lacking, and that states and local governments may use allocated funding to achieve different goals with varying levels of effectiveness and coverage. As an example, the waiver may result in reduced dietary quality for meals served to children. A unique network of five teams of interdisciplinary, university-based food systems researchers conducted this study. The five teams are each involved in mapping their own urban food systems. Thus, in March 2020, as cities had to quickly respond to the realities of the pandemic, these researchers were well-positioned to evaluate broad, system-level changes occurring in the food systems, as they had previously demonstrated bridge-building between organizations working with the local food systems and across scientific disciplines to apply for funds to carry out their research. 4 Accordingly, this article uses the experiences, insights, and networks of these teams to provide information on changes that occurred within the emergency food service system due to COVID-19 and to begin to describe the effectiveness of food system interventions taken to respond to school closures and provide emergency food service support to children and/or families with children. The five city-based project teams focus on Albany, NY; Austin, TX; Cleveland, OH; Denver, CO; and Flint, MI. Table 1 presents some comparative demographic data across each of the counties in which the cities are located, as well as for the entire U.S. The focus counties in which are cities are located have populations ranging from 307,117 (Albany) to 1,248,743 (Austin). Two of the counties have white alone populations higher than the U.S. average: Genesee County (Flint) (72.5%) 5 and Albany (71.6%). Only Cleveland (as well as the city of Flint, though not Genesee County) has a population of black or African American alone (28.8%) that exceeds the U.S. average (12.3%). Both Austin and Denver have Hispanic or Latino (of any race) populations (33.9% and 29.7%, respectively) that exceed the U.S. average (18.3%). All of the counties (cities) except Genesee County (Flint) have populations 25 years and over with a bachelor's degree or higher that exceed the U.S. average. Cleveland and Genesee County (Flint) both have median household income levels ($49,910 and $48,127, respectively) below the U.S. median income ($61,937). In addition, although none of the cities had an unemployment rate exceeding 5% prior to the pandemic (Genesee County -Flint -had the highest rate of the five cities in January 2020), by May 2020 unemployment rates had jumped to 9.3% (Albany), 11.4% (Denver), 11.6% (Austin), 17.9% (Cleveland), and a staggering 24.5% in Genesee County (Flint). Table 2 provides the Feeding America estimates of the 2020 projected overall food insecurity rate for each of the five cities, along with the 2020 projected child food insecurity rates and projected increases in overall and child food insecurity from 2018-2020. As might be expected from its increase in unemployment, Flint has the highest projected overall food insecurity rate (21.0). More surprising, Cleveland has the highest projected child food insecurity rate (30.3), Albany has the highest projected percent increase in food insecurity (51.2), and Denver has the highest projected percent increase in child food insecurity (71.4). Each of the five project research teams conducted semistructured interviews and/or focus groups from June 15 to July 1, 2020 with key informants with whom they had preexisting relationships. 6 Each interview or focus group consisted of five open-ended questions (figure 1) that were developed to help gain an understanding of local policy responses, as well as perceptions of effectiveness by local decision makers and emergency response providers. In addition, when available, the research teams collected and reviewed internal documentation on food needs assessments, impacts, or future plans. Using purposive sampling (Yin 2015) , we selected key informants based on their intimate involvement with COVID-related emergency food service provision, particularly to households with K-12 aged children, including members of emergency food task forces and operations, city and county employees, food service leaders from city school districts or in-school feeding These data are calculated using the model developed by Feeding America for their Map the Meal Gap, which applies projected changes to annual unemployment and poverty rates to develop their food insecurity estimates. They argue that while the Map the Meal Gap regression model does include other variables that will change in magnitude over time, the most significant changes due to COVID-19 will be in unemployment and poverty, as jobs are lost and incomes decline (Gundersen et al. 2020) . 1 ""2020 Projected Overall Food Insecurity Rate."" Feeding America, June 3, 2020, www.feedingamericaac tion.org/the-impact-of-coronavirus-on-food-insecurity/. 2 "" 2020 Projected Child Food Insecurity Rate."" Feeding America, June 3, 2020, www.feedingamericaac tion.org/the-impact-of-coronavirus-on-food-insecurity/. programs, and senior employees at food banks. Given the variation in conditions and existing policies, programs, and key institutions across sites, the positions of key informants differed. The objective was to obtain diverse experiences and perspectives on different spaces in the food system by leveraging relationships and local knowledge at each site based on the ongoing research by the five project teams. Researchers from each site conducted the interviews and focus groups. Once all the interviews were complete, they compiled notes and asked follow-up questions for clarification. Using a structural coding method (Saldaña 2015) , we then coded data into themes focused on perceptions of effectiveness. As schools closed due to COVID-19, the case study school districts developed different strategies to support emergency feeding programs for kids and families, given that there were no clear federal mandate to continue feeding students and no guidelines for effectively executing feeding programs (Kinsey, Kinsey, and Rundle 2020) . Further, the relaxation of federal rules provided incredible flexibility in the types of reimbursable programs that local education authorities could implement. Here we document some of the ways in which our focus cities responded. 7 7 Working with our key informants, our research team tried to estimate the meal gap during COVID as a measure of how these emergency feeding strategies impacted effectiveness. We focused on the number of kids that were eligible for free and reduced priced meals through the NSLP that continued to receive meals post-school closures. However, starting in March 2020, the school districts all received waivers from the USDA FNS that allowed them to feed all students under eighteen without any documentation. Accordingly, the answer to this question is unknowable. Several of the case study cities' school districts decided to focus on feeding programs at selected school sites. Cleveland Metropolitan School District, for example, established emergency food service provision at twenty-two of their ninety-one sites. Similarly, Denver Public School District set up feeding sites at twenty-four of 162 school locations. However, the districts quickly realized that with limited feeding locations, they needed to support enhanced access to transportation. Denver, realizing it was only reaching about 25% of the free and reduced-price lunch eligible children that they usually fed as part of the NSLP, decided to add thirty-six delivery locations (drop-off sites), which were strategically determined based on the highest concentrations of student populations eligible for free or reduced-price meals. Cleveland started utilizing its school busses to pick up students each day (between 11:30 a.m. and 1 p.m.) to take them to the sites; if no students show for an entire week, then the route is canceled. The City School District of Albany added a home delivery option but became quickly overwhelmed by demand and had to close new registrations. As an alternative to limiting the number of sites available, some districts offered meals on selected days of the week. The Flint Community Schools, for example, was initially designed to feed kids every day, but the program transitioned to distributing three breakfasts and three lunches on Tuesdays, and four breakfasts and four lunches on Thursdays. However, there was concern in some cities that limiting the days of feeding programs left gaps. Accordingly, Cleveland and Albany started to provide backpacks filled with food on Friday to meet weekend food needs. Initially the backpacks were limited to students, but the school district quickly made the decision to open the meals to any in need. Denver initially provided only breakfasts and lunches through its onsite and delivery locations but quickly developed a partnership with Denver's Office of Children's Affairs to expand the program to include dinner. Based on the responses of key informants, we identified three themes that appear to indicate the effectiveness of different local approaches to emergency food service policies and programming during the pandemic: (i) cross-sector collaboration, (ii) adaptable supply chains, and (iii) addressing gaps in services to increased-risk populations. The pandemic brought a proliferation of public and private programs and services to support emergency feeding programs. Informants noted wide variation in the effectiveness of collaborations across city partnerships, based in part on the level of partnering prior to the pandemic, as well as the ability to support effective communication. Both Denver and Austin reported strong networks that have supported effective cross-city and cross-sector coordination of emergency food service provision. Prior to the pandemic, the City and County of Denver participated in calls with food rescue organizations to support coordination of efforts to address improved food security outcomes. Although these prepandemic meetings were limited in scope, they built trust across food rescue organizations. Once the pandemic started, the City and County of Denver organized an Emergency Operations Center, including a child food security subteam Emergency Food Provision for Children and Families during the COVID-19 Pandemic that focused on ""needs"" and ""haves"" coordination-for example, which of the partners need or have access to transportation, storage, food, bags and boxes, sanitation supplies, and so on. Key informants noted that coalescing this group was made easier because many in the group had pre-existing relationships through the prepandemic group, and this cross-sector collaboration has helped address gaps in emergency food service provision across neighborhoods while also supporting new collaborations and partnerships. The Austin-Travis County Food Policy Board has been in existence since 2008 and has several working groups, including a Healthy Food Access Working Group. While pandemics and emergency response were not necessarily a key focus of the Working Group, its existence prior to the pandemic has helped to create and foster a transdisciplinary network. Once the pandemic started, Austin Public Health and Austin's Office of Sustainability began leading the Food Access Task Force as a strategy group within the Social Services Branch of the Emergency Operations Center. Informants noted that the pre-existing network of the Healthy Food Access Working Group has been incredibly helpful for learning about and coordinating initiatives and supporting the diffusion of information and resources in a pandemic environment. The Food Access Task Force now includes over seventy-five participating organizations, with a distribution list of over 200 individual contacts. Like Denver, key informants note that this type of collaboration and trust has facilitated ""needs"" and ""haves"" coordination related to emergency food access and enhanced communication of critical food access needs. Further, informants report that broad, inclusive collaboration built upon longstanding relationships has helped to support strategic placement of additional emergency food sites in underserved areas. Key informants in Flint, on the other hand, noted a lack of coordination across efforts, even though many organizations were working towards similar goals. Some of these challenges, particularly a lack of trust in government and external actors, date back to the Flint Water Crisis that began in 2014. During the water crisis, organizations were forced to work together in order to successfully navigate the influx of media attention and financial resources coming into the city. In the context of the pandemic, however, informants reported limited outside resources incentivizing collaboration. In addition, they hypothesized that the inability to get together in-person hindered efforts in collaboration that had previously been navigated at in-person events centered around the faith community; many residents lack access to the technology necessary for virtual communication. The lack of coordination has reportedly resulted in the inefficient use of resources. Informants reported that the primary request from pandemic-related small grant programs was funding to support transportation for emergency food service delivery. Many of these efforts were funded in Flint without a requirement for coordination across projects, and Flint lacked a forum for this conversation. As a result, groups designed and implemented their own plans, resulting in redundant efforts. Two supply chain issues emerged that appear to impact the effectiveness of emergency feeding programs in the five studied cities. First, larger networks with more buying power appeared less likely to experience supply chain challenges relative to smaller programs with more limited buying power. As an example, at the beginning of the pandemic, several cities reported that food banks faced challenges with their supply chains. Part of the challenge was that donations from grocery stores declined as consumers hoarded products. Flint informants noted that they had to source food from much further away and pay extra transportation fees, and Cleveland respondents reported that the food bank required increased lead time to get food to Cleveland because truckers were backlogged and access to freight was less certain. Perhaps due to these supply chain issues, several cities reported that Feeding America, the nation's largest domestic hunger-relief organization, issued advice and emergency operations plans to its national network of more than 200 food banks recommending that they move to a system that focused on their bigger partners so they could move food more efficiently; inherently, moving a small amount of food to a food pantry is not very efficient. 8 Anecdotally, this likely contributed to the closure of 35%-50% of the small pantries across the larger US cities. In Denver, the food bank was able to move double to triple more food than usual, even though as of April, 2020, only 62 (58%) of its pantries operating before the pandemic were still in operation (prior to the pandemic there were 106 food pantries in the City of Denver) (see figure 2) . Part of the reason that many of these smaller pantries closed was their inability to access food through their food bank partners. Key informants noted that the fact that the food banks and pantries could move much more food through just over half the number of pantries says something about the inefficiencies of these pantries. Additionally, if food banks are seeing increased demand and making up the gap between what families are able to afford and what they need, then more food bank distributions mean that the gap has widened. The other challenge that reportedly emerged from these supply chain issues is that nutritional quality may have suffered, particularly relative to the strict standards of the NSLP. Flint Community Schools, for example, noted that they had to rely on frozen food items, as sometimes up to half of the products they ordered from suppliers did not arrive. Second, feeding programs that rely on volunteer labor or were unable to develop cross-sector partnerships to fill gaps appeared to experience challenges in their ability to provide emergency food. Each city noted that despite increased need, fewer of their volunteers and food service workers were available because they are often older or particularly vulnerable to This led many people to stop volunteering or step away from their jobs because of personal health and safety concerns. Cleveland informants noted that the lack of a volunteer or paid workforce was likely the reason that the school district was one of the few summer meal programs, out of 187, that was operating during the pandemic. In Albany, the food bank opted not to participate in the summer food service program because it was too demanding for its staff and they did not feel they had the capacity to implement it in a safe way (the food bank opted to increase its backpack program instead). Flint informants noted that before the pandemic there were about ninety-five food service employees preparing and serving breakfasts and lunches for Flint Community Schools. Due to health concerns of an elderly workforce, they are now operating with forty-two employees despite the increased number of meals served. Both Albany and Cleveland noted that they leveraged their highly successful new cross-sector partnerships to make up for the lack of food service workers and volunteers. The National Guard, for example, has stepped in to provide support with meal service provision in both cities. Cleveland informants noted that there are over seventy National Guard members providing support, including making 500 meal deliveries per week to families who are homebound. COVID-19 has highlighted how long-standing systematic health and social inequalities have put some racial and ethnic minority groups at increased risk (CDC 2020a). Further, although the relationship between race/ethnicity and food insecurity is intertwined with other established determinants of food insecurity, including poverty, unemployment, incarceration, and disability, the concentration of social and economic disadvantage among people of color over the life course is a significant driver of higher rates of food insecurity (Odoms-Young 2018; Coleman-Jensen et al. 2019) . Accordingly, all key informants were asked if they saw differences or gaps in emergency food service provision based on neighborhood demographics. Several cities could not respond to this question or noted the need for additional data in order to respond accurately. In Albany, although informants highlighted challenges-for example, dietary restrictions (e.g., for those with diabetes, which disproportionately impacts Black, Asian, and Hispanic Americans; CDC 2020c)-the City of Albany determined that considering dietary needs and restrictions would be a hurdle for getting food to people quickly. Both Denver and Austin, however, discussed the prioritization of documenting unmet and emerging needs and identifying plans to meet those needs as part of their Emergency Operations Centers. We postulate that the enhanced ability of Denver and Austin to confront this important issue may be due to strong cross-sector collaborations. The inability to understand and address gaps in service indicates less effective emergency food service provision. In Austin, the Office of Sustainability food team is using data to inform food access planning and policy initiatives. With its partners, the city created a map of emergency food resources to document the availability and location of emergency feeding operations and school meal sites. Staff are currently working to further identify populations with the highest food access needs. In the first phase, analysis of United Way 2-1-1 call data identified areas and populations with food needs that have increased significantly in response to COVID-19. Results from this analysis, along with a data scan and gap analysis of existing data collection efforts, will inform primary data collection in the coming months. The second phase will prioritize targeted outreach to ensure that the needs of hard-to-reach communities and other high-need populations are captured and documented. Utilizing March and April 2020 data, most emergency food services are located in lower-income, predominantly racial/ethnic minority, and urban zip codes. In each of the Denver internal food assessments that the research team reviewed, Denver calls out that ""gaps in city-sponsored and communitybased food programs likely now exist for socially vulnerable populations that are in isolation or quarantined, those without internet access to food resource information, English Language Learner populations, and undocumented immigrants or refugees."" 10 As of June 2020, Denver's plan to support the food needs of these populations included (i) developing a food security recovery plan in concert with a broader plan for socially vulnerable populations, (ii) incorporating an equity approach into the food insecurity strategy for COVID-19 recovery, and (iii) developing a comprehensive strategy to meet the basic needs of socially vulnerable home-bound populations.@story_separate@Geographic diversity and variation in COVID-19 prevalence require solutions for feeding children that are flexible. Federal guidance on best practices for handling meals to simultaneously ensure continued program participation and reduce the spread of COVID-19 is also needed. In the absence of federal guidance, cities quickly developed their own programming and policies, leveraging additional resources and waivers provided by the federal government to result in a diverse patchwork of emergency feeding programs to support children and families across the US. While local officials adapted to rapidly changing conditions, school officials in particular are not trained to design effective food policies, and the patchwork approach may have left some families with children behind. This article uses interviews, focus groups, and a document review to provide insight into local emergency feeding programs and policies developed in five cities to serve kids and families 10 One Denver key informant mentioned that a challenge in serving the immigrant and refugee population is that early in the pandemic, personnel from the U.S. Immigration and Customs Enforcement were waiting for undocumented individuals outside of one of the Denver Public School feeding sites. The informant believes that despite the lack of media attention, word about this incident spread throughout several of the immigrant and refugee communities, inciting fear in these populations and making it more difficult for the city and community-based feeding programs to effectively serve these populations. during the pandemic. Based on our qualitative analysis, we find that the effectiveness of local approaches appears to depend on (i) cross-sector collaboration, (ii) adaptable supply chains, and (iii) addressing gaps in services to increased-risk populations. Although we agree that the heterogeneity of needs and food environments across the US necessitates a decentralized approach, more direct guidance from the federal government on best practices to support the system of emergency food service provision may have improved the effectiveness, or at least the efficiency, of local programming and policies. For example, the fact that at least three of the cities' schools started with a specific feeding plan before changing course is indicative of the fact that their initial strategies were not effectively meeting the needs of their populations. Further, although the relaxation of federal nutrition standards may have been necessary given supply chains and other challenges, there are likely trade-offs given the dependence of some households with children on emergency food service provision. As data becomes more widely available postpandemic, quantitative assessments and complex system modeling evaluating the strategies of different localities in providing emergency food to children and families are needed to help better reflect upon best practices and recommendations for the future, including potential trade-offs between emergency food service provision and dietary quality. In addition, each of the local approaches illustrates the importance of a systems perspective in emergency food service provision. For example, several cities noted that separate programs for people out of work and kids makes it more difficult for local entities to figure out how to feed entire families and pull together the requisite resources. Lockdown and shelter-in-place policies impact volunteers and food service employees, which reduces the availability of programming; increases the burden on schools, food banks, and pantries; creates the need for additional cross-sector partnerships, such as with the National Guard; and exacerbates mental health concerns for those still at work.","As lockdown and school closure policies were implemented in response to the coronavirus, the federal government provided funding and relaxed its rules to support emergency food provision, but not guidance on best practices for effectiveness. Accordingly, cities developed a diverse patchwork of emergency feeding programs. This article uses qualitative data to provide insight into emergency food provision developed in five cities to serve children and families. Based on our qualitative analysis, we find that the effectiveness of local approaches appears to depend on: (i) cross‐sector collaboration, (ii) supply chains, and (iii) addressing gaps in service to increased risk populations."
"Medicinal plant species are known to be in use since time immemorial for the treatment and cure of human and animal ailments. Though their use and practice registered a decline with the advent of antibiotics and sulfa-drugs, the toxicity and harmful effects associated with synthetic drugs and antibiotics have brought the herbal systems of medicine again to the forefront of healthcare system. According to WHO and other reports (WHO 2002; Willcox and Bodeker 2004) , around 80% of the global population still relies on botanical drugs and there is speculation that more than two billion people may be heavily reliant on medicinal plants (Lambert et al. 1997) . This system plays prominent role in the strategy to contain and treat severe acute respiratory syndrome (Wen et al., 2003) . Vinblastin and Vincristine of Catharanthus roseus G. are potent anti-cancer agents and are the first agents to advance into clinical use for the treatment of cancer (Cragg and Newman 2005) . The discovery of paclitaxel derived from Taxus brevifolia Nutt. (Taxaceae), is another evidence of the success in natural product drug discovery. Two most important anti-malarial drugs quinine and artemisinin are derived from traditional medical knowledge in Peru and China respectively. Survey reports showed that 78% of patients living with HIV/AIDS in the USA use medicinal herbs (WHO 2002) and similar patterns have been reported in other countries. Other systematic studies on efficacy are slowly emerging suggesting antiretroviral, immunomodulatory and opportunistic infection reducing effects of traditional management methods (Liu 2007) . Apart from general healers, traditional orthopedic practitioners, birth attendants, poison healers, spiritual therapists, mental health providers, healers specialized in eye, pediatric conditions, skin diseases etc., are some of the specialty areas (Payyappallimana 2010) . The international trade of herbal products is one of the major forces in the global economy and the demand is increasing in both developed and developing countries. Survey of literature reveals that more than 1000 companies are engaged in the production of herbal products with the annual revenues in excess of US$60 billion (Newmaster et al. 2013) . In North America, herbal medicinal market is considered to constitute the mostly rapidly growing segment (Gutierrez et al. 2004) , with over 29,000 herbal substances (Astin et al. 1998; Kaye et al. 2000) generating billions of dollars in trade. These statistics are the direct indication of the rapid growth (approximately 15% per year) in the market place from natural plant products and broadening consumer base which show interest in herbal products from different countries including India. The value of botanical related trade in India is about US$10 billion per annum with the annual export of US$1.1 billion (Singh et al. 2003 ). China's annual herb drug production is worth US$48 billion with annual export of US$3.6 billion (Handa 2004) . India is ranked third in the herbal medicine category with less than 2% global market share. The Indian market is growing at 15-20% per annum-Rs 7000 million or $150 million (www.indianmedicine.nic.in). Therefore, massive demand of herbal medicinal system at both national and international level has resulted in renewed interest of biologists in this field to maintain the quality and purity of herbal raw material and finished products. The prime cause of the problems associated with the standardization of medicinal plants is due to reasons of complex composition of drugs used in the form of whole plants, plant parts or extracts obtained there from. Therefore, first step is to make reproducibility and minimal batch-to-batch variation a desirable quality of any herbal remedy, and side-by-side initiating steps towards use of authentic starting material. In ancient days, the activity of herb procurement, storage, preparation of drugs and its distribution remained mainly the responsibility of local physicians (Vaidyas and Hakims). They were very well versed with the identity of medicinal plants as they had very close contact with nature. But gradually in the process of urbanization this contact with nature was lost and, consequently, the knowledge about the identification of medicinal plants has also deteriorated to a great extent. A perusal of literature available on medicinal plants (Sivarajan and Balachandran 1994) reveals that different workers have interpreted ancient texts differently resulting in coining of same Unani or Ayurvedic name for more than one plant and different names for the same drug plant. This way a number of medicinal plants have controversial botanical identity due to the existence of homonyms (same name for different drug plants) and synonyms (different names for same drug plants). Such situation has also been compounded by linguistic diversity, and prevalence of local dialects. For example, different botanically identified plants are being used for the same traditional drug and vice-versa in different parts of India. Thus, there exists at present, a chaotic state of botanical and vernacular nomenclature with regards to medicinal plants. Due to ambiguity of plant names, over-lapping of data occur in chemical or pharmacological information where the botanical identity of market samples of crude drugs taken up for research is not ascertained. This has put many drug plants in controversial position and their identity has become doubtful. In addition to ambiguity in nomenclature, the crude drugs sold in the market are adulterated or substituted by quite unrelated plant materials. Many researchers have examined a number of market samples of crude drugs used in Indian systems of medicine (Afaq 1999) and observed that the prevalence of adulteration is such that quite unrelated plants are being sold in the crude drug markets in place of genuine ones. For example, Anemone flowers are sold as 'Banafsa' (Viola spp.); paper colored, scented and cut into small pieces as 'Saffron' (Crocus sativa); Malva rotundifolia as 'Brahmi' (Centella asiatica); Parthenium hysterophorus, an obnoxious weed, as Shahtara '(Fumaria indica); culm of different grasses as 'Chirayata' (Swertia spp.); Leea alata as 'Manjith' (Rubia cordifolia), and so on. It is invariably found that the adverse effects/reports are not due to the intended herb, but rather due to the presence of an unintended herb (De Smet et al., 1992) . The credibility of any system of medicine depends not only on the skill of the physician but also on the quality of medicine administered to the patients. Correct identification of plants forming the drug is a prerequisite and fundamental to whole realm of medicine and science. Thus, authentication of botanical source of plant taken up for research or medicinal use is a necessity to achieve satisfactory results and also to maintain efficacy and therapeutic property of the preparations in which these plants are used. We have therefore, tried to present a comprehensive review on strategies related to identification of medicinal plants.@story_separate@DNA-based markers that are based on analysis of the unique genetic structure are undoubtedly higher level markers and have the upper hand over other marker systems because these are not affected by age, environmental factors and physiological conditions. Moreover, these markers are not tissue specific and thus can be detected at any stage of plant development. Compared with phenotypic and chemical markers, DNA-based technology can provide an efficient, accurate and cheaper means of testing the authenticity of hundreds of samples simultaneously as these can be amenable to automation. DNA based authentication of medicinal plants can be useful as a tool for quality control and safety monitoring of herbal pharmaceuticals and neutraceuticals and will significantly add to the medical potential and commercial profitability of herbal products. A genetic marker may be defined as gene or a nucleotide sequence on a chromosome that has the potential to differentiate cells, individuals or species. As the DNA sequences are highly specific, they can be identified with the help of the known molecular markers which can find out a particular sequence of DNA from a group of unknown. A vast numbers of molecular markers ( Table 1) Each of the techniques are targeted towards a particular component of the genome or is completely arbitrary, face unique methodological, technical and material challenges; thus no DNA marker can be considered ideal. The use of a particular marker is therefore, dependent on objectives of the researcher. RFLPs ( Fig. 1 ) are considered as one of the first developments in the field of genetic markers, responsible for initiating the field of molecular genetics. The technique is based on the principle of variation that is present due to occurrence of mutations in restriction enzyme binding and cleavage sites; additionally, any re-organization in the genomic region flanked by restriction sites that also disrupts their distribution and thus causes polymorphism also contributes to RFLP. The digested fragments vary in size, have to be separated using Southern blot analysis and accordingly visualized by hybridization to specific probes which could be homologous or heterologous in nature. Alternatives of Southern analysis in RFLPs are polymerase chain reactions. When the flanking regions of nucleotide sequence are known, the region meant for RFLPs could be amplified through polymerase chain reaction. However, it must be kept in mind that If the length polymorphism is caused by a relatively large (N approx. 100 bp depending on the size of the undigested PCR product) deletion or insertion, gel electrophoresis of the PCR products should reveal the size difference and when the length polymorphism is caused by base substitution at a restriction site, PCR products must be digested with a restriction enzyme to reveal the RFLP. The positive point of this marker is its co-dominant nature. Like other DNA based markers, there is ample literature (mainly PCR-RFLP) that suggests use of this technique in the identification of medicinal plants. For example, Six plant species -Desmodium giganicum, Aegle marmelos, Solanum xanthocarpum, Solanum indicum, Tribulus terresteris, Oroxylum indicum were identified through polymerase Chain Reaction-Restriction Fragment Length Polymorphism (PCR-RFLP) and the regions amplified were Internal transcribed spacer (ITS) with the aid of ITS1 (F) and ITS4 (R) primers . The same technique has been applied on Boerhavia diffusa L. in which 700 bp of ITS region was obtained via polymerase chain reaction and when this region was restricted with Msp I, provided four unique fragments that differentiated this specie from T. portulacastrum and T. monogyna . Feng et al. (2010) differentiated Angelica sinensis from its seven different adulterant Angelica species; here a pair of primers specific for ITS region were designed which amplified 520 bp from the adulterants and no products was amplified with the DNA of A. sinensis.  • The limited sensitivity of detection associated with RFLPs is the serious problem; because it is very difficult to get valid profiles from trace biological evidence or from samples that are too aged or have significantly compromised environmental insults. • RFLP is time consuming, involves radioactivity, and is laborious and difficult to automate. However, this can be overcome by PCR-based DNA typing systems. Simple Sequence Repeats (Fig. 2 ) are comprised of 2-5 bp DNA monomeric units that are repeated multiple times at a specific locus. Such markers are completely co-dominant; used for fingerprinting, marker assisted selection, kinship, breeding behavior such as selfing and outcrossing, establish population structure etc. Microsatellites are locally tandemly duplicated, and are also found dispersed throughout the genome. Thus it becomes important to amplify a specific microsatellite in a locus specific manner using locusspecific primers. The primer designing involves identifying microsatellites, either is manual examination in case the sequences are small or of limited length, or using automated tools for locating microsatellite such as microsatellite finders. However, depending upon the research objectives, either unique flanking regions can be used for primer designing where the products are co-dominant, or microsatellites can themselves be used as primers where the products generated act as dominant markers. Microsatellite discovery also involves cloning microsatellite-enriched library and sequence analysis. The clones containing repeats can also be identified through hybridization of fluorescent labeled probe with the repeats. DNA segment containing the microsatellites is then sequence verified and employed for primer designing. Microsatellite markers are valued for their hyper-variability which occurs because these regions can add or delete one or two nucleotides because of the slippage during replication. Research reports suggest involvement of microsatellites in authentication and identification of medicinal plants. Hon et al. (2003) applied 16 microsatellites to analyze 150 and 40 American ginseng and Oriental ginseng roots respectively. Of the 16 microsatellites, 9 could differentiate Chinese samples from American ginseng. Capsicum species which are commonly used as spices have been analyzed through microsatellites; the study involves 800 lines collected from different locations of Central and South America. SSR primers (5751 pairs) were designed and similarity search with tomato genome resulted successful mapping of 2245 C. annuum markers onto the tomato genome. Ninety six were found to span entire tomato genome and selected for further analysis. Sixty markers showed polymorphism in Capsicum lines and based on this, the 192 lines were grouped into five clusters. Additionally, plastid genes, matK and rbcL, divided the Capsicum lines into 3 main groups; over all, 19 marker loci reveal genotype specificity to species and clusters (Shirasawa et al., 2013) . • It requires much time and cost to isolate and characterize each SSR locus when the DNA sequence of a plant species is not available. • Another drawback is the occurrence of null alleles. This may be due to the poor primer annealing because of nucleotide sequence divergence, inconsistent DNA quality or low DNA quantity (Ellegren 2004) or it might be due to mutations in the primer binding site. This can cause difficulty in the determination of allelic and genotypic frequencies and an underestimation of heterozygosity (Kumar et al. 2009 ). In RAPD technology (Fig. 3) , random short synthetic oligonucleotide primers (10-12 base pairs) are used to amplify the genomic DNA through polymerase chain reaction under low annealing temperature. The amplicons generated are separated on agarose gels based on sizes. As stated that primer size is short, therefore annealing temperature range is 28-38°C. At this temperature range, primers anneal wherever they find complementary sequences from the genome and the profile of amplified DNA vary in size that depends on nucleotide sequence homology and the primer at the end of each amplified product. As it is obligatory that primers for RAPD are arbitrarily chosen, therefore, a minimum of 40% GC and the absence of palindrome sequence is a prerequisite for RAPDs. Majority of the RAPD fragments are due to the amplification of one locus, furnishing two types of polymorphismsthe band could be present (1) or absent (0). The bands obtained may vary in intensity which could be due to the differences in copy number or relative sequence abundance; therefore, may work for distinguishing homozygote dominant from heterozygote because more bright bands are expected for the former. However, some workers (Thormann et al. 1994) have found no correlation between copy number and band intensity. The possible occurrence of fainter bands could be due to the varying degree of primer mismatch. The other drawback associated with RAPD markers is the low reproducibility. However, this problem could be overcome through the choice of an appropriate DNA extraction protocol to remove any contaminants, by optimizing the polymerase chain reaction parameters, by testing several oligonucleotide primers and most importantly scoring only reproducible DNA fragments. RAPDs have been widely used for authentication of plant species of medicinal importance. Two varieties of S. marianum which are very difficult to distinguish in dried conditions could be differentiated with RAPD. The banding pattern amplified with primer OPP-10 contained two (600 and 1000 bp) characteristic bands; primers OPG-03, OPC-17 generated two unique bands (1000 and 300 bp). This profile specific for S. marianum var. album could differentiate it from S. marianum var. purple (Abouzid 2014) . Similarly, two species of the parasite Cuscuta (C. reflexa and C. chinensis) have been distinguished with primers OPC-1, OPC-02, OPC-03, OPC-04, OPC-05, OPC-06, OPC-07 and OPC-08 (Khan et al. 2010a ). Ali et al. (2013) , while characterizing Clitoria ternatea at inter-zonal level identified complete monomorphism with primer OPN-02, therefore, the identification of this herb with OPN-02 is the good choice. Molecular characterization of Convolvulus pluricaulis revealed that primer OPN-09 is the specie specific primer for the herb (Ganie et al., 2015) . A common band of 2.2 kb amplified by Primer OPN-05 was found when different accessions of Evolvulus alsinoides were studied through RAPD analysis (Ganie and Sharma 2014) . Laboratories with limited budget prefer RAPDs as the entire process is only dependent on thermal cycler and gel electrophoresis unit. RAPDs can efficiently differentiate taxa below the species level (Choo et al. 2009 ), because it reflects both coding and non-coding regions of the genome. • RAPD is a less reproducible marker. Because the annealing temperature for such marker is low (28-38°C) therefore, there are chances of wrong annealing. • It is a dominant marker This technique (Vos et al., 1995) which is a combination of both RFLP and RAPD is based on the detection of restriction fragments by PCR amplification and can be used for DNA of any origin or complexity, and quality (Fig. 4) . The fingerprints are produced without any prior knowledge of sequence using a limited set of primers. Fragments are generated with two different end sequences which form template for adapter ligation. Such adapters then form the basis for PCR which is performed using end-labeled nested primers with selective nucleotides. The amplified products are electrophoresed in a 6% denaturing polyacrylamide gel and autoradiographed or detected through fluroscent detection. AFLPs are generally considered highly valued marker for analyzing the genetic diversity for both animal and plant systems compared to authentication reports. Seven specific fragments identified with the primer combinations E-ATC + M-AG and E-GCA + M-GT could serve as the genetic markers for Aloe vera (Tripathi et al. 2011) . Although the three species of the genus Echinacea could easily be distinguishable in fresh and intact conditions, but it becomes very tough to differentiate them in commercial preparations particularly ground, dry plant parts of E. purpurea (valuable species for chemotherapeutic properties) mixed with the other two species. Therefore, Russi et al. (2009) used fresh material collected from cultivated Echinacea spp. for the discrimination of these species by AFLP. E + CAC/M + AAT and E + CAC/ M + AGC generated 13, 9, and 4 or 7, 5, and 5 specific fragments for E. purpurea, E. angustifolia, and E. pallida, respectively. Passinho-Soares et al. (2006) identified specie specific bands of different species of the genus Plectranthus. During the study 2, 2, 1, unique bands were confirmed for P. barbatus, P. grandis and P. ornatus respectively with the primer combination EcoR 1-CAC + Msc 1-GCA. Applying AFLP technique, Gowda et al. (2010) using P + GC/M + CTA combination, found three bands of the range 500-700 bp in Embelica ribes and could be considered unique to this species. In the same study, P + CA/ M + CTG combination yielded two unique bands between 500 and 517 bp for E. tsjeriam-cottam. • Like RAPD markers AFLPs are also dominant. • The method needs purified and high molecular weight DNA. Also, the procedure involves harmful radioactive materials; however, this can be overcome by using fluorescent tags. 6. Inter-simple sequence repeats (ISSR) ISSR (Fig. 5) is one of dominant markers involved in amplification of DNA segment present at an amplifiable distance in between two identical microsatellite repeat regions oriented in opposite direction. This technique relies on the principle of using microsatellite as primers which target multiple genomic loci to amplify inter simple sequence repeats of the genomic DNA of different sizes. Microsatellite used as primers for ISSRs are di-penta nucleotide. The primers for the ISSRs could either be unanchored or anchored at 3`-5`end having 1-4 degenerate bases extended in to the flanking sequences. Compared with RAPDs the size of the primers in ISSRs are much longer (18-25 mers), which permit the annealing of the primers at higher temperatures leading to higher stringency. The DNA fragments obtained are generally 0.5-2.0 kb long and could be detected both by agarose and polyacrylamide gel electrophoresis. Survey of literature reveals that ISSR markers show high reproducibility than RAPDs (Kojima et al. 1998 ) although it varies with the detection method used. Fang and Roose (1997) reported greater than 99% reproducibility level after performing repeatedly tests for ISSR markers with the DNA samples of the same cultivar grown in different locations, DNA extracted from different aged leaves of the same individual, and by performing separate PCR runs. However, in other studies, the reproducibility of ISSRs amplification products are in the range of 86-94%, with the maximum when the priority is given to polyacrylamide gel electrophoresis and AgNO 3 staining over agarose gel electrophoresis and faint bands are totally excluded while scoring the bands. The species of Rheum viz. -Rheum officinale Baill., Rheum palmatum L., and Rheum tanguticum Maxim. ex Balf are very difficult to distinguish on the basis of arial morphological and anatomical studies. Though root and rhizome is prescribed to have medicinal importance, however to distinguish these plant species, the aerial parts leave doubt regarding the differentiation of the three species. Wang (2011) used ISSRs to authenticate these Rheum species with different ISSR primers. A successful attempt by Tamhankar et al. (2009) (c); [Prior to selective amplification, pre amplification is carried out with a single nucleotide extension, followed by selective amplification using three 3-bp extension] (Mueller and Wolfenbarger 1999) . market samples and the three authentic species was amplified using ISSR primers and the profile obtained was compared and the differentiations were obtained with primers 808 and 809. The roots of Cissampelos pareira L. var. hirsuta (Buch.-Ham. ex DC.) generally named as Patha in India is substituted with two other species, viz., Cyclea peltata (Lam.) Hook.f. & Thomson and Stephania japonica (Thunb.) Miers. ISSR profiles (Vijayan et al. 2014 ) distinguished genuine raw drug of 'Patha' from its substitutes/adulterants to guarantee the quality and legitimacy of this drug in the market. • ISSR markers do have more value compared to RAPDs; however, the marker has the reproducibility issues. • This marker is also dominant. The most important marker for authentication of medicinal plants is SCAR (Fig. 6) . It is sequence-based mono-locus and a co-dominant marker in which forward and reverse primers are designed from the particular region of a cloned AFLP, RAPD and ISSR DNA fragment linked to a trait of interest. SCAR may be a specific gene or random DNA fragment in the genome of an organism and the primers for amplification are located at any suitable position within or flanking the unique AFLP, RAPD, ISSR amplicon. SCAR is fast, reliable and highly reproducible marker used in molecular biology. The designed primers are used to identify the target species from the pool of related species by the presence of a single, distinct and bright band in the desired sample (Kiran et al. 2010) . The length and GC content is also concern for SCAR markers and generally 20-25 oligonucleotide bases are sequence specific (Kiran et al. 2010) . SCAR markers developed from AFLP and SSR though is more reproducible but simultaneously such markers are costly, time consuming and more difficult (particularly in AFLP where silver staining is required for the elution of DNA fragment from polyacrylamide gels). To convert a selected unique RAPD, AFLP, ISSR or SSR band to a SCAR marker, each unique band is eluted, cloned and sequence verified. The nucleotide sequence of the unique DNA band is analyzed for uniqueness by comparing with the known DNA sequences available at various databases for synthesizing specific SCAR primers. These markers have the advantage of being co-dominant and are highly reproducible. Molecular biologists prefer these markers and the most recent data shows that these markers are actively used to authenticate medicinal plants. Yadav et al. (2012) confirmed a 589 bp species specific band with RAPD primer OPAA-3 in Bacopa monnieri accessions and not found in other adulterant candidates. For further processing a pair of SCAR primers (between 406 bp of 589 bp sequence of RAPD amplicon) was designed. The PCR confirmation resulted a distinct band from Bacopa monnieri and not in the adulterants. Seethapathy et al. (2014) authenticate Ativisha (Aconitum heterophyllum) and Musta (Cyperus rotundus) using nrDNA ITS sequence based SCAR markers and when market samples were examined it was found that SCAR primers (Cyr- FP and Cyr-RP) could identify tissue sample containing 750 μg to 4.76 mg/100 mg of Musta in complex mixtures of DNA extracted from commercial herbal drugs and it was also found Ativisha was not be identified through SCAR markers confirming that this authentic species is not used to prepare herbal drugs despite its being labeled as one of the ingredients in formulations. Abdin (2013) aimed to develop RAPD based SCAR markers for the genuine herbs, C. angustifolia and C. acutifolia and their adulterants, C. sophera and C. tora. Analysis of results confirmed that these samples were more than 50% adulterated. Fu et al. (2013) studied Lonicera japonica, a traditionally used medicinal plant by an improved random amplified polymorphic DNA (RAPD) analysis and SCAR markers developed differentiated the different accessions/populations. Similarly Li and Park (2012) while using SCAR markers ""SA06 and SB05"" differentiated Ophiopogon japonicas with an amplicon of 460 and 553-bp respectively from Liriope platyphylla; the marker SA12 amplified a 485-bp fragment specific to Liriope platyphylla. Another case is the Phyllanthus amarus Schum. & Thonn used as antipyretic, diuretic, to treat liver diseases and viral infections. Theerakulpisut et al. (2008) efficiently differentiated this specie from the less effective species which include P. debilis L. and P. urinaria Klein ex Willd. • The need for sequence data to design the PCR primers is prerequisite for SCAR markers. DNA barcoding may be defined as use of short nuclear or organelle DNA sequences for the identification of organisms. DNA barcoding has a clear goal to identify an unknown sample utilizing pre-existing classification and not to determine patterns of relationship. This technique is over now a decade old when Hebert et al. (2003) proposed that the mitochondrial enzyme CO 1 (Cytochrome oxidase 1) coding DNA could be applied to generate DNA barcode in animals. As mitochondrial genes in plant systems are slowly evolving with very low substitution rates, therefore these are not considered suitable for barcoding (Techen et al. 2014 ). An alternative is the use of chloroplast/nuclear genomes which have high substitution rates. Many chloroplast genomic regions (rbcL, matK, trnH-psbA, trnL-F, rpl36-rps8, ITS and 5S rRNA) have been evaluated in plant systems by-""The Consortium for the Barcode of Life Plant Working Group (CBOL)"" (CBOL 2009), of which rbcl is considered as universal but is having low species resolution and reverse is the case with matK; combination of these two markers could show better results. Cameron and Chase (1999) showed less specie discriminating ability with rbcl and matK when very close taxa are concerned. Hence, Li et al. (2011) included nucleur ITS to the combination matK + rbcL with the aim to have better discriminating ability in closely related species. In DNA barcoding the main focus is to find out a universal DNA sequence that must a balance of conserved sequence as well as harbor enough diversity in order to differentiate organisms. Primers are therefore designed which are complementary to the conserved sequences and flank the variable barcode sites. This process becomes problematic when the primer binding sequences have also accumulated sufficient sequence divergence over evolutionary time. It is therefore; quite difficult to identify universal primer sets that satisfy all taxonomic hierarchies. To overcome this dilemma, barcode primers should accommodate sequence variation, or degeneracy, at one or several nucleotide positions. As is obvious that there are enough chloroplast genomes in a single plant cell, so, amplification of barcode regions of rbcL and COI are higher than nuclear loci, thus minute material provides ample template to get higher quantities of product simultaneously lowering contaminant concentration that could otherwise affect PCR. The DNA sequence of chosen DNA amplicon (e.g. rbcL, COI or ITS) is required in both orientation through bi-directional sequencing to obtain a reliable DNA barcode. Several excellent reports have appeared towards authentication of medicinal plants through DNA barcoding. A very good example is of Crocus sativus, one of the most important and expensive medicinal spice products in the world. Because of its high market value, this herb is often adulterated with other spurious materials-Carthamus tinctorius L. and Calendula officinalis L. flowers, Hemerocallis L. petals, Daucus carota L. fleshy root, Curcuma longa L. rhizomes, Zea mays L., and Nelumbo nucifera Gaertn. stigmas (Jiang et al. 2014 ). Jiang et al. (2014) developed accurate detection of these adulterants in traded saffron with the application of barcoding melting curve analysis method (Bar-MCA). Another example is the discrimination of Schisandra chinensis ) at the species and population levels with internal transcribed spacer 2 (ITS2). Li et al. (2013) observed C → A substitution at site 86-bp in wild populations when compared with cultivated populations. Further, ITS 2 region clearly differentiated S. chinensis from S. sphenanthera. Other study was aimed to identify Astragalus (Gao et al. 2009 ), many of its species share morphological similarity. During this study four coding (trnH-psbA, rpoC1, rbcL, matK) and two noncoding regions (ITS, ITS2) were compared among 319 species; ITS2 and ITS barcodes were more productive towards discriminating the species. Moving forward is the case in which Peucedanum praeruptorum has been discriminated by DNA barcoding. Zhou et al. (2014) used ITS and nrDNA barcodes to distinguish it from common substitutes and adulterants. Further study about the applications of DNA markers is mentioned in Table 2 . • It has been found that DNA barcoding fail to distinguish recently diverged species (Kerr et al. 2007 ). • It is also to mention that use of barcoding depends to a large extent over the amplification of degraded DNA. This is one of the most difficult aspects because sequences characterized are longer than 500 bp  (continued on next page) Lee et al. (2010) and therefore, create problem in amplification (Min and Hickey 2007) . Hence, DNA barcoding shall not be considered universal like other conventional markers. Loop-mediated isothermal amplification (LAMP) is a molecular biology technique (Notomi et al. 2000 ) that relies on auto-cycling strand displacement DNA synthesis with Bst DNA polymerase. Unlike other DNA markers, here two primer pairs (inner and outer) are required to amplify the target gene. It has very high specificity, efficiency and rapidity and the molecular biology reports have shown these markers could amplify a specific gene from the whole genome discriminating a single nucleotide difference (Parida et al. 2008) . DNA synthesis occurs within 1 h at a single temperature which is in range of 60-66°C. Further, this technique does not demand thermo-cycler as simple incubators and block heaters are good enough to furnish the temperature for successful amplification. Gel electrophoresis is also not mandatory since LAMP products can be detected by the turbidity that come to light due to a large amount of by-product, pyrophosphate ion, being produced, yielding an insoluble white precipitate of magnesium pyrophosphate in the reaction mixture (Mori et al. 2001) . The applications of LAMP markers for medicinal plant identification, although is scarce; however, there are reports which confirm its utilization in plant authentication studies. Ganie et al. (2013) developed RAPD based LAMP markers to develop molecular ID for Nigella sativa. Taraxacum formosanum is substituted by many plant species which include Taraxacum officinale, Ixeridium laevigatum, Youngia japonica, Ixeris chinensis and Emilia sonchifolia var. javanica. Lai et al. (2015) designed four specific LAMP primers based on the nucleotide sequence of the internal transcribed spacer 2 (ITS2) and nuclear ribosomal DNA (nrDNA). LAMP amplicons were amplified and detected; here amplification of authentic plant species (Taraxacum formosanum) occurred and no such amplification in non-targeted adulterant plant DNA was observed. Twelve samples of Zingiber officinale from different regions of India were collected and screened with RAPD. A prominent specie specific DNA fragment of 780 bp was cloned and sequence verified with LAMP primers . Other examples that support application of LAMP markers in plant medicinal biology include Curcuma longa (Sasaki and Nagumo 2007) , Panex ginseng (Sasaki et al. 2008) , Catharanthus roseus . • Primer designing in LAMP technology is complex; a minimum of two primer pairs is required to identify six different regions of target gene/ DNA sequence. The advent of reversible chain-termination reaction in sequencing coupled with high resolution detection, popularly termed as Next Generation Sequencing or NGS allows concurrent sequencing of a large number of molecules therefore generating vast amount of sequence data simultaneously. The technique (Fig. 7) is based on the principle that DNA templates are first fragmented and thereafter immobilized on a solid support. These fragments are to be amplified and sequenced. Three main technologies/strategies that are in practice for NGS are commercialized by Roche/454 Life Sciences (Indianapolis, IN), Illumina/ Solexa Genome Analyzer (San Diego, CA) and Applied iosystems/ SOLiD System (orange county, CA). All of them retain their distinctive enzyme systems, sequencing chemistry, hardware and software engineering (Mardis 2008; Shendure and Ji 2008; Metzker 2010) ; also, the sequencing reads obtained with these technologies varies in total sequencing output. Among these Illumina/Solexa and Applied Biosystems/SOLiD platforms have the ability to generate tens of millions of short reads (25-35 bp) per run; whereas Roche/454, might generate a few hundred thousand to 1 million reads of 400-500 bp DNA fragments per run (Sarwat and Yamdagni 2015) . However, it must be kept in mind that Roche/454 is more advantageous regarding the identification of species because this system is more rapid and produces longer read lengths (Metzker 2010) . The technology uses pyrosequencing in which pyrophosphate ions released are detected during the addition of nucleotides by DNA polymerase (Ronaghi 2001) . The release of these ions starts off a series of reactions of which end product is to be detected by the formation of light by fire-fly luciferase. NGS technology relies extensively on use of complex algorithms for filtering, assembly and sequence analysis. Most of the commercially available tools such as DNAStar, CLCBio, GeneSpring are now quiet capable of analyzing NGS data. The advent of such rapid and in-expensive method of data generation has now allowed analysis of transcriptomes of medicinal plant species through the sequencing of their cDNA (RNA sequencing) rather to enter whole genome profiling. Transcriptome data could be helpful to provide the details of plant's response to developmental cues and the related environment. With the aid of RNA-sequencing methodologies it is possible to address questions encompassing cell type-specific transcriptomics, transcript secondary structure and gene mapping (Sangwan 2014) . Transcriptome analyses in medicinal plants furnish enormous data to screen the entire proposed metabolic pathways with massive flexibility to examine the data. Next Generation Sequencing has been employed for identifying molecular signatures in the transcriptome related to physiological functions of plant tissues. For example the leaf transcriptome of Costus pictus was sequenced applying Illumina reversible dye terminator sequencing technology and using combination of bioinformatics tools, transcripts related to anti-diabetic properties of this plant species was identified (Annadurai et al. 2012) . Yun et al. (2015) applied NGS (Roche 454 GS-FLX Titanium Platform) and developed 9 microsatellite markers for Aconitum austrokoreense, an endangered medicinal plant. The same platform was applied to find out the prime components of the biosynthetic pathway in Dendrobium officinale through the formation of ESTs (Guo et al. 2013) . Luo et al. (2010) identified the genes and their transcriptome regulation meant for the biosynthetic pathway in Huperzia serrata and Phlegmariurus carinatus with the aid of Roche/ 454 Titanium platform. Two sesquiterpenes (VoTPS1, VoTPS2) have been identified from one million transcript reads in the roots of Valeriana officinalis (Pyle et al. 2012) . Ghangal et al. (2013) identified 13,299 SSRs of the 10,980 (12.4%) seabuckthorn (Hippophae rhamnoides L.) transcripts of which the mononucleotide SSRs represented the largest fraction (56.4%) followed by di-nucleotide repeats (21.5%) and the tri nucleotide repeats constitute the least (18.9%). It is mandatory to mention that traditional full length sequencing is a better choice when the aim is to obtain full length barcodes; however, for the degraded (Shokralla et al. 2009 ) mixed species samples (Ivanova et al. 2009 ), species phylogeny (Liu et al. 2013 ) Roche/454 pyrosequencing or Illumina NGS is the best option. Further reports are mentioned in Table 3 . DNA based technology though is superior has certain drawbacks. One requirement is of high quality DNA while analyzing samples, which might be a problem for dried or processed materials. During drug-processing, there could be a change in temperature and pH that may lead to degradation (fragmentation) of the DNA, rendering PCR analysis difficult. However, depending on the degree of degradation of DNA some methods can still be used in processed materials. Again, even low content of secondary metabolites (polysaccharides, tannins, essential oils, phenolics, alkaloids, etc.) may inhibit PCR or might affect DNA isolation. As secondary metabolite content increases with the age and this becomes severe as the material gets older. Such contaminations are problematic, either they stop or minimize the activity of many enzymes, such as polymerases, ligases, and restriction endonucleases. The market samples might be contaminated with endophytic fungi that could shatter the results of dominant markers like RAPD, AFLP and ISSR and might also influence DNA sequencing; however, this can  10 Populus trichocarpa Antipyretic, analgesic and to control inflammation Expressed sequence tag based methods ""The genome of black cottonwood, Populus trichocarpa (Torr. & Gray)"". Tuskan et al. (2006) be overcome with a plant-specific primer design. DNA related methods totally fail when the herb is in capsule form or an extract. Many markers, like ITS region of the 18S, 5.8S, and 26S nuclear ribosomal cistron, might show intra-specific sequence variation because of non functional paralogous sequences (pseudogenes) and for DNA barcoding, only orthologous DNA sequences is the choice. Consequently cloning of PCR products is sometimes inevitable. In order to develop a marker for identification of taxa, DNA analysis of closely related species and/or varieties and common botanical contaminants and adulterants is necessary, which is a costly and time-consuming process. The authors declare that they have no conflict of interest.@story_separate@The genetic profile of the medicinal plant species will find applications in the quality control of the drugs obtained from these species not only by the pharmaceutical industries, but also Govt, agencies responsible for monitoring their quality. DNA markers which fill the maximum gap in solving the problem of identification, off-course is a boom to the molecular biology but is dependent over other two markers because you cannot find the efficiency of an authentic drug without chemical analysis. DNA markers are not tissue specific, is an advantage but, the same statement creates a problem when adulterants of the same plant are sold (Sometimes the flower of the plant species has the medicinal properties but instead of flowers some other part of the same plant e.g. roots, leaves etc. are sold), in such cases you simply cannot judge it by DNA markers because it will provide the same profile to all the different tissues of the same plant. In our viewpoint RAPD, AFLP, SAMPL and ISSR should not be allowed for authentication unless and until these markers are converted either into LAMP or SCAR. These markers can determine efficiently the genetic diversity of plant species. SCAR, LAMP and DNA bar-coding are ideal for medicinal plant authentication besides morphological, anatomical and chemical markers. In future, DNA markers can be used to build a reference library of traditional medicine (such as DNA sequences and fingerprints), in order to get complete rid of adulterants and spurious materials that has ruined this medicine.","Medicinal plants have been used worldwide for centuries to maintain health and to treat diseases, more so chronic diseases. However, adulteration and use of spurious materials as substitutes have become a major concern for users and industry for reasons of safety and efficacy. Therefore, authentication of medicinal plants is of utmost importance. Morphological, anatomical, chemical and DNA markers solve the problem by differentiating the genuine material from the adulterants, substitutes and spurious drugs. DNA markers use nucleotide sequences to identify species; it takes preference over the other two markers being not age dependent, tissue specific and having a higher discriminating power. Therefore, characterization of plants with such markers is an ideal approach for identification of medicinal plant species and populations/varieties of the same species. Availability of certified taxonomic specimens in herbaria is certainly required for unambiguous confirmation through final visual comparison and analysis."
"The COVID-19 pandemic has arisen in a period of increasing vaccine hesitancy in the United States. Vaccine hesitancy is defined as a delay in the acceptance of a vaccine or the outright refusal to take a vaccine despite its availability [1] Vaccine hesitancy is of particular concern when a vaccine is the primary method to mitigate the spread of a serious disease. Prior to the beginning of the COVID-19 pandemic, vaccine hesitancy was declared one of the top ten threats to global health by the World Health Organization [2] . The pandemic emerged shortly after a 2019 measles outbreak, which has since been tied to parental reluctance to vaccinate schoolchildren [3, 4] . This was the worst outbreak of its kind since 1992 [5] and since a historic low of 0.15 measles cases per million in a 2002 [6] outbreak. Several national opinion polls have found a significant portion of the US population is hesitant to take a COVID-19 vaccine. The prevalence of COVID-19 vaccine hesitancy has ranged from a quarter to half of the US population depending on the time in which surveys were conducted, reflecting the ongoing challenge of addressing vaccine hesitancy in the pursuit of herd immunity [6, 7] .@story_separate@Multiple mechanisms can contribute to the spread of vaccine hesitancy, among which online forums play an important role in persuasion [8] [9] [10] . In the past, persuasion might have occurred via a ""two-step flow,"" in which opinion leaders were integral to the adoption of people's worldviews [11] . However, with the growth of increasingly personalized and automatically customized content channels offered on the web, some scholars have observed the emergence of a complementary ""one-step flow"" of persuasion [12, 13] . In this ""one-step flow,"" web users are influenced directly from an online experience that has been algorithmically tailored to address their interests-and psychological vulnerabilities [14] . The present study is informed by the hybrid theory of Hilbert et al. [15] , which argues that while persuasion has indeed become less interpersonal, and more automated and direct, online influencers and trusted offline sources still play a crucial role in shaping opinion. Several authors have examined how social media platforms contributed to vaccine hesitancy prior to the COVID-19 outbreak [16] [17] [18] [19] [20] . Amplification of vaccine hesitancy online has continued in light of development of the COVID-19 vaccine [21] . Studies reviewed by Puri and colleagues [21] describe how anti-vaccine content frequently generates greater user engagement than its pro-vaccine counterparts on Facebook. Singh and colleagues [22] found that low-quality sources of misinformation on COVID-19 were more commonly retweeted than those with high-quality information. In a comparative analysis of the spread of misinformation on five social media platforms (Twitter, Instagram, YouTube, Reddit, and Gab), Cinelli and colleagues [23] analyzed more than 8 million comments and posts over a time span of 45 days, to model the spread of misinformation and demonstrated that social media platforms can serve as amplifiers of misinformation. Vaccine hesitancy at large often arises in response to real-world events that create a window of opportunity for narratives countering vaccine uptake. According to Betsch et al, even limited and short-term exposure to anti-vaccine websites increased individual perceptions of vaccine risks [24] . Buller and colleagues [25] have found that an individual's degree of engagement with Facebook posts on the HPV vaccine was predictive of greater vaccine hesitancy. Buller et al. hypothesize that on the social media platform, alleged risks associated with vaccines appear more immediate and tangible than risks associated with not receiving the vaccine (the success of vaccination is the absence of disease) [21] . Further, anti-vaccine messaging tends to be more focused on emotions and personal anecdotes with powerful imagery in contrast to the empirical strategies utilized by pro-vaccination literature and platforms. These emotional approaches tend to be more appealing to social media users and are consistent with other content that tends to be shared on social media [26] . Often vaccine hesitancy is treated by policymakers and risk communicators as a uniform belief; people are either hesitant to receive a vaccine or not hesitant. However, a subset of research has identified ways in which vaccine hesitancy is not a uniform belief system, but rather consists of several tropes and narratives that coalesce around common themes. In a review of 480 websites, all of which were promoting vaccine hesitancy, Moran and colleagues [20] found several key values among those reviewed: choice, freedom, natural/holism, independence/individuality, and religion. These values were expressed in narratives related to topics ranging from lifestyle norms (references to alternative messaging or other health behaviors), mistrust in communicating authority, vaccine-related diseases, and vaccine ingredients counter to religion (pork products, for example). The most common value was ""choice,"" appearing on one-third of the sample identified in the study. Moran was the first to consider values or the ""core"" principles that may drive the more specific beliefs held by-or comments made by-individuals. The study by Moran and colleagues adds to an ongoing literature aiming to characterize the type of anti-vaccination content on the internet [6, [27] [28] [29] . These prior studies have identified a variety of specific comments or beliefs among content producers. Bean [27] builds on the work of Davies and Wolfe and refers to specific values that emerge from this content: safety and effectiveness, civil liberties, and alternative treatments. More recent work by Johnson et al. [30] has found that there is a greater number of smaller anti-vaccination groups online relative to pro-vaccination groups, allowing these groups to cover more ""surface area"" and attract the undecided to anti-vaccination messages. This ""surface area"" is further expanded when anti-vaccination groups create content focused on more than just vaccination-related issues, connecting to the other core beliefs these authors have described. Critically, Johnson et al. note that anti-vaccine messages tend to be framed as conversations between equals, that is, as peer-to-peer communication. Conversely, pro-vaccine content tends to take the form of expert-to-masses, top-down messages. Anti-vaccine communication, thus, bridges the gap between one-step and two-step flows of persuasion, perhaps the better to take advantage of online media's unique style of social ambiguity. Whereas these prior studies analyzed the quality of information related to vaccine hesitancy and the values that motivate hesitancy, the study we conducted focuses on the narrative tropes and rhetorical styles of anti-vaccine content. Narratives combined with particular rhetorical strategies can be more or less influential. This study adopts a simple definition of the term ""narrative"" predicated on the features of change and temporality. Dahlstrom provides an excellent definition of narrative in the context of science communication to mass audiences as ""a particular structure that describes the cause-and-effect relationships that take place over a particular time period that impact particular characters"" [31] (p. 13614). Our simple definition is in keeping with established scholarly uses of the term [32] [33] [34] [35] . For the purposes of this study, a ""trope"" is understood to mean a subsidiary element of narrative, indicative of the larger narrative or narratives in which it is contained [32, [36] [37] [38] -narratives which might be vague, only partially articulated, or even based on mysterious/absent plot, characters, and/or meaning [39] [40] [41] . Tropes, therefore, ""are about relationships, and never about the term in itself"" [42] (p. 3). Tropes, in other words, definitionally refer to something beyond the context in which they appear. A ""narrative trope,"" therefore, is some semiotic element-visual, aural, or written-which connotes a larger story or worldview. For the purposes of this study, a ""rhetorical strategy"" refers to those modes of persuasion that can be separated from narrative appeals, which do not in-and-of-themselves indicate a larger story or narrativized worldview. These generally comport with the classical categories of rhetorical appeal-ethos (authority), pathos (emotion), and logos (logic) [43] -and with the Platonic critique of rhetoric such as vulgar and manipulative [44] . On one hand, we look to the classical definitions because contemporary definitions of rhetoric are diverse and unresolved [45] [46] [47] [48] . This study takes an expansive view of rhetoric, to include audio-visual as well as written and verbal rhetoric. This is in keeping with the common scholarly use of the terms and concept [49] [50] [51] [52] . Narrative tropes and rhetorical strategies, thus, combine to form persuasive messages, which may be either anti-social (as in this study) or prosocial (as in the public health messaging described below). While the literature is not uniform in its conclusions [53, 54] , there is evidence to suggest that narrative and perspectival persuasion can be more effective than factualargumentative approaches [55] [56] [57] [58] [59] [60] [61] [62] [63] . Research shows that audience absorption into a narrative reduces the audiences' capacity to form counterarguments against messages contained in the narrative [64] [65] [66] and tends to strengthen the persuasiveness of weak arguments and appeals [67] . As per Maertens, Roozenbeek and Van der Linden [68] , messages addressing a persuasion technique rather than a specific factual claim offer the potential ""to achieve broad-spectrum resistance against manipulation,"" which factual rebuttal might not [68] (n.p.). Braddock's work in the field of attitudinal inoculation likewise suggests that attention to form yields greater negative attitudinal reactance against undesirable belief or behavior than attention to content [69] . Ratcliff and Sun argue that narrative's effectiveness comes from its ability to circumvent psychological resistance, so that ""when a persuasive message is embedded in the story and/or carried by the characters, persuasion occurs to the immersed, less critical, and less defensive"" [52] (p. 414). Additionally, literature from the field of violent extremism studies suggests that individuals are most often brought to false and conspiratorial perspectives not by rational decision making, but through a search for emotional and social fulfillment [70, 71] . Work in the field of public health messaging has demonstrated that messaging that focuses on narrative and rhetoric (form) tends to yield better persuasive outcomes than messaging that focuses on facts alone (i.e., content) [55, 60, 62, [72] [73] [74] . A variety of studies from the field of advertising, media, and communication studies suggest that narrative messaging yields more effective outcomes than analytic and informative messages [66, 67, 75] . As a practical matter, Deng et al. found advertising messaging related to COVID-19 deployed ""transformational"" strategies (that is, appealing to emotions) over informational ones by a ratio of nearly two-to-one [76] . In anticipation of the unfolding COVID-19 vaccination campaign, this study sought to identify narrative tropes and rhetorical strategies in the emerging vaccine hesitancy discourse. To this end, we developed a codebook of the most commonly found antivaccination themes, both general and specific to COVID-19. We did so with the intent of providing public health communicators and social media moderation teams with a codebook of compelling anti-vaccination themes, against which counter-messages might be tailored. This work contributes to the nascent literature on COVID-19 vaccine hesitancy beliefs and the ways in which anti-vaccine messages are persuasive. This study employs a simple manual coding approach to identify the narrative tropes and rhetorical styles described above. This method uses both inductive and deductive analytic approaches to gather its corpora. These corpora are analyzed both inductively and deductively, in two rounds of independent manual coding by a team of three subject area experts. Each team member's codes are compared so as to substantiate their relevance, and then consolidated ""to construct more abstract concepts"" [77] (p. 2) in keeping with the action research approach of identifying salient narratives and rhetorics. This final body of codes is then assessed quantitatively to determine code frequency and distribution, that is, both how many times a code appeared and how many distinct pieces of content it appeared in. This methodological approach is a conventional and widely accepted tool [78] [79] [80] [81] , which excels at identifying ""summative, salient, essence-capturing, and/or evocative attribute[s]"" [80] (p. 4) in mixed-media corpora. This subtlety and complexity is not so easily gleaned using more quantitatively centered methods and large datasets. However, similar to any method, it does possess shortcomings. These gaps, and the future avenues of study they suggest, are detailed in the ""Future Directions"" section at the end of this article. Data collection aimed to develop corpora (i.e., large collections of codable content) for two separate rounds of coding. These corpora were developed via purposeful sampling methodology. Using hashtag and keyword searchers, a team of subject matter experts identified 20 channels (i.e., bounded sources of content, such as a social media account), which appeared to contain a high degree of anti-vaccine content and/or COVID denialism. For each round, five distinct channels were selected for preliminary coding. Only publicly available, English language media were selected, both to comply with platform terms of service and to focus coding efforts on content available to the uncommitted and vaccine hesitant. Geography was not considered, due to the transnational availability of the channels that were surveyed. Channels were selected according to the criteria of (1) offering 50-100 pieces of codable content from the past six months, (2) covering written, video, and/or image/meme media, (3) related to COVID skepticism/denial, anti-vaccine ideology, and/or conspiracism, and (4) discursive significance, based on quantitative and qualitative evaluation. The five corpora coded in this first round included: the Plandemic propaganda documentary, the Vaxxed propaganda documentary, official posts from the Facebook group of the anti-vaccine and COVID-skeptic organization The Children's Health Defense (going back three months, excluding comments), the ""fake news"" blog OffGuardian's ""COVID Factchecker"" vertical (comprising seven blog posts), and the Instagram account ""COVID Funny Memes"" (constituting 100 pieces of relevant content, excluding comments). The discursive significance of these channels was established based on the following criteria: the films Vaxxed and Plandemic enjoyed widespread distribution on online platforms [82, 83] ; the Children's Health Defense organization's Facebook page has over 145,000 followers and is headed by celebrity vaccine detractor Robert F. Kennedy Jr. [84] ; the ""Funny COVID Memes"" page had only approximately 5000 followers, but was selected for its apparent ideological neutrality (i.e., both vaccine-denialist and pro-vaccine content appeared in roughly equal proportion); the OffGuardian blog represented the least widely consumed inclusion, ranking 74,278 in global internet engagement according to Alexa rankings-it was chosen in order to include a text-only coding source and due to its clear COVID/vaccineskeptic position. Sampling for the second round was likewise purposive, with a focus on capturing media and audiences that might have been missed during Round 1. Channels that spoke to minority demographics were specifically sought out. Once again, five channels were selected for coding based on the same criteria as Round 1. The five corpora constituting the second round of coding were: the Twitter account of Joyce Brooks (a representative of the Denver NAACP and vaccine denialist), the Twitter account of Toby Rogers (a popular and prolific anti-vaccine figure with a following of 29.7k at the time of sampling), the YouTube video ""A Message to Aussie Muslims"" by Sufyaan Khalifa (urging resistance to COVID public health measures), the Gardasil Girls ""vaccine injury"" Instagram account (including top comments), and the Vaccines Uncovered Instagram account. For all four non-video accounts, 50 individual posts, including retweets and reposts, were collected. The purpose of this selection methodology was not to select the most popular or influential COVID/vaccine-skeptic/denialist channels, but to select a spread of channels that could reasonably be expected to move the research team toward theoretical saturation. Saturation was defined by the research team as that point at which ""additional data do not lead to any new emergent themes"" [85] (p. 135). Round 1 corpora were loaded into NVivo, and each member of the four-person codebook team independently coded each corpora. Codes were then compared and consolidated. Infrequent codes were set aside. In the end, preliminary coding produced 34 unique codes pertaining to the narrative tropes and rhetorical strategies that circulate in the anti-vaccine and COVID-skeptic media. These initial 34 codes were then applied to the second round of corpora. Round 2 corpora were coded according to the preliminary codebook produced in Round 1, with new codes added as deemed appropriate by the coding team. The coding schema developed by each individual member of the codebook team were compared and consolidated. An additional 29 codes were identified during the second round of coding. However, these codes were either found only sporadically or could be consolidated into existing codes. These codes were then analyzed according to an action research methodology approach [86] . The rates of code appearance across corpora were analyzed in comparison with their frequency within corpora. Based on repetition of themes, it was determined that codes pertaining to general audiences (i.e., not demographically specific) had reached a point of adequate saturation. However, in keeping with action research methodology, some relatively infrequent codes were kept. This was done in order to address codes specific to minority demographics. The codebook team drafted detailed explanations of the codes and then grouped them according to whether they referred to a narrative trope or a rhetorical strategy, based on the criteria outlined in the literature review. Narrative tropes were further organized according to the implicit antagonist of the narrative. Implicit antagonists were determined based on close reading of content from which these codes were derived. Rhetorical strategies that frequently occurred alongside specific narrative tropes were noted. Examples from the corpora were assigned to each code in order to further illustrate. Of the final codebook's list of narrative tropes, five patterns represented more than half of the coded items: ""Corrupt Elites,"" ""Vaccine Injury,"" ""Sinister Origins,"" ""Freedom Under Siege,"" and ""Health Freedom."" Of the final codebook's list of rhetorical styles, four patterns represented just over 40% of all coded rhetorical items: ""Think of the Children!"" ""Do Your Own Research,"" ""Heroes and Freedom Fighters,"" and ""Panic Button"" (see Table 1 ). All nine of these codes appeared across all four major platforms from which data were sampled: YouTube, Twitter, Facebook, and Instagram. However, it should be noted that salience cannot be determined solely by the frequency with which a code appeared either within or across channels. In keeping with this study's action research methodology, other factors, such as interaction with other narratives and rhetorics and subjective judgements of affective intensity, were taken into account when determining salience. In total, the results of our coding show that online, English-language, anti-vaccine, and COVID-denial content can be classified according to twenty-two narrative tropes and sixteen rhetorical strategies (see Tables 2 and 3 ). The twenty-two narrative tropes can further be classified as directed toward five major types of antagonists: (i) the government, (ii) the medical establishment and political/economic elites; (iii) mainstream (and implicitly, pro-vaccine) society at large; (iv) an entirely unspecified ""shadowy villain""; (v) the vaccine itself. Some additional unclassified antagonists form a miscellaneous category.  Populist framing of a righteous majority versus corrupt elite. Elite perceived as forcing lockdowns and health practices for their own financial gain (e.g., big pharma) and/or power. A catch-all for all of the harms the vaccine can do to you, from physical deformities to mental illness to microchips that violate your autonomy/privacy. Sinister Origins The people who intentionally created the COVID vaccine are shadowy and suspicious. Geopolitical powers and intelligence agencies are likely implicated. Freedom under Siege Common rights such as speech, assembly, or autonomy are being stripped from you! This claim attempts to hijack feelings of protection, vulnerability, and the sacred. Health Freedom Frames public health as a matter of individual freedom rather than collective responsibility. ""My body, my choice"" misapplied to vaccines. Tied to religious freedom/freedom of speech. 7.8% Table 1 . Cont. Think of the Children! Frames this as an advocacy campaign for protecting children. Uses emotionally affecting (manipulative) images of cute children. 16 .1% States a conclusion and then urges the reader to research the reasons why. Visual clues lead to building arguments in favor of a predetermined anti-vax position. Speaking Truth to Power Doctors, nurses, and other professional ""experts"" speaking against COVID alarmism are brave whistleblowers, courageously bringing truth to the people. Panic Button Audio and visual cues intended to spark alarm, fear, or disgust, such as ominous music and images of needles or malformations. 7.2% Table 2 . Rhetorical strategies. Rhetoric that holds up public health practices and cultural expressions of care/anxiety over COVID-19 to ridicule. This includes ridiculing both experts and laypeople, sometimes through misrepresentation (see ""Mountains and Molehills""). Key to this rhetorical strategy is an overall tone of mockery and/or contempt. Anti-vaccination messages that appropriate the language and values of feminism, such as claiming that vaccine resistance is the positive moral equivalent of advocating for reproductive rights; also, sometimes appropriating themes of femininity, the stereotypes of maternal wisdom and nurturance. This strategy frames the speaker as brave for publicly voicing their anti-vaccine opinions, despite the potential for public backlash, parenting judgment, or criticism from supposed experts. This strategy celebrates vaccine resistance by depicting its messengers as heroic in their stand against the establishment, akin to a whistleblower standing up to corruption. Sometimes, this takes the form of the speaker themselves claiming he or she is brave; other times, someone else's bravery is highlighted. In vaccine-hesitant and -resistant spaces, the bravery often pertains to standing up to others' ridicule, or to the implication that one is a bad parent. This approach often states a conclusion contrary to mainstream beliefs or scientific consensus, and then urges the audience to research the reasons why the conclusion is correct. This leads inquiring minds to build their own arguments in favor of a predetermined position. Other times, this strategy is deployed to avoid answering questions or engaging in debate. The implication is that if audiences reach the correct conclusions (i.e., the ones the speaker asserted), then they have done good research. If they disagree, their research must have been bad. The struggle against vaccination is framed as one of global, historical, or even mythic proportions. Hyperbolic rhetoric and superlatives are used to convey that this threat is profound enough to change the world, to enshrine the power of a corrupt elite-or to imperil the most vulnerable among us (children). In addition to the exaggeration of the threat posed by vaccines, this strategy positions the audience as capable of, or even obligated to, participate in this epic quest for justice. Rather than inflating the threat of the vaccine to epic proportions, this strategy inflates the anti-vaccine movement itself. The voices of ordinary people all around the world are depicted as speaking as one, a unified, grassroots groundswell against evil. Sometimes anti-vaccine and anti-public health movements are framed as just the beginning of a groundswell that addresses other conspiracies. This strategy employs a populist frame that all over the world, good ordinary people (""just plain folks"") are ready to rise up and take back the power over their own lives. This strategy frames public health as a matter of individual freedom rather than collective responsibility. Sometimes, this even borrows from the language of women's reproductive rights, re-appropriating concepts such as ""my body, my choice"" to vaccines. This is sometimes related to religious freedom (vaccines) or freedom of speech (anti-mask).  In general, memes work by using a familiar format to make a new joke or prove a new point. Rhetorical strategies that hijack formats adopt popular formats that are associated with harmless humor and use that familiarity to lower our emotional and cognitive defenses. With its audiences' critical defenses down, it then presents its manipulative message. Beyond memes, this also applies to TV, film, and game formats that are appropriated for propaganda. This strategy also includes ""hashtag hijacking,"" where vaccine misinformation will be tagged with hashtags relating to less controversial issues and groups, such as #blacklivesmatter or #americancancersociety. Hashtag hijacking is particularly effective for exposing newcomers to anti-vaccine messages. Rhetoric similar to this frames vaccine skepticism alongside social justice issues or frames vaccine skepticism itself as a social justice issue in its own right. Sometimes, it may invoke systemic racism or the abuse of minorities by the police to imply that the medical establishment is similarly racist. It may frame its argument more generally, too, presenting vaccine resistance as a matter of either civil rights or religious conscience. It may describe non-vaccinators as ""health minorities"" or ""dissidents."" Allies and fellow ""truth-tellers"" are showered with affirmation, accolades, validation, and compliments. This often includes emotive videos or images celebrating allies for their cause as heroes or persecuted saints (see also: ""Sleeping Giants""). Risks and benefits to vaccines are presented with intentionally distorted proportions. Extremely small risks (e.g., negative reactions to a vaccine) are framed as catastrophic and universal. Simple and far-reaching solutions (e.g., mask mandates) are presented as onerous and ineffective. This strategy distorts the risk/reward calculus of vaccines in order to seed doubt, often by emphasizing fringe or outlier cases of vaccine injury. A common rhetorical technique that uses audio and visual cues intended to spark alarm, disgust, confusion, squeamishness, anxiety, or dread in audiences. Ominous music can be used to indicate that viewers should be worried or mistrustful about what is shown to them. Images of hypodermic needles, malformations purportedly caused by vaccines, or forced vaccinations are depicted in ways that evoke fear and/or disgust. This strategy states or implies that ""many"" people feel a certain way, evoking a social norm against vaccination. The strategy depicts those who agree with the speaker as good people, and those who disagree as fearful conformists. It may imply that evidence exists simply because other people are allegedly saying it, even though there is no actual evidence presented. Otherwise, it may rely on testimonies, first-hand accounts that usually emphasize emotion over facts, and may or may not actually be true. A technique that poses questions designed to set up a narrative, as opposed to asking questions for objective journalistic purposes. This strategy asks a series of questions that lead to a specific anti-vaccine answer, while framing the conversation as objective and inquisitive. This rhetoric suggests that anti-vaccine advocacy is not about what activists want for themselves, but rather what is best for children. Arguments are framed so as to position children's exaggerated physical vulnerability and moral purity as the decisive factor in assessing risk. It often uses emotionally affecting (manipulative) images of cute children. Often a visual rhetoric, this strategy uses symbols of authority and expertise to give added weight to an argument. A speaker might be in an office full of books. They might be in a doctor's office. They might be expensively dressed. The interviewer or director might refer to them with exaggerated deference. Sometimes, their credentials are presented as if they were very impressive but, when examined more closely, are spurious or over-inflated. Of the twenty-two narrative tropes coded, four key common narrative tropes were: ""Vaccine Injury,"" ""Corrupt Elite,"" ""Heroes and Freedom Fighters,"" and ""Sinister Motives."" Each of these narrative tropes addressed a separate antagonist, representing all categories of antagonist-the Government/the Medical Establish/Media, Society at Large, a Shadowy or Unknown Villain, and the Vaccine Itself-except for ""Misc./No Clear Antagonist."" The narrative of ""Corrupt Elite"" was the most frequently coded narrative. This offered a standard populist appeal in which an innocent put disempowered ""silent majority"" suffer under the tyranny of a powerful and corrupt minority [87] . In a process of circular logic, the fact that the government, medical establishment, and high-profile cultural figures support such measures as lockdowns, masks, and vaccines is taken as sufficient evidence that these measures are untrustworthy. The narrative of a corrupt elite was very frequently seen with related but distinct codes. ""Follow the Money,"" for example, often co-occurred, offering financial motives for elite corruption. ""Sinister Motives"" offers malevolent and even supernatural explanations for elite missteps. The ""Unaccountable Elites"" narrative frames government and the medical establishment as immune to consequences from the bad or incompetent actions; it is motive agnostic, but argues that whatever their motives, elites bear no consequences for the mistakes and, therefore, are always to be mistrusted and disobeyed. These, along with other compatible narratives, point to a larger metanarrative that pits potential vaccine recipients against all of the social institutions working to provide them with a vaccine. Table 3 . Narrative tropes (organized by primary antagonist). Narratives 1-8 are framed in such a way as to villainize experts, authorities, and figures of cultural influence. These ""elites"" consist of groups such as the medical establishment, governments, media, and press. This narrative depicts the COVID pandemic and all public health measures associated with it as the final few steps toward a maximally repressive global government. It presents a ""domino theory,"" in which free speech, freedom of religion, and freedom of travel will soon be abolished. Every time a new public health directive has been passed, it says, many vaguer, but far worse, oppressions are sure to come next. This narrative presents a distorted pattern of events in which authorities' warnings and measures against COVID are overblown. (see Fluffing the Curve and Follow the Money) Digital platforms and social media are portrayed as actively engaged in ""censoring"" advocates of ""health freedom."" This is often framed as a David vs. Goliath scenario where powerful companies conspire against brave individuals speaking truth to power. This is described in the language of a grave injustice. This narrative is a standard populist appeal. The world can be divided into a corrupt elite and a righteous majority. The corrupt elite is on the side of lockdowns and mandatory masks/vaccines. The fact that the elite favors these lockdowns, masks, and vaccines is taken as more than sufficient evidence that they should not be trusted. So the reasoning goes: the elites must be corrupt, because they are pushing an untrustworthy and potentially dangerous medicine. This narrative argues that officials are misrepresenting the numbers of COVID injuries and deaths, or that doctors are somehow incentivized to report more deaths. Perhaps they are doing so to ensure profits (see ""Follow the Money""), or perhaps to instill fear and control (see ""1984,"" ""Sinister Motives""). This category also includes ""apples to oranges"" comparisons of patient categories, different diseases' mortality rates, vaccinated vs. unvaccinated health outcomes, and more. This narrative paints the COVID pandemic as an unprecedented opportunity for corporate looting and medical profiteering. Additionally, anything that points to more robust public health initiatives is almost certainly a set-up for crony handouts and panic-driven marketing. There is big money in medicine, this narrative says, and for media giants, there is big money in making people ""panic-watch"" and ""doomscroll."" These are stories in which powerful men will do whatever it takes to compete and aggrandize their wallets and ego-whether it means lying, neglect, withholding care or resources, or plain out killing. There is a specific sub-category that describes claims made against Anthony Fauci regarding supposed fraud. Most famous is the ""HIV Scandal"" involving a series of vague accusations of silencing patients, academics, and scientists to uphold a Ponzi scheme related to HIV treatment protocols [88] . This narrative paints a story in which common rights such as speech, assembly, or possession of some entitled object are being stripped from citizens. This claim attempts to hijack feelings of protection, vulnerability, and the sacred. Can also be framed with the key words, ""Religious and Philosophical Exemption."" These narratives are framed around the assumption that doctors, politicians, and the media will never have to account for their lying or incompetence. So the story goes: if they have no skin in the game, then why should we believe a word they say? Table 3 . Cont. Antagonist: Society at Large: Narratives 9-12 pit anti-vaccine advocates and COVID denialists against society in general or specific elements of it, such as our public political discourse or areas where racial disparities are acutely felt. Here, doctors (and ""doctors"") speaking out against vaccine injury or COVID alarmism are brave whistleblowers, acting at tremendous personal and professional risk to bring the truth to the people. The people protesting public health measures are painted as the moral and ideological equivalent of Soviet dissidents, the founding fathers, and the Arab Spring all rolled into one. This narrativizes the ""Brave Truthtellers"" rhetorical strategy by imbuing it with specific protagonists and struggles. This narrative argues that people of color are shut out of public debate over vaccination, that their voices are dismissed, or they are tokenized and only deployed when it is convenient for the white and powerful. It might also argue that people of colors' rights to ""health freedom"" or their experiences of ""vaccine injury"" are invisible due to systemic racism in the medical system. It usually accompanies tropes such as ""Racist Medicine"" or ""POC Injury."" It is an example of how effective anti-vaccine narratives can be essentially correct, but still point toward false and damaging conclusions. This narrative points to the real history of medical abuse of minorities in the US and elsewhere and implies that minorities should, therefore, mistrust what they hear about COVID and vaccines. Usually, no specific threat or conspiracy is articulated. The history is described and the connection with the present day is left implicit, but clear (see also: Intersection with Social Justice, Erasing POC, POC Injury). This frames the conflict between vaccination and non-vaccination as a partisan political issue. On one hand, it might state that pro-public health voices are the ones making this political, when it is actually a matter of common sense, religious freedom, or personal choice. On the other hand, this narrative category might take an explicitly partisan tone, for example arguing that former President Donald Trump was heroically battling big pharma and a corrupt elite. Narratives 13-14 do not offer a specific villain, but implicate an extremely powerful and mysterious agent whose means and motives are unknown-perhaps beyond comprehension. Conspiracy theories that verge on the supernatural often framed their antagonist in these terms. These demonstrate that narratives can be based around an absence or unarticulated mystery (see literature review). These stories claim with absolute certainty while lacking in substantive proof that the virus was created or leaked from the Wuhan lab in China. These tropes are distinct from legitimate inquiry into a possible ""lab-leak hypothesis,"" because of the narratives that they indicate. Sometimes, those narratives claim that a virus cannot mutate that quickly, or that COVID is a powerful bioweapon and the idea that we can easily stop it with masks or a vaccine is laughably naïve. These narratives are highly compatible with long-existing anti-Asian stereotypes as a sinister ""enemy within"" Western countries. The people behind the COVID vaccine are described as shadowy and suspicious. Geopolitical powers, pharmaceutical corporations, and intelligence agencies are likely implicated. Narratives 15-19 focus on the harm they imagine a COVID vaccine will inflict. Unless tied to another narrative or rhetoric specifying additional antagonists or personifying the vaccine, these narratives offer an antagonist that is impersonal and without motive. These narratives are often framed around anecdotes of supposed vaccine injury. Children are presented as perfect angels, baby geniuses, junior Olympians, etc. Parents are presented as bursting with pride, ready for a smooth, normal, American (or English or Australian or w/e) life. Then came the vaccine, and its injury. Then came the never-ending tribulations. The dream is long dead. This narrative states that ethnic minorities have congenital conditions which allopathic medicine does not properly consider during the development of treatments and vaccines. One example is the claim that African Americans, particularly boys, have stronger immune systems that are more reactive to vaccines. While the coding team did not encounter similar messages targeting women of any race, it seems possible that women's higher rates of autoimmune disorder, and historic mistreatment in medicine, could underpin similarly pseudoscientific theories (see also ""Racist Medicine""). These narratives say that the COVID vaccine has been rushed to market without proper testing, that it could not have gone through trustworthy safety protocols, and that the public cannot trust that it will be safe.  These narratives assume that we should apply the precautionary principle to dangers associated with preventing COVID (i.e., vaccines) but not to COVID itself (e.g., the danger is overblown, go to the pub!) (see also: Mountains and Molehills). This is distinct from the Vaccine Injury narrative, as it focuses on vague potential future outcomes, whereas Vaccine Injury focuses on specific, and often present-day, claims of injury. A catch-all term for all the bad things vaccines can do to you, with no legitimate causal link required. Extremely common. Narratives 20-22 either did not present a clear antagonist or were not consistent enough in their imagined antagonists to effectively classify. These narratives cast their heroes and villains as either all trustworthy, good, and ""on the right side"" or else dangerously misguided, stupid, or evil. Narratives of this sort warn their audience that ""time is running out,"" and something terrible is either happening or about to happen very soon. This threat could be specific (e.g., a law being debated that would mandate vaccines for public school attendance), or it could be vague (e.g., the end of America). The warning is very frequently accompanied with some call to action, such as calling your congressman or evangelizing in favor of anti-vax messages. These narratives dismiss risks associated with COVID as overblown. They sometimes misuse statistics to reach this conclusion, such as comparing high-risk populations' flu mortality rates to low-risk populations' COVID mortality. Most often, these narratives center around an emotionally dismissive claim of others' alarmism. This is distinct from the Alarmist Authorities code, as it addresses a more general cultural alarmism that may originate in not-elite sources. ""Vaccine Injury"" appeared to be the most salient of narratives, though not the most frequent. The code was a catch-all concept describing all negative outcomes (almost exclusively imagined or untrue) associated with taking a vaccine. Examples of this narrative rarely provided a clear causal link between vaccination and injury. Instead, it most frequently juxtaposed a claim to having been vaccinated alongside a claim to injury. These injuries were often vaguely described and only infrequently accompanied by claims to an actual diagnosis of malady. Messages conveying this narrative frequently used the ""Panic Button"" style of audio-visual rhetoric, in which images of needles, crying infants, unsettling sounds, or unattractive colors are employed to produce feelings of disgust and unease. A third popular narrative, ""Heroes and Freedom Fighters,"" is compatible with populist framings, presenting anti-vaccine or COVID-denialist medical doctors (as well as chiropractors and naturopaths) as brave whistleblowers, risking their reputations and careers by speaking truth to power. This narrative often coincided with rhetorics of ""Brave Truthteller,"" ""Sleeping Giants,"" and ""Health Freedom,"" presenting the people organizing against public health measures as the moral equivalent of pro-democracy dissidents. Of the sixteen rhetorical strategies coded, four key, common rhetorical strategies were: (i) the ""Brave Truthteller,"" (ii) ""Do Your Own Research (DYOR),"" (iii) ""Mountains and Molehills,"" and (iv) ""A Global Movement/Sleeping Giants"". Each of these rhetorical strategies was present across multiple categories of narrative antagonist. For example: the rhetorical strategy labeled ""Brave Truthteller""-in which a speaker claims to be speaking a dangerous truth that ""the establishment"" or society at large is suppressing-was significantly present in all four categories of antagonists and even in those relatively few narratives with no clear antagonist. Another common rhetorical strategy that is directed toward multiple protagonists is ""DYOR"" or ""Do Your Own Research."" DYOR works by trying to empower the audience to develop their own bodies of evidence and methods of reasoning in order to reach a preordained conclusion. Sometimes, this leads inquiring minds to build their own arguments in favor of a predetermined position. Other times, DYOR offers vaccine denialists and skeptics a means to avoid answering questions or engaging in debate: they may simply demand that the interlocutor should do their own research. If the interlocutor reaches the correct conclusions (i.e., anti-vax conclusions), then they have done good research. If they still disagree, so the reasoning goes, their research must have been bad. A third popular category is what we refer to as ""Mountains and Molehills."" In this rhetorical strategy, vaccines' risks and benefits are presented without a proper sense of proportion. Extremely small risks (e.g., negative reactions to vaccines) are framed as catastrophic and universal. Simple and far-reaching solutions (e.g., mask mandates) are presented as onerous and ineffective. The risk/reward calculus is thereby severely distorted. This strategy is used to seed doubt via emphasizing fringe or outlier cases. Presenting COVID-19 vaccine resistance as a part of a global movement of ""sleeping giants""-honest, everyday citizens who are on the cusp of rising up against an oppressive ""global elite""-was a common rhetorical strategy that cut across narratives targeting all categories of antagonists. This rhetoric frames its accompanying narrative to suggest that the voices of ordinary people all around the world are articulating that narrative as a unified mass. Anti-vax and anti-public health movements are presented to be just the beginning of this groundswell. All over the world, so the trope goes, self-conceived ""ordinary people"" are ready to rise up and take back the power over their own lives. This rhetoric taps into the populist persuasive strategies and schemata outlined above, which frame the pure, ordinary people against the nefarious, evil elite. In some cases, populist rhetoric intersects with nationalist rhetoric, arguing that only a stronger state can save ordinary people from bad elites. In other cases, these populist frames intersect with anti-government resistance, framing elites as not only out of touch with the needs of the pure, ordinary people but actively working against them in tyrannical ways that warrant uprisings, revolution, armed resistance, or even, a new civil war. The scope of this study is intended to create a codebook of online English-language anti-vaccination narratives and rhetoric, so as to support government officials and civil society groups engaged in managing disinformation during the COVID-19 vaccination campaign. Further research into languages besides English tailored to address the regional cultural contexts that shade narratives and rhetoric are underway by members of this team, but beyond the scope of the present article. Local, national, and international governments, as well as civil society organizations, need to be prepared to manage the infodemic by promoting the timely dissemination of accurate information based on science and evidence, in particular to high-risk groups. This dissemination of accurate information should be both positive and defensive. That is, messaging campaigns must communicate both the latest in scientific understanding of COVID, its spread and prevention, and effective countermessages against misinformation. The codes identified by this study offer governments and civil society groups a catalogue of anti-vaccine message styles that may assist in the latter efforts. Pro-vaccine audiences, the vaccine hesitant, and the wholly agnostic can generally be addressed as a single group. Anti-vaccine belief holders, a much smaller subset of the overall vaccine hesitancy spectrum [89] , however, must have counter-messaging tailored specifically for them. This comports with the distinction between ""prophylactic"" and ""therapeutic"" counter-messaging [90] . Evidence demonstrates that prophylactic exposure to counter-messaging would prompt hesitant, agnostic, and pro-vaccine audiences to develop their own counterarguments against misinformation and disinformation [91, 92] . Furthermore, these audiences would not need to be warned against every type of misinformation or disinformation they might encounter. Exposure to counter-messaging against one dimension of a mis/disinformation campaign confers resistance to other dimensions associated with that topic of mis/disinformation [93] [94] [95] . This phenomenon is sometimes called the ""blanket of protection"" [96, 97] . So, for example, an effective counter-message addressing exaggerated claims of vaccine injury can in theory be expected to confer some resistance to any other narrative trope or rhetorical strategy listed in this codebook. The joint effects of targeted counter-messaging and blanket of immunity might best be mobilized through counter-messaging that addresses tropes and/or strategies that appear most frequently, and that are thematically linked to other denialist narratives and rhetoric. For example, the versatility of rhetorical strategies such as ""Brave Truthtellers"" may be both a cause and a symptom of their effectiveness; its versatility lends itself to a variety of narratives, while its repetition across narratives enhances its effectiveness through repetition. Counter-messaging that alerts audiences to the manipulative persuasion of the ""Brave Truthteller"" strategy will, therefore, be effective against a variety of misinformation and disinformation utilizing the strategy, as well as likely conferring further future resistance against the rhetoric and narratives that appear alongside it. Similarly, ""Do Your Own Research"" is also a popular rhetorical strategy throughout conspiracy cultures, such as QAnon. QAnon disinformation networks have been shown to amplify anti-vaccination rhetoric and messaging [98] , which raises important questions about the impact of overlapping persuasive rhetorical strategies in addition to amplification through hashtags or coordinated campaigns. By counter-messaging against transnetwork themes, a blanket of immunity may protect audiences from anti-vaccine and COVIDdenialist themes that are not described in this codebook or have yet to emerge. Counter-messaging to address audiences who already hold undesirable viewpoints (i.e., therapeutic counter-messaging) is a newer and less well-established process than its prophylactic counterpart [90, 96, 99] . A potential for backlash is always present in countermessaging campaigns [100, 101] . Additionally, while the so-called ""backlash effect"" (that is, the theory that factual counterargument entrenches false beliefs) has been credibly challenged [102] , there is ample evidence that carelessly repeating false information can help spread it [103] [104] [105] [106] . Therefore, public health messaging that addresses anti-vaccination audiences, already hardened in their beliefs, must be preceded by especially rigorous testing. This codebook is presently informing a series of tests to determine the efficacy of public messaging that addresses some of the narratives and rhetoric found in it. The results of that study are expected to be available in pre-print by early summer 2021. The present study has shed light on narrative and rhetorical patterns in anti-vaccine and COVID-denialist online media. However, the methods that made this study possible have also limited it in key ways. While the combined deductive/inductive coding process appeared to produce a saturation of codes, this cannot be definitively stated absent a corroborating study based on a large data sample. Such a study might be undertaken, using the present study's codebook as a deductive point of departure for a big data text mining and topic modeling project. It is possible that such an expanded study might reveal unexplored dimensions of anti-vaccine and COVID-denialist positions. By the same token, this study was conducted with the intent of helping to inform public health messaging. A follow-up study is currently underway, which utilizes several of the codes mentioned in this article to create public health counter-messages. Among other questions, this follow-up study tests the efficacy of emotionally based countermessages relative to factually based counter-messages. It asks: is form indeed more salient than content to debunk health misinformation and disinformation? Here, more research is needed. Further work might also consolidate codes to supplement the ""antagonist"" categories offered here. Such a consolidation may help others to adopt these codes in independent public health messaging endeavors. Finally, it is worth delving into the question of ""why"" these narratives and rhetorics hold such appeal. One might easily imagine a study of people holding anti-vaccine and COVID-denialist attitudes, which tests the salience of the narratives and rhetorics presented here. Such a survey could also address overlapping attitudes and worldviews to better ascertain the narratives indicated to believers by these tropes, and why such narratives and rhetorics are appealing. The data presented in this study are available on request from the corresponding author. The data are not publicly available due to concern for the privacy of the subjects whose public social media posts were used in the codebooking process.@story_separate@This paper reports on the qualitative classification of online, English-language antivaccination rhetoric about a COVID-19 vaccine. Our analysis of sixteen persuasive rhetorical strategies and twenty-two anti-vaccination messages directed toward specific antagonists is necessarily descriptive at this stage. We hope this work inspires additional empirical research to help illuminate the following questions: which of these rhetorical strategies and messages are most encountered online and for which demographic groups? Which of the messages carries the most persuasive appeal? How can persuasive rhetorical strategies be effectively countered in online spaces? How might different narratives and rhetorics appeal to audiences in different countries, different demographics and subcultures, and in different languages? Given the rise in populist movements across many countries, it seems possible that similar antagonisms would be articulated in anti-vaccine and COVIDdenialist media content. However, given the highly contextual and referential qualities of memes and other social media content, these antagonisms could reasonably be expected to assume significantly different expressive forms. To avoid the risk of blowback, it is essential that similar coding studies and counter-message testing be undertaken prior to the launch of public health campaigns addressing anti-vaccine and COVID-denialist misand disinformation.","Vaccine hesitancy (delay in obtaining a vaccine, despite availability) represents a significant hurdle to managing the COVID-19 pandemic. Vaccine hesitancy is in part related to the prevalence of anti-vaccine misinformation and disinformation, which are spread through social media and user-generated content platforms. This study uses qualitative coding methodology to identify salient narratives and rhetorical styles common to anti-vaccine and COVID-denialist media. It organizes these narratives and rhetorics according to theme, imagined antagonist, and frequency. Most frequent were narratives centered on “corrupt elites” and rhetorics appealing to the vulnerability of children. The identification of these narratives and rhetorics may assist in developing effective public health messaging campaigns, since narrative and emotion have demonstrated persuasive effectiveness in other public health communication settings."
"It seems to have taken this pandemic for all of us to more explicitly value health workers. Health workers occupy a unique position in response to COVID-19. The epidemiology of the virus contributes to an unprecedented increase in the volume and acuity demand on the health workforce, while at the same time it diminishes health worker supply. As the backbone of health systems, health workers are the key responders to the crisis as it unfolds, and in being at the point of care, they are also most at risk. A useful depiction of the different types of the health impacts of the pandemic over the short, medium and long term is depicted in Fig. 1 [1] . This includes a first wave addressing the immediate response to COVID-19, which may also entail post-intensive care unit (ICU) recovery and readmissions. Three additional population health needs include a second non-COVID-19 wave of the backlog of other urgent health conditions. A third wave depicts the impact of interrupted care of chronic conditions, which could be in primary or long-term care settings. The backdrop to each of these waves is a fourth wave highlighting the psychological trauma and economic injury caused within the broader population. For each of these waves the corresponding health workforce requirements that parallel each COVID-19 wave need to be considered. In this commentary, we describe the range of the initial health workforce considerations in response to the pandemic, highlighting some of the key issues considered and not fully considered across a number of selected countries. We begin with a discussion of how health workforces were readied for the first wave through increasing surge capacity and access to personal protective equipment (PPE). We add the growing concern with the psychological health and safety of health workers as the pandemic unfolded. Across both issues, we highlight the important equity dimensions. Next, we discuss attempts to increase health worker flexibility in how they respond to the pandemic, which raises the issue of underrecognised workforces. The cross-cutting issue of the need for open and flexible leadership is also highlighted.@story_separate@Paradoxically, pandemic response plans in country after country often failed to explicitly address the health workforce requirements and implications on the workforce itself. Initial prominent concerns were whether facilities, regions and countries would have sufficient supplies of resources to respond to the surge. Concerns about the number of ventilators, masks and other PPE can obscure whether there are sufficient operators trained to manage life sustaining equipment, and generally provide care around intensive care beds. As Professor Ivan Cavicchi at the University of Tor Vergata in Rome explains, ""We made a mistake, especially in Lombardy. … We were totally focused on increasing the number of beds in intensive care units, without having enough anesthesiologists. "" [2] A range of policy options have been explored and undertaken to rapidly increase workforce capacity, each with associated benefits and challenges. A cross-country analysis of policy measures by the European Observatory on Health Systems and Policies has shown that the majority of countries used a multitude of different strategies to scale up their workforces within a short timeperiod [3] . This included expanding staff capacity among the existing workforce, calling upon trainees and retirees, and integrating internationally educated health professionals (IEHPs). Selected examples are noted below. Voluntarily recalling retired staff or those on leave or inactive is a common response across many countries. In the Netherlands, for example, there was an overwhelming response from 20,000 retired health workers and those on leave to come back to the health sector in response to COVID-19, with over 3000 working by the end of March [4]. In Germany, the president of the German Federal Association also called upon retired physicians to return to medical work or to help with case tracing or telephone helplines [5] . Regulatory authorities have responded quickly to enable inactive practitioners to come back to work as well as fast-track trainees (discussed below) [6] . These calls are not without concern because of the often neglected need for short-term retraining, but also because the greater potential risks to older workers of exposure to the virus [7] . Fast-tracking trainees near the end of their programs is another common strategy. In Australia, for example, nursing students were employed as assistant nurses to free up registered nursing time to deal with more acute cases. In Germany, following a call from the federal medical student association, over 20,000 medical students have registered to work in clinical practice by the end of March. In the Netherlands, medical students supported GP practices and provided health information to the general population [8] . Trainees have also volunteered, as for example in Jamaica, to help support frontline health workers by providing child care [9] . Fast-tracking of trainees requires additional considerations, such as those identified by Jane Ball in an opinion piece in the Nursing Times [10] : ""1. Students are students-they require supervisions and support. They are not yet fully trained, nor assessed as being safe to practise independently; 2. If students need to become part of the workforce in an emergency, they are no longer students-but part of the workforce; 3. They must be free to make this choice themselves. …; 4. If they become part of the workforce, they must be paid appropriately relative to level of skills and have employment rights. "" Integrating IEHPs already in country is another strategy, albeit controversial. In the UK, an accelerated process was implemented to get international nurses onto the register more quickly [11] . A strategy that some countries have considered is to import foreign nurses or physicians, such as Cuban doctors proposed by some Indigenous communities in Canada to support the response to COVID-19 [12] . Policy decision-makers have been cool to these proposals [13] . For example, a recent call from a local politician in Canada to allow-more-foreign-traineddoctors-to-help-with-covid-19-crisis sparked controversy with regulatory authorities concerned with safety implications [14] , but an emergency policy was enacted nonetheless on a short-term basis [15] . In Mexico, concerns were that these strategies neglect endemic local underemployment [16] , and suspicions were unleashed about the functions that this personnel will be able to perform and the way the will be contracted and paid over the course of the epidemic [17] . Calls for health worker mobility have also come from more heavily affected areas. The Governor of New York State, for example, asked health workers from across US to help shore up the surge particularly in New York City, a favour later returned when there was need in the state of Utah [18] . In Canada, the province of Nova Scotia developed a ""Good Neighbour Protocol"" to facilitate 'sharing' of health workers across and within jurisdictions after H1N1 that was re-activated for COVID-19 [19] . China sent health workers to Italy at the height of its surge [20] . This solidarity is also needed for those areas that face critical workforce shortages across the globe. Safety concerns and access to PPE in a state of global shortage, have figured prominently in policy discussion and public discourse. Early in the crisis, the World Health Professions Alliance, representing a range of health workers, called upon governments to prioritise support for healthcare workers in the frontline against coronavirus [21] . They detailed how health workers. ""are putting themselves at risk as they battle to protect their communities, often without the required personal protective equipment, such as masks and hazardous material suits, that can keep them safe from infection and therefore able to carry on their vital work. "" Health workers have figured prominently in the number of those infected with COVID-19, and in COVID-19-related deaths [22, 23] . Lack of access to PPE has significantly reduced health workforce capacity, either because workers have become exposed and subsequently quarantined, or have become infected or sick, or have not come to work or walked off the job because of the risks they bear [24] . For instance, the Berlin Association of Statutory Health Insurance Physicians sent an open letter to Berlin's mayor and the Minister of Health warning about a potential collapse of the ambulatory care system if the supply chain for PPE remained irregular [25] . In the Netherlands at the beginning of April, where 900 out of the 2500 nursing homes reported COVID-19 infections, some workers chose to quit their jobs because they lacked sufficient PPE [26] . Access to PPE has revealed invisible hierarchies within the health workforce, including those that reflect broader gender and racial dimensions. Initial calls of support for nurses and doctors failed to recognise the risks to staff in administration, transport and cleaning roles. Although we are starting to see a more sophisticated view of the different risk profiles, there were a number of instances across many countries where certain cadres of health workers were not considered in the calls for PPE [27] . The differential impact of the COVID-19 virus to racialised persons is also expressed in the disproportionate infection and death rates amongst racialised health workers [28] , and how this intersects with their status in the health care hierarchy. In Canada, a memorial for health workers who have died from COVID-19 reveals a disproportionate impact on racialised workers, particularly those in the poorly recognised and protected longterm care sector [29] . Even when accessible, the gender dimension of PPE can be notable. The Gender Equity Hub of the Global Health Workforce Network, for example, pointed out how PPE can be challenging for the largely female health workforce, as it is often not designed with women's bodies in mind [30] . Conversely, guidance from the CDC has recognised the impact of different types of men's facial hair for safety and fit of protective masks [31] . Similar considerations were needed for health workers who wear turbans, hijabs or other religious head coverings. The dilemmas faced by health workers during the COVID-19 pandemic reveal another assault on their safety, this being to their psychological health and safety [32] . It has become clear that the response to COVID-19 is more akin to a marathon than a sprint, and working at or beyond full capacity is not sustainable in the long or even medium term. Anticipatory anxiety at the preparatory phase emerged at first, which gave way to exhaustion when the epidemic curve hit exponential growth. Burnout from too much work, combined with challenging, high-pressure and morally demanding working conditions is particularly notable for those in emergency and intensive care. This includes having to make difficult decisions about who has access to ventilators and who suffers in their absence because they are considered less likely to survive [33] . Moreover, frontline workers face difficult emotional situations as they support patients in the last moments of their lives when family and relatives are not allowed to be with their family member. Wearing needed protective equipment hampered being able to provide emotional support [34] . Dilemmas also emerged when concerns about whether capacity would be sufficient to respond to the crisis outweighed guidance about when exposed health professionals should be quarantined [35] . The caring dilemma, to borrow a concept from Susan Reverby [36] , faced by health workers concerned about potential transmission of the virus to their families when they come home from caring for patients is also emerging as a key concern. Responses have included quarantined spaces within health worker homes [37] , where possible, or in local hotels or donated recreation vehicles parked in hospital parking lots [38] . These responses raise yet another caring dilemma of being away from families at the same time as they are sheltering at home with schools closed. Providing mental (peer) support is required, and valuable lessons from current experiences can be learned for the future crisis situations [39] . In addition to efforts to safely increase the number of providers within health worker cadres, efforts to undertake work differently, and to shift tasks and increase the flexibility of health workers across the workforce have emerged. Here is another way a whole of the health workforce approach is relevant. Opportunities for workforce flexibility include the shifting or delegation of tasks and new skill mixing innovations leveraging the full scope of skills available within and outside of the health workforce. In Australia, for example, several physiotherapists were trained to work in acute respiratory teams [40] . In the UK, dental offices were asked to redeploy some of their dental staff for National Health Service work-particularly those with sedation skills; podiatric surgeons have been deployed to manage orthopaedic medical wards and assist in 'proning' critically ill patients. Other forms of deployment including shifting health workers freed up from cancelled elective surgeries to other sectors in greater need, a strategy adopted in Australia and Canada [41] . Flexibility in staffing ratios supports workforce flexibility. This has included guidance regarding needed variability in acute care staffing ratios to capture both 'regular' and 'surge' versions-specific to COVID-19 [42] . In Germany, for example, the Ministry of Health has suspended minimum staffing levels for nurses to allow for more flexibility on nurse placements in hospitals during the crisis [43] . Researchers in Australia have also used previously established staffing ratios to estimate numbers of additional ICU nurses and physicians that would be required to operationalise additional ICU beds and ventilators should the country be compelled to use them all [44] . Unfortunately, jurisdictions often lack even these most basic guidelines on workforce adequacy, hindering efforts to monitor and adjust these in response to the pandemic [45] . Shifting tasks may require some upskilling if the skill set is not within the existing cadre of worker. One of the specific interventions considered in Canada is to training up more Registered Nurses (RNs) to handle ventilators, in case of a shortage of Respiratory Therapists (RTs), given that there are many more RNs than RTs in the jurisdiction (of a factor of 30 to 1) [46] . There has been a rapid uptake of telehealth by most primary care providers, including in settings where this was previously considered infeasible. In Canada, for example, new fee codes for virtual care were fast-tracked immediately where previously governments limited these types of funding options [47, 48] . In Germany, the 2018 law on telemedicine, which was previously slowly taken up in practice, has seen a rapid adoption during COVID-19 [49] . Virtual care also affords opportunities for new models of care, including point-of-care testing and for patients to go directly to specimen collection points (not requiring a GP referral). This complemented the return of retirees as telehealth was seen as a way for older clinicians to more safely deliver care. In the US, retirees were brought back in telehealth roles to reduce their risk exposure [50] . Renewed interest in workers in public health roles is emerging after years of chronic underfunding and understaffing [51] . Several countries have taken measures to expand the public health workforce, employing more public health specialists and workers to help with contact tracing, staffing help lines and organising quarantine measures [52] . In Canada, the province of British Columbia announced it would invest $1.6 billion to hire 7000 health care workers to support a major influenza vaccination campaign to prevent the combination of COVID-19 and influenza from overwhelming it [53] . Hardest hit from the pandemic has been the older adult, or long-term care sector. The vulnerability of the residents was mirrored in the vulnerabilities of their care workers, a situation that predated the pandemic, but for which it brought to the fore of public attention through the daily briefings of COVID-19 infections and deaths [29] . In Canada, where over 80% of deaths are linked to long-term care, a recent national opinion poll revealed over 90% of the public consider a systemic review of long-term care facilities, notably in terms of management and level of staffing, to be paramount [54] . Across these different strategies adopted and adapted, change management in the short, medium and longer terms bears consideration. In the short term, management structures and systems require distributed leadership ensuring strong governance if and when managers become exposed or fall ill. Different types of situational leadership skills are also needed-beyond the clinical-to manage the crisis at the point of care, including flexible, empathetic and open communication [55] . Leadership will also be needed to recognise how this crisis reinforced existing inequalities in the health workforce, as well as in care for the broader population [56] . Workers across disciplines at the frontline need to be recognised in decision-making. This means creating space and opportunities to have management positions occupied by women, people from ethnic minorities, various religious backgrounds where there are clearly identified leadership gaps. Leadership at the political level is also significant. The politicisation of COVID-19 and the response to it carries the risk of hampering equity and both technical and allocative efficiency, directly risking the safety of the whole of the health workforce. It is clear that a whole of country approach as well as international cooperation are required to allocate scarce resources in a timely way to where they are needed, as well as accommodate for localised adaptation according to demographic profiles. The responses to this pandemic, and in particular the considerations of health workforce implications, has also revealed the importance of different political, health systems and cultural approaches to creating and deploying surge capacity. Systems with central government coordination, led by policy-makers who are open to scientific evidence-based recommendations, have been better able to respond in a more coordinated way. At the same time, care has to be taken to avoid cumbersome administrative procedures than can hamper decision-making for changes in care provision that are required immediately. There is a delicate balance between a central command and control model vs. one that allows for more local authority and decision-making. This pandemic has clearly changed how health workers provide care, are deployed and managed. It has also laid bare the consequences of the lack of attention to health workforce considerations and how necessarily these are for improved pandemic preparedness and responsiveness. This lack of attention has been notable for workforces in particularly neglected sectors, such as in long-term care and public health. What will be the legacies of these pandemic responses? Will there be better planning, including health workforce planning? Will it be like the Canadian response to Severe Acute Respiratory Syndrome (SARS) in 2003, where an initial flurry of policy and concerns with public health workforce responsiveness, some of which quickly subsided without full implementation? It is important to resist the tendencies towards stasis in the system when crises are overcome. Future pandemic preparedness plans should routinely include processes for estimating health workforce requirements based on projections of the pandemic spread, and incorporate options for rapidly scaling up the health workforce through modelling and scenario planning. Sufficient financial resources to ensure these scenarios can be implemented rapidly and at scale will be necessary. Pandemic preparedness requires readily available and flexible back up options for surge capacity. Many health systems which have moved towards a lean management approach of the health workforce will need to reconsider in light of how this strategy significantly limits surge capacity in times of crisis. GPs: General practitioners; ICU: Intensive care unit; IEHPs: Internationally educated health professionals; PPE: Personal protective equipment; RNs: Registered nurses; RTs: Respiratory therapists; SARS: Severe acute respiratory syndrome.@story_separate@While support and appreciation is seen for all those health workers putting themselves at risk to save other people's lives and to provide care in extremely difficult circumstances across many societies, more explicit policies and practices to support health workers are needed for a sustainable health workforce through the pandemic and further into the future. As we move from the initial 'shock' of the pandemic, the health workforce adaptions and practices required to sustain workers will be longer term than first envisaged. The second and subsequent waves of the pandemic, arising from changing lock-down and social distancing measures, will create an echo of the four waves of both population health needs depicted in Fig. 1 and consequent health workforce requirements. Countries will need to move beyond crisis management and better integrate the full range of health workforce considerations into subsequent planning phases, and rigorously monitor and evaluate the health workforce response along with its overall response to a pandemic.","This commentary addresses the critically important role of health workers in their countries’ more immediate responses to COVID-19 outbreaks and provides policy recommendations for more sustainable health workforces. Paradoxically, pandemic response plans in country after country, often fail to explicitly address health workforce requirements and considerations. We recommend that policy and decision-makers at the facility, regional and country-levels need to: integrate explicit health workforce requirements in pandemic response plans, appropriate to its differentiated levels of care, for the short, medium and longer term; ensure safe working conditions with personal protective equipment (PPE) for all deployed health workers including sufficient training to ensure high hygienic and safety standards; recognise the importance of protecting and promoting the psychological health and safety of all health professionals, with a special focus on workers at the point of care; take an explicit gender and social equity lens, when addressing physical and psychological health and safety, recognising that the health workforce is largely made up of women, and that limited resources lead to priority setting and unequitable access to protection; take a whole of the health workforce approach—using the full skill sets of all health workers—across public health and clinical care roles—including those along the training and retirement pipeline—and ensure adequate supervisory structures and operating procedures are in place to ensure inclusive care of high quality; react with solidarity to support regions and countries requiring more surge capacity, especially those with weak health systems and more severe HRH shortages; and acknowledge the need for transparent, flexible and situational leadership styles building on a different set of management skills."
"Coronavirus disease 2019 (COVID -19) is a global public health threat and has evolved to become a pandemic crisis around the world, which is caused by the severe acute respiratory syndrome, coronavirus 2 (SARS-CoV-2) [1] . In response to this serious situation, COVID-19 was declared as a public health emergency of international concern by the World Health Organization (WHO) on January 30 and called for collaborative efforts of all countries to prevent the rapid spread of COVID-19 [2] . In Bangladesh, the first confirmed case was reported on 8 March 2020 [3] . Infection rates apparently remained low until the end of March, but a steep rise in cases began in April 2020 with case doubling times of 2 days [4] . As of 01 June 2020, according to the Institute of Epidemiology, Disease Control and Research (IEDCR), in Bangladesh 49,534 confirmed cases were reported, including 10,597 (21.4%) who recovered, and 672 (1.36%) related deaths [3] . The highest attack rate (AR) was observed in Dhaka city (874.9/ 1,000,000), followed by (2,040/1,000,000), followed by Narayanganj district (616.2/1,000,000), Munshiganj (432.4/1,000,000), Gazipur (168.7/1,000,000), Gopalganj (145.7/1,000,000) [3] . COVID-19 prompted implementation of public health protocols to control the spread of the virus, many of them involving social distancing, hand washing, and lockdown procedures, but has also resulted in creating public anguish and massive fear [5] , particularly among the unaffected population [6] . Bangladesh has not previously experienced epidemics such as SARS or MERS, and it is clear that the public healthcare systems are not readily prepared for COVID-19. The magnitude and rapid proliferation of COVID-19 through slightly symptomatic or asymptomatic infected people in Bangladesh stresses the need to identify the behavioral responses of the population, such as to better address behavioral determinants of pandemic control [7] . Official measures such as school closures, shutdown of offices for an initial 30-day duration, restrictions on leaving home after 6.00 pm, and legal actions on individuals leaving their dwellings after 7.00 pm, along with gathering restrictions in mosques and people gatherings have rapidly been imposed in many regions of the country [8, 9] . However, for such measures to be effective, public adherence is essential, which is affected by their knowledge, attitudes, and practices (KAP) towards COVID-19 [10, 11] . There are a limited number of studies on knowledge and attitudes during epidemics that have been conducted in Bangladesh. However, the lessons learned from the studies conducted in other countries in an epidemic situation such as the SARS outbreak in 2003 suggest that knowledge and attitudes towards infectious diseases are associated with serious panic and other emotional reactions among the population, which can further complicate attempts to prevent the spread of the disease [12, 13] . Suggestions from a Latin America-based study during the outbreaks of chikungunya, zika, and dengue reported low levels of participation and commitment to the imposed control measures in populations [14] . KAP is an important cognitive key in public health regarding health prevention and promotion. It involves a range of beliefs about the causes of the disease and exacerbating factors, identification of symptoms, and available methods of treatments and consequences [15] . Beliefs about COVID-19 come from different sources, such as stereotypes concerning similar viral diseases, governmental information, social media and internet, previous personal experiences, and medical sources. The accuracy of these beliefs may determine different behaviors about prevention and could vary in the population. In many cases, the absence of knowledge, or if most of the medical-related beliefs are actually misconstrued or false, these may carry a potential risk [16] . In Hubei, China, one of the first studies analyzing attitudes and knowledge about COVID-19 concluded that attitudes towards government measures to contain the epidemic were highly associated with the level of knowledge about COVID-19 [17] . The authors reported that higher levels of information and education were associated with more positive attitudes towards COVID-19 preventive practices [5, 17] . Perception of risk is also a key factor in commitment to prevention during outbreaks of global epidemics [5, [18] [19] [20] [21] . Considering the lack of studies related to coronavirus epidemics and how to facilitate outbreak management of COVID-19 in Bangladesh, there is an urgent need to understand the public's KAP of COVID-19. Here, we aimed to investigate KAP towards COVID-19 during the rapid rise period and immediately after the implementation of lockdown measures in Bangladesh.@story_separate@a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 A cross-sectional and anonymous online population-based survey was conducted among individuals aged 12-64 years. The survey was conducted from March 29 to April 20, 2020, immediately after the implementation of lockdown measures by the government of Bangladesh. A semi-structured questionnaire was designed for the Google survey tool (Google Forms), and the generated link was shared to public on social media (i.e., Facebook, WhatsApp). The link was also shared personally to the contact list of investigators and research assistants. The investigators' decision to collect the data using online approaches was predicated on maintaining social distance during the strict lockdown in Bangladesh. Initially, 2,068 potential respondents provided written informed consent online. Of these, 2,017 respondents completed the entire survey, generating a response rate of 97.5%. The inclusion criteria to participate in the study were being a Bangladeshi resident, having internet access, and voluntary participation. A semi-structured and self-reported questionnaire containing informed consent, questions regarding socio-demographics, knowledge, attitude, and practice. Socio-demographic measures. Socio-demographic information was collected, including gender, age, education, occupation, marital status, nature of the family (nuclear/joint, with the joint being an extended family, often of multiple generations), number of family members, monthly family income, and location of permanent residence. Monthly family income was categorized into three classes: <20,000 Bangladeshi Taka (BDT), 20,000-30,000 BDT, and >30,000 BDT [22] . Knowledge, attitude, and practice. To assess the level of knowledge, attitude, and practice of the respondents, a total of 19 questions (including 6 for knowledge, 6 for attitude, and 7 for practice) were included. The survey questions were adapted and modified from previously published literature regarding viral epidemics related to MERS-CoV disease [23, 24] , infection prevention and control measures for COVID-19 by World Health Organization [25] , and guidelines suggested by the country's Institute of Epidemiology, Disease Control and Research (IEDCR) [26] . After completion of the initial draft of the survey questionnaire, it was validated and adopted as follows: firstly, the questionnaire was sent to four academic experts knowledgeable in the area. After coordination and consensus of all experts' opinions, the final questionnaire was drafted, and underwent pilot testing in 30 individuals to confirm the reliability of the questionnaire. The data from the pilot study were loaded into SPSS version 25, and subjected to reliability coefficient analysis. Regarding the pilot data, the Cronbach's alpha coefficient of the knowledge, attitude, and practice were 0.60, 0.43, and 0.74, respectively, and overall Cronbach's alpha of KAP questions was 0.73, which indicates acceptable internal consistency [27] . For field data, the Cronbach's alpha coefficient of the knowledge, attitude, and practice were 0.60, 0.20, and 0.63, respectively, and overall Cronbach's alpha of KAP questions was 0.60. The knowledge section consisted of 6 items and each question had a possible response of ""Yes"", ""No"" and ""Don't know"" (e.g., Is COVID-19 a dangerous disease?). The correct answer (Yes) was coded as 1, while the wrong answer (No/ Don't know) was coded as 0. The total score ranged from 0-6, with an overall greater score indicates more accurate knowledge. A cut off level of �4 was set for more accurate knowledge. The attitude section consisted of 6 items, and the response of each item was indicated on a 3-point Likert scale as follows 0 (""Disagree""), 1 (""Undecided""), and 2 (""Agree"") (e.g., It is crucial to report a suspected case to health authorities.). The total score was calculated by summating the raw scores of the six questions ranging from 0 to 12, with an overall greater score indicating more positive attitudes towards COVID-19. A cut off level of �11was set for more positive attitudes towards the prevention of COVID-19. The practice section included 7 items practice measures responding to the COVID-19, and each item was responded as ""Yes"", ""No"", and ""Sometimes"" (e.g., Do you use tissues or handkerchiefs during coughing/sneezing?). Practice items' total score ranges from 0-7, with an overall greater score indicates more frequent practices towards the COVID-19. A cut off level of �6 was set for more frequent practices. The data analysis was performed using Microsoft Excel 2019 and SPSS version 25.0 (Chicago, IL, USA). Microsoft Excel was used for editing, sorting, and coding. The excel file was then imported into SPSS software. Descriptive statistics (frequencies, percentages, means, standard deviations) and first-order analyses (i.e., chi-square tests) were performed. Binary logistic regression was performed with a 95% confidence interval to determine significant associations between categorical dependent and independent variables. The study was conducted in accordance with the Institutional Research Ethics and the declaration of Helsinki. Formal ethical approval was granted by the Ethical Review Committee, Uttara Adhunik Medical College, Uttara, Dhaka-1260, Bangladesh (Ref: UAMC/ERC/04/2020). The consent form documented the aims, nature, and procedure of the study. Anonymity and confidentially were strictly maintained. A total of 2,017 respondents were included in the final analysis, of which 59.8% male with an average age of 24.4±5.4 years (SD) ranging from 12 to 64 years. Almost all respondents were not married (80.8%). The majority were students (71.2%), had a bachelor's level of education (61.0%), came from urban areas (69.8%), lived in nuclear families (77.9%) and their monthly family income was >30,000 BDT (50.0%) ( Table 1) . In the perception component, Table 2 depicts our findings. For the mode of transmission, more than half of the respondents reported close contact with an infected person (93.7%), direct transmission during coughing (66.4%), touching contaminated surfaces (61.3%), along with others as just as contact with infected animals (30.8%), through eating infected animal products (e.g., meat, milk) (21.4%), and only 0.5% had no idea about the mode of transmission of COVID-19. Most of the respondents (91.3%) reported the correct incubation period (2-14 days), and only 2.4% had no knowledge. Most of the respondents (99.4%) reported fever, dry cough, and difficulty breathing as the common symptoms of the COVID-19. On the other hand, half of the respondents (51.2%) reported sore throat, nasal stuffiness, along with headache (0.1%), diarrhea (0.7%), and no idea (0.4%). The respondents identified risk groups for developing COVID-19 as follows: older age persons (86.1%), individuals with cancer, diabetes, chronic respiratory diseases (74.6%), migrants from other parts of the world having COVID-19 (44.8%), children (25.3%), pregnant women (21.2%), and no idea (0.8%). The majority (80.7%) reported supportive treatments, but a vaccine was rarely mentioned (1.0%), and 18.3% had no idea about the treatment options of COVID-19. The respondents recognized the following preventive measures for the COVID-19: washing hands with water and soap (93.5%), maintaining social distance (93.5%), avoid touching the eyes, nose with hands (90.4%), using a mask (87.2%), avoid contacts with infected people (84.7%), taking all family members into home quarantine (78.1%), maintaining self-quarantine (76.9%), strengthening to health care (63.6%), and creating a strong force to fight against COVID-19 (26.7%). The respondents took the initiative to protect their family members: temporary and absolute restricted access to outside people coming inside the home (87.8%), arrange for handwashing with soap inside or outside the home (85.5%), and wash hands with soap after touching pets (39.4%). The respondents also reported that they faced many problems to create awareness among their family members: not being able to stop from leaving the house (57.1%), negligence about the severity of the disease (40.3%), reluctance to use masks (25.5%), and only 19.7% had no problems. For each question of knowledge, the distribution of responses from participants is presented in Table 3 with gender differences. There were no significant gender differences for each item of knowledge questions; 48.3% of respondents had more accurate knowledge, and 51.7% of respondents had comparatively inaccurate knowledge regarding COVID-19. The proportion of more accurate knowledge were significantly more likely to be among (i) younger (12-20 years) (49.3% vs. 38.8% in aged more than 30 years, p = .029), and (ii) be a respondent from a rural area (52.8% vs. 46.3% in those from an urban area, p = .008) (see Table 6 ). The sociodemographic factors of more accurate knowledge were 12-29 years age group vs. >30 years (OR = 1.54; 95%CI = 1.10-2.16, p = .012), and rural vs. urban areas (OR = 1.295; 95CI% = 1.07-1.57, p = .008) (see Table 6 ). For each question focused on attitude, the distribution of responses from participants is presented in Table 4 . The response rates of ""Agree"" were significantly higher in females (99.5% vs. 98.3% in males, p = .043) to the item of attitude section regarding ""It is crucial to report a suspected case to health authorities"". Furthermore, the response rates of ""Agree"" were significantly higher in females (99.6% vs. 98.1% in males, p = .011) to ""It is important to use a face mask in a crowded place."" The findings indicated that 62.3% of respondents had more positive attitudes towards COVID-19. The proportion of more positive attitudes were significantly more likely to be (i) among older individuals (> 30 years) (72.5% vs. 55.1% in aged 12-20 years, p < .001), and (ii) those with higher education (74.1% vs. 52.2% in intermediate [class [11] [12] , p < .001), (iii) married (70.4% vs. 37.5% in divorced, p = .001), (iv) housewives (78.1% vs. 58.2% in student, Table 6 ). Finally, regarding variables related to more positive attitudes against COVID-19, we found being younger (aged 12-20 years) vs. older (>30 years) significantly differed (OR = 0.47; 95% CI = 0.33-.67, p < .001). Additional factors of more positive attitudes against COVID-19 were having higher education (above bachelor), being unemployed, having joint families, having monthly family income more than 30,000 BDT, and having more frequent practices (Table 6 ). For each question of practice, the distribution of responses from participants is presented in Table 5 . The response rates of ""Yes"" were significantly higher in females (81.8% vs. 73.5% in males, p < .001) to the item of practice section regarding ""Do you use tissues during coughing/ sneezing?"", as well as ""Do you wash hands frequently using water and soaps?"" (95.6% vs. 92.5% in males, p = .023). Similarly, ""Yes"" response rates were significantly higher in females (96.2% vs. 87.1% in males, p < .001) to ""Do you maintain social distance (or home quarantine)?"", to ""Do you maintain a healthy lifestyle focusing on outbreak?""(88.3% vs. 81.4% in males, p < .001), and to ""Do you obey all government rules related to the COVID-19?"" (93.0% vs. 85.4% in males, p < .001). Furthermore, 55.2% of respondents had more frequent practices towards the COVID-19. The proportion of more frequent practices were significantly more likely to be (i)female (59.2% vs. 52.6% in male, p = .003), (ii) older (age > 30 years) (64.0% vs. 48.6% in aged 12-20 years, p < .001), (iii) have higher education (63.6% vs. 35.0% in secondary [6 th -10 th grades], p < .001), (iv) be a housewife (68.8% vs. 52.2% in students, p = .001), (v) have monthly family income 20,000-30,000 BDT (57.9% vs. 48.6% in those < 20,000, p = .002), (vi) be a respondent from urban area (58.7% vs. 47.2% in those from rural areas, p < .001), and (vii) have more positive attitudes (58.6% vs. 49.7% in comparatively less positive attitudes, p < .001) (see Table 6 ). The sociodemographic factors of more frequent practices were sex (males vs females: OR = 0.76; 95%CI = 0.64-0.92, p = .003), being younger (12-20 years) vs. older (>30 years) (OR = 0.53; 95%CI = 0.38-0.75, p < .001), having secondary (6 th -10 th grades) vs. higher education(above bachelor) (OR = 0.31; 95%CI = 0.12-0.79, p = .014), having monthly family income less than 20,000 vs. more than 30,000 BDT (OR = 0.71; 95%CI = 0.57-0.88, p = .001), rural vs. urban area (OR = 0.63; 95CI% = 0.52-0.76, p < .001), and having more vs. comparatively less positive attitudes (OR = 1.43; 95%CI = 1.19-1.71, p < .001) (see Table 6 ). This study was conducted aiming at measuring the level of knowledge, attitude, and practice of COVID-19 and perceptions regarding the disease among Bangladeshi people. The findings reveal a substantial number of sociodemographic factors that affect KAP and should prove useful when planning health education programs about emerging infectious diseases. In the scope of perception towards COVID-19, the vast majority of the study participants reported some of the commonest symptoms related to COVID-19 [28] , with only a very small minority being unaware of any of the symptoms, similar to other studies elsewhere [19, 29] . Knowledge about the incubation period was also excellent and similar (86.2%) to the study conducted by Zegarra et al. [29] Similarly, routes of transmission of COVID-19 were reported by the participants: with only a minimal minority (0.2%) participants not being sure or unable of recognizing transmission routes. Perception of COVID-19 severity in the community showed that only 13.8% did not face any difficulty when they discussed and tried to convince their family members about COVID-19 severity. Most of the responses by the participants indicated negligence about the severity of the disease, reluctance to use masks, and the reluctance of complying with not being able to stop going out of the house. This may imply less participation in the preventive measures stipulated by the government as well as less inclination to observe social distancing and other individual preventive actions, although some alternative adaptive strategies were also mentioned. The most frequently identified gap in knowledge among participants was related to disease treatment. Only 18.3% of participants believed that Ref. there is no treatment for COVID-19, while 47.3% participants indicated that COVID-19 is a treatable disease, similar to another study [30] . Furthermore, only 1% of the participants reported vaccine as an option for preventing COVID-19, in marked contrast with the previous study by Srichan et al which found that 31.2% were aware of the vaccine as a potential option [30] . In an earlier study by Aldowyan et al., only 19% of the participants were aware that there is no treatment for coronavirus like MERS-CoV, while 26.6% indicated the use of supportive treatment for MERS-CoV, and 31.1% of the participants mentioned the vaccine option for preventing MERS-CoV [24] . Compared to 3 other studies [17, 30, 31] , our survey uncovered markedly reduced accurate knowledge, positive attitudes, and frequent practices towards COVID-19 [17, 31] . This indicates a significant education gap, likely reflecting suboptimal public health information and dissemination regarding COVID-19, particularly since as indicted our survey primarily sampled educated younger people with ready access to a variety of information sources. Indeed, more accurate knowledge was significantly more likely among young adults, but intriguingly among respondents from rural areas, possibly reflecting that most of the participants were students, and that they all went back home, mostly to rural areas during the lockdown period. Srichan et al. found marital status, education, occupation, annual income were significant factors associated with more accurate knowledge of COVID-19 [30] , whereas Zhong et al. found that male sex, age-group of 16-29 years, marital status, education, employment and being a student were significantly associated with knowledge [17] . Therefore, tailoring of the information provided by health officials and other media outlets on the disease needs to address the multifactorial nature of the drivers leading to reduced knowledge. The findings showed virtually universal agreement among the participants towards reporting to health authorities suspected cases of COVID-19, on the issue wearing a face mask before going to a crowded place, and in following other recommendations. These findings were similar to a very recent study conducted in China, during the rapid rise of COVID-19 outbreak [17] . Saqlain et al. also reported positive attitudes among the vast majority of healthcare professionals towards wearing protective gear [30] . Similarly, the overall attitude towards actions such 'wash hands and face after coming from outside' and 'health education can play an important role for COVID-19 prevention' was universally favorable. Like in this study, Saqlain et al. reported that more than 80% participants strongly agreed that transmission of COVID-19 could be prevented by following universal precautions given by WHO or CDC [31] . During the SARS epidemic, 70.1-88.9% of Chinese residents believed that SARS can be successfully controlled or prevented [17, 32] . Zhong et al. found that 90.8% of the respondents agreed that with control measures such as traffic limits all throughout China, and the shutdown of cities and counties of Hubei Province [17] . Surprisingly, the participants' attitudes differ by age, education, marital status, occupation, family type, monthly income, and practices. In contrast, Saqlain et al. found participants' attitudes were not affected by age, gender, experience, and job/occupation. Giao et al. also found that attitudes regarding COVID-19 did not present any significant associations with age, gender, and experience, but found a statistically significant association with occupation/job [33] . Also of relevance, Albarrak et al. and Khan et al. did not find any differences in attitude towards MERS among doctors, pharmacists, and nurses [34, 35] . In the multiple logistic regression analyses, sociodemographic variables associated with more positive attitudes regarding COVID-19 were older age, having higher education, being employed, having joint family, having higher monthly family income, and implementing more frequent practices, overall recapitulating previous findings from China [17] . The issue of preventive practices merits some comment since for some measures such as hand washing the results were remarkably similar to the findings other [30, 35, 36] , albeit with the exception of the study by Srichan et al., in which 54.8% did not regularly use soap during washing of hands [30] . Globally, women were significantly more likely to adopt preventive activities than men, a finding that may be of critical importance since targeting of women during household dissemination of education and preventive guidelines may ultimately yield improved implementation in households. Accordingly, we found that the sociodemographic factors associated with more frequent practice measures were being female, older age, having higher education, higher income, urban area residence, and having more positive attitudes. Male gender, occupation of ""students"", COVID-19 knowledge score, marital status, and residence were significantly associated factors in the Zhong et al. study, while experience was indicated by Saqlain et al., Ivey et al. and Hussain et al. [31, 37, 38] . Considering the fact that Bangladesh is a multi-ethnic country with vastly different economic income, education levels, traditions, it is expected that the levels of knowledge, attitude, and prevention will also markedly differ in the population. Although good KAP was present in a sizeable proportion of the sample, it is very likely that population sectors that have no access to internet or live in regions with less likely fast escalation of transmission may also display reduced KAP when standard and uniform education and dissemination initiatives are promulgated and implemented. Indeed, it is highly probable that large clusters of people will become less informed and adoptive of prevention practices on COVID-19 [22] . Accessibility to information, dissemination and illustration of preventive behaviors, and sanitary educational measures are essential, especially in rural areas, among old people, poorer neighborhoods or communities, since these may have difficulties in getting access to novel information or encounter financial or resource barriers to implementation of preventive measures [15] . It is common consensus that a more educated population about any given disease will comply better with the preventive and treatment measures [39] . This study has several limitations. First, this study followed a cross-sectional study design. Therefore, causal inferences may not be established. Second, compared with face-to-face interviews, self-reporting has limitations including multiple biases. Third, this study used an online-based survey method to avoid possible transmission, such that the cohort reflects sampling biases by being conducted online, thereby restricted to only those with internet access, and consequently unlikely to represent an accurate reflection of the whole Bangladeshi population. Notwithstanding, our study indicates that KAP assessments towards the COVID-19 pandemic of vulnerable populations warrant special effort to address the gaps incurred by the current study approach. Fourth, we used a limited number of questions to measure the level of knowledge, attitude, and practice. Thus, additional assessments would be important, using all aspects of KAP towards COVID-19, to determine the actual extent of KAP in the general population. Additionally, the unstandardized and inadequate assessment of attitudes and practices towards COVID should be developed via focus group discussion and in-depth interviews and constructed as multi-dimensional measures.@story_separate@Our findings indicate that after the immediate lockdown and during the rapid rise period of the COVID-19 outbreak, internet users in Bangladesh displayed substantial differences in KAP regarding the pandemic. Our findings suggest the need for effective and tailored health education programs aimed at improving COVID-19 knowledge, thereby leading to more favorable attitudes and to implementation and maintenance of safe practices. Supporting information S1 Data. (XLSX)","In Bangladesh, an array of measures have been adopted to control the rapid spread of the COVID-19 epidemic. Such general population control measures could significantly influence perception, knowledge, attitudes, and practices (KAP) towards COVID-19. Here, we assessed KAP towards COVID-19 immediately after the lock-down measures were implemented and during the rapid rise period of the outbreak. Online-based cross-sectional study conducted from March 29 to April 19, 2020, involving Bangladeshi residents aged 12–64 years, recruited via social media. After consenting, participants completed an online survey assessing socio-demographic variables, perception, and KAP towards COVID-19. Of the 2017 survey participants, 59.8% were male, the majority were students (71.2%), aged 21–30 years (57.9%), having a bachelor's degree (61.0%), having family income >30,000 BDT (50.0%), and living in urban areas (69.8). The survey revealed that 48.3% of participants had more accurate knowledge, 62.3% had more positive attitudes, and 55.1% had more frequent practices regarding COVID-19 prevention. Majority (96.7%) of the participants agreed ‘COVID-19 is a dangerous disease’, almost all (98.7%) participants wore a face mask in crowded places, 98.8% agreed to report a suspected case to health authorities, and 93.8% implemented washing hands with soap and water. In multiple logistic regression analyses, COVID-19 more accurate knowledge was associated with age and residence. Sociodemographic factors such as being older, higher education, employment, monthly family income >30,000 BDT, and having more frequent prevention practices were the more positive attitude factors. More frequent prevention practice factors were associated with female sex, older age, higher education, family income > 30,000 BDT, urban area residence, and having more positive attitudes. To improve KAP of general populations is crucial during the rapid rise period of a pandemic outbreak such as COVID-19. Therefore, development of effective health education programs that incorporate considerations of KAP-modifying factors is needed."
"It is spring 2020 and the COVID-19 pandemic has the world in its grip. Infection with COVID-19 can lead to a simple cold or no symptoms at all, while it can also rapidly develop into a life threatening disease, especially for patients with existing cardiovascular problems, obesity, or diabetes [1] . Death by COVID-19 is most often the result of massive alveolar damage and progressive respiratory failure [2] . Treatment of a severe COVID-19 infection can involve admission to the Intensive Care (IC) unit of a hospital, where the patient may be kept in a state of sleep and may be supported via artificial respiration. A stay at the IC may take weeks, resulting in high pressure on the availability of IC beds. In order to hamper the spread of COVID-19 and to manage the IC capacity, many countries have applied a lockdown strategy for their citizens [3] . At the moment of writing this article (May 2020), the spread of the virus is declining in Europe, and countries are loosening the restrictions, like lockdown they imposed upon their citizens. In order to control the spread of COVID-19 after a lockdown, and to minimize the effective reproduction number of the disease, several measures can be applied, of which social distancing, combined with aggressive case-finding and isolation seem to be the most effective [4] . eHealth applications have been recognized as a valuable tool for supporting symptom recognition and monitoring [5] , for contact tracing [6] , and ultimately, for reducing COVID-19's effective reproduction number by means of timely intervention. In short, a contact tracing app would record a citizen's contacts with other people via Bluetooth technology and, in the case of a COVID-19 infection, will warn the persons that the index patient recently had contact with so that they can apply self-isolation and be attentive for any COVID-19 symptoms. However, for such applications to be effective, high uptake among the population is necessary. For the case of a tracing application, it has been estimated that 56% of a country's population should use the application to suppress the epidemic [7] . It is therefore crucial that the design of these applications and the implementation strategies that accompany them take the factors that affect acceptance into account. The factors that determine acceptance of COVID-19 apps are largely unknown [8] . The exception here is privacy. Since the first plans of governments to implement these technologies, a fierce public debate has erupted on whether or not large scaling tracing of contacts for this goal is an unacceptable breach of privacy or not. While the issue of privacy has been recognized as an important antecedent of acceptance of mobile health applications [9] , the unique and disturbing situation that the COVID-19 pandemic places us in, makes it difficult to apply existing models and frameworks for eHealth acceptance. The Dutch government wants to develop and implement two mobile applications to prevent the spread of the COVID-19 virus and support Dutch municipal health services. In this paper, we report on an online survey among Dutch citizens with the goal to identify antecedents of acceptance of 1) a mobile application for COVID-19 symptom recognition and monitoring, and 2) a mobile application for contact tracing.@story_separate@To identify antecedents of acceptance of a mobile application for COVID-19 symptoms recognition and monitoring (hereafter: symptom app), and a mobile application for contact tracing (hereafter: tracing app), an online survey was developed, tested and distributed among Dutch citizens. This study did not require formal ethical approval (as ruled by CMO Arnhem Nijmegen, file number: 2020-6628). At the beginning of the survey, participants were asked for consent to use their data for research purposes. The online survey (see appendix 1) consisted of four parts. The first part included questions on demographics, the second part contained questions related to perceived health, the third part consisted of questions related to the fear of a COVID-19 infection, and the final part included questions to assess the intention to use the two suggested mobile applications. In April 2020, the Dutch government announced plans to develop and implement two mobile applications for preventing the spread of the COVID-19 virus. However, the exact design of these applications remained unknown at this time. Therefore, we introduced both mobile applications in the survey via a short description of their general aim. We pre-tested the survey with 14 Dutch citizens to improve legibility. We assessed gender, age, smartphone use, educational level (student, primary school, secondary school, high school, bachelor's degree / University / PhD), work status (unemployed and searching for work, not able to work due to illness, volunteer work, part-time work, full-time work, retired, student), income level (below average wages, average wages, above average wages) and living status (living alone, living together, other). We assessed the participants' attitude towards technology, using the Personal Innovativeness in the Domain of Information Technology scale by Agarwal & Prasad, 1998 [10] , consisting of four statements and accompanied by a five-point Likert scale (ranging from 1 (strongly disagree) to 5 (strongly agree)). Finally, we also asked whether participants were (once) infected with COVID-19. The answer options for this question were: Yes, In doubt, or No. To assess perceived health, we asked participants to complete three questions. These questions were used previously to assess perceived health among Dutch citizens [11] . These questions/statements were: 1. How would you describe your health?; 2. How concerned are you about your health?; and 3. I am ill more often than other people of the same age and sex. These were accompanied by a five-point Likert scale ranging from 1 (bad, not concerned and totally disagree, respectively) to 5 (excellent, very concerned and totally agree, respectively). The participants' fear of a COVID-19 infection was assessed by means of four questions related to this topic. -Have you been concerned about the outbreak of the COVID-19 virus in recent weeks? [five-point Likert scale, ranging from 1 (not at all concerned) to 5 (extremely concerned)]; -How often did you think of the outbreak of the COVID-19 virus in recent weeks? [five-point Likert scale, ranging from 1 (never) to 5 (always)]; -How afraid were you of the outbreak of the COVID-19 virus in recent weeks? [five-point Likert scale, ranging from 1 (not afraid at all) to 5 (very afraid)]; -How afraid are you of getting sick from the COVID-19 virus? [five-point Likert scale, ranging from 1 (not afraid at all) to 5 (very afraid)]. Finally, participants were asked to rate their intention to use the two mobile applications: 1) a symptom app, and 2) a tracing app. The statements for the construct intention to use were based on Van Velsen et al., 2015 [12] . All three questions were accompanied by a five-point Likert scale All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.02.20113423 doi: medRxiv preprint ranging from 1 (strongly disagree) to 5 (strongly agree). Next to these closed questions, respondents were also asked what the main reasons were to 'use' and 'not to use' the mobile applications. Distribution of the survey started on April 15, 2020. Participants were eligible if they were 18 years of age or older. We used a snowball sampling via posts on social media (LinkedIn, Twitter and Facebook) and personal connections. Next to this, we recruited participants via a Dutch panel of older adults that indicated they were interested in participating in research on the topic of eHealth. The survey was closed on April 30, 2020. Due to the method of recruitment, a response rate could not be calculated. Data were analysed by using SPSS, version 19. Descriptive statistics were performed for all outcomes. Cronbach's alphas were calculated to assess internal consistency for attitude towards technology, perceived health, fear of COVID-19 and intention to use. Next, survey scores were interpreted for these factors as being negative (score 1 or 2), neutral (score of 3), or positive (score 4 or 5). Via a paired t-test, the difference in intention to use score between both mobile applications was tested. To identify antecedents of acceptance of 1) a symptom app, and 2) a tracing app, we conducted multiple linear regression analyses (backward model analyses). The intention to use each app was used as the dependent variable. The independent variables were those demographic characteristics and factors that (borderline) significant correlated (Pearson Correlation cut-off level p≤0.10) with the dependent variable. For the paired t-test and regression analyses, the level of significance was set at p < 0.05. In total, 238 Dutch citizens completed the survey. Fifteen responders only completed the intention to use survey of a tracing app as this app was presented first and these responders stopped with the survey after these questions. Almost 60% of the responders were female and the average age was 45.6 years (SD±17.4). Only five responders (2.1%) did not own a smartphone and almost 75% claimed that they carried their smartphone with them for most of the day. The internal consistence of the attitude towards technology scale was good (Cronbach's Alpha = 0.85). Most responders (73.9%) had a moderate attitude towards technology. Only three responders (1.3%) claimed to be infected with COVID-19. All demographic characteristics are presented in table 1. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020.  The internal consistency of the four items in this scale was acceptable to good (Cronbach's Alpha = 0.78). The mean score on this topic was 3.3 (SD±0.68). The majority of the responder's opinion on this topic was neutral (80.7%) and 16% of the responders were afraid for a COVID-19 infection. Only a few responders (3.4%) were not afraid (table 2) . For the three items to assess the perceived health of the responders the internal consistence was acceptable (Cronbach's Alpha = 0.69). The mean score on this scale was 3.8 (SD±0.68). Most respondents were positive about their health (58.4%). The intention to use was assessed for the symptom app and the tracing app. For both scales, internal consistency was excellent; Cronbach's Alpha symptom app = 0.96 and Cronbach's Alpha tracing app = 0.96. For both apps, the majority's intention to use was neutral (see table 2 ). However, an additional paired t-test indicated that there is a significant difference in the scores on intention to use for the symptom app (M=3.38, SD±1.07, n=223) and the tracing app (M=3.27, SD±1.13, n=223); t(222)=-2.598 and p=0.01. Indicating that the responders were more willing to use a mobile application for COVID-19 symptom recognition and monitoring compared to a mobile application for contact tracing. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020.  The intention to use a symptom app is related to income level (r=0.132, p<0.05), attitude towards technology (r=0.220, p<0.01) and fear of COVID-19 (r=-0.291, p<0.01). The intention to use a tracing app is related to age (r=0.135, p=0.04), attitude towards technology (r=0.223, p<0.01) and fear of COVID-19 (r=-0.303, p<0.01). Based on these outcomes the independent variables within the linear regression analysis were: age, income level, attitude towards technology, fear of COVID-19 and perceived health. Table 3 provides an overview of the correlations between all demographics and factors, and the intention to use.  A multiple linear regression analysis was conducted to predict the intention to use a symptom app based on age, income level, attitude towards technology, fear of COVID-19 and perceived health. The final model included the predictors attitude towards technology, fear of COVID-19, and age. The model has an R 2 of 0.141. It contains three factors that affect the intention to use, but only two of them are significant predictors: -Fear of COVID-19, β=0.272, t=4.305, p<0.001; All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020.  An overview of all reasons the responders brought forth for using both mobile applications is presented in table 4. The main reason (28.4%) for responders to use the symptom app, was to control the spread of the COVID-19 virus. In addition, respondents were willing to use this mobile application to monitor own complaints (19.0%) and to gain more insight into the spread and symptoms of the COVID-19 virus (16.4%). The main reason to use a tracing app was also to control the spread of the COVID-19 virus (30.6%). Next to this, respondents were willing to use this mobile application to gain more insight into the spread and symptoms of the COVID-19 virus (23.1%) and for one's own health (12.9%).  An overview of the reasons not to use the mobile applications is presented in table 5. For both mobile applications, privacy was mentioned as the main reason (symptom app=55.7% and tracing app=64.8%) not to use the mobile applications. Other reasons for not using the mobile applications were the expected usefulness of the application (symptom app=23.5% and tracing app=13.4%) and a fear of becoming over aware of the situation and its potential consequences, leading to unnecessary stress (symptom app=7.8% and tracing app=11.3%). Table 5 : Overview of the main reasons not to use the two mobile applications. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020.  The aim of this paper was to identify antecedents of acceptance of 1) a mobile application for COVID-19 symptom recognition and monitoring, and 2) a mobile application for contact It is difficult to relate our findings to the existing literature, as technology acceptance studies have not focused on mobile applications to be used during a pandemic, and insights on factors that determine the acceptance of COVID-19 related mobile applications are lacking [8] . In general, age and attitude towards technology are widely-acknowledged antecedents of acceptance. For age there is evidence that older age is associated with lower level of acceptance of mobile applications [13] . Previous results also indicated that attitude towards technology is an important antecedent of acceptance of mobile applications [13, 14] . The degree to which an individual is willing to try out any new mobile application is related to the intention to use [13] . Our results show that fear of COVID-19 is the most important COVID-19-related factor that predicts acceptance of mobile applications to deal with the COVID-19 pandemic. Since it is difficult to translate this fear into technology design, this finding needs to be seen in a bigger picture. Public health campaigns during the COVID-19 epidemic will need to educate citizens about the dangers of COVID-19 (personally and for society as a whole), and should then offer downloading COVID-19 mobile applications as a personal strategy to deal with this fear. Next, the positive attitude towards technology that precedes a decision to download a COVID-19 app should be taken into consideration when using these innovations. The end-user population might be skewed towards those with interest in technology (traditionally these are younger, highly-educated men [15] ) which can create a use divide, and thus, a health divide in society. Measures should be installed to support those groups in society that are not, by nature, technically interested, like promotional stalls in the community and diverse channels of user support. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.02.20113423 doi: medRxiv preprint The following four limitations should be taken into account for this study. First, the selection bias of our sample. Given the results the education level of our sample is higher compared to the general population. In addition, most respondents had a moderate attitude towards technology. This could be explained by our way to distribute the survey by snowball sampling. Second, for our analysis the power of our sample was sufficient. However, a larger sample would improve the generalizability of our outcomes as mainly Dutch citizens from the eastern part of the Netherlands (87% of our sample) completed our survey. Third, in our survey the two mobile applications are introduced by means of a short description of their general aim. It is unclear if this description was sufficient for the responders to understand to purpose of both mobile applications. Fourth, the explained variance of both our models is relatively low. Normally, in studies such as these, this number is boosted by including the predictors ease of use and perceived usefulness. However, since including these factors leads to little practical results (concluding that the applications should be easy to use is a given and does not inform design), the identification COVID-19-related factors is an important extension of existing technology acceptance models. The survey was developed by SJK, MH and LvV. Statistical analyses were performed by SJK and LvV. All authors were involved in the distribution of the survey and participated in drafting the article and revising it critically for important intellectual content. Not applicable What was already known on the topic: What this study added to our knowledge: • eHealth applications have been recognized as a valuable tool to reduce COVID-19's effective reproduction number by means of timely intervention • The factors that determine acceptance of COVID-19 apps are unknown • eHealth could be a solution to rapidly cope with health demands during a pandemic as an addition to the health care infrastructure • 41-45% of the Dutch adults are willing to use mHealth to prevent the spread of COVID-19 • Age, attitude towards technology and fear of COVID-19 predict the intention to use mHealth to prevent the spread of COVID-19 • The main reasons to use this application are to control the spread of the COVID-19 virus for the general purpose, to monitor their own complaints and to gain more insight into the spread and symptoms of the COVID-19 virus • Privacy, doubting the usefulness of the mHealth application and fear of over awareness leading to unnecessary stress All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.02.20113423 doi: medRxiv preprint are the main reasons not to use mHealth to prevent the spread of COVID-19 9 References (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. What is the main reason for you to use this App? 24 Wat is voor u de belangrijkste reden om geen gebruik te maken van deze App? What is the main reason for you not to use this App?@story_separate@This study is the first to determine the factors related to the acceptance of COVID-19 apps. Age, attitude towards technology and fear of COVID-19 are important predictors of the acceptance of COVID-19 mobile applications for symptom recognition and monitoring and for contact tracing. These predictors should be taken into account during the development and implementation of these mobile applications to secure acceptance.","Introduction: eHealth applications have been recognized as a valuable tool to reduce COVID-19s effective reproduction number. In this paper, we report on an online survey among Dutch citizens with the goal to identify antecedents of acceptance of a mobile application for COVID-19 symptom recognition and monitoring, and a mobile application for contact tracing. Methods: Next to the demographics, the online survey contained questions focussing on perceived health, fear of COVID-19 and intention to use. We used snowball sampling via posts on social media and personal connections. To identify antecedents of acceptance of the two mobile applications we conducted multiple linear regression analyses. Results: In total, 238 Dutch adults completed the survey. Almost 60% of the responders were female and the average age was 45.6 years (SD=17.4). For the symptom app, the final model included the predictors age, attitude towards technology and fear of COVID-19. The model had an R2 of 0.141. The final model for the tracing app included the same predictors and had an R2 of 0.156. The main reason to use both mobile applications was to control the spread of the COVID-19 virus. Concerns about privacy was mentioned as the main reason not to use the mobile applications. Discussion: Age, attitude towards technology and fear of COVID-19 are important predictors of the acceptance of COVID-19 mobile applications for symptom recognition and monitoring and for contact tracing. These predictors should be taken into account during the development and implementation of these mobile applications to secure acceptance."
"As clinicians from black and minority ethnic (BAME) background working in the acute services fighting the COVID-19 pandemic, we acknowledge that the contagion has led to disproportionately higher mortality rates in the ethnic minorities. The excess mortality from the SARS-Cov-2 virus in BAME groups is not limited to the general population; it has also adversely affected the healthcare professionals belonging to these backgrounds. Many governments (including the United Kingdom) have rolled our risk assessments and mitigation programmes for BAME healthcare workers with a view to identify those at the highest risk of developing severe disease and re-assign them to the nonacute areas. As clinicians, we find ourselves in a dilemma; whether to exercise caution and avoid high risk work environment or to follow our compassion and continue to deliver the best quality clinical care at the front end.@story_separate@Since the report of the first case of coronavirus disease in China late last year, the infection has rapidly spread around the globe in the last 9 months. To date, the total number of confirmed COVID-19 cases stands at 63 million with approximately 1.5 deaths across the world [1]. Advancing age, diabetes, hypertension and underlying respiratory and cardiovascular conditions are associated with an increased risk of developing severe form of the disease ultimately resulting in higher mortality rates [2] . In addition, individuals from black and minority ethnic (BAME) background are also at higher risk of death from COVID-19. The initial data from the Office of National Statistics (UK) revealed that after adjusting for age, sociodemographic characteristics and comorbidities; patients from BAME groups were nearly twice as likely to die from the pandemic compared to those belonging to the white ethnicity [3] . The UK ethnic minorities represent 14% of the population; however, approximately one-third of seriously ill intensive care COVID-19 patients belonged to BAME background [4] . Similar figures have been recorded in the USA, where 24.3% of all COVID-related deaths occurred in black Americans who account for 12.4% of the USA population [5] . The ethnicity-related excess rates of COVID-19 deaths are not limited to the general population; similar trends have been noted in the healthcare professionals working for the National Health Service (NHS), too. According to the data published by British Medical Association (BMA), approximately onefifth of NHS healthcare workers come from black or ethnic minority background; however, two-thirds of all healthcare staff who died due to COVID19 were from these ethnic groups [6] . The mortality figures for medical staff are even more worrying, where 94% of all deaths occurred in doctors originating from black and minority ethnic groups [7] . The disproportionately high mortality rate amongst BAME staff is not adequately explained by the age, gender and sociodemographic factors and other work-place based inequalities faced by these staff groups must be explored further [8] . Fear of repercussions for reporting COVID related concerns, adverse psychological support, isolation at work place and poor access to personal protective equipment may all play a role. In line with BMA's recommendations, NHS organisations have started to carry out risk assessments for medical staff belonging to ethnic minorities. It was thought that a robust, well-structured and collaborated risk assessment would improve the confidence amongst the healthcare workers about on-the-job protection. Although 'remote working' was initially suggested as an option to reduce the exposure to contagion; however, it is not feasible for the majority of frontline staff who are involved in providing direct face-to-face care to acutely unwell patients. Besides, it is well documented that remote working facilities are not consistently available to all medical and nursing staff, with BAME staff being particularly disadvantaged [9] . Senior clinicians working in the emergency and acute medicine specialties were offered risk assessment with a view to redeploy those with the highest risk, away from the frontline acute areas. Whilst this strategy can help to reduce their risk of contracting COVID-19; it does not address their professional and emotional needs. Like our non-BAME colleagues, we also take our commitment to providing a timely, effective and compassionate clinical care to patients at the front door very seriously. Managing the COVID-19 pandemic is an unfinished task, and as senior clinicians and leaders, we would not just walk away from it, until it is successfully dealt with. Moreover, our responsibility is not limited to providing the direct patient care; we also have a duty to guide our teams comprising medical, nursing and allied healthcare staff, who are looking towards us for inspiration during these difficult times. Role modelling is an integral component of clinical teaching and is particularly effective during complicated and challenging situations. To 'lead by example' is what distinguishes clinical teachers from the classroom lecturers [10] , and facilitates the development of attitudes, values and professional competencies in medical students and trainees. We find ourselves in a dilemma, stuck between our passion of medicine and duties as role models on one hand and personal health risks, on the other, whilst we are advised to exercise caution and accept re-deployment to non-acute areas to reduce the risk of developing severe COVID-19 disease. Guided by our professional and moral responsibility, we wish to continue leading our team from the front with compassion, courage and commitment during these difficult times.@story_separate@As we write these lines, the world continues to battle the COVID-19 pandemic. It is a testing time for our communities and the medical profession. It is important that the risk assessments are open-ended and genuinely attempt to capture the sensitivity of the situation of BAME staff. Urgent steps must be taken to improve their access to PPE and to facilitate remote working, where appropriate. Whilst most of the risk assessment focus on the physical factors; employers must also nurture the psychological and emotional well-being of their BAME health care staff. The risk of severe COVID-19 disease and death remains high in the BAME healthcare staff. Despite this, as clinicians from minority ethnic groups, we feel reinfused with enthusiasm to continue serving our patients and profession. When this pandemic will be over, we would look back at this difficult era, with pride that not only we served our patients but also led our trainees in the face of adversity and uncertainty, during a raging pandemic.","The wide disparity in coronavirus disease (COVID-19)–related death rates based upon the ethnic origin is well established by now. The higher incidence of COVID-19 deaths amongst the healthcare staff belonging to black and minority ethnic (BAME) communities living in the United Kingdom has generated a great deal of concern and anxiety in clinicians. Public Health England (PHE) has outlined mitigation strategies after immense pressure from professional organisations and influential clinical leaders. Although seemingly well thought through, these measures fall short of addressing the professional, moral and emotional dilemma faced by the BAME clinicians who feel that they are being expected to choose between their duty towards their patients and the profession, and their responsibility to look after their own health."
"Pandemics such as the current COVID-19 are large-scale outbreaks of infectious diseases that can greatly increase the mortality over a wide geographic area and cause significant economic, social, and political disruption [1, 2] . Based on evidences, experts suggest that the likelihood of pandemics occurrence has increased significantly [3, 4] . Issues such as global travel and integration, urbanization, land use, and intensive exploitation of the natural resources contribute significantly to stimulate this problem [3] . An epidemic can be defined as the occurrence, in a community or region, tors and the stock market volatility across five major world economies were studied [40] . In the follow-up the data and methods adopted in this work, such as the cointegration analysis [9, 10] and the VECM methodology [12] are discussed.@story_separate@We consider the TS describing the 4 disease outbreaks and 11 key stock exchange indices. The data are avaiable at the World Health Organization (WHO) website (https://www.who.int/) and at the Investing website (https://www.investing.com/). We analyze the evolution of the number of cases of the 4 pandemics during first 79 days of available data versus the evolution of the financial indices during the same period. The work aims to measure the impact of the outbreaks against the indices. Figure 1 shows the market data and the total number of cases for each of the disease outbreaks sets. In order to normalize the curves, the z-score standardization is adopted [41] . The stationarity of the TS are evaluated by means of the Augmented Dickey-Fuller (ADF) test [42] . The presence of unit roots in a TS is detected by not rejecting the null hypothesis of the aforesaid test. The trend, drift and constant are types of regression models that can properly identify the integration order (d) of a TS, that is, the number of times necessary to differentiate a TS that was originally non-stationary to become a stationary one. This is a necessary property to identify a cointegration relation between two TS [10] . The cointegration process [43] is analyzed by means of the Johansen test [9] and they are explained in the sections 3.1 and 3.2, respectively. Whenever a cointegration relation is observed between the TS, the VECM equation [44, 45] is estimated and the OIR and FEVD are analyzed. We also calculate the historical market volatility σ for the 11 stock indices as the square root of the sum of squared returns over the past 79 trading days [46] .  The cointegration relation between two TS was firstly introduced by Granger [43] . Later, Engle and Granger [47] explored the cointegration and the error correction mainly for estimation and testing. A simple interpretation of a cointegration relation and the process of adjustment known as the error correction model was proposed by Murray [48] . Smith et al. [49] proposed an extension of the concepts by exploring the multiple cointegration with 3 or more cointegrated variables. Hereafter, in the scope of investigating the transmission process among the pandemics and stock exchanges, the cointegration hypothesis is considered. J o u r n a l P r e -p r o o f Often, we observe some misinterpretation between the terms ""cointegration"" and ""correlation"". Alexander [50] pointed that a cointegration process takes into account both the concepts of integration and stationarity, while that is not considered in a correlation measure. Additionally, the correlation calculates a linear association between two TS. The cointegration of two or more TS can be studied, while a correlation is simply a coefficient in the range [−1, 1]. However, a cointegration process cannot be ""quantified"", and, instead, it is ""identified"". The equilibrium error term for a TS x t was defined by Engle and Granger [47] as where t stands for the discrete-time sampling instants and z t is in the perfect equilibrium state that occurs when α = 0. In addition, x t is said to be a stationary TS if its integration order d is equal to 0. For d > 0 each step represents the quantity needed to differentiate the TS in order to make it stationary [48] . When a cointegration relation is revealed between two different TS such as, between x t and y t , both of them must be integrated at the same order. Thus, if x t ∼ I(d), then a + bx t ∼ I(d) is also true, where a and b are real constants and b = 0. Therefore, the error term can be rewritten as a linear combination as follows This means that when d = b = 1, if both TS are integrated at I(1), then the z t is said to be cointegrated of order zero I(0), and the adjustment occurs for each step. However, it is possible the occurrence of some special cases, namely, z t ∼ I(d−b), 0 < b < 1, that would lead to a fractional differentiation process [51] . In other words, this relation can also be expressed by defining the following error correction parameters f and g as where x t and y t denote the cointegrated variables, u t and w t represent stationary white noise and e 1t−1 = y t−1 − x t−1 and e 2t−1 = x t−1 − y t−1 are the cointegration relations between the variables x t and y t , respectively. J o u r n a l P r e -p r o o f In this work, we evaluate the cointegration process among the 4 pandemics, with respect to the 11 stock exchanges indices. The cointegration is calculated by means of the Johansen test, and the VECM is estimated when the cointegration between a particular disease with respect to the particular stock index is verified. The VECM is based on the generalized vector autoregression (VAR), that allows the adjustment of a regression model between multiple variables to evaluate their relationship [44, 45] . Let us consider p 1t and p 2t as two non-cointegrated and non-stationary TS. The relation between these TS can be described using the VAR model of order j ∈ N for both variables as [52]  where γ and θ are the equation autoregressive terms of p 1t and p 2t , respectively, ε 1t and ε 2t denote white-noise disturbances and i the equation lag order i = 1, ..., j. However, if the TS are not initialy stationary, then the log returns (∆) in p 1t and p 2t can be applied in order to become stationary equations as [53, 52] : Thus, the VAR(j) model is applied to the differences giving If the two TS can exhibit a cointegrated relation between each other, then the Error Correction Term (ECT) represented by α i (β 0 + β 1 p 1t−1 + 7 J o u r n a l P r e -p r o o f β 2 p 2t−1 ) can be implemented and the VAR model becomes a VECM as follows [54, 55, 56, 57]  where β and α are matrices whose dimensions are n × r, representing the TS and the cointegrated vectors, respectively. The β parameters are related to the long-run equilibrium among the TS. The parameters α reflect how fast the series tend to return the equilibrium after some perturbation by defining the steps to come back to equilibrium s, such as s = 1/α. Moreover, from the ECT term one can extract the following relation β 0 + β 1 p 1t−1 + β 2 p 2t−1 = 0 that represents the equilibrium equation between p 1t and p 2t . Statistical analysis, estimation, hypothesis testing and inference of cointegration vectors related to the β and α terms can be found in [58, 59, 60] . The Johansen test verifies if the rank r of the matrix α β is equal to zero (null hypothesis), that is, if r = rank(α β) = 0. If r = 0, then this implicate the non-existence of the error correction term (ECT). Otherwise, if r = 0, then the null hypothesis is rejected and there is a cointegration relation between the TS. Johansen proposed two possibilities, namely, the Max-Eigen and the Trace tests, that are based in the assumption of pure unit root denoted by [61, 59] LR trace (r 0 , r 0 where LR denotes the likelihood ratio for testing the null hypothesis of r = r 0 , T stands for the sample size, λ is the eigenvector associated with the matrix and n is the maximum number of possible cointegrating vectors. In contrast to the method for cointegration validation proposed by Engle-8 J o u r n a l P r e -p r o o f Granger [47] , the Johansen test allows the study of more than one cointegration relation among the variables. For this reason, we adopt the Johansen approach for analysing possible cointegration processes between the disease incidence versus the stock index. Whenever a cointegration is detected, the VECM is applied for the stock indices. This section presents the obtained results for the stationarity of the TS, using the ADF method [42] . The cointegration results achieved by means of the Johansen test based on the Max-Eigen and Trace criteria for 11 different financial indices against the 4 outbreaks are analyzed. Afterwards, the Hansen and Seo [62] threshold existence significance test is explored. This test is important to decide if VECM is an appropriate model to carry out the work. The correlation, the VECM, the response from an orthogonal impulse (OIR) and the FEVD are depicted. The historical volatility during the 4 outbreaks for the 11 stock exchange indices is also obtained. Tables 1 and 2 summarize the obtained results for trend, drift and constant models. One can note that all financial indices are integrated at order d = 1 with the COVID-19, EBOLA and MERS data and at order d = 2 with the SARS data. Tables 1 and 2 indicate also that the SARS data and the financial indices present cointegrations of orders I(2) and I(1), respectively. This means that the significant results produced by the Johansen test can indicate a spurious result. Table 3 shows the results of the Johansen cointegration test for the 11 financial indices against the 4 outbreaks. One can observe that the majority of the financial indices is strongly affected by the disease outbreaks. Moreover, we verify the cointegration of all stock exchange indices with the COVID-19, EBOLA and MERS. However, not all indices follow that trend in what concerns the SARS. Tables 4, 6, 8 and 10 summarize the obtained results for the threshold effects by testing the significance of their existence through linear cointegration versus threshold cointegration. Indeed, the threshold cointegration test listed in Table 10 confirms that a linear cointegration would not be appropriate for a few TS involving the SARS, namely S&P 500, Nikkei, HSI and Nifty. Nevertheless, among the 44 possibilities (11 financial indices versus 4 outbreaks) listed in Tables 4, 6 Drift None did not reject the null-hypothesis for linear cointegration. Therefore, they should not be handled by using the threshold approach [62] . Bearing this fact in mind and knowing that the OIR and the FEVD are VECM-based tools, we decided to maintain the cointegration relations between the financial indices and the outbreaks that showed a linear cointegration by means of the Johansen test. In this context, we consider the VECM model as appropriate for describing the relationship between the outbreaks and the financial indices. Their results are analyzed for all pairs that presented a cointegration process by means of the Johansen criteria. Tables 5, 7, 9 and 11, list the correlation and the VECM parameters for the indices that revealed cointegration against the COVID-19, EBOLA, MERS and SARS data, respectively.  J o u r n a l P r e -p r o o f We now explore the OIR and apply the FEVD to measure the variance of the forecast error regarding the shocks of the outbreaks data. In order to normalize the OIR results, the z-score standardization is also performed. Figures 2a, 2c, 3a and 3c represent the OIR over time. On the other hand, the figures 2b, 2d, 3b and 3d depict the FEVD analysis for the 11 stock exchange indices also against the COVID-19, EBOLA, MERS and SARS data. Steps (a) The OIR: financial indices against COVID-19. by the EBOLA outbreak. However, it tends to bounce back to equilibrium in the following steps. Figure  J o u r n a l P r e -p r o o f Figure 3a shows that, in general, all indices tended to be negatively influenced by the MERS outbreak. This effect is confirmed by the FEVD in figure 3b . Moreover, the HSI and Ibov are the most influenced in terms of the variance of their residuals. In turn, the shocks caused by the SARS provoked a strong initial negative response in the Nifty and Nikkei and a retarded negative shock in the CAC and EuroStoxx, as shown in figure 3c. However, when observing the FEVD in Figure 3d one can note that the SARS affects mostly the Ibov, Nikkei, Nifty and HSI. This pattern would be expected in the Asian stocks, but the same would not be expected in the Ibov since the OIR showed a positive response. Probably, this result can be related to a false positive. Table 9 : The Correlation and the VECM parameters for the cointegrated indices against the MERS. Confidence levels: 90%(*), 95%(**) and 99% (***). J o u r n a l P r e -p r o o f Tables 5, 7, 9 and 11, show a significant number of lags for the VECM equations in all outbreaks, with exception for the MERS. We verify a 8-lags equation for all the stock exchange indices against the COVID-19 data which confirms a large influence of the outbreak with respect to the residuals of the steps. Also, when using the equilibrium relation s = 1/α it is shown that for all equations a huge number of steps is necessary to reach equilibrium back from the COVID-19. When looking to the indices relation with the EBOLA outbreak it is seen a high lagged VECM only for North American indices. However, all the indices shows high disequilibrium reflected by the parameter α. The results for the indices against the MERS were expected since the disease lead a moderate number of cases if compared to the other outbreaks, which is also confirmed by the higher of α values. Despite the SARS outbreak being mostly spread over Asian countries, the HSI presented a 3-lags equation rather than the 8-lags of the other indices. J o u r n a l P r e -p r o o f  J o u r n a l P r e -p r o o f In synthesis, with exception of the SARS, all stock indices are cointegrated with the COVID-19, EBOLA and MERS. This feature is not evinced by the SARS since some indices related mainly to the North America and Europe revealed a weak or even null cointegration. Figure 4 shows the historical market volatilities σ for the 11 stock indices during the period of the diseases episodes. In the map, we mark the historical volatility as the square root of the sum of squared returns over the past 79 trading days. With the exception of the Nikkey and HSI indices, all other indices experienced higher historical volatility during the analyzed period for the COVID-19, suggesting an unprecedented stock market impact caused for it and a greater difficulty to bounce back the financial indices. Moreover, one can note that among all indices explored in this work, the Ibov index was the most susceptible and strongly affected by the shocks due to the diseases. We believe the results offer ground for some reflection about of heavy-25 J o u r n a l P r e -p r o o f handed restrictions on the economical activity in the scope of the efforts to contain pandemics. The healthcare rationale for travel restrictions, business closures, and social distancing mandates is clear, but it is also painfully evident that these policies bring great economic and financial negative consequences. Therefore, an important challenge is how to address health crisis created by pandemics (such as the COVID-19) and, simultaneously, to avoid strangle the economy. A pandemic can be followed by sustained periods -over years or decades -with affected investment opportunities, possibly due to heightened desires to save, that is, due to an increase in precautionary saving or to a rebuilding of depleted wealth. Several nations have adopted an aggressive counter-pandemic fiscal expansion that will boost the public debt further, reducing the national savings rate. In turn, this might put upward on the interest rate, even though that the expansion of public debt could be easier to sustain in the long-run. This movement can affect, among others, the subsequent low returns to assets, impacting (to some extent) the stock exchange indices worldwide. Regarding the current COVID-19 pandemic, the global economic trajectory seems very different than was expected only some months ago.@story_separate@This paper considered the Johansen cointegration test and the bivariate VECM analysis, exploited by the OIR and the FEVD, to investigate the bilateral relationship between the incidence of important 4 diseases outbreaks against 11 stock exchange indices. The historical volatilities of the same stock indices were also calculated. The results revealed that the shocks caused by hte diseases has a significant effect upon the stock indices. Most of the indices suffered initial strong shocks due the impulse in each disease outbreak. However, differently from the others diseases, an impulse in the COVID-19 maintained a significant volatility after the initial period, showing recovering difficulties of the financial indices due the shock caused by COVID-19. Additionally, the higher historical volatility occurred mainly during the period of the COVID-19. The results point to a higher impact over the Ibov-Brazil and reveal its poor recovering dynamics when compared to the others indices. This phenomenon can be explained by the fact that, in general, there is a larger perception of risk by investors related to countries with larger economic and social fragility. 26 J o u r n a l P r e -p r o o f","The COVID-19 brings back the debate about the impact of disease outbreaks in economies and financial markets. The error correction terms (ECT) and cointegration processing tools have been applied in studies for identifying possible transmission mechanisms between distinct time series. This paper adopts the vector error correction model (VECM) to investigate the dynamic coupling between the pandemics (e.g., the COVID-19, EBOLA, MERS and SARS) and the evolution of key stocks exchange indices (e.g., Dow-Jones, S&P 500, EuroStoxx, DAX, CAC, Nikkei, HSI, Kospi, S&P ASX, Nifty and Ibov). The results show that the shocks caused by the diseases significantly affected the markets. Nonetheless, except for the COVID-19, the stock exchange indices reveal a sustained and fast recovering when an identical length time window of 79 days is analyzed. In addition, our findings contribute to point a higher volatility for all financial indices during the COVID-19, a strong impact over the Ibov-Brazil and its poor recover when compared to the other indices."
"The COVID-19 pandemic has, to date, shown a devastating impact on our society, with more than 49 million confirmed cases and total fatalities exceeding 1,249,000 (as of 6 November 2020) [1] . Global efforts such as early lockdown and travel bans [2, 3] have successfully slowed the virus's spread, as evident by the reduction in the number of people infected and deceased and the subsequent relief of demand on hospitals [4] . Despite their effectiveness, these strong measures led to many dire consequences, including economic [5, 6] and mental health crises [7, 8] . Driven by these challenges, different countries utilized various criteria and strategies to ease previously applied measures and gradually return to normalcy [9] . Relaxing the protective measures included, for example, reopening businesses, schools, restaurants, and recreational facilities [10] . Among other factors, the Fall and Winter seasons are making the situation worse by pushing people back inside closed spaces where the virus has a much easier time spreading than the outdoors [11] . Nevertheless, reopening communities comes with the risk of triggering multiple pandemic waves, which is typically more aggressive than the first wave and could potentially cause devastating social and economic consequences [12] . The concern over multiple waves or spikes of the pandemic has been the subject of various national and international debates. Infected cases from second and third waves of COVID-19 have already been recorded in North America, Europe, and Asia, particularly after easing lockdown orders and allowing indoor activities [1] . The U.S., which has the highest number of confirmed COVID-19 cases [1] (see Fig 1A) , has recently experienced a sudden increase in the number of daily confirmed cases in many states during the last week of October and the first week of November 2020. Common among these states is that they removed the stay-at-home order, reopened schools, and allowed indoor activities, causing a large jump in the confirmed daily cases (see Fig 1B) . A spike in the daily confirmed cases can be observed in more than 42% of the U.S. counties (the total number of counties is 3,143), as shown in Fig 1C. These spikes are forming what appears to be a massive third wave that is expected to have a total number of infected cases exceeding the first and second waves, requiring more protective measures and, in some cases, the need to return to complete lockdown. Understanding the different possibilities and consequences of early easing or removing the previously imposed protective measures is critical for devising effective planning and mitigation policies for reducing social and economic consequences. Hospitals, among other emergency services, are the frontline in the fight against the COVID-19 pandemic. However, since the start of the pandemic, hospital facilities have experienced tremendous strain brought by the demand exceeding their capacity, forcing them to make hard choices between those who can and cannot receive treatments [13, 14] . The hospitalization services needed for COVID-19 cases are based on case criticality. They can be classified into those needing regular beds (inpatient), intensive care unit (ICU) beds, and ICU beds with mechanical ventilators with the hospitalization services and length of stay being a function of the patient's age [15] [16] [17] . Failing to provide adequate and appropriate hospitalization services to those infected can increase the fatality rates, especially for critical cases. In the U.S., the total number of hospitals is 6,630 (see Fig 1D) and includes about 961,092 licensed beds, 92,513 ICU beds [18] , and 62,000 ICU beds with fully-featured mechanical ventilators [19] . The number of unoccupied beds per county (see S1 Fig in S1 File), which can be calculated using the data pertaining to the total number of licensed beds and utilization rates for these beds [18, 20] , shows disparities in the distribution of the hospitals where many U.S. counties, have no beds for any patients including COVID-19-related patients [21] (see Material and Methods). This is simply because no hospitals exist in these counties. These disparities can have a devastating impact on the hospitals' outcomes [22] especially for vulnerable populations (aged +60), as shown in S2 Fig in S1 File, where no one would have access to neither inpatient nor ICU beds in their counties, as shown in Fig 1E and 1F . In this study, we show the impact of multiple waves of COVID-19 on healthcare networks in the U.S. after states reopening during the Fall and Winter seasons. Here, we define healthcare networks as hospital facilities with licensed beds. We perform a disease transmission analysis at the county level to estimate the expected number of hospitalization cases. We further compare the different estimated number of hospitalized cases with the available hospitalization resources to highlight the impact of waves with different magnitudes on patients' access to medical services. We test different state reopening scenarios along with various percentages of susceptible cases and protection rates to assess each scenario's impact on the expected number of cases needing hospitalization services and the number of counties facing a surge in patients beyond their beds capacity. We also investigate the effectiveness of various mitigation strategies, including enforcing protective measures for longer periods, applying states' lockdown at different time scales, and increasing hospital capacity, on enhancing the hospitals' abilities to provide services for the infected patients. Furthermore, we provide an estimate of the required numbers of inpatient and ICU beds as well as ICU beds with mechanical ventilators for different states' reopening scenarios. The cartographic boundary of the U.S. states and counties were obtained from the United States Census Bureau [23] .@story_separate@Colorado State University. The content expressed in this paper are the views of the authors and do not necessarily represent the opinions or views of NIST or the U.S Department of Commerce. The George T. Abell Professorship discretionary funding provided support in the form of salary for author HNM. This section discusses the impact of multiple COVID-19 waves on hospitals in the U.S. Some of the results in this section, for certain variables, are presented as the ratio between the calculated value at a given time and that of the peak of the second wave. With a total of 10,067,513 confirmed cases, the U.S. has the highest number of active cases (See Material and Methods for the definition of active cases, A) in the world as of 6 November 2020 [1] . This number of cases is expected to increase during the coming weeks, as shown in Fig 2A, if the same protection rates and measures, which were applied before the Fall season, are continued as is. Based on a modified SEIR disease transmission model (see Material and Methods), the disease spread prediction is calibrated to data collected until 6 November 2020 and is referred to as the basic case. This basic case does not consider the relaxation of protective measures that some states such as Florida and Utah applied during the Fall season [27] . Fig 2A shows the prediction for the aggregated active cases, A, in each county, compared with two different datasets [1, 28] . Due to the current limitations and lack of consistency between the reported recovery data [29] , we used the average recovery data published by Worldometers [1] and Johns Hopkins [28] . Assuming no easing or relaxing of measures that were applied before Fall season, the active cases' peak is expected to take place in early January of 2021, reaching more than 4.6 million, as shown in Fig 2A. Distribution of the COVID-19 cases that need hospitalization services during the peak of the first, second, and third waves are displayed in S3 Fig in S1 File, showing, unlike the first wave, the second and third waves to substantially increase the number of hospitalized cases in most counties located in the Mid-America region. Considering the uncertainty associated with the ratio of patients from the active cases requiring hospitalization [24] , b) the daily number of confirmed cases in the U.S. with the moving seven-day average means from the initial outbreak to 6 November 2020 [24] , c) the U.S. counties recording their highest daily number of confirmed cases in the last week of October and the first week of November 2020 (we excluded the counties with mean daily cases less than 5), d) the location of U.S. hospitals with licensed staffed beds that can be used to treat COVID-19 patients [25] , e) the number of licensed beds per 1,000 population aged +60, and f) the number of ICU beds per 1000 population aged +60 [20, 25, 26] . https://doi.org/10.1371/journal.pone.0247463.g001 services, the expected number of inpatient and ICU admissions, as well as patients in ICU requiring mechanical ventilators, is shown in Fig 2B. This expected demand for the hospitals is compared with the number of unoccupied staffed beds capacity in the U.S. The analysis shows that the U.S. hospitals can handle the maximum demand from COVID-19 cases resulting from the basic case scenario; however, during the peak of the third wave, a shortage of hospital beds and mechanical ventilators is expected in Mid and Southern states as shown in S3  Fig in S1 File. In addition to the basic case, we investigate the impact of eliminating protective measures on increasing the disease's spread. Eliminating the protective measures includes reopening [1] and Johns Hopkins published data [28] sets as well as the predicted active cases for the third wave using the basic case assumptions, b) expected number of the hospitalized cases including inpatients, ICU admitted patients, and patients requiring ICUs with mechanical ventilators compared with the available capacity of the U.S. beds in first two categories (the shaded area is the envelope for the 2.5 and 97.5 percentiles for each bed category). c) the number of hospitalized cases for different state reopening scenarios compared with the basic case and the distribution of hospitalization cases during the peak of the basic case. The impact of different state reopening scenarios on the ratio of d) the maximum number of cases needing hospitalization in the U.S. to the peak hospitalization during the second wave, e) the total number of counties with expected hospital demand exceeding the capacity to the maximum number of counties with overwhelmed hospital beds during the second wave, and f) the total number of counties with expected ICU demand exceeding the capacity to the maximum number of counties with overwhelmed ICU beds during the second wave. Distribution of counties expected to be overwhelmed with COVID-19 patients for the g) basic case, h) fully susceptible population with 50% reduction in protection rate, and i) fully susceptible population with no protection. https://doi.org/10.1371/journal.pone.0247463.g002 more schools and workplaces, allowing indoor activities, easing the mask mandatory and social distancing orders, and restoring mobility rates. In this analysis, we use a modified SEIR model in which we adjust the percentage of susceptible cases (S) and protection rate (α) with the time to simulate the increase in mobility and release of protective measures (see Material and Methods) after the deactivation of stay-at-home orders, which resulted sequentially in increasing mobility, easing the mandatory of wearing a mask, reopening schools and workplaces at each state (see S1 Table in S1 File). The percent increase in S defines the percentage of the population returning to their normal daily routine. An increased α (Δα > 1) represents more restrictions while a reduced α (Δα < 1) indicates less restrictive measures such as easing social distancing and not requiring face masks as well as delaying the next stay-at-home order and states lockdown. The case of α equals zero, denotes that no additional restrictions will be applied or lifted. The results show a significant increase in hospitalized cases due to the elimination of protective measures compared with the basic case (see Fig 2C) . The ratios between the peak of the cases that need hospitalization during each scenario and the peak of the second wave are indicated in Fig 2D. The figure shows that enhancing the protective measures (increasing α) can reduce the number of hospitalized cases up to 12.8% compared with the basic case but reducing these measures while allowing all population to return to normalcy (i.e., the change in susceptible cases (ΔS) is one), can be catastrophic and could result in hospitalization of 13.7 times that of the peak of the second wave, which increases the demand for hospitals in many counties beyond their capacity, as shown in Fig 2E and 2F . These figures show that the change in protection rate (Δα), which is measured by the ratio of change in protective measures (listed in S1 Table in S1 File), is more significant for the spread of the disease than the change in susceptible cases (ΔS), which is measured by the percentage of the population returned to normalcy. In addition, freezing all protective measures (Δα = 0) while not changing the susceptible cases (ΔS = 0) increases the number of hospitalized cases more than three times that of the second wave. Therefore, maintaining the protective measures is critical in reducing the number of cases and preventing the overwhelming of hospital facilities. More details about the expected number of cases needing inpatient beds, ICU beds, and ICU beds with mechanical ventilators compared with available beds in each state can be found in S4-S6 Figs in S1 File for the three scenarios discussed in the following section. We also identify counties in the U.S. with expected hospitals demand exceeding the county's unoccupied licensed bed capacity, as shown in Fig 2G-2I for the basic case, fully susceptible population and 50% protection rate, and fully susceptible population and no protection, respectively. In addition to the counties with no staffed beds for any of the three considered bed types (758 counties), the number of counties that might experience a shortage in inpatient beds is 323 {2.5p th = 770, 97.5p th = 60}, the ICU beds is 586 {2.5p th = 1117, 97.5p th = 18}, and the mechanical ventilators is 526 {2.5p th = 1260, 97.5p th = 94} for the basic case. Most of these counties are in the Mid-America region. The number of patients' overflow in these counties is less than most of the states' bed and ventilator capacity; therefore, the patients can be accommodated by patient transfer to other hospitals within each state. However, for the full susceptible population with 50% reduction in the protection rate of the basic case, the numbers of overwhelmed counties will increase to 894 {2.5p th = 1302, 97.5p th = 482} for the inpatient beds, 1146 {2.5p th = 1570, 97.5p th = 322} for the ICU beds, and 1060 {2.5p th = 1636, 97.5p th = 382} for the mechanical ventilators. For the fully susceptible population and no protection, the number of overwhelmed counties will be 1168 {2.5p th = 1483, 97.5p th = 823} for the inpatient beds, 1365 {2.5p th = 1687, 97.5p th = 676} for the ICU beds, and 1283 {2.5p th = 1748, 97.5p th = 689} for the mechanical ventilators. In these two scenarios, we show that urban counties, despite having a large number of staffed beds, might also be overwhelmed. The distribution for counties expected to be overwhelmed with COVID-19 patients during peak cases, based on different susceptible cases and protection rates, is shown in S7 Fig in S1 File for most of the scenarios summarized in Fig 2D. Applying the scenario of easing the protective measures during the Fall and Winter seasons (full susceptible population and 50% protection rate) is also applied to other countries that have different disease spread rates, various protective measures, and dissimilar healthcare system capacities compared with the U.S. as shown in S8  Fig in S1 File. We found that easing these protective measures, even with a lower number of active cases, can cause other waves of disease spread that exceed the healthcare system capacity in some countries. This section investigates different strategies that might help reduce the consequences of partially eliminating protective measures, while states are reopened during the Fall and Winter seasons. Communities and hospital owners and operators commonly use these strategies to decrease the number of hospitalized cases and/or enhance the hospitals' ability and capacity to treat patients. Here, we use the case of a fully susceptible and 50% reduction in protection rate, which we discussed earlier in the results section. Keeping the schools and workplaces open during the Fall and Winter seasons and without protective and strong measures, especially with a large number of active cases from the second wave, can have devastating impacts, including a sudden increase in the number of infected cases and, in some cases, severe multiple waves of disease spread. Our analysis shows that delaying the states' reopening schools, workplaces, and other indoor activities as well as maintaining strong mitigation measures can efficiently reduce the number of infected and hospitalized cases and decrease the risk of overwhelming the hospitals with patients, as shown in Fig 3A. While early reopening ultimately leads to a third wave with a magnitude of 5.0 {2.5p th = 9.7, 97.5p th = 1.9} times the second wave, appropriate timing of the reopening can result in minor waves with a substantial reduction in the peak of the hospitalized cases, which can crucially prevent overwhelming of the hospitals. It can also be noticed from the analysis that the impact of reopening is a function of the number of infectious cases at the reopening stage. However, this is not always the case and, if no further protective measures are applied (α = 0), this impact will be minimal. On the other hand, applying additional lockdown of states and increasing the protective measures (α = 2), even for a short period, can have a more significant reduction on the number of hospitalization cases and counties with overwhelmed hospital beds as shown in S9 Fig in S1 File. A two-week lockdown of states can reduce the peak number of hospitalization cases by about 50% and decrease the total number of counties with expected hospital demand exceeding the capacity by more than 60% compared with the case of no lockdown. One of the main approaches hospitals use to manage patients' sudden increase is to provide surge capacity [30] . This can be realized by reducing regular patients' hospitalization rates to allow more COVID patients to be admitted. The number of regular patients in each county has been documented since the beginning of the pandemic [31] . In this analysis, we assume no increase in licensed beds in each hospital, but we consider the option of operating the licensed and physically available but unstaffed beds to treat COVID-19 related patients. Increasing the surge capacity approach can considerably reduce the number of overwhelmed counties, as shown in Fig 3B; however, providing surge capacity is limited by the number of beds in each facility. When compared to the second wave, providing surge capacity can reduce the ratio of counties with overwhelmed hospitals to 8.9 {2.5p th = 14.0, 97.5p th = 3.6} and counties with overwhelmed ICU beds to 4.7 {2.5p th = 6.9, 97.5p th = 1.0}. On the other hand, the number of overwhelmed counties can significantly increase if the surge in capacity is limited. In such case, the ratio of counties with overwhelmed hospitals can increase to 18.6 {2.5p th = 23.6, 97.5p th = 10.4} and counties with overwhelmed ICU beds to 8.7 {2.5p th = 10.4, 97.5p th = 3.3} compared with the second wave. Another method to increase the capacity of the hospitals is to add additional staffed beds. These additional staffed beds can be added as field hospitals [32] or backup beds at the existing hospitals [30] . In this analysis, we identify the states that will need additional beds and quantify the number of beds that will be required. To quantify the optimal number of staffed beds needed at each U.S. state, we first evaluate the expected maximum number of cases needing hospitalization per state and assume that each state's hospitals can manage to treat patients from overwhelmed counties [33] . However, when all hospitals within a state are overwhelmed (see S5  Fig in S1 File) , additional support will be required to bridge the staffed beds' demand and capacity gap. Fig 3C-3E show the number of staffed beds needed per state based on the base, 2.5, and 97.5 percentiles (see Material and Methods) for the inpatient beds, ICU beds, and ICU beds with mechanical ventilators, respectively. The analysis shows that the states located in Mid-America are more vulnerable to their hospitals being overwhelmed and will need additional beds, and mechanical ventilators if states are fully reopened, and a 50% reduction in protection rate is utilized. The required additional inpatient beds, ICU beds, and ICU beds and mechanical ventilators per state for other different scenarios are shown in S10 Fig in S1 File. Among many other disease transmission models [34] , the SEIR models are commonly used to model the COVID-19 pandemic [35, 36] . We developed a modified version of the generalized six-states SEIR disease transmission model [37] to include ten different states as follow {S, P, E, I, Q, T, C, V, R, D} t to represent the susceptible, insusceptible, exposed, infective, self-quarantined, inpatient admitted, ICU admitted, cases on a mechanical ventilator, recovered, and deceased cases, respectively as a function of time, t. The additional four cases (Q, T, C, and V) represent different types of confirmed cases based on their hospitalization services needs in which Q is for cases with mild or no symptoms, T is for cases needing hospital admission, C is for cases needing ICU, and V is for cases needing mechanical ventilators. These four states can be aggregated to represent the total number of active cases, A, which represents all the positive (confirmed) cases with no outcomes (recovered or deceased) yet. T, C, and V cases together form the total COVID-19 demand on the hospitals, H. The following model is constructed for population, N, of each county, i, in the U.S. The differential equations below are used to determine the total number in each state in county i. Where, β is the infection rate, α is the protection rate, 1/γ is the average incubation period, 1/δ is the average quarantine time, z is the hospitalization rate, η is the ICU rate, and κ is the mechanical ventilator rate. In addition, λ Q , λ H , λ C , and λ V are the recovery rates for self-quarantined, inpatient, ICU, and mechanical ventilator cases, respectively. Moreover, ν Q , ν H , ν C , and ν V are the death rate for the self-quarantined, inpatients, and patients in the ICU, and those on a mechanical ventilator, respectively. Furthermore, the basic reproduction number, R 0 , is the average number of secondary infective cases produced by one infective case in the same county during the infectious period of this case and equals to β/δ(1-α) t . In the utilized model we assume a constant population for each investigated county over the epidemic time, N, which satisfies the equilibrium of N = S+P+E+I+Q+T+C+V+R+D at any time t. Using the modified SEIR model and including self-quarantined and hospitalized states while accounting for protective measures' impact allows for more reliable fitting and forecasting of the COVID-19 disease spread. Assigning positive values to the protection rate, α, simulates different protective measures, including lockdown, social distancing, wearing protective masks, etc. To simulate state reopening, we model different percentages of the population who return to normalcy and become non-protected (ΔS) in the reopened counties by increasing the number of susceptible populations at the time of stay-at-home deactivation and resuming time for schools and businesses (see S1 Table in S1 File). While modeling the strengthening or easing of each county's protective measures, such as mask mandatory wearing orders, is realized by changing the protection rate as a ratio of the protection rate for the basic case (Δα) at the county reopening or schools and businesses resuming date (see S1 Table in S1 File). Shifting the α can change the disease spread rate and the basic reproduction number, R 0 , which can be reduced with time [37] using protective measures [38] . Estimation of the model parameters (β, α, γ, δ, and ν(s)) is made by fitting the published data for confirmed and deceased [24] , while λ(s) are estimated as a time-dependent parameter from the published US recovery data [1, 28] and assumed to be similar for all the US counties. Initial values for the parameter estimation are assumed based on previous studies [16, 39] and CDC reports [15, 38] . During the state's reopening and resuming of schools and businesses, α is modified based on the investigated scenario. We simulated the z as gamma distribution with 0.025, 6.33, and 0.004 for base, shape, and scale parameters, respectively, while for η we used gamma distribution with 0.16, 6.13, and 0.02 for base, shape, and scale parameters, respectively, and for κ we utilized beta distribution with 0.46, 5.22, and 3.08 for base, shape, and scale parameters, respectively [16, 39] . These distributions are used to model the uncertainty associated with the number of different hospitalization cases, in which we use Monto-Carlo simulations with 100,000 trials. Modeling the hospitals' capacity in the U.S. is based on the published data for all the U.S. hospitals, including hospital location, the number of licensed/staffed beds and ICU beds, and the utilization ratio of these beds [18, 20] . We aggregate these data to calculate the number of total inpatient and ICU beds in each county. Due to the limited data on the number of mechanical ventilators per county, we assume that the number of mechanical ventilators per the ICU bed is constant and is based on recently published estimates of ventilators in the U.S. [19] . To simulate the available surge capacity (unoccupied beds) per county, we use the number of licensed staffed beds multiplied by the utilization rates, while considering the potential use of licensed and physically available but unstaffed beds. The capacity calculations are then verified with the data from the CDC dashboard [40] . These beds are used in our analysis for COVID-19 cases that require hospitalization service. COVID-19 patients from counties with no staffed beds are redistributed to unoccupied beds in hospitals within the same state. For the cases where no beds are available in the whole state, the patient is considered untreated. The distribution of patients is realized using a patient-driven model, previously developed by Hassan and Mahmoud [41] , to determine the most probable hospital. Supporting information S1 File. (DOCX)@story_separate@In conclusion, we explored the impact of second and third waves of COVID-19 on hospitals in the U.S. We used a modified SEIR model to predict the number of hospitalized cases for each county considering various state reopening scenarios, including partial or fully reopening, while considering different levels of population protection rates. We identified the counties that might experience overwhelming patients demand that exceeds their hospitals' capacity. We further investigated the impact of different mitigation strategies on the number of cases that need hospitalization, hospital availability, and the number of staffed beds that will be needed to overcome the expected shortage of the staffed beds. The analysis focused on estimating the cases that need hospitalization while considering the available resources in each county. We assumed the number of recovered cases in each county based on the recovery rates in the U.S. due to data limitations. We evaluated the uncertainty in the hospitalized cases and fitted the disease transmission model to published data to estimate the disease model parameters. However, utilizing more data could lower the level of uncertainties in these estimates. We assumed that the population per county is constant, and we neglected the impact of the relocation between states on disease spread. Furthermore, we used published data to estimate the number of staffed beds per county and the utilization of these beds, and we are not accounting for the additional staffed beds and field hospitals built after the pandemic outbreak in the U.S. We also did not include the effect of the population vaccinated for the virus nor the different virus mutations on the forecasted disease spread.","The risk of overwhelming hospitals from multiple waves of COVID-19 is yet to be quantified. Here, we investigate the impact of different scenarios of releasing strong measures implemented around the U.S. on COVID-19 hospitalized cases and the risk of overwhelming the hospitals while considering resources at the county level. We show that multiple waves might cause an unprecedented impact on the hospitals if an increasing number of the population becomes susceptible and/or if the various protective measures are discontinued. Furthermore, we explore the ability of different mitigation strategies in providing considerable relief to hospitals. The results can help planners, policymakers, and state officials decide on additional resources required and when to return to normalcy."
"From behavioral finance theory, we learn that in addition to their own fundamentals, financial markets may be driven by news, rumors, uncertainty, irrational exuberance, animal spirits, investors' feelings, etc. (Shiller 2015; Akerlof and Shiller 2009 ). For example, high uncertainty can lead to more anxiety and panic for investors, subsequently creating more volatility on the financial markets (Jawadi et al. 2017) . The recent and ongoing risk of the Coronavirus epidemic, for instance, has made investors highly uncertain and anxious, and as a result, the French, German and US stock markets lost over 10% of their value in the last week of February 2020 and more recently, which are the highest losses since 2008. This recent occurrence illustrates the significant relationship between the stock market and investors' behavior, attention and attitude. To analyze the linkage between investor sentiment and the stock market, this paper investigates the impact of investor attention on stock return dynamics. In particular, we focus on the Islamic stock market in the US and its interaction with investor attention. Islamic finance emerged as an alternative form of finance in the aftermath of the global finance crisis in 2008. The huge losses experienced by investors resulted in severe criticism of the conventional financial system. This led to an increase in investors' interest in the Islamic stock market since the latter appeared to provide an investment framework that is more social, societal, ethical and less risky than the conventional financial system. The origins of Islamic finance can be traced back to the 1970s, when it was developed as an investment framework compliant with Shariah law to provide a financial framework that met the investors' faith requirements. The Shariah law regulations are based on specific rules, such as prohibition of interest rates, speculation and uncertainty; the sharing of both profit and loss; and greater transparency . However, investor interest in Islamic finance has mainly been observed in the last decade, especially during the severe downturns in the conventional financial investment markets, in the aftermath of the recent global financial crisis. The relationship between investor attention and the Islamic stock market is particularly relevant since Islamic finance -at least from a theoretical point of view-has built its ethical investment rules in keeping with the principles of Sharia-compliant investors, while conventional investors or speculators might behave differently, sometimes embracing mispricing activities in order to maximize their profits. Accordingly, and given the presence of heterogeneous investors (Jawadi et al. 2017) , investor sentiment could impact the Islamic stock market differently depending on the actors who dominate the market. Indeed, the dynamics of the Islamic stock market may be galvanized in two ways: by pure drivers of conventional stock markets (unethical investors according to Shariah law) or investor attention, corresponding to the stabilizing actions of ethically principled investors. This paper proposes a new specification per quantile to model the dynamics of Islamic stock returns, taking into account the effects of investor attention. In particular, it enables us to further capture the effects of investor attention and interest in Islamic Finance for lower as well as higher quantiles. This specification has the advantage of capturing further asymmetry, nonlinearity and time-variation in the relationship between investor attention and Islamic stock returns. Further, unlike previous related studies, we proxy investor sentiment with a Google Search index using specific research and interest in the Islamic stock market, and we test its capacity to forecast future Islamic stock returns. Our findings show that investor attention has a significant impact on Islamic returns, and that investor attention helps to drive Islamic stock returns higher. The remainder of this paper is structured as follows. Section 2 presents a brief literature survey. We rapidly present the econometric methodology in Sect. 3. The empirical results are discussed in Sect. 4, while Sect. 5 concludes.@story_separate@The three-factor Fama-French (1993) model has frequently been applied to explain the dynamics of stock returns. While this model supplants the CAPM (Capital Asset Pricing Model) to explain stock return dynamics through information about firm size and market-to-book ratio in addition to market risk data (Gaunt 2004) , other empirical studies point to the presence of additional factors that might explain the dynamics of stock returns: time-varying investment opportunities (Petkova 2006) , firm profitability and investment (Fama and French 2015) , investor attention (Tang and Zhu 2017; Nguyen et al. 2019) , etc. 1 Nguyen et al. (2019) investigated the impact of investor attention on the dynamics of stock returns for five emerging countries (Indonesia, Malaysia, Philippines, Thailand and Vietnam) over the period 2009-2016. Using the Google search index to proxy investor attention, the authors showed that investor attention has a negative and significant effect on stock returns for the Philippines, Thailand and Vietnam, suggesting that investors might react more quickly to bad rather than to good news in their investment decisions. According to Calvo, investors in emerging markets are less rational and less informed and their strong interest could thus generate lower stock returns as they may overreact to negative signals. In the same context, Preis et al. (2013) suggested that Google search changes are an indication of changes in investor attention. They captured the interest of investors and found an association between changes in Google searches and high future returns for Germany. Meanwhile, Bollen et al. (2011) showed that the use of searches on Twitter improved the forecasting of Dow Jones Industrial stock returns. According to Preis et al. (2013) , changes in Google searches constitute early warning signs of stock market variations. In the same context, Kim et al. (2019) showed that changes in Google searches do not impact contemporaneous and future abnormal returns but lead to volatility and trading volume. Bekiros et al. (2016) argued that investor sentiment does not help to improve the forecasting of stock returns. Overall, studies on the impact of investor attention and/or sentiment on the conventional stock market are not only scarce but also come to different conclusions. We identified four recent empirical studies with regard to the impact of investor attention on the Islamic stock market. First, Perez-Liston et al. (2016) investigated the linkage between investor sentiment and Islamic stock returns and found a positive relationship. Second, Aloui et al. (2016) , also using a wavelet test, identified a high positive correlation between investor sentiment and Islamic stock returns. Third, Ftiti and Hadhri (2019) also applied time-scale tests to show the utility of information provided by investor sentiment and economic policy uncertainty to forecast Islamic stock returns only in the short and medium-terms. Fourth, Khan et al. (2019) constructed a sentiment index for the Islamic stock index using the information provided by Google search volume and showed its usefulness in improving the predictability of Islamic stock returns. However, all the above studies inappropriately proxy investor sentiment using the financial stress index or the consumer confidence index, for example, which are principally sentiment-related indexes for conventional finance. Indeed, these proxies do not explicitly capture specific investor attention and interest in Islamic stock funds and investment. In addition, the proxies used in previous studies are impacted more by economic variables than by investor sentiment. In our paper, we rely on a Google Search index using a lexical category specific to the Islamic stock market, which, unlike previous studies, better captures investor attention and interest in Islamic funds. Changes in this index provide further evidence of changes in Islamic stock market attention and monitoring. In addition, unlike previous related empirical studies, we investigate the relationship between Islamic stock returns and investor attention using Quantile Regressions, enabling us to measure the effect of investor attention on Islamic stock returns not only around the mean but also for higher and lower quantiles. We specify the relationship between investor attention and Islamic stock returns, while taking into account the fact that the effect of investor sentiment might differ depending on the state of the business cycle. Accordingly, investor attention on Islamic stock returns may have a nonlinear effect. In order to capture this further nonlinearity, we specify a quantile regression, enabling us to characterize this relationship through several quantiles (Koenker and Hallock 2001) . This specification presents the advantage of relating the quantiles with investor attention, which could help explain the dynamics of Islamic stock returns. Formally, we specify the dynamics of Islamic stock returns, noted RIS t , as follows where IA t denotes investor attention and X t is a control variable that includes the stock return of the conventional US Dow Jones Industrial. 1 X t + 2 IA t is the conditional mean of the level of the Islamic stock return and t is the error term. In practice, we estimate the quantiles of the conditional distribution of Islamic stock returns and, for each quantile, we specify an equation for the conditional quantile of Islamic stock returns, denoted hereafter as q (RIS t |I t ) , where I t contains information known at time t and defined as: Equation (2) enables us to estimate a time-varying distribution of Islamic stock returns, which is less restrictive than a standard OLS approach as the slope coefficients 1, and 2, can vary by quantiles. In particular, if the effect of investor attention is time-varying and fluctuates with the tail of the Islamic stock return distribution, this specification might have a different coefficient in the quantile regression tails from that in the median. Accordingly, we estimate the parameters 1, and 2, by replacing the conventional quadratic loss function with the so-called 'tick' loss function 2 : where e t = C t � q ,t is the forecast error; � q ,t = q (C t |ℑ t ) refers to the conditional quantile forecast computed at time t, and 1{·} is the indicator function. Our data include the monthly Islamic stock index (Dow Jones Index) for the US and the investor attention index proxied by a Google search index on the Islamic stock market in the US. Both indexes covered the period January 2004-December 2016. We also used the conventional Dow Jones industrial stock index obtained from Bloomberg as a control variable, as well as the Islamic stock index. This is a particularly appropriate sample selection for analyzing the interaction between investor attention and the Islamic stock market both before and after the recent Global Financial crisis. The Islamic stock index was also obtained from Bloomberg and was set up using the closing daily stock price of the end of the month, while the investor attention index was set up using the number of Google searches carried out in the US with the keyword ""Islamic Stock Market"". This Google trend index thus captures the level and frequency of investor's attention with regard to the Islamic Stock market. First, from Fig. 1 , we note that the Islamic stock index was negatively impacted by the recent Global Financial Crisis (GFC), but that it evolved around a positive tendency in the aftermath of the GFC, benefitting from the downturn in the conventional stock market in 2008. Otherwise, the market attention index shows more volatility excess during the pre-crisis and the GFC periods, suggesting that investor attention in Islamic stocks rose during the most turbulent times, but stabilized in the last decade. The application of unit root tests shows that the Islamic stock index is integrated of one order (noted I(1)) in the same way as the conventional stock index, while the investor attention series is stationary. To better illustrate the dynamics of these two variables, Fig. 2 reports the means of two variables by season and suggests a time-varying dynamic for both series. We focus hereafter on the specification of the relationship between investor attention and Islamic stock market returns. Thus, we compute the descriptive statistics for both series and note that while symmetry and normality are rejected for both series, (3) L e t+1 = ( − 1{e t+1 < 0})e t+1 the investor attention series appears more volatile than the Islamic stock return series. Further, the significant difference between the mean and the median for both variables suggests further evidence of asymmetry in the data. Next, the analysis of unconditional correlation, reported in Table 1 , shows that while the two variables are weakly correlated over the whole period (around 3%), the linkages between Islamic stock returns and investor attention reached 19% during the crisis period and 45% in the aftermath of the bankruptcy of Lehman Borther's bank, suggesting further evidence of a time-varying relationship between investor attention and the Islamic stock market. However, further asymmetrical or nonlinear linkages might escape analysis through the Pearson correlation coefficient analysis. Second, to better characterize the relationship between the two variables, in Fig. 3 we report the scatter of the two variables. The level of concentration observed in the scatter dynamics suggests that both variables might significantly interact, but that their linkages are not linear. This result is confirmed when we linearly regress the Islamic stock return on the stock return of conventional stock and investor attention as the latter has no Table 2 , line OLS (1), there is no memory effect in the dynamics of Islamic stock returns and only the US conventional stock return has a positive and significant effect. Next, from the OLS(1*) line, we note that when we augment Eq. (1) with the associated effect of Investor attention on conventional US stock returns, even though investor attention still remains nonsignificant, the latter interacts with fundamental drivers and reduces the effect of conventional US stock returns on the Islamic one by 4%, in addition to its statistical significance. This suggests that higher investor attention to Islamic stock returns weakens the effect of the conventional financial system. Next, in order to characterize the effect of investor attention on Islamic stock returns, we investigate their relationship per quantile. We report the main results in Table 3 and note the various interesting findings. First, investor attention has a negative and significant effect on the low quantiles of Islamic stock returns, suggesting that for lower quantiles, investors are more impacted by bad news than by good news, although the higher the quantile, the lower the effect of investor attention. The memory effect in the dynamics of Islamic stock returns is negative and significant only for the quantile 2.5%. The effect of the conventional stock market is positive and significant, however, and higher than that of market attention. Further, when combining the impact of market attention with that of the conventional stock market, the effect on Islamic stock returns is positive, suggesting that for lower quantiles, Islamic stock returns are driven more by fundamentals through the effect of the conventional stock market than by market attention. Second, when looking at the relationship between investor attention and Islamic stock returns around the median, there is no evidence of a significant effect of investor attention. Third, for higher quantiles of Islamic stock return distribution, investor attention has a positive and significant impact, suggesting that for higher quantiles, investor attention, strengthened by good and positive news, might stimulate the level of Islamic stock returns. To check the robustness of our results, we applied the Wald test and rejected the hypothesis of symmetry across quantiles. Further, using Khmaladze (1981) and Koenker and Xiao (2002) 's test, we show that the slope coefficients vary across quantiles. These findings confirm the suitability of our specification and validate the assumption of the presence of a time-varying investor attention effect. Indeed, the latter enters the dynamics of Islamic stock returns differently, while remaining negative for lower quantiles and positive for higher quantiles of Islamic stock return distribution. Finally, we check whether the use of information provided by investor attention could help to improve forecasting of future dynamics of Islamic stock returns. We carried out an out-of-forecasting test over the forecasting period January 2013-December 2016. We report the main results in Fig. 4 . Our findings show the usefulness of information provided by investor attention to improve the forecasting of future Islamic stock returns. In particular, the forecasting provided by quantile regressions supplants the linear OLS regression forecast (Eq. 1). Khmaladze (1981) and Koenker and Xiao (2002) test computes a joint test for which the covariate effects satisfy the null hypothesis of equality of the slope coefficients across quantiles ***, **, *Statically significant at the 10%, 5% and 1% level, respectively I  II III IV I  II III IV I  II III IV I  II III IV   2013  2014  2015 I  II III IV I  II III IV I  II III IV I  II III IV   2013  2014  2015 I II III IV I II III IV I II III IV I II III IV   2013  2014  2015 I  II III IV I  II III IV I  II III IV I  II III IV   2013  2014  2015 @story_separate@This paper investigates the relationship between investor attention and the Islamic stock market during calm and turbulent times. Our results show that while standard linear modeling fails to capture the effect of market attention, our quantile regression specification exhibits a significant effect of investor attention on the dynamics of Islamic stock returns. Interestingly, we show that the attention effect enters nonlinearity and has a time-varying impact on Islamic stock returns. Indeed, while investor attention might reduce the increase in Islamic stock returns around the low quantile, its effect is significantly more simulative around the high quantile. This suggests for higher Islamic stock returns, Islamic finance become more attractive and therefore more driven by investor's attention, as investors seek for highest benefits. Finally, we find that investor attention could help to improve the forecasting of future Islamic returns. This result is particularly interesting as the focus on investor attention, interest and sentiment may help us to better understand the evolution of Islamic stock markets and to analyze its trends.","This paper investigates the relationship between investor attention and the Islamic stock market. In particular, we investigate whether investor attention—measured by Google searches—could help to improve the forecasting of Islamic stock returns. To this end, we used quantile regressions to examine the relationship over the period 2004–2016 in order to capture its evolution during calm and turbulent times. We thus investigated the effect of investor attention not only on the mean, but also for the different quantiles. Our findings highlight two important points. First, the relationship between investor attention and Islamic stock returns exhibits time-variation and nonlinearity as investor attention significantly impacts the dynamics of Islamic returns, but its sign and effect vary per quantile. Second, the usefulness of information provided by investor attention improves the forecasting of future Islamic stock returns."
"Thailand reported the first domestic case of the coronavirus disease (COVID-19) on January 13, 2020, 1 after a lab-confirmed infection of a traveler from Wuhan, China. 2 The number of cases started to jump by mid-March 3 and increased continuously, which was partly attributed to night club and boxing stadium clusters. 4 Responding to the surge of cases, the Thai government followed the World Health Organization (WHO) recommendation for mitigating COVID-19 outbreaks by implementing aggressive measures to halt the infection. A curfew was imposed nationwide, starting on March 28, between the hours of 10 p.m. and 4 a.m. Nonessential businesses were shut-down to encourage people to remain in their home neighborhoods and limit social contact. Public facilities that normally also serve as venues for physical activity (PA), including schools, offices, malls, and public parks, were closed, and mass gatherings were prohibited. In addition to adapting to these stringent measures imposed by the government, the emergence of COVID-19 in Thailand imposed a strain on the entire society. Academia and the business sector was strongly recommended to work from home, and advised to replace face-to-face interaction with online communication whenever possible. Ordinary community residents were also challenged to modify their leisure activities, such as dining-out, leisure travelling, and outdoor PA, with home cooking, home entertainment, and home-based PA. This rather extreme response by the government and by many individuals in Thai society was incited by dramatic super-spreader events and the growing awareness that COVID-19 could be spread by asymptomatic carriers through virtually airborne transmission when in close proximity to susceptible persons. [4] [5] [6] It is reasonable to posit that PA can play a significant role in boosting the immune system and relieving stress during the COVID-19 pandemic. [7] [8] [9] [10] [11] [12] Other things being equal, if a person is infected with COVID-19, the physically active person will have less severe symptoms, shorter recovery times, and may be less likely to infect others. 13 PA is also beneficial for those who are asymptomatic or experiencing only mild symptoms because it improves the natural immune response to both the influenza and pneumococcal vaccines. [13] [14] [15] Therefore, staying fit during the pandemic has become a major health promotion message. Indeed, the Thai government has encouraged the population to stay active during the pandemic by promoting Fit from Home (FFH): Technique and Guidelines, which was issued by the Thai Health Promotion Foundation and released right after the partial lockdown policy was imposed. The FFH campaign was distributed nationwide through various channels, including print and online media, and served as a guide for the Thai population in an effort to shift their outdoor PA into recommended home-based exercise, 13, 16, 17 such as brisk walking, stair climbing, yard and house work, and playing active games with the family. 13 FFH also provides sample videos of various training programs (i.e., strength, balance, endurance, body weight) and includes virtual activities such as running at home and biking at home. Before the COVID-19 pandemic, the Thai government had been progressing toward a key milestone of its 5-Year National non-communicable diseases (NCDs) Prevention and Control Strategic and Action Plan (2017-2021): 80% of the population would be ""active"". 18 Thailand's Surveillance on Physical Activity (SPA) survey reported that 74.4% of the country's entire population and 78.4% of Thai adults were meeting the WHO 2018 recommendation of a cumulative 150 min of moderate or 75 min of vigorous PA per week, 19, 20 whereas 26.2% of Thailand's children and youth had a total of at least 60 min of moderate-to-vigorous physical activity (MVPA) daily. 21 However, the COVID-19 pandemic has undoubtedly slowed Thailand's progress toward the PA target and perhaps even reversed the improving trend. By essentially being confined to their domiciles and immediate neighbourhoods, individuals and families were faced with greatly restricted access to PA facilities. Furthermore, it can be expected that an increased percentage of society engaged more in sedentary activities due to the need to work from home (i.e., sitting in front of a computer screen) or due to watching more TV or video entertainment than usual. Several studies have examined the effects of COVID-19 on the PA of other countries' populations. [22] [23] [24] However, there is no published data comparing the level and pattern of PA before and after the COVID-19 outbreak in Thailand. Thus, this study hopes to fill that void by comparing the PA level (prevalence of sufficient MVPA and average cumulative minutes of MVPA) prior to and during the pandemic in Thailand. Our study also documents the changes in the types and amount of PA among different groups of the Thai population based on their socio-demographic characteristics. Second, this study assesses whether people exposed to the national campaign, called Fit from Home (FFH): Techniques and Guidelines, had better PA outcomes during the pandemic. The results of our study provide the first evidence of the adverse effects of COVID-19 pandemic on PA as it pertains to Thailand, and this information should be beneficial for government officials and policymakers in formulating strategies for elevating the PA level of the population.@story_separate@This study employed Thailand's SPA 2019 and 2020 datasets to compare the PA level of the Thai population before and during the COVID-19 pandemic. Conducted as an annual surveillance by the Institute for Population and Social Research-Mahidol University and the Thai Health Promotion Foundation, SPA datasets have been used as the source of reference by the Thai government in formulating Thailand's National Physical Activity Plans. The SPA 2019 employed a multistage, stratified random sampling to select a nationally representative sample by considering the place of residence (urban or rural), gender, and age. Face-to-face interviews were conducted in 5 regions, 13 provinces, and 36 villages and involved a total of 7333 cases age 5 years or older. However, to enable a comparison with SPA 2020, only 4460 adults age 18-64 years who could access the Internet were included in the analysis. With the confinement and restriction of movement during the COVID-19 pandemic, SPA 2020 was conducted as an online survey, and the population of interest was defined as all Thai adults who had access to an online system. The online method was also chosen because 85% of the Thai population has Internet access. Using data provided by the National Statistical Office (NSO), the online population was calculated, classified by province, and represented as a proportion of the actual Thai population. Probability random sampling was applied to draw the samples from Facebook pages. The research team randomly selected Facebook pages by district and invited Facebook users to join the survey by using a systematic random technique. Using the inclusion criteria of having a clear gender specification on the Facebook profile page and being age 18-64 years, 4482 individuals from the SPA 2020 sample were included in the analysis. To avoid different environmental effects (i.e., climate, season) in relation to PA, the data combination of vigorous and moderate intensity of PA for adults. 26 Gender, age, area of residence (urban/rural), education, occupation, having a chronic disease(s), and residence by type of epidemic zone (red, yellow, green) formed the independent variables for Objective 1 of the study: differentiating PA before and during the COVID-19 pandemic. Gender was dichotomized as (1) male or (2) female, and age was categorized into 2 groups: (1) young adult (18-39 years old) and (2) given and after their rights to join or withdraw from the research at their convenience was made clear. Although the SPA 2019 was representative of all Thais age 5 years or older, in order to enable comparison with SPA 2020 only those who had Internet access and were age 18-64 years were selected for analysis. To validate different instruments and ensure their measurability, the test-retest method was conducted with 30 cases in order to compare responses from the SPA 2019 face-to-face interviews with the self-reports from the online questionnaires used for SPA 2020. The overall correlation showed a value of 0.882, attesting to the validity of the questions for all population characteristics. A paired t test was employed to evaluate individual items, and the results showed that there was no significant difference between the offline and online responses for all items of interest. Sampling bias was controlled by testing 2 samples that were included and excluded in the SPA 2019. Descriptive statistics was presented to compare the sample characteristics from both surveys. While a t test was employed to compare the cumulative minutes of MVPA between SPA 2019 and SPA 2020, an F test was used to compare MVPA across study periods. Since the data were not normally distributed, multivariate analysis with binary logistic regression was used to determine factors associated with sufficient MVPA of the Thai population during the COVID-19 pandemic. All variables were included in the model, with a significance level of 0.005 or lower used to determine whether a variable had an effect on PA. The study sample comprised Thais age 18-64 years, with a slight tendency toward younger adults among SPA 2020 respondents. While the composition of the SPA 2019 sample was equal between genders, the proportion of males in the SPA 2020 sample was higher than females (53.4% and 46.6%, respectively). The socioeconomic characteristics of the sample (Table 1) . The prevalence of sufficient MVPA among Thai adults decreased from 74.6% in SPA 2019 to 54.7% in SPA 2020 (Fig. 1A) . The decrease in the prevalence was also accompanied by a reduction in the average cumulative minutes of MVPA from 580 to 420 (Fig. 1A) . The prevalence of sufficient MVPA was at its lowest during the maximum curfew period (DC), when the Thai government imposed strict restrictions to contain the virus by closing public facilities, including public parks and gyms, and by prohibiting late-night travel. Although several measures were relaxed during the shorter curfew period and had limited facility openings, the prevalence of the sample with sufficient MVPA remained low, with only a slight increase during the AC period (Fig. 1B) . The restrictions were intended to contain the spread of the virus by limiting people's movement, but they also adversely affected all types of PA. The results of the t test analysis suggest that there was a significant difference in the cumulative minutes of MVPA of Thai adults before and during the COVID-19 pandemic (t = 11.864, p < 0.001). The F-test analysis also indicates that a significant difference in PA exists in two of 3 periods of the pandemic: BC vs. DC, and BC vs. AC (F = 70.610, p < 0.001) ( Fig.   1A and Fig. 1B) . The cumulative minutes of work-related, transportation, and recreational PA also declined during the pandemic period (Fig. 2) . The detailed changes in the cumulative minutes of MVPA by sociodemographic characteristics, pandemic zones, and FFH intervention, classified by each type of PA (work-related, transportation, or recreational) are available in the Supplementary Table 1 . The COVID-19 pandemic has affected the PA of the Thai population in both genders and all age groups. As was the case in the pre-pandemic period, Thai males accumulated a higher level of PA than their female counterparts during the pandemic (Table 2) . Likewise, the proportion of middle-age adults who had sufficient MVPA was consistently higher than for the younger adults in both the pre-pandemic and pandemic periods. The proportion of Thai adults who met the recommended level of MVPA was lowest among those who completed their secondary education and were unemployed, whereas the highest proportion was found among agricultural workers and those with a primary (SPA 2019) and post-secondary education (SPA 2020). Surprisingly, the proportion of respondents with sufficient MVPA was slightly higher among those with a chronic disease(s) in both years compared to those without a chronic disease(s) ( Table 2) . Results of the multivariate analysis suggest that gender, age, occupation, the presence of chronic disease(s), area of residence, and exposure to the FFH campaign had statistically significant associations with MVPA sufficiency among Thai adults during the COVID-19 pandemic. When controlling for other factors, males were 1.3 times more likely to have sufficient MVPA during the pandemic compared to their female counterparts. Middle-aged adults were 1.1 times more likely to meet the recommended MVPA, whereas those residing in an urban area and with a chronic disease(s) were 13% and 29% less likely to meet the recommended MVPA during the pandemic, respectively. Compared to individuals employed in the agricultural sector, those who were unemployed were 27% less likely to have sufficient MVPA ( Table 3 ). Given that behavior is partly influenced by knowledge, our study included the FFH campaign in the model as one of the interventions provided by Thai Health Promotion Foundation. As one of the key findings of the study, the effect of the FFH campaign is evidenced by the higher proportion and higher likelihood of having sufficient MVPA (Table 3) . Those who received the FFH techniques and guidelines were 1.4 times more likely to have sufficient MVPA compared to those who did not receive the information (Table 3 ). There was no significant effect on MVPA sufficiency by educational level and residence in or out of an epidemic zone. Also, living in an area with a lockdown policy had no significant effect on sufficient MVPA of Thai adults. There is no doubt that the COVID-19 pandemic adversely affected the PA of the Thai population. PA was at its peak at the early stage of the COVID-19 pandemic and then began a decline as the government imposed several measures to contain the virus by restricting people's movement in society at large. Schools, offices, and public facilities were closed to encourage people to be fully at home from March 28 to May 2 and extended to limited movement up to July 1, 2020. The fear of infection also motivated Thais to self-isolate by working from home and replacing face-to-face interactions with online socializing or teleconferencing. As a consequence, the cumulative minutes of PA for work-related and transportation purposes declined since a majority of office work was performed at home. The closure of public parks, gyms, and other sports facilities also reduced the opportunity for Thais to engage in their regular recreational PA outside the home. It is also worth noting that, in the earliest stage of the pandemic, the government focused on containing the spread of the virus, and health promotion was relegated to a lower priority. Anticipating a prolonged period of restrictions, the Thai Health Promotion Foundation issued a series of guidelines (i.e., FFH) on how to stay fit during the pandemic to help Thais maintain or regain good health status. Although the amount of MVPA slightly increased after maximum curfew was relaxed (AC), it remained lower than the level of MVPA before the COVID-19 lockdown (BC). Behavior theory suggests that a common emotional response to a pandemic is an exaggerated feeling of fear or anxiety. [27] [28] [29] Thus, persuading people that they need to engage in more PA may be difficult in the current environment. The boxing stadium cluster of COVID-19 infections (which was traced to a single super-spreader) has perhaps instilled a fear of mass gatherings to observe sports events or even engage in outdoor PA. Thus, it may take months or years for people to let their guard down and resume their pre-COVID-19 PA routine. On the other hand, while there has been a loosening of restrictions on movement and gradual reopening of public recreational facilities, the Thai government is being extremely cautious about the need to avoid a second outbreak. Although the Thai Ministry of Public Health (MOPH) has recommended social distancing of at least a 2-m radius, research suggests that running more than 2 m behind a (possibly infectious) person could still be dangerous since micro-droplets containing viable COVID-19 virus can remain airborne for minutes. 30 Our study found similar patterns of MVPA before and during the pandemic as well as an absolute decline in the amount of time spent in PA. Most MVPA was work-related, while the least PA was related to traveling from place to place. Reductions in cumulative minutes of work-related, transportation, and recreational MVPA imply that the COVID-19 pandemic has disrupted the pattern of PA of Thai adults in most aspects of their daily life. As more Thais attempt to work from home, the opportunity for MVPA is limited if they are confined to their domiciles or immediate neighborhoods. Also, working from home often means sitting for prolonged periods in a stationary position in front of the computer screen or other electronic device. In the pre-COVID-19 situation, it is assumed that people moved around more when working at the office, including commuting to and from the workplace. The partial lockdown policy also inhibited travel outside the home for dining, shopping, or leisure PA, all of which accumulates as more sedentary time. In both pre-pandemic and pandemic periods, Thai males were more physically active than females. Both in terms of cumulative minutes and the proportion achieving sufficient MVPA, Thai males exceeded their female counterparts. Other things being equal, men are evolutionarily wired for more vigorous PA given their historical role as the ""hunter"", and have a predilection for competitive physical challenges. 31 The male body is also physiologically constructed for a larger skeletal frame and muscle mass, which can influence duration of exertion in performing PA. 32 Additionally, the cultural belief in the importance of fair skin for Thai females may have played a significant barrier to outdoor PA. 33 During the pandemic, while the restrictive measures applied to all Thais, males were still able to accumulate more minutes of MVPA than females. Furthermore, other studies have found that females are more likely to practice social distancing, 28, [34] [35] [36] whereas males are reported to be less compliant with self-isolation guidance. 34 Female psychological distress 37 and greater compliance with COVID-19 restrictive measures may have led many women to be more house-bound and, thus, they may have had fewer opportunities for PA. Middle-aged adults (40-64 years) were more active than their younger counterparts, both before and during the pandemic. Since middle-aged adults include those in the peak earning years, most of their PA was work-related. Younger adults, on the other hand, are more likely to record more recreational PA since some of them are students. While a previous study reported that older adults participated in less PA during the pandemic due to their inability to find substitutes for their outdoor PA, 23 the reasons why the middle-aged Thai population in our study was more physically active than its younger counterparts in both pre-pandemic and pandemic period was unclear. During the pandemic, urban residents were less likely to have sufficient MVPA compared to their rural counterparts. Urban dwellers also recorded fewer cumulative minutes of MVPA than the rural sample in all PA domains. This may be because during the pandemic many urban dwellers were occupied with screen-related activities and had fewer opportunities for PA due to working from home (WFH) policies, whereas rural residents were still able to work in the field. The containment policy was also more strict for urban residents because an urban setting is a better environment for the spread of aerosolized virus since there is more The limitations of our study should be acknowledged. The differing methods of data collection (face-to-face interviews vs. online self-reporting) could have affected our overall results, particularly because online surveys tend to overestimate certain data. PA levels among children and the elderly also could not be documented and compared to the previous surveys due to the limitations of these 2 populations in accessing the Internet.@story_separate@The pandemic measures imposed by the government reduced the cumulative minutes of work-related, transportation, and recreational PA and slowed Thailand's progress toward its PA goals. Although the FFH campaign probably contributed to a slight increase in MVPA, it will take some time for Thais to return to pre-COVID-19 levels of PA. Health promotion messages need to be continuously delivered as a health-promoting intervention in order to reduce irrational fear of infection and boost the PA level of the Thai population. It is important to note, however, that the COVID-19 pandemic is one of many public health threats with an unpredictable path. Although in Thailand the current trend is toward a continuous decline in new cases, there is always the possibility of subsequent waves of transmission, especially as the country enters the annual flu season in October. The pandemic has also placed the population at a double risk because physical inactivity and a sedentary lifestyle may worsen the impact of future epidemics or exacerbate non-communicable disease threats (e.g., obesity, hypertension, and diabetes), which are also risk factors for complications of COVID-19 infection). Thus, the decreasing prevalence of sufficient MVPA among Thai adults should be a matter of concern for the government and policy makers as they consider strategies for protecting the health of the population in the months and years ahead. (1) freelancers and (2) professional athletes. Red zone: more than 10 confirmed positive cases. Orange zone: 1-10 confirmed positive cases. Green zone: no infection has been reported. Sufficient MVPA: an accumulation of 75 min of vigorous-intensity PA per week or a 150min combination of vigorous-and moderate-intensity PA per week. Abbreviations: MVPA = moderate-to-vigorous physical activity; SPA = Surveillance on Physical Activity. (1)","BACKGROUND: The coronavirus disease (COVID-19) pandemic has undoubtedly disrupted the physical activity (PA) of the Thai population. This study examined the effect of the COVID-19 pandemic on moderate-to-vigorous PA (MVPA) of Thai adults and assessed the effects of the national curfew policy and health promotion campaigns in influencing PA during the pandemic. METHODS: Thailand's Surveillance on Physical Activity (SPA) 2019 and 2020 datasets were employed to compare the PA level of Thai adults aged 18–64 years before and during the COVID-19 pandemic. Samples of 4460 respondents from SPA 2019 and 4482 respondents from SPA 2020 were included in the analysis. Global Physical Activity Questionnaires (GPAQ) Version 2.0 was used to measure PA in both periods. Sufficient MVPA for adults was defined based on the recommendation of 75 min of vigorous PA or a combination of 150 min of MVPA per week. RESULTS: The proportion of Thai adults who had sufficient MVPA declined from 74.6% before the pandemic to 54.7% during the pandemic, and that decline was accompanied by a reduction in the cumulative minutes of MVPA from 580 to 420. During the COVID-19 pandemic, male and middle-aged individuals were 1.3 and 1.1 times more likely to have sufficient MVPA, respectively. Those who were unemployed, resided in an urban area, and/or had chronic disease(s) were 27%, 13%, and 29% less likely to meet the recommended level of PA during the pandemic, respectively. Those who were exposed to the Fit from Home (FFH) campaign were 1.4 times more likely to have sufficient MVPA. CONCLUSION: The pandemic measures imposed by the government have reduced the cumulative minutes of work-related PA, transportation PA, and recreational PA and have slowed Thailand's progress toward its PA goals. Although the FFH campaign has probably contributed to a slight increase in MVPA, it will take some time for Thais to return to the pre-COVID-19 level of PA. Health promotion messages need to be continuously delivered to reduce irrational fear of infection and to boost the PA level of the Thai population as a health-promoting intervention."
"We now discuss the question of how the virus came to Denmark. Our phylogenetic analysis shows that around 70% of the Danish sequences have haplotype A2a2a. By comparing the distribution of haplotypes across different countries, by utilizing date information, and, for some international sequences, also location data as well as travel histories, we conclude that the majority of the Danish sequences with A2a2a originate directly or indirectly from Ischgl. This is illustrated with examples of specific chains of mutations from Ischgl. Our observation that a large proportion of Danish sequences originate in Ischgl is not unexpected given the public knowledge of travel histories [38] . Our analysis, however, can be regarded as an independent cross-check of this existing narrative. The remaining portion of the sequences is consistent with multiple entries from other countries, among them Italy, the UK and the Netherlands. We have illustrated this with example chains of mutations which can be associated to those countries. In the case of Italy, this is based on the haplotype A2a1, in the case of the UK, it is a specific mutation on top of haplotype A2a2a and in the case of the Netherlands, it is a mutation in addition to a well-known triple deletion. These conclusions are consistent with the testing results in mid-March [39] . From this point of view, our genomic analysis cross-validates the public statements and supports findings in the Iceland study [27] that indicate that Ischgl was a hotspot earlier than widely recognized.@story_separate@Our findings are consistent with several introductions of the virus to Denmark from independent sources. We identify several chains of mutations that occurred in Denmark. In at least one case we find evidence that the virus spread from Denmark to other countries. A number of the mutations found in Denmark are non-synonymous, and in general there is a considerable variety of strains. The proportions of the most common haplotypes remain stable after lockdown. In this work, we use publicly available sequenced genome of the SARS-CoV-2 virus. In the following, we describe how we obtained and analyzed these sequences. For a flow chart of this process, see Fig 1.  The sequences were downloaded from the GISAID EpiCoV database [17, 18] on May 26, 2020, including 742 Danish sequences. See the S2 File for a full list of sequences including their origins. From the available sequences, we selected those which we deemed of high quality and used them for our analysis. Specifically, we only consider sequences with at least 29,000 nucleotides having at most 300 unidentified nucleotides (N's). This corresponds to the requirement of having at most 1% unidentified nucleotides, which is also imposed by GISAID for sequences designated as high coverage. Similar cut-off values are used, for example, in [19] . Moreover, we only consider sequences that originate from a human host. After these steps, we were left with 582 Danish sequences, which we focus on in our analysis. As such our analysis is based on significantly more data as compared to the more global, but less Denmark-specific analysis by Nextstrain. Moreover, the analysis is carried out in greater detail. Nextstrain lists 132 Danish sequences for the relevant date range (retrieved on: August 21 2020). Based on the genetic data the phylogenetic trees of this manuscript where inferred from BEAST [20] in conjunction with the statistical software package R [21] . In particular, in a first step the sequences were aligned with the help of the R package DECIPHER [22, 23] . The resulting alignments were then further processed with BEAST in order to construct the phylogenetic trees. In all cases, the GTR + I + G model was used as the basis for the phylogenetic analysis. In order to cross-check this procedure, a maximum likelihood tree was built additionally, which in all cases supports the conclusions drawn from the BEAST results. The specific code we used can be found at https://github.com/qmath/phylo_qmath. We use the R-package treedater [24] to estimate mutation rates. The mutations identified by this haplotype analysis were cross-validated via bootstrapping for the corresponding maximum-likelihood phylogenetic trees, with resulting bootstrap values consistent with the number of mutations defining the different clades. Moreover, we crosschecked our results with TreeTime [25] , which led to similar tree-topologies. However, we do not require the additional time information provided by the TreeTime package in order to reach our conclusions. We choose to root our trees with respect to the reference sequence NC-045512.2 (SARS-CoV-2 isolate Wuhan-Hu-1), which is also the reference for Nextstrain [26] and for [19, 27, 28] . This is unlikely to be the original sequence, as argued in [29] . The same work suggests rooting with respect to sequences found in bats and there is a debate in the literature concerning the most appropriate rooting strategy [29] [30] [31] . However, our haplotypes build upon the ones used in [27] , which use this sequence as a reference. These haplotypes were in turn derived from (the original clades of) Nextstrain [26] . Furthermore, the sequences we consider were not collected before late February 2020. Therefore, the sequence NC-045512.2 from December 31, 2019 is sufficiently distant to serve as an outgroup to root our tree. In light of that, we believe that rooting with respect to NC-045512.2 has the advantage of allowing for a more straightforward comparison of the results of this work with [27] without compromising the quality of the displayed trees. In Table 1 , we list the mutations corresponding to the names we will use, following [27] . In addition, we list their names in the more recent Nextstrain convention [32] and the clades from the pangolin system that they are included in [28] . Finally, we list the corresponding amino acid changes and in which genes they can be found. See [33] for an overview of the SARS-CoV-2 genome.  List of relevant haplotypes with their definition in terms of mutations as well as their new Nextstrain label. We note that both the reference string used and all the haplotypes listed have the four mutations specified as haplotype A in [27] . We therefore do not list those. The second to last column is the label for the currently identified pangolin lineage clades they are included in. The last column gives the corresponding amino acid changes and the genes they occur in. https://doi.org/10.1371/journal.pone.0241405.t001 To get an overview of mutations prevalent in Denmark, we identify positions where sufficiently many of the analyzed sequences exhibit a substitution or a deletion as compared to the reference sequence. For a better overview and readability we choose different thresholds depending on the context. We analyze the co-occurrence of the new mutations with previously identified haplotypes from [27] and with each other in the entire worldwide data set. In this section, we review our results. After a general overview of the mutations over time, we study three different types of mutations in more detail: First, we consider mutations which were present in some region of the world and appeared in Denmark at some point. Second, we look at chains of mutations which only appear in Denmark. Finally, we look at mutations for which a Danish origin is predominant. The mutations we identify here are used subsequently in the Discussion section to analyze the spread from, to and within Denmark. Let us now investigate the ratio of the haplotypes over time. The most common haplotypes in Denmark are A2a2a and A2a1. Fig 2 shows in the top panel the relative weight of those haplotypes over time with a seven-day rolling average. In the lower panel we plot the seven-day rolling average of the number of sequences. We observe a larger fraction of A2a1, which is associated to Italy, before the lockdown. From the onset of the lockdown, the fractions stay rather stable in time with A2a2a, which we discuss in detail below, making up around 70%. A lower number of sequences may be interpreted as a larger error bar on the haplotype percentages, making the haplotype distribution in time consistent with constant proportions. The mutation rate we infer from the Danish data is consistent with the 6 � 10 −4 nucleotides/ genome/year found in [19] . Please see [19, Table 1 ] for an overview of mutation rates for SARS-CoV-2 obtained in the literature. In the following, we study haplotypes present in Denmark which are also common in other countries. The aim is to identify from where they have been introduced to Denmark. We start with the haplotypes most common in the Danish data and proceed with specific examples of mutations less prevalent in Denmark. For an overview we refer to S1 Fig in S1 File. A2a2a: A common mutation in Denmark and Ischgl. Approximately 70% of the available Danish sequences have haplotype A2a2a. This makes it the most common haplotype in our Danish data with 405 out of 582 sequences. In our complete data set, we see that 4343 out of 20239 sequences have this haplotype (see S1 Table in S1 File), with sequences originating from the US, Denmark, the UK, Australia, France and other countries. This haplotype was already reported in [27] where the authors point out that travelers from Austria had the haplotype A2a2 together with the mutation C1059T which is the definition of A2a2a. The haplotype A2a2 corresponds to an amino acid change Q57H in Orf3a as compared to A2a and the haplotype A2a2a corresponds to an amino acid change T265I in Orf1a as compared to A2a2 (see also Table 1 ). Both mutations have already been studied in [34] . In the following we first give evidence that some of the sequences with A2a2a originate from the skiing area of Ischgl in the region of Tyrol, Austria, by identifying specific chains of mutations. We will then argue that most, but likely not all of this haplotype comes from that area. In order to identify a specific chain of mutations, we will look at mutations that occur in addition to A2a2a. Consider therefore mutation A6825C which corresponds to the amino acid change N2187T in Orf1a and which is seen in nine sequences that have A2a2a worldwide. These include six Danish ones, while the others are from Austria, Norway and Scotland. The Norwegian sequence can be traced with metadata to Austria. The Norwegian sequence is dated to March 9, which makes it likely that this mutation has been present in Austria prior to that date. It is therefore consistent with the hypothesis that the Danish sequences, the first of which also is dated to March 9, originate from Austria. Since the Austrian sequence is from Ischgl, a spread from Ischgl, a tourist skiing destination, seems likely. Similarly, the mutation G15380T (corresponding to S5039L in Orf1a) appears with haplotype A2a2a in 32 sequences worldwide. Among those 32 are 16 of Danish origin. Of the remaining ones with A2a2a, there are eight Austrian sequences. All of them stem from the region of Tyrol and in particular six are from Ischgl. In order to argue that most Danish sequences with A2a2a originate from Austria, we first observe that the ratio of sequences with A2a2 versus A2a2a is close to 1 in Germany, Denmark, Norway, Austria, Iceland, Sweden and Switzerland what regards European countries, and lower in other European countries such as the UK, France and the Netherlands from which significant travel to Denmark would be expected. Since the number of Danish sequences with A2a2a is high even when restricting to the time around the onset of the lockdown, there must have been multiple introductions of A2a2a to Denmark, and it therefore seems unlikely that this could have happened from a country with a much different ratio than that of Denmark. Tourism from European countries to Alpine ski resorts around February and March would provide a natural travel route for the virus, in particular to Denmark, Sweden, Norway and Germany. For Iceland, this assumption is supported by the travel information collected in [27] . The sequences from Switzerland have no travel histories, but location data shows that the Swiss sequences with A2a2a are mainly spread across the German-speaking part and that they are in particular not concentrated at one location. This makes it unlikely that there was a hotspot in a Swiss ski resort. In contrast, the Austrian sequences can be mainly attributed to the skiing region of Ischgl. We refer to the Austrian data presented in S2 Fig of S1 File, where one sees that the haplotype A2a2a is mostly present in sequences from the ski village of Ischgl in the region of Tyrol, Austria, and the adjacent region of Vorarlberg. Accordingly, it seems very plausible that Ischgl was indeed a hotspot for the transmission of the haplotype A2a2a to the aforementioned countries. The Norwegian sequences have travel metadata and give further supporting evidence for this infection route. Here, three out of twelve sequences with the haplotype A2a2a also have recent travel history to Austria (the others having unknown travel history). This is shown in S3 Fig in S1 File. The Icelandic study [27] also associated the haplotype A2a2a with travel to Austria. However, due to the abundance of the haplotype A2a2a in the world, it is likely that some portion of the sequences with the haplotype A2a2a are not part of transmission route through Ischgl. As an example we discuss A2a2a + G24368T in Subsection S1.4 of S1 File, which we identify as likely originating from the UK. A2a1: A common mutation in Denmark and Italy. While the previous haplotype could be linked to Austria, we now proceed with a haplotype that can be traced back to a different country. The haplotype A2a1, which we consider now, appears 38 times in Denmark. Moreover, 36 sequences with haplotype A2a1 were found in the early targeted testing group (January 31-March 15) in the Icelandic study [27 Table 2 ]. Out of these, 29 had a travel history from Italy and three from Austria. Furthermore, the earliest Danish sequence (dated February 26) is from when there was only one confirmed case in Denmark. As reported in the news, this case has travel history to an Italian ski-area. It also has haplotype A2a1. The triple deletion ATGA1605A with coincident mutation T514C. Both in the Danish and the worldwide data sets we observe sequences with a triple deletion at sites 1606-1608 (ATGA1605A) which is sometimes coincident with a substitution T514C (identified as A6 in [27 Table S3] ). The triple deletion corresponds to the triple deletion ATGA1604A identified as haplotype A9 in [27 Table S3 ]. Note that [27 Table S3 ] places it at position 1604 rather than 1605, which seems to be a typo. The CoV-GLUE database confirms the deletion at the nucleotides where we find it [35] . Most of the sequences in our data set with the triple deletion ATGA1605A but without the substitution T514C are from the UK (293 out of 346). Noticeably, there are six sequences from early February (the remaining dated from earliest March 1). Five of these are from the UK and one is from France. In contrast, most of the sequences with both the deletion ATGA1605A and the substitution T514C are from the Netherlands (98 out of 138). In addition, the earliest of the sequences with both ATGA1605A and T514C are from the Netherlands as well. Therefore, we conclude it to be likely that the triple deletion originated in the UK and then spread to the Netherlands, where it picked up the mutation T514C. Interestingly, some of the UK sequences also exhibit mutation T514C. We deem that they originate from the UK thus highlighting the multidirectional spread of the virus. In Denmark, we observe nine sequences with ATGA1605A, two of which additionally have T514C. These latter two Danish sequences are likely of Dutch origin. The mutation T514C is not shown in S1 Fig of S1 File, since it appears only twice in the Danish data. However, the sequences in question are those at the very bottom, with numbers EPI_ISL_444828|2020-03-11 and EPI_ISL_429295|2020-03-13. Now, we turn to chains of mutations which occurred inside Denmark. From S1 Fig in S1 File, one identifies several such chains of mutations. Here we report two of the most pronounced. Chain of mutations starting at C15842A. The first chain we consider starts at C15842A. The corresponding phylogenetic tree with an overview of the associated haplotypes for this mutation can be found in Fig 3. There are 20 sequences with the mutation C15842A and the haplotype A2a2a worldwide and they are all of Danish origin. From the 20 (all Danish) sequences with A2a2a and C15842A, there are 17 which also have the mutation C12781T. Furthermore, of the sequences that have both the mutations C15842A (T5193N in Orf1a) and C12781T (synonymous), there are eight which in addition have the non-synonymous mutation G22103C (G181R in the spike protein). Another four sequences have the mutation A23975G instead and finally, there are two which have C25499T. Some of the previously mentioned sequences have additional mutations. The longest chain of mutations appearing at least twice has length three (not counting the mutations composing the haplotype A2a2a; see Fig 3) . Chain of mutations starting at C1302T. The Danish sequences with haplotype A2a2a frequently show the mutation C1302T. It is non-synonymous and corresponds to amino acid change T346I in Orf1a. We will argue that this mutation originated in Denmark and that it mutated further in Denmark as well as spread to other countries. See Fig 4 for the phylogenetic tree corresponding to this mutation. In order to see that this mutation spread further from Denmark, note that worldwide there are 115 sequences with the mutation C1302T co-occurrent with the haplotype A2a2a, 103 of which are Danish. The remaining ones are Latvian (1), Icelandic (5) and Swedish (6) . The travel histories of the five Icelandic sequences show that two have traveled to Denmark (as first reported in [27] ), while the other cases do not contain travel information. Of the six Swedish sequences, one is from Uppsala dated to March 12 while the five others are from Norrbotten (in the north of Sweden) dated from March 24 until April 2. The earliest Danish sequence with C1302T is from March 3. Whereas our analysis does not completely exclude that the virus spread from Sweden or Latvia to Denmark, we believe that the earlier date of the Danish sequence, together with the high abundance in Denmark, makes it very likely that it originated in Denmark and further spread from Denmark. See also Fig 5(a) for an illustration of the international presence of the mutation. In order to see that the strain A2a2a + C1302T further mutated in Denmark we inspect the corresponding clade of the Danish tree in S1 Fig of S1 File (see also Fig 4) . Ten of the sequences have C11074T (a combination which is not found outside of Denmark. The eleventh sequence in this clade has an N at 11074.). Of these, six have the mutation C29095T. Three of them moreover have the mutation A9280G, whereas two have the mutation C619T (this is only visible in Fig 4 due to a threshold of three when displaying mutations in S1 Fig of S1 File) . Of the ones with mutation A9280G, two have a mutation at C7164T. Some of the sequences have additional single mutations. We have thus identified the Danish chains of mutations in Fig  5(b) . We will start the discussion with the ratio of haplotypes over time before considering the different types of transmission routes we have found. We will conclude the section with an outlook. During the initial period of the introduction of the virus to Denmark from different sources the percentages of the different major haplotypes change: From a larger proportion of haplotype A2a1 associated to Italy to a 70% proportion A2a2a associated to Ischgl. After lockdown,  SARS-CoV-2 transmission routes: Denmark however, we do not observe a significant change in the proportions anymore. Therefore, we find no evidence for different virality. We find no clear pattern in individual mutations of the strains appearing in Denmark either. Therefore, we suspect that they are consistent with random mutation events. After the research on this study had been concluded, a possible difference in virality of the occurrence/non-occurrence of mutation D614G in the spike protein has been discussed in [36, 37] . We point out that nearly all studied Danish sequences have this mutation (see S1 Table in S1 File). After its introduction to Denmark, the virus continued to mutate within the country. We have listed all mutations that appear at least three times inside Denmark in S2 Table in S1 File and also plotted them in S1 Fig of S1 File. We note that many more Danish chains of mutations can be identified from S1 Fig of S1 File. In the results, we discussed two particularly pronounced chains of mutations based on this plot and Fig 3. For the two chains described in the results we conclude that they are chains of mutations that happened inside Denmark. We have chosen these two since these mutation chains only co-occur with the haplotype A2a2a in Denmark (except of the first mutation C1302T). This shows clearly how one can track the virus mutating as it spreads inside Denmark. The longest chain that we conclude happened inside Denmark is five mutations long and consists of the mutations [C1302T ! C11074T ! C29095T ! A9280G ! C7164T]. These mutations took place in a period from before March 15 to before April 14 based on the dating of the sequences. The average mutation rate we obtain is consistent within error bars with the 6 � 10 −4 nucleotides/genome/year obtained in [19] . Not only did the virus follow the travel routes into Denmark, it also spread from Denmark. For the mutation C1302T, based on its high prevalence in Denmark compared to the rest of the world together with the travel histories of the Icelandic cases, we conclude that it appeared first in Denmark and spread from there to Sweden, Latvia and to Iceland. Some reservations remain since the Swedish data in GISAID is very limited with only 163 sequences as of May 26. Further, the chain of mutations described shows how the virus has spread extensively within Denmark and mutated at least four times after that. Hence we see indications that the virus has mutated several times inside Denmark and spread from Denmark, as illustrated in Fig 5. We have listed and discussed the most common mutations. As we show in S1 File, some of the mutations we see seem to have occurred independently elsewhere, in particular in the UK, which has a large number of sequences in GISAID. An example of this is the mutation C7011T. The conclusions above are based on a rather large number of high quality Danish sequences with date information as well as on sequences from other countries some of which have more metadata. Even though we do not have firm knowledge of the representativity of the Danish sequences, we can assert that they cover the entire time from the first identified case up to May 9. In order to confirm the analysis of the proportion of haplotypes seen, it would be important to supplement this with information about the representativity of the analysed data set or obtain a more representative sample. At the same time, our analysis also shows how to effectively incorporate metadata (date, country of origin or travel history) in such an analysis. We have used the SARS-CoV-2 genomic data to identify transmission routes, thus highlighting the potential of such methods for understanding the spread of the virus in a population. Although here we present a case study for Denmark, a similar analysis could be carried out for outbreaks in other countries, regions or even smaller units such as hospitals. If sufficient data is available, such methods can also be used to identify transmission chains between individuals as done e.g. in [27] . If the genomic data is available in real-time, such an analysis can inform mitigation measures even during an ongoing outbreak, for instance supplementing traditional methods such as contact tracing.  Hôpitaux universitaires de Genève Laboratoire de Virologie Thorsteinsdottir; Kari Stefansson   EPI_ISL_417619, EPI_ISL_417620, EPI_ISL_417621, EPI_ISL_417622, EPI_ISL_417623, EPI_ISL_417624, EPI_ISL_417625, EPI_ISL_417626, EPI_ISL_417627, EPI_ISL_417628, EPI_ISL_417629, EPI_ISL_417630, EPI_ISL_417631, EPI_ISL_417632, EPI_ISL_417633, EPI_ISL_417634, EPI_ISL_417635, EPI_ISL_417636,  EPI_ISL_417637, EPI_ISL_417638, EPI_ISL_417639, EPI_ISL_417640, EPI_ISL_417641, EPI_ISL_417642, EPI_ISL_417643, EPI_ISL_417644, EPI_ISL_417645, EPI_ISL_417646, EPI_ISL_417647, EPI_ISL_417648, EPI_ISL_417649, EPI_ISL_417650, EPI_ISL_417651, EPI_ISL_419733, EPI_ISL_419734, EPI_ISL_419735, EPI_ISL_419736, EPI_ISL_419737, EPI_ISL_419738, EPI_ISL_419739, EPI_ISL_419740, EPI_ISL_419741, EPI_ISL_419742, EPI_ISL_419743, EPI_ISL_419744, EPI_ISL_419745, EPI_ISL_419746, EPI_ISL_419747, EPI_ISL_419748, EPI_ISL_419749, EPI_ISL_419750,  EPI_ISL_419751, EPI_ISL_419752, EPI_ISL_419753, EPI_ISL_419754, EPI_ISL_419755, EPI_ISL_419756, EPI_ISL_419757, EPI_ISL_419758, EPI_ISL_419759, EPI_ISL_419760, EPI_ISL_419761, EPI_ISL_419762, EPI_ISL_419763, EPI_ISL_419764, EPI_ISL_419765, EPI_ISL_419766, EPI_ISL_419767, EPI_ISL_419768,  EPI_ISL_419769, EPI_ISL_419770, EPI_ISL_419771, EPI_ISL_419772, EPI_ISL_419773, EPI_ISL_419774, EPI_ISL_419775, EPI_ISL_419776, EPI_ISL_419777, EPI_ISL_419778, EPI_ISL_419779, EPI_ISL_419780, EPI_ISL_419781, EPI_ISL_419782, EPI_ISL_419783, EPI_ISL_419784, EPI_ISL_419785, EPI_ISL_419786,  EPI_ISL_419787, EPI_ISL_419788, EPI_ISL_419789, EPI_ISL_419790, EPI_ISL_419791, EPI_ISL_419792, EPI_ISL_419793, EPI_ISL_419794, EPI_ISL_419795, EPI_ISL_419796, EPI_ISL_419797, EPI_ISL_419798, EPI_ISL_419799, EPI_ISL_419800, EPI_ISL_419801, EPI_ISL_419802, EPI_ISL_419803, EPI_ISL_419804,  EPI_ISL_419805, EPI_ISL_419806, EPI_ISL_419807, EPI_ISL_419808, EPI_ISL_419809, EPI_ISL_419810, EPI_ISL_419811, EPI_ISL_419812, EPI_ISL_419813, EPI_ISL_419814, EPI_ISL_419815, EPI_ISL_419816, EPI_ISL_419817, EPI_ISL_419818, EPI_ISL_419819, EPI_ISL_419836, EPI_ISL_419837, EPI_ISL_419838, EPI_ISL_419839, EPI_ISL_419840, EPI_ISL_419841, EPI_ISL_419842, EPI_ISL_419843, EPI_ISL_419844, EPI_ISL_419845, EPI_ISL_419846, EPI_ISL_419847, EPI_ISL_419848, EPI_ISL_419849, EPI_ISL_419850, EPI_ISL_419851, EPI_ISL_419852, EPI_ISL_419853,  EPI_ISL_419854, EPI_ISL_419855, EPI_ISL_419856, EPI_ISL_419857, EPI_ISL_419858, EPI_ISL_419859, EPI_ISL_419860, EPI_ISL_419861, EPI_ISL_419862, EPI_ISL_419863, EPI_ISL_419864, EPI_ISL_419865, EPI_ISL_419866, EPI_ISL_419867, EPI_ISL_419868, EPI_ISL_419869, EPI_ISL_419870, EPI_ISL_419871,  EPI_ISL_419872, EPI_ISL_419873, EPI_ISL_419874, EPI_ISL_419875, EPI_ISL_419876, EPI_ISL_419877, EPI_ISL_419878, EPI_ISL_419879, EPI_ISL_419880, EPI_ISL_419881, EPI_ISL_419882, EPI_ISL_419883, EPI_ISL_419884, EPI_ISL_419885, EPI_ISL_419886, EPI_ISL_419887, EPI_ISL_419888, EPI_ISL_419889,  EPI_ISL_419890, EPI_ISL_419891, EPI_ISL_419892, EPI_ISL_419893, EPI_ISL_419894, EPI_ISL_419895, EPI_ISL_419896, EPI_ISL_419897, EPI_ISL_419898, EPI_ISL_419899, EPI_ISL_419900, EPI_ISL_419901, EPI_ISL_419902, EPI_ISL_419903, EPI_ISL_419904, EPI_ISL_419905, EPI_ISL_419906, EPI_ISL_419907,  EPI_ISL_419908, EPI_ISL_419909, EPI_ISL_419910, EPI_ISL_419911, EPI_ISL_419912, EPI_ISL_419913, EPI_ISL_419914, EPI_ISL_419915, EPI_ISL_419916, EPI_ISL_419917, EPI_ISL_419918, EPI_ISL_419919, EPI_ISL_419920, EPI_ISL_419921, EPI_ISL_419922, EPI_ISL_419923, EPI_ISL_419924, EPI_ISL_419925,  EPI_ISL_419926, EPI_ISL_419927, EPI_ISL_419928, EPI_ISL_419929, EPI_ISL_419930, EPI_ISL_419931, EPI_ISL_419932, EPI_ISL_419933, EPI_ISL_419934, EPI_ISL_419935, EPI_ISL_419936, EPI_ISL_419937, EPI_ISL_419938, EPI_ISL_419939, EPI_ISL_419940, EPI_ISL_419941, EPI_ISL_419942, EPI_ISL_419943,  EPI_ISL_419944, EPI_ISL_419945, EPI_ISL_419946, EPI_ISL_419947, EPI_ISL_419948, EPI_ISL_419949, EPI_ISL_419950, EPI_ISL_419951, EPI_ISL_419952, EPI_ISL_419953, EPI_ISL_419954, EPI_ISL_419955, EPI_ISL_419956, EPI_ISL_419957, EPI_ISL_419958, EPI_ISL_419959, EPI_ISL_419960, EPI_ISL_419961,  EPI_ISL_419962, EPI_ISL_419963, EPI_ISL_419964, EPI_ISL_419965, EPI_ISL_419966, EPI_ISL_419967, EPI_ISL_419968, EPI_ISL_419969, EPI_ISL_419970, EPI_ISL_419971, EPI_ISL_419972, EPI_ISL_419973, EPI_ISL_419974, EPI_ISL_419975, EPI_ISL_419976, EPI_ISL_420631, EPI_ISL_420632, EPI_ISL_420633, EPI_ISL_420634, EPI_ISL_420635, EPI_ISL_420636, EPI_ISL_420637, EPI_ISL_420638, EPI_ISL_420639, EPI_ISL_420640, EPI_ISL_420641, EPI_ISL_420642, EPI_ISL_420643, EPI_ISL_420644, EPI_ISL_420645, EPI_ISL_420646, EPI_ISL_420647, EPI_ISL_420648,  EPI_ISL_420649, EPI_ISL_420650, EPI_ISL_420651, EPI_ISL_420652, EPI_ISL_420653, EPI_ISL_420654, EPI_ISL_420655, EPI_ISL_420656, EPI_ISL_420657, EPI_ISL_420658, EPI_ISL_420659, EPI_ISL_420660, EPI_ISL_420661, EPI_ISL_420662, EPI_ISL_420663, EPI_ISL_420664, EPI_ISL_420665, EPI_ISL_420666,  EPI_ISL_420667, EPI_ISL_420668, EPI_ISL_420669, EPI_ISL_420670, EPI_ISL_420671, EPI_ISL_420672, EPI_ISL_420673, EPI_ISL_420674, EPI_ISL_420675, EPI_ISL_420676, EPI_ISL_420677, EPI_ISL_420678, EPI_ISL_420679, EPI_ISL_420680, EPI_ISL_420681, EPI_ISL_420682, EPI_ISL_420683, EPI_ISL_420684,  EPI_ISL_420685, EPI_ISL_420686, EPI_ISL_420687, EPI_ISL_420688, EPI_ISL_420689, EPI_ISL_420690, EPI_ISL_420691, EPI_ISL_420692, EPI_ISL_420693, EPI_ISL_420694, EPI_ISL_420695, EPI_ISL_420696, EPI_ISL_420697, EPI_ISL_420698, EPI_ISL_420699, EPI_ISL_420700, EPI_ISL_420701, EPI_ISL_420702,  EPI_ISL_420703, EPI_ISL_420704, EPI_ISL_420705, EPI_ISL_420706, EPI_ISL_420707, EPI_ISL_420708, EPI_ISL_420709, EPI_ISL_420710, EPI_ISL_420711, EPI_ISL_420712, EPI_ISL_420713, EPI_ISL_420714, EPI_ISL_420715, EPI_ISL_420716, EPI_ISL_420717, EPI_ISL_420718, EPI_ISL_420719, EPI_ISL_420720,  EPI_ISL_420721, EPI_ISL_420722, EPI_ISL_420723, EPI_ISL_420724, EPI_ISL_420725, EPI_ISL_420726, EPI_ISL_420727, EPI_ISL_420728, EPI_ISL_420729, EPI_ISL_420730, EPI_ISL_420731, EPI_ISL_420732, EPI_ISL_420733, EPI_ISL_420734, EPI_ISL_420735, EPI_ISL_420736, EPI_ISL_420737, EPI_ISL_420738,  EPI_ISL_420739, EPI_ISL_420740, EPI_ISL_420741, EPI_ISL_420742, EPI_ISL_420743, EPI_ISL_420744, EPI_ISL_420745, EPI_ISL_420746, EPI_ISL_420747, EPI_ISL_420748, EPI_ISL_420749, EPI_ISL_420750, EPI_ISL_420751, EPI_ISL_420752, EPI_ISL_420753, EPI_ISL_420754, EPI_ISL_420755, EPI_ISL_420756,  EPI_ISL_420757, EPI_ISL_420758, EPI_ISL_420759, EPI_ISL_420760, EPI_ISL_420761, EPI_ISL_420762, EPI_ISL_420763, EPI_ISL_420764, EPI_ISL_420765, EPI_ISL_420766, EPI_ISL_420767, EPI_ISL_420768, EPI_ISL_420769, EPI_ISL_420770, EPI_ISL_420771, EPI_ISL_420772, EPI_ISL_420773, EPI_ISL_420774 EPI_ISL_420913, EPI_ISL_420914, EPI_ISL_420915, EPI_ISL_420916, EPI_ISL_420917, EPI_ISL_420918, EPI_ISL_420919, EPI_ISL_420920, EPI_ISL_420921, EPI_ISL_420922, EPI_ISL_420923, EPI_ISL_420924, EPI_ISL_420925, EPI_ISL_420926, EPI_ISL_420927, EPI_ISL_420928, EPI_ISL_420929, EPI_ISL_420930,  EPI_ISL_420931, EPI_ISL_420932, EPI_ISL_420933, EPI_ISL_420934, EPI_ISL_420935, EPI_ISL_420936, EPI_ISL_420937, EPI_ISL_420938, EPI_ISL_420939, EPI_ISL_420940, EPI_ISL_420941, EPI_ISL_420942, EPI_ISL_420943, EPI_ISL_420944, EPI_ISL_420945, EPI_ISL_420946, EPI_ISL_420947, EPI_ISL_420948,  EPI_ISL_420949, EPI_ISL_420950, EPI_ISL_420951, EPI_ISL_420952, EPI_ISL_420953, EPI_ISL_420954, EPI_ISL_420955, EPI_ISL_420956, EPI_ISL_420957, EPI_ISL_420958, EPI_ISL_420959, EPI_ISL_420960, EPI_ISL_420961, EPI_ISL_420962, EPI_ISL_420963, EPI_ISL_420964, EPI_ISL_420965, EPI_ISL_420966,  EPI_ISL_420967, EPI_ISL_420968, EPI_ISL_420969, EPI_ISL_420970, EPI_ISL_420971, EPI_ISL_420972, EPI_ISL_420973, EPI_ISL_420974, EPI_ISL_420975, EPI_ISL_420976, EPI_ISL_420977, EPI_ISL_420978, EPI_ISL_420979, EPI_ISL_420980, EPI_ISL_420981, EPI_ISL_420982, EPI_ISL_420983, EPI_ISL_420984,  EPI_ISL_420985, EPI_ISL_420986, EPI_ISL_420987, EPI_ISL_420988, EPI_ISL_420989, EPI_ISL_420990, EPI_ISL_420991, EPI_ISL_420992, EPI_ISL_420993, EPI_ISL_420994, EPI_ISL_420995, EPI_ISL_420996, EPI_ISL_420997, EPI_ISL_420998, EPI_ISL_420999, EPI_ISL_421000, EPI_ISL_421001, EPI_ISL_421002,  EPI_ISL_421003, EPI_ISL_421004, EPI_ISL_421005, EPI_ISL_421006, EPI_ISL_421007, EPI_ISL_421008, Thorsteinsdottir; Kari Stefansson   EPI_ISL_424379, EPI_ISL_424380, EPI_ISL_424381, EPI_ISL_424382, EPI_ISL_424383, EPI_ISL_424384, EPI_ISL_424385, EPI_ISL_424386, EPI_ISL_424387, EPI_ISL_424388, EPI_ISL_424389, EPI_ISL_424390, EPI_ISL_424391, EPI_ISL_424392, EPI_ISL_424393, EPI_ISL_424394, EPI_ISL_424395, EPI_ISL_424396,  EPI_ISL_424397, EPI_ISL_424398, EPI_ISL_424399, EPI_ISL_424400, EPI_ISL_424401, EPI_ISL_424402, EPI_ISL_424403, EPI_ISL_424404, EPI_ISL_424405, EPI_ISL_424406, EPI_ISL_424407, EPI_ISL_424408, EPI_ISL_424409, EPI_ISL_424410, EPI_ISL_424411, EPI_ISL_424412, EPI_ISL_424413, EPI_ISL_424414,  EPI_ISL_424415, EPI_ISL_424416, EPI_ISL_424417, EPI_ISL_424418, EPI_ISL_424419, EPI_ISL_424420, EPI_ISL_424421, EPI_ISL_424422, EPI_ISL_424423, EPI_ISL_424424, EPI_ISL_424425, EPI_ISL_424426, EPI_ISL_424427, EPI_ISL_424428, EPI_ISL_424429, EPI_ISL_424430, EPI_ISL_424431, EPI_ISL_424432 EPI_ISL_424929, EPI_ISL_424930, EPI_ISL_424931, EPI_ISL_424932, EPI_ISL_424933, EPI_ISL_424934, EPI_ISL_424935, EPI_ISL_424936, EPI_ISL_424937, EPI_ISL_424938, EPI_ISL_424939, EPI_ISL_424940, EPI_ISL_424941, EPI_ISL_424942, EPI_ISL_424943, EPI_ISL_424944, EPI_ISL_424945, EPI_ISL_424946,  EPI_ISL_424947, EPI_ISL_424948, EPI_ISL_424949, EPI_ISL_424950, EPI_ISL_424951, EPI_ISL_424952, EPI_ISL_424953, EPI_ISL_424954, EPI_ISL_424955, EPI_ISL_424956, EPI_ISL_424957, EPI_ISL_424958, EPI_ISL_424959, EPI_ISL_424960, EPI_ISL_424961, EPI_ISL_424962, EPI_ISL_424963, EPI_ISL_424964 EPI_ISL_425737, EPI_ISL_425738, EPI_ISL_425739, EPI_ISL_425740, EPI_ISL_425741, EPI_ISL_425742, EPI_ISL_425743, EPI_ISL_425744, EPI_ISL_425745, EPI_ISL_425746, EPI_ISL_425747, EPI_ISL_425748, EPI_ISL_425749, EPI_ISL_425750, EPI_ISL_425751, EPI_ISL_425752, EPI_ISL_425753, EPI_ISL_425754,  EPI_ISL_425755, EPI_ISL_425756, EPI_ISL_425757, EPI_ISL_425758, EPI_ISL_425759, EPI_ISL_425760, EPI_ISL_425761, EPI_ISL_425762, EPI_ISL_425763, EPI_ISL_425764, EPI_ISL_425765, EPI_ISL_425766, EPI_ISL_425767, EPI_ISL_425768, EPI_ISL_425769, EPI_ISL_425770, EPI_ISL_425771, EPI_ISL_425772,  EPI_ISL_425773, EPI_ISL_425774, EPI_ISL_425775, EPI_ISL_425776, EPI_ISL_425777, EPI_ISL_425778, EPI_ISL_425779, EPI_ISL_425780, EPI_ISL_425781, EPI_ISL_425782, EPI_ISL_425783, EPI_ISL_425784, EPI_ISL_425785, EPI_ISL_425786, EPI_ISL_425787, EPI_ISL_425788, EPI_ISL_425789, EPI_ISL_425790,  EPI_ISL_425791, EPI_ISL_425792, EPI_ISL_425793, EPI_ISL_425794, EPI_ISL_425795, EPI_ISL_425796, EPI_ISL_425797, EPI_ISL_425798, EPI_ISL_425799, EPI_ISL_425800, EPI_ISL_425801, EPI_ISL_425802, EPI_ISL_425803, EPI_ISL_425804, EPI_ISL_425805, EPI_ISL_425806, EPI_ISL_425807, EPI_ISL_425808,  EPI_ISL_425809, EPI_ISL_425810, EPI_ISL_425811, EPI_ISL_425812, EPI_ISL_425813, EPI_ISL_425814, EPI_ISL_425815, We gratefully acknowledge the following Authors from the Originating laboratories responsible for obtaining the specimens, as well as the Submitting laboratories where the genome data were generated and shared via GISAID, on which this research is based. EPI_ISL_426817, EPI_ISL_426818, EPI_ISL_426819, EPI_ISL_426820, EPI_ISL_426821, EPI_ISL_426822, EPI_ISL_426823, EPI_ISL_426824, EPI_ISL_426825, EPI_ISL_426826, EPI_ISL_426827, EPI_ISL_426828, EPI_ISL_426829, EPI_ISL_426830, EPI_ISL_426831, EPI_ISL_426832, EPI_ISL_426833, EPI_ISL_426834,  EPI_ISL_426835, EPI_ISL_426836, EPI_ISL_426837, EPI_ISL_426838, EPI_ISL_426839, EPI_ISL_426840, EPI_ISL_426841, EPI_ISL_426842, EPI_ISL_426843, EPI_ISL_426844, EPI_ISL_426845, EPI_ISL_426846, EPI_ISL_426847, EPI_ISL_426848, EPI_ISL_426849, EPI_ISL_426850, EPI_ISL_426851, EPI_ISL_426852,  EPI_ISL_426853, EPI_ISL_426854, EPI_ISL_426855, EPI_ISL_426856, EPI_ISL_426857, EPI_ISL_426858, EPI_ISL_426859, EPI_ISL_426860, EPI_ISL_426861, EPI_ISL_426862, EPI_ISL_426863, EPI_ISL_426864, EPI_ISL_426865, EPI_ISL_426866, EPI_ISL_426867, EPI_ISL_426869, EPI_ISL_426870, EPI_ISL_426871,  EPI_ISL_426872, EPI_ISL_426873, EPI_ISL_426874, EPI_ISL_426875, EPI_ISL_426876, EPI_ISL_426877, EPI_ISL_426878, EPI_ISL_426879, EPI_ISL_429706, EPI_ISL_429707, EPI_ISL_429708, EPI_ISL_429709, EPI_ISL_429710, EPI_ISL_429711, EPI_ISL_429712, EPI_ISL_429713, EPI_ISL_429714, EPI_ISL_429715, EPI_ISL_429716, EPI_ISL_429717, EPI_ISL_429718, EPI_ISL_429719, EPI_ISL_429720, EPI_ISL_429721, EPI_ISL_429722, EPI_ISL_429723,  EPI_ISL_429724, EPI_ISL_429725, EPI_ISL_429726, EPI_ISL_429727, EPI_ISL_429728, EPI_ISL_429729, EPI_ISL_429730, EPI_ISL_429731, EPI_ISL_429732, EPI_ISL_429733, EPI_ISL_429734, EPI_ISL_429735, EPI_ISL_429736, EPI_ISL_429737, EPI_ISL_429738, EPI_ISL_429739, EPI_ISL_429740, EPI_ISL_429741,  EPI_ISL_429742, EPI_ISL_429743, EPI_ISL_429744, EPI_ISL_429745, EPI_ISL_429746, EPI_ISL_429747, EPI_ISL_429748, EPI_ISL_429749, EPI_ISL_429750, EPI_ISL_429751, EPI_ISL_429752, EPI_ISL_429753, EPI_ISL_429754, EPI_ISL_429755, EPI_ISL_429756, EPI_ISL_429757, EPI_ISL_429758, EPI_ISL_429759,  EPI_ISL_429760, EPI_ISL_429761, EPI_ISL_429762, EPI_ISL_429763, EPI_ISL_429764, EPI_ISL_429765, EPI_ISL_429766, EPI_ISL_429767, EPI_ISL_429768, EPI_ISL_429769, EPI_ISL_429770, EPI_ISL_429771, EPI_ISL_429772, EPI_ISL_429773, EPI_ISL_429774, EPI_ISL_429775, EPI_ISL_429776, EPI_ISL_429777  , EPI_ISL_432191, EPI_ISL_432192, EPI_ISL_432193, EPI_ISL_432194, EPI_ISL_432195, EPI_ISL_432196, EPI_ISL_432197, EPI_ISL_432198, EPI_ISL_432199, EPI_ISL_432200, EPI_ISL_432201, EPI_ISL_432202, EPI_ISL_432203, EPI_ISL_432204, EPI_ISL_432205, EPI_ISL_432206, EPI_ISL_432207, EPI_ISL_432208, EPI_ISL_432209, EPI_ISL_432210, EPI_ISL_432211, EPI_ISL_432212, EPI_ISL_432213, EPI_ISL_432214, EPI_ISL_432215, EPI_ISL_432216, EPI_ISL_432217, EPI_ISL_432218, EPI_ISL_432219, EPI_ISL_432220, EPI_ISL_432221, EPI_ISL_432222, EPI_ISL_432223, EPI_ISL_432224 ,  EPI_ISL_432225, EPI_ISL_432226, EPI_ISL_432227, EPI_ISL_432228, EPI_ISL_432229, EPI_ISL_432230, EPI_ISL_432231, EPI_ISL_432232, EPI_ISL_432233, EPI_ISL_432234, EPI_ISL_432235, EPI_ISL_432236, EPI_ISL_432237, EPI_ISL_432238, EPI_ISL_432239, EPI_ISL_432240, EPI_ISL_432241, EPI_ISL_432242,  EPI_ISL_432243, EPI_ISL_432244, EPI_ISL_432245, EPI_ISL_432246, EPI_ISL_432247, EPI_ISL_432248, EPI_ISL_432249, EPI_ISL_432250, EPI_ISL_432251, EPI_ISL_432252, EPI_ISL_432253, EPI_ISL_432254, EPI_ISL_432255, EPI_ISL_432256, EPI_ISL_432257, EPI_ISL_432258, EPI_ISL_432259, EPI_ISL_432260,  EPI_ISL_432261, EPI_ISL_432262, EPI_ISL_432263, EPI_ISL_432264, EPI_ISL_432265, EPI_ISL_432266, EPI_ISL_432267, EPI_ISL_432268, EPI_ISL_432269, EPI_ISL_432270, EPI_ISL_432271, EPI_ISL_432272, EPI_ISL_432273, EPI_ISL_432274, EPI_ISL_432275, EPI_ISL_432276, EPI_ISL_432277, EPI_ISL_432278,  EPI_ISL_432279, EPI_ISL_432280, EPI_ISL_432281, EPI_ISL_432282, EPI_ISL_432283, EPI_ISL_432284, EPI_ISL_432285, EPI_ISL_432286, EPI_ISL_432287, EPI_ISL_432288, EPI_ISL_432289, EPI_ISL_432290, EPI_ISL_432291, EPI_ISL_432292, EPI_ISL_432293, EPI_ISL_432294, EPI_ISL_432295, EPI_ISL_432296,  EPI_ISL_432297, EPI_ISL_432298, EPI_ISL_432299, EPI_ISL_432300, EPI_ISL_432301, EPI_ISL_432302, EPI_ISL_432303, EPI_ISL_432304, EPI_ISL_432305, EPI_ISL_432306, EPI_ISL_432307, EPI_ISL_432308, EPI_ISL_432309, EPI_ISL_432310, EPI_ISL_432311, EPI_ISL_432312, EPI_ISL_432313, EPI_ISL_432314,  EPI_ISL_432315, EPI_ISL_432316, EPI_ISL_432317, EPI_ISL_432318, EPI_ISL_432319, EPI_ISL_432320, EPI_ISL_432321, EPI_ISL_432322, EPI_ISL_432323, EPI_ISL_432324, EPI_ISL_432325, EPI_ISL_432326, EPI_ISL_432327, EPI_ISL_432328, EPI_ISL_432329, EPI_ISL_432330, EPI_ISL_432331, EPI_ISL_432332,  EPI_ISL_432333, EPI_ISL_432334, EPI_ISL_432335, EPI_ISL_432336, EPI_ISL_432337, EPI_ISL_432338, EPI_ISL_432339, EPI_ISL_432340, EPI_ISL_432341, EPI_ISL_432342, EPI_ISL_432343, EPI_ISL_432344, EPI_ISL_432345, EPI_ISL_432346, EPI_ISL_432347, EPI_ISL_432348, EPI_ISL_432349, EPI_ISL_432350,  EPI_ISL_432351, EPI_ISL_432352, EPI_ISL_432353, EPI_ISL_432354, EPI_ISL_432355, EPI_ISL_432356, EPI_ISL_432357, EPI_ISL_432358, EPI_ISL_432359, EPI_ISL_432360, EPI_ISL_432361, EPI_ISL_432362, EPI_ISL_432363, EPI_ISL_432364, EPI_ISL_432365, EPI_ISL_432366, EPI_ISL_432367, EPI_ISL_432368 Templeton K   EPI_ISL_433268, EPI_ISL_433269, EPI_ISL_433270, EPI_ISL_433271, EPI_ISL_433272, EPI_ISL_433273, EPI_ISL_433274, EPI_ISL_433275, EPI_ISL_433276, EPI_ISL_433277, EPI_ISL_433278, EPI_ISL_433279, EPI_ISL_433280, EPI_ISL_433281, EPI_ISL_433282, EPI_ISL_433283, EPI_ISL_433284, EPI_ISL_433285,  EPI_ISL_433286, EPI_ISL_433287, EPI_ISL_433288, EPI_ISL_433289, EPI_ISL_433290, EPI_ISL_433291, EPI_ISL_433292, EPI_ISL_433293, EPI_ISL_433294, EPI_ISL_433295, EPI_ISL_433296, EPI_ISL_433297, EPI_ISL_433298, EPI_ISL_433299, EPI_ISL_433300, EPI_ISL_433301, EPI_ISL_433302, EPI_ISL_433303,  EPI_ISL_433304, EPI_ISL_433305, EPI_ISL_433306, EPI_ISL_433307, EPI_ISL_433308, EPI_ISL_433309, EPI_ISL_433310, EPI_ISL_433311, EPI_ISL_433312, EPI_ISL_433313, EPI_ISL_433314, EPI_ISL_433315, EPI_ISL_433316, EPI_ISL_433317, EPI_ISL_433318, EPI_ISL_433319, EPI_ISL_433320, EPI_ISL_433321,  EPI_ISL_433322, EPI_ISL_433323, EPI_ISL_433324, EPI_ISL_433325, EPI_ISL_433326, EPI_ISL_433327, EPI_ISL_433328, EPI_ISL_433329, EPI_ISL_433330, EPI_ISL_433331, EPI_ISL_433332, EPI_ISL_433333, EPI_ISL_433334, EPI_ISL_433335, EPI_ISL_433336, EPI_ISL_433337, EPI_ISL_433338, EPI_ISL_433339,  EPI_ISL_433340, EPI_ISL_433341, EPI_ISL_433342, EPI_ISL_433343, EPI_ISL_433344, EPI_ISL_433345, EPI_ISL_433346, EPI_ISL_433347, EPI_ISL_433348, EPI_ISL_433349, EPI_ISL_433350, EPI_ISL_433351, EPI_ISL_433352, EPI_ISL_433353, EPI_ISL_433354, EPI_ISL_433355, EPI_ISL_433356, EPI_ISL_433357 EPI_ISL_436505, EPI_ISL_436506, EPI_ISL_436507, EPI_ISL_436508, EPI_ISL_436509, EPI_ISL_436510, EPI_ISL_436511, EPI_ISL_436512, EPI_ISL_436513, EPI_ISL_436514, EPI_ISL_436515, EPI_ISL_436516, EPI_ISL_436517, EPI_ISL_436518, EPI_ISL_436519, EPI_ISL_436520, EPI_ISL_436521, EPI_ISL_436522,  EPI_ISL_436523, EPI_ISL_436524, EPI_ISL_436525, EPI_ISL_436526, EPI_ISL_436527, EPI_ISL_436528, EPI_ISL_436529, EPI_ISL_436530, EPI_ISL_436531, EPI_ISL_436532, EPI_ISL_436533, EPI_ISL_436534, EPI_ISL_436535, EPI_ISL_436536, EPI_ISL_436537, EPI_ISL_436538, EPI_ISL_436539, EPI_ISL_436540,  EPI_ISL_436541, EPI_ISL_436542, EPI_ISL_436543, EPI_ISL_436544, EPI_ISL_436545, EPI_ISL_436546, EPI_ISL_436547, EPI_ISL_436548, EPI_ISL_436549, EPI_ISL_436550, EPI_ISL_436551, EPI_ISL_436552, EPI_ISL_436553, EPI_ISL_436554, EPI_ISL_436555, EPI_ISL_436556, EPI_ISL_436557, EPI_ISL_436558,  EPI_ISL_436559, EPI_ISL_436560, EPI_ISL_437803, EPI_ISL_437804, EPI_ISL_437805, EPI_ISL_437806, EPI_ISL_437807, EPI_ISL_437808, EPI_ISL_437809, EPI_ISL_437810, EPI_ISL_437811, EPI_ISL_437812, EPI_ISL_437813, EPI_ISL_437814, EPI_ISL_437815, EPI_ISL_437816, EPI_ISL_437817, EPI_ISL_437818, EPI_ISL_437819, EPI_ISL_437820,  EPI_ISL_437821, EPI_ISL_437822, EPI_ISL_437823, EPI_ISL_437824, EPI_ISL_437825, EPI_ISL_437826, EPI_ISL_437827, EPI_ISL_437828, EPI_ISL_437829, EPI_ISL_437830, EPI_ISL_437831, EPI_ISL_437832, EPI_ISL_437833, EPI_ISL_437834, EPI_ISL_437835, EPI_ISL_437836, EPI_ISL_437837, EPI_ISL_437838,  EPI_ISL_437839, EPI_ISL_437840, EPI_ISL_437841, EPI_ISL_437842, EPI_ISL_437843, EPI_ISL_437844, EPI_ISL_437845, EPI_ISL_437846, EPI_ISL_437847, EPI_ISL_437848, EPI_ISL_437849, EPI_ISL_437850, EPI_ISL_437851, EPI_ISL_437852, EPI_ISL_437853, EPI_ISL_437854, EPI_ISL_437855, EPI_ISL_437856,  EPI_ISL_437857, EPI_ISL_437858, EPI_ISL_437859, EPI_ISL_437860, EPI_ISL_437861, EPI_ISL_437862, EPI_ISL_437863, EPI_ISL_437864, EPI_ISL_437865, EPI_ISL_437866, EPI_ISL_437867, EPI_ISL_437868, EPI_ISL_437869, We gratefully acknowledge the following Authors from the Originating laboratories responsible for obtaining the specimens, as well as the Submitting laboratories where the genome data were generated and shared via GISAID, on which this research is based. EPI_ISL_438550, EPI_ISL_438551, EPI_ISL_438552, EPI_ISL_438553, EPI_ISL_438554, EPI_ISL_438555, EPI_ISL_438556, EPI_ISL_438557, EPI_ISL_438558, EPI_ISL_438559, EPI_ISL_438560, EPI_ISL_438561, EPI_ISL_438562, EPI_ISL_438563, EPI_ISL_438564, EPI_ISL_438565, EPI_ISL_438566, EPI_ISL_438567,  EPI_ISL_438568, EPI_ISL_438569, EPI_ISL_438570, EPI_ISL_438571, EPI_ISL_438572, EPI_ISL_438573, EPI_ISL_438574, EPI_ISL_438575, EPI_ISL_438576, EPI_ISL_438577, EPI_ISL_438578, EPI_ISL_438579, EPI_ISL_438580, EPI_ISL_438581, EPI_ISL_438582, EPI_ISL_438583, EPI_ISL_438584, EPI_ISL_438585,  EPI_ISL_438586, EPI_ISL_438587, EPI_ISL_438588, EPI_ISL_438589, EPI_ISL_438590, EPI_ISL_438591, EPI_ISL_438592, EPI_ISL_438593, EPI_ISL_438594, EPI_ISL_438595, EPI_ISL_438596, EPI_ISL_438597, EPI_ISL_438598, EPI_ISL_438599, EPI_ISL_438600, EPI_ISL_438601, EPI_ISL_438602, EPI_ISL_438603,  EPI_ISL_438604, EPI_ISL_438605, EPI_ISL_438606, EPI_ISL_438607, EPI_ISL_438608, EPI_ISL_438609, EPI_ISL_438610, EPI_ISL_438611, EPI_ISL_438612, EPI_ISL_438613, EPI_ISL_438614, EPI_ISL_438615, EPI_ISL_438616, EPI_ISL_438617, EPI_ISL_438618, EPI_ISL_438619, EPI_ISL_438620, EPI_ISL_438621,  EPI_ISL_438622, EPI_ISL_438623, EPI_ISL_438624, EPI_ISL_438625, EPI_ISL_438626, EPI_ISL_438627, EPI_ISL_438628, EPI_ISL_438629, EPI_ISL_438630, EPI_ISL_438631, EPI_ISL_438632, EPI_ISL_438633, EPI_ISL_438634, EPI_ISL_438635, EPI_ISL_438636, EPI_ISL_438637, EPI_ISL_438638, EPI_ISL_438639,  EPI_ISL_438640, EPI_ISL_438641, EPI_ISL_438642, EPI_ISL_438643, EPI_ISL_438644, EPI_ISL_438645, EPI_ISL_438646, EPI_ISL_438647, EPI_ISL_438648, EPI_ISL_438649, EPI_ISL_438650, EPI_ISL_438651, EPI_ISL_438652, EPI_ISL_438653, EPI_ISL_438654, EPI_ISL_438655, EPI_ISL_438656, EPI_ISL_438657,  EPI_ISL_438658, EPI_ISL_438659, EPI_ISL_438660, EPI_ISL_438661, EPI_ISL_438662, EPI_ISL_438663, EPI_ISL_438664, EPI_ISL_438665, EPI_ISL_438666, EPI_ISL_438667, EPI_ISL_438668, EPI_ISL_438669, EPI_ISL_438670, EPI_ISL_438671, EPI_ISL_438672, EPI_ISL_438673, EPI_ISL_438674, EPI_ISL_438675 Emma Thomson   EPI_ISL_439144, EPI_ISL_439145, EPI_ISL_439146, EPI_ISL_439147, EPI_ISL_439148, EPI_ISL_439149, EPI_ISL_439150, EPI_ISL_439151, EPI_ISL_439152, EPI_ISL_439153, EPI_ISL_439154, EPI_ISL_439155, EPI_ISL_439156, EPI_ISL_439157, EPI_ISL_439158, EPI_ISL_439159, EPI_ISL_439160, EPI_ISL_439161,  EPI_ISL_439162, EPI_ISL_439163, EPI_ISL_439164, EPI_ISL_439165, EPI_ISL_439166, EPI_ISL_439167, EPI_ISL_439168, EPI_ISL_439169, EPI_ISL_439170, EPI_ISL_439171, EPI_ISL_439172, EPI_ISL_439173, EPI_ISL_439174, EPI_ISL_439175, EPI_ISL_439176, EPI_ISL_439177, EPI_ISL_439178, EPI_ISL_439179,  EPI_ISL_439180, EPI_ISL_439181, EPI_ISL_439182, EPI_ISL_439183, EPI_ISL_439184, EPI_ISL_439185, EPI_ISL_439186, EPI_ISL_439187, EPI_ISL_439188, EPI_ISL_439189, EPI_ISL_439190, EPI_ISL_439191, EPI_ISL_439192, EPI_ISL_439193, EPI_ISL_439194, EPI_ISL_439195, EPI_ISL_439196, EPI_ISL_439197,  EPI_ISL_439198, EPI_ISL_439199, EPI_ISL_439200, EPI_ISL_439201, EPI_ISL_439202, EPI_ISL_439203, EPI_ISL_439204, EPI_ISL_439205, EPI_ISL_439206, EPI_ISL_439207, EPI_ISL_439208, EPI_ISL_439209, EPI_ISL_439210, EPI_ISL_439211, EPI_ISL_439212, EPI_ISL_439213, EPI_ISL_439214, EPI_ISL_439215,  EPI_ISL_439216, EPI_ISL_439217, EPI_ISL_439218, EPI_ISL_439219, EPI_ISL_439220, EPI_ISL_439221, EPI_ISL_439222, EPI_ISL_439223, EPI_ISL_439224, EPI_ISL_439225, EPI_ISL_439226, EPI_ISL_439227, EPI_ISL_439228, EPI_ISL_439229, EPI_ISL_439230, EPI_ISL_439231, EPI_ISL_439232, EPI_ISL_439233,  EPI_ISL_439234, EPI_ISL_439235, EPI_ISL_439236, EPI_ISL_439237, EPI_ISL_439238, EPI_ISL_439239, EPI_ISL_439240, EPI_ISL_439241, EPI_ISL_439242, EPI_ISL_439243, EPI_ISL_439244, EPI_ISL_439245, EPI_ISL_439246, EPI_ISL_439247, EPI_ISL_439248, EPI_ISL_439249, EPI_ISL_439250, EPI_ISL_439251,  EPI_ISL_439252, EPI_ISL_439253, EPI_ISL_439254, EPI_ISL_439255, EPI_ISL_439256, EPI_ISL_439257, EPI_ISL_439258, EPI_ISL_439259, EPI_ISL_439260, EPI_ISL_439261, EPI_ISL_439262, EPI_ISL_439263, EPI_ISL_439264, EPI_ISL_439265, EPI_ISL_439266, EPI_ISL_439267, EPI_ISL_439268, EPI_ISL_439269,  EPI_ISL_439270, EPI_ISL_439271, EPI_ISL_439272, EPI_ISL_439273, EPI_ISL_439274, EPI_ISL_439275, EPI_ISL_439276, EPI_ISL_439277, EPI_ISL_439278, EPI_ISL_439279, EPI_ISL_439280, EPI_ISL_439281, EPI_ISL_439282, EPI_ISL_439283, EPI_ISL_439284, EPI_ISL_439285, EPI_ISL_439286, EPI_ISL_439287 Panzera,Y., Delfraro,A., Ramos,N., Frabasile,S., Calleros,L., Techera,C., Grecco,S., Fuques,E., Goni,N., Coppola,L., Ramos,V., Chiparelli,H., Arbiza,J. and Perez,R. Ivan Pavlov   EPI_ISL_444520, EPI_ISL_444521, EPI_ISL_444522, EPI_ISL_444523, EPI_ISL_444524, EPI_ISL_444525, EPI_ISL_444526, EPI_ISL_444527, EPI_ISL_444528, EPI_ISL_444529, EPI_ISL_444530, EPI_ISL_444531, EPI_ISL_444532, EPI_ISL_444533, EPI_ISL_444534, EPI_ISL_444535, EPI_ISL_444536, EPI_ISL_444537,  EPI_ISL_444538, EPI_ISL_444539, EPI_ISL_444540, EPI_ISL_444541, EPI_ISL_444542, EPI_ISL_444543, EPI_ISL_444544, EPI_ISL_444545, EPI_ISL_444546, EPI_ISL_444547, EPI_ISL_444548, EPI_ISL_444549, EPI_ISL_444550, EPI_ISL_444551, EPI_ISL_444552, EPI_ISL_444553, EPI_ISL_444554, EPI_ISL_444555,  EPI_ISL_444556, EPI_ISL_444557, EPI_ISL_444558, EPI_ISL_444559, EPI_ISL_444560, EPI_ISL_444561, EPI_ISL_444562, EPI_ISL_444563, EPI_ISL_444564, EPI_ISL_444565, EPI_ISL_444566, EPI_ISL_444567, EPI_ISL_444568, EPI_ISL_444569, EPI_ISL_444570, EPI_ISL_444571, EPI_ISL_444572, EPI_ISL_444573,  EPI_ISL_444574, EPI_ISL_444575, EPI_ISL_444576, EPI_ISL_444577, EPI_ISL_444578, EPI_ISL_444579, EPI_ISL_444580, EPI_ISL_444581, EPI_ISL_444582, EPI_ISL_444583, EPI_ISL_444584, EPI_ISL_444585, EPI_ISL_444586, EPI_ISL_444587, EPI_ISL_444588, EPI_ISL_444589, EPI_ISL_444590, EPI_ISL_444591 EPI_ISL_445380 EPI_ISL_446695, EPI_ISL_446696, EPI_ISL_446697, EPI_ISL_446698, EPI_ISL_446699, EPI_ISL_446700, EPI_ISL_446701, EPI_ISL_446702, EPI_ISL_446703, EPI_ISL_446704, EPI_ISL_446705, EPI_ISL_446706, EPI_ISL_446707, EPI_ISL_446708, EPI_ISL_446709, EPI_ISL_446710, EPI_ISL_446711, EPI_ISL_446712, EPI_ISL_446713, EPI_ISL_446714, EPI_ISL_446715, EPI_ISL_446716, EPI_ISL_446717, EPI_ISL_446718, EPI_ISL_446719, EPI_ISL_446720, EPI_ISL_446721, EPI_ISL_446722, EPI_ISL_446723, EPI_ISL_446724, EPI_ISL_446725, EPI_ISL_446726, EPI_ISL_446727, EPI_ISL_446728, EPI_ISL_446729, EPI_ISL_446730, EPI_ISL_446731, EPI_ISL_446732, EPI_ISL_446733, EPI_ISL_446734, EPI_ISL_446735, EPI_ISL_446736, EPI_ISL_446737, EPI_ISL_446738, EPI_ISL_446739, EPI_ISL_446740, EPI_ISL_446741, EPI_ISL_446742, EPI_ISL_446743, EPI_ISL_446744, EPI_ISL_446745, EPI_ISL_446746, EPI_ISL_446747, EPI_ISL_446748 ,  EPI_ISL_446749, EPI_ISL_446750, EPI_ISL_446751, EPI_ISL_446752, EPI_ISL_446753, EPI_ISL_446754, EPI_ISL_446755, EPI_ISL_446756, EPI_ISL_446757, EPI_ISL_446758, EPI_ISL_446759, EPI_ISL_446760, EPI_ISL_446761, EPI_ISL_446762, EPI_ISL_446763, EPI_ISL_446764, EPI_ISL_446765, EPI_ISL_446766,  EPI_ISL_446767, EPI_ISL_446768, EPI_ISL_446769, EPI_ISL_446770, EPI_ISL_446771, EPI_ISL_446772, EPI_ISL_446773, EPI_ISL_446774, EPI_ISL_446775, EPI_ISL_446776, EPI_ISL_446777, EPI_ISL_446778, EPI_ISL_446779, EPI_ISL_446780, EPI_ISL_446781, EPI_ISL_446782, EPI_ISL_446783, EPI_ISL_446784,  EPI_ISL_446785, EPI_ISL_446786, EPI_ISL_446787, EPI_ISL_446788, EPI_ISL_446789, EPI_ISL_446790, EPI_ISL_446791, EPI_ISL_446792, EPI_ISL_446793, EPI_ISL_446794, EPI_ISL_446795, EPI_ISL_446796, EPI_ISL_446797, EPI_ISL_446798, EPI_ISL_446799, EPI_ISL_446800, EPI_ISL_446801, EPI_ISL_446802,  EPI_ISL_446803, EPI_ISL_446804, EPI_ISL_446805, EPI_ISL_446806, EPI_ISL_446807, EPI_ISL_446808, EPI_ISL_446809, EPI_ISL_446810, EPI_ISL_446811, EPI_ISL_446812, EPI_ISL_446813, EPI_ISL_446814, EPI_ISL_446815, EPI_ISL_446816, EPI_ISL_446817, EPI_ISL_446818, EPI_ISL_446819, EPI_ISL_446820,  EPI_ISL_446821, EPI_ISL_446822, EPI_ISL_446823, EPI_ISL_446824, EPI_ISL_446825, EPI_ISL_446826, EPI_ISL_446827, EPI_ISL_446828, EPI_ISL_446829, EPI_ISL_446830, EPI_ISL_446831, EPI_ISL_446832, EPI_ISL_446833, EPI_ISL_446834, EPI_ISL_446835, EPI_ISL_446836, EPI_ISL_446837, EPI_ISL_446838,  EPI_ISL_446839, EPI_ISL_446840, EPI_ISL_446841, EPI_ISL_446842, EPI_ISL_446843, EPI_ISL_446844, EPI_ISL_446845, EPI_ISL_446846, EPI_ISL_446847, EPI_ISL_446848, EPI_ISL_446849, EPI_ISL_446850, EPI_ISL_446851, EPI_ISL_446852, EPI_ISL_446853, EPI_ISL_446854, EPI_ISL_446855, EPI_ISL_446856,  EPI_ISL_446857, EPI_ISL_446858, EPI_ISL_446859, EPI_ISL_446860, EPI_ISL_446861, EPI_ISL_446862, EPI_ISL_446863, EPI_ISL_446864, EPI_ISL_446865, EPI_ISL_446866, EPI_ISL_446867, EPI_ISL_446868, EPI_ISL_446869, EPI_ISL_446870, EPI_ISL_446871, EPI_ISL_446872, EPI_ISL_446873, EPI_ISL_446874,  EPI_ISL_446875, EPI_ISL_446876, EPI_ISL_446877, EPI_ISL_446878, EPI_ISL_446879, EPI_ISL_446880, EPI_ISL_446881, EPI_ISL_446882, EPI_ISL_446883, EPI_ISL_446884, EPI_ISL_446885, EPI_ISL_446886, EPI_ISL_446887, EPI_ISL_446888, EPI_ISL_446889, EPI_ISL_446890, EPI_ISL_446891, EPI_ISL_446892,  EPI_ISL_446893 , EPI_ISL_446894, EPI_ISL_446895, EPI_ISL_446896, EPI_ISL_446897, EPI_ISL_446898, EPI_ISL_446899, EPI_ISL_446900, EPI_ISL_446901, EPI_ISL_446902, EPI_ISL_446903, EPI_ISL_446904, EPI_ISL_446905, EPI_ISL_446906, EPI_ISL_446907, EPI_ISL_446908, EPI_ISL_446909, EPI_ISL_446910, EPI_ISL_446911, EPI_ISL_446912, EPI_ISL_446913, EPI_ISL_446914, EPI_ISL_446915, EPI_ISL_446916, EPI_ISL_446917, EPI_ISL_446918, EPI_ISL_446919, EPI_ISL_446920, EPI_ISL_446921, EPI_ISL_446922, EPI_ISL_446923, EPI_ISL_446924, EPI_ISL_446925, EPI_ISL_446926, EPI_ISL_446927, EPI_ISL_446928, EPI_ISL_446929, EPI_ISL_446930, EPI_ISL_446931, EPI_ISL_446932, EPI_ISL_446933, EPI_ISL_446934, EPI_ISL_446935, EPI_ISL_446936, EPI_ISL_446937, EPI_ISL_446938, EPI_ISL_446939, EPI_ISL_446940, EPI_ISL_446941, EPI_ISL_446942, EPI_ISL_446943, EPI_ISL_446944, EPI_ISL_446945, EPI_ISL_446946, EPI_ISL_446947, EPI_ISL_446948, EPI_ISL_446949, EPI_ISL_446950, EPI_ISL_446951, EPI_ISL_446952, EPI_ISL_446953, EPI_ISL_446954, EPI_ISL_446955, EPI_ISL_446956, EPI_ISL_446957, EPI_ISL_446958, EPI_ISL_446959, EPI_ISL_446960, EPI_ISL_446961, EPI_ISL_446962, EPI_ISL_446963, EPI_ISL_446964, EPI_ISL_446965, EPI_ISL_446966, EPI_ISL_446967, EPI_ISL_446968, EPI_ISL_446969, EPI_ISL_446970, EPI_ISL_446971, EPI_ISL_446972, EPI_ISL_446973, EPI_ISL_446974, EPI_ISL_446975, EPI_ISL_446976, EPI_ISL_446977, EPI_ISL_446978, EPI_ISL_446979, EPI_ISL_446980, EPI_ISL_446981, EPI_ISL_446982, EPI_ISL_446983, EPI_ISL_446984, EPI_ISL_446985, EPI_ISL_446986, EPI_ISL_446987, EPI_ISL_446988, EPI_ISL_446989, EPI_ISL_446990, EPI_ISL_446991, EPI_ISL_446992, EPI_ISL_446993, EPI_ISL_446994, EPI_ISL_446995 EPI_ISL_447690, EPI_ISL_447691, EPI_ISL_447692, EPI_ISL_447693, EPI_ISL_447694, EPI_ISL_447695, EPI_ISL_447696, EPI_ISL_447697, EPI_ISL_447698, EPI_ISL_447699, EPI_ISL_447700, EPI_ISL_447701, EPI_ISL_447702, EPI_ISL_447703, EPI_ISL_447704, EPI_ISL_447705, EPI_ISL_447706, EPI_ISL_447707, EPI_ISL_447708, EPI_ISL_447709, EPI_ISL_447710, EPI_ISL_447711, EPI_ISL_447712, EPI_ISL_447713, EPI_ISL_447714, EPI_ISL_447715, EPI_ISL_447716, EPI_ISL_447717, EPI_ISL_447718, EPI_ISL_447719, EPI_ISL_447720, EPI_ISL_447721, EPI_ISL_447722, EPI_ISL_447723, EPI_ISL_447724, EPI_ISL_447725, EPI_ISL_447726, EPI_ISL_447727, EPI_ISL_447728, EPI_ISL_447729, EPI_ISL_447730, EPI_ISL_447731, EPI_ISL_447732, EPI_ISL_447733 see above unknown Genomic platform De Prost,N., Fourati,S., Lamoureux,C., Schmitz,D., Deveaux,I., Picard,O., Lepeule,R., Surgers,L., Mekontso-Dessap,A., Woerther,P.-L., Canoui-Poitrine,F., Pawlotsky,J.-M., Clinical Study Group,C., Rodrigue,C., Gricourt,G., N'debi,M., Demontant,V. , Trawinski,E.   EPI_ISL_447734, EPI_ISL_447735, EPI_ISL_447736, EPI_ISL_447737, EPI_ISL_447738, EPI_ISL_447739, EPI_ISL_447740, EPI_ISL_447741, EPI_ISL_447742, EPI_ISL_447743, EPI_ISL_447744, EPI_ISL_447745, EPI_ISL_447746, EPI_ISL_447747, EPI_ISL_447748, EPI_ISL_447749, EPI_ISL_447750, EPI_ISL_447751,  EPI_ISL_447752, EPI_ISL_447753, EPI_ISL_447754  EPI_ISL_448647, EPI_ISL_448648, EPI_ISL_448649, EPI_ISL_448650, EPI_ISL_448651, EPI_ISL_448652, EPI_ISL_448653, EPI_ISL_448654, EPI_ISL_448655, EPI_ISL_448656, EPI_ISL_448657, EPI_ISL_448658, EPI_ISL_448659, EPI_ISL_448660, EPI_ISL_448661, EPI_ISL_448662, EPI_ISL_448663, EPI_ISL_448664,  EPI_ISL_448665, EPI_ISL_448666, EPI_ISL_448667, EPI_ISL_448668, EPI_ISL_448669, EPI_ISL_448670, EPI_ISL_448671, EPI_ISL_448672, EPI_ISL_448673, EPI_ISL_448674, EPI_ISL_448675, EPI_ISL_448676, EPI_ISL_448677, EPI_ISL_448678, EPI_ISL_448679, EPI_ISL_448680, EPI_ISL_448681, EPI_ISL_448682,  EPI_ISL_448683, EPI_ISL_448684, EPI_ISL_448685, EPI_ISL_448686, EPI_ISL_448687, EPI_ISL_448688, EPI_ISL_448689, EPI_ISL_448690, EPI_ISL_448691, EPI_ISL_448692, EPI_ISL_448693, EPI_ISL_448694, EPI_ISL_448695, EPI_ISL_448696, EPI_ISL_448697, EPI_ISL_448698, EPI_ISL_448699, EPI_ISL_448700,  EPI_ISL_448701, EPI_ISL_448702, EPI_ISL_448703, EPI_ISL_448704, EPI_ISL_448705, EPI_ISL_448706, EPI_ISL_448707, EPI_ISL_448708, EPI_ISL_448709, EPI_ISL_448710, EPI_ISL_448711, EPI_ISL_448712, EPI_ISL_448713, EPI_ISL_448714, EPI_ISL_448715, EPI_ISL_448716, EPI_ISL_448717, EPI_ISL_448718,  EPI_ISL_448719, EPI_ISL_448720, EPI_ISL_448721, EPI_ISL_448722, EPI_ISL_448723, EPI_ISL_448724, EPI_ISL_448725, EPI_ISL_448726, EPI_ISL_448727, EPI_ISL_448728, EPI_ISL_448729, EPI_ISL_448730, EPI_ISL_448731, EPI_ISL_448732, EPI_ISL_448733, EPI_ISL_448734, EPI_ISL_448735, EPI_ISL_448736,  EPI_ISL_448737, EPI_ISL_448738, EPI_ISL_448739, EPI_ISL_448740, EPI_ISL_448741, EPI_ISL_448742, EPI_ISL_448743, EPI_ISL_448744, EPI_ISL_448745, EPI_ISL_448746, EPI_ISL_448747, EPI_ISL_448748, EPI_ISL_448749, EPI_ISL_448750, EPI_ISL_448751, EPI_ISL_448752, EPI_ISL_448753, EPI_ISL_448754,  EPI_ISL_448755, EPI_ISL_448756, EPI_ISL_448757, EPI_ISL_448758, EPI_ISL_448759, EPI_ISL_448760, EPI_ISL_448761, EPI_ISL_448762, EPI_ISL_448763, EPI_ISL_448764, EPI_ISL_448765, EPI_ISL_448766, EPI_ISL_448767, EPI_ISL_448768, EPI_ISL_448769, EPI_ISL_448770, EPI_ISL_448771, EPI_ISL_448772,  EPI_ISL_448773, EPI_ISL_448774, EPI_ISL_448775, EPI_ISL_448776, EPI_ISL_448777, EPI_ISL_448778, EPI_ISL_448779, EPI_ISL_448780, EPI_ISL_448781, EPI_ISL_448782, EPI_ISL_448783, EPI_ISL_448784, EPI_ISL_448785, EPI_ISL_448786, EPI_ISL_448787, EPI_ISL_448788, EPI_ISL_448789, EPI_ISL_448790,  EPI_ISL_448791, EPI_ISL_448792, EPI_ISL_448793, EPI_ISL_448794, EPI_ISL_448795, EPI_ISL_448796, EPI_ISL_448797, EPI_ISL_448798, EPI_ISL_448799, EPI_ISL_448800, EPI_ISL_448801, EPI_ISL_448802, EPI_ISL_448803, EPI_ISL_448804, EPI_ISL_448805, EPI_ISL_448806, EPI_ISL_448807, EPI_ISL_448808,  EPI_ISL_448809, EPI_ISL_448810, EPI_ISL_448811, EPI_ISL_448812, EPI_ISL_448813, EPI_ISL_448814, EPI_ISL_448815, EPI_ISL_448816, EPI_ISL_448817, EPI_ISL_448818, EPI_ISL_448819, EPI_ISL_448820, EPI_ISL_448821, EPI_ISL_448822, EPI_ISL_449801, EPI_ISL_449802, EPI_ISL_449803, EPI_ISL_449804, EPI_ISL_449805, EPI_ISL_449806, EPI_ISL_449807, EPI_ISL_449808, EPI_ISL_449809, EPI_ISL_449810, EPI_ISL_449811, EPI_ISL_449812, EPI_ISL_449813, EPI_ISL_449814, EPI_ISL_449815, EPI_ISL_449816, EPI_ISL_449817, EPI_ISL_449818,  EPI_ISL_449819, EPI_ISL_449820, EPI_ISL_449821, EPI_ISL_449822, EPI_ISL_449823, EPI_ISL_449824, EPI_ISL_449825, EPI_ISL_449826, EPI_ISL_449827, EPI_ISL_449828, EPI_ISL_449829, EPI_ISL_449830, EPI_ISL_449831, EPI_ISL_449832, EPI_ISL_449833, EPI_ISL_449834, EPI_ISL_449835, @story_separate@Employing phylogenetic methods on Danish genome sequences of SARS-CoV-2, we exemplify how genetic data can be used to trace the introduction of a virus to a country. This provides alternative means for verifying existing assumptions. For example, our analysis supports the hypothesis that the virus was brought to Denmark by skiers returning from Ischgl. On the other hand, we identify transmission routes which suggest that Denmark was part of a network of countries among which the virus was being transmitted. This challenges the common narrative that Denmark only got infected from abroad. Our analysis concerning Introduction According to peer-reviewed studies, the first cases of COVID-19 were reported in the city of Wuhan (China) at the first of December 2019 and a new virus, named SARS-CoV-2, was later identified as its origin [1] . At the time of writing, the pandemic is ongoing and has spread to more than 180 countries [2] . The first European case was reported in France on January 24, 2020 [3] . Italy confirmed its first two cases only a few days later on January 31 [4] . Austria reported its first cases on February 25 [5] . In March, Europe was the center of the global pandemic with many European countries introducing lockdown measures and travel restrictions. Early on, the ski area of Ischgl in Tyrol, Austria, was identified as a transmission hot-spot by some countries, so Iceland already declared it a risk area on March 5 [6] . Quarantine measures in Ischgl, however, were only imposed on March 13 [7] . Denmark confirmed its first case on February 27 after a man who returned home on February 24 from skiing holidays in Northern Italy had tested positive [8] . The second case was confirmed on February 28 and it was also associated to a traveller returning home from Northern Italy [9] . The number of cases kept increasing, and there was increased suspicion of community transmission after two cases had been confirmed at a local high school on March 8 [10] . During this first phase of the pandemic Denmark had issued travel warnings for certain high-risk areas. On March 2, Denmark advised against all travel to Northern Italy [11]. On March 10, Denmark additionally advised against travel to the Austrian state of Tyrol, as many travellers had tested positive after returning home from ski holidays in Ischgl. [12] . On March 11, the Danish prime minister Mette Frederiksen announced a lockdown, which happened in several stages and included closures of borders and schools [13] . Overall, the measures were not as severe as in some other European countries. On April 6, the prime minister announced that the first phase of reopening would start from April 14 [14] . The country has opened up further since. As of May 26, there were 11,428 confirmed infections and 563 deaths in Denmark in connection with the disease [15] . From March 12, only people with serious symptoms and people in risk groups were tested. Since April 1, the number of tests has been increased [16] . In this work, we study all the publicly available genome sequences of the SARS-CoV-2 virus from Denmark as of May 26. The amount of sequences available makes Denmark a natural choice for a case study. Moreover, Denmark can serve as a prototype for a country which was internationally well-connected at the beginning of the pandemic and subsequently went into a strict lockdown. An investigation of the transmission routes of the virus in Denmark could therefore be used to understand the development in other countries as well. For this investigation, we compare the Danish sequences used for our work to genome sequences from abroad. See S2 File for a list of sequences and their labs of origin. We use the mutations in the genomic data to identify transmission routes. These appear in the genetic data as sequences of consecutive mutations and can be thought of as a coarse-grained version of transmission chains where one cannot resolve the transmission between individuals, because some of the sequences might be identical. Our focus is on chains of mutations highlighting the introduction of the virus to Denmark, its transmission within Denmark, and its spread to other countries.","BACKGROUND: The first cases of COVID-19 caused by the SARS-CoV-2 virus were reported in China in December 2019. The disease has since spread globally. Many countries have instated measures to slow the spread of the virus. Information about the spread of the virus in a country can inform the gradual reopening of a country and help to avoid a second wave of infections. Our study focuses on Denmark, which is opening up when this study is performed (end-May 2020) after a lockdown in mid-March. METHODS: We perform a phylogenetic analysis of 742 publicly available Danish SARS-CoV-2 genome sequences and put them into context using sequences from other countries. RESULTS: Our findings are consistent with several introductions of the virus to Denmark from independent sources. We identify several chains of mutations that occurred in Denmark. In at least one case we find evidence that the virus spread from Denmark to other countries. A number of the mutations found in Denmark are non-synonymous, and in general there is a considerable variety of strains. The proportions of the most common haplotypes remain stable after lockdown. CONCLUSION: Employing phylogenetic methods on Danish genome sequences of SARS-CoV-2, we exemplify how genetic data can be used to trace the introduction of a virus to a country. This provides alternative means for verifying existing assumptions. For example, our analysis supports the hypothesis that the virus was brought to Denmark by skiers returning from Ischgl. On the other hand, we identify transmission routes which suggest that Denmark was part of a network of countries among which the virus was being transmitted. This challenges the common narrative that Denmark only got infected from abroad. Our analysis concerning the ratio of haplotypes does not indicate that the major haplotypes appearing in Denmark have a different degree of virality."
"The Coronavirus Disease (COVID-19) pandemic, caused by transmissible infection of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), has resulted in tens of millions of diagnosed cases and over 1 450 000 deaths worldwide [1] ; straining healthcare systems, and disrupting key aspects of society and the wider economy. It is thus important to identify effective treatments rapidly via discovery of new drugs and repurposing of existing drugs. Here, we leverage advances in natural language processing to enable automatic identification of drug candidates being studied in the scientific literature. The magnitude of the pandemic has resulted in an enormous number of academic publications related to COVID-19 research since early 2020. Many of these articles are collated in the COVID-19 Open Research Dataset Challenge (CORD-19) collection [2, 3] . With 198 875 articles at the time of writing, that collection is far too large for humans to read. Thus, tools are needed to automate the process of extracting relevant data, such as drug names, testing protocols, and protein targets. Such tools can save domain experts significant time and effort. Towards this goal, we describe here how we have tackled two important problems: creating labelled training data via judicious use of scarce human expertise, and applying a named entity recognition (NER) model to automatically identify drug-like molecules in text. In the absence of rich labeled data for the growing COVID literature, we employ an iterative model-in-the-loop collection process inspired by our previous work [4, 5] . We first assemble a small bootstrap set of human-verified examples to train a model for identifying similar examples. We then iteratively apply the model, use human reviewers to verify the predictions for which the model is least confident, and retrain the model until the improvement in performance is less than a threshold. (The human reviewers were administrative staff without scientific backgrounds, with time available for this task due to the pandemic.) Having collected adequate training data via this model-guided human annotation process, we then use the resulting labeled data to re-train a NER model originally developed to identify polymer names in materials science publications [6] and apply this trained model to . We show that the labeled data produced by our approach are of sufficiently high quality than when used to train NER models, which achieves a best F-1 score of 80.5%-roughly equivalent to that achieved by non-expert humans. The labeled data, model, and model results are all available online, as described in Section 7.@story_separate@We aim to develop and apply new computational methods to mine the scientific literature to identify small molecules that have been investigated or found useful as antiviral therapeutics. For example, processing the following sentence should allow us to determine that the drug sofosbuvir has been found effective against the Zika virus: ""Sofosbuvir, an FDA-approved nucleotide polymerase inhibitor, can efficiently inhibit replication and infection of several ZIKV strains, including African and American isolates."" [7] . This problem of identifying drug-like molecules in text can be divided into two linked problems: 1) identifying references to small therapeutic molecules (""drugs"") and 2) determining what the text says about those molecules. In this work, we consider potential solutions to the first problem. A simple way to identify entities in text that belong to a specialized class (e.g., drug-like molecules) is to refer to a curated list of valid names, if such is available. In the case of drugs, we might think to use DrugBank [8] or the FDA Drug Database [9], both of which in fact list sofosbuvir. However, such databases are not in themselves an adequate solution to our problem, for at least two reasons. First, they are rarely complete. The tens of thousands of entity names in DrugBank and the FDA Drug Database together are just a tiny fraction of the billions of molecules that could potentially be used as drugs. Second, such databases may be overly general: DrugBank, for example, includes the terms ""rabbit"" and ""calcium,"" neither of which have value as antiviral therapeutics. In general, the use of any such list to identify entities will lead to both false negatives and false positives. We need instead to employ the approach that a human reader might follow in this situation, namely to scan text for words that appear in contexts in which a drug name is likely to appear. In the following, we explain how we use natural language processing (NLP) techniques for this purpose. Finding strings in text that refer to drug-like molecules is an example of named-entity recognition (NER) [10] , an important NLP task. Both grammatical and statistical (e.g., neural networkbased) methods have been applied to NER; the former can be more accurate, but require much effort from trained linguists to develop. Statistical methods use supervised training on labeled examples to learn the contexts in which entities of interest (e.g., drug-like molecules) are likely to occur, and then classify previously unseen words as such entities if they appear in similar contexts. For instance, a training set may contain the sentence ""Ribavirin was administered once daily by the i.p. route"" [11] , with ribavirin labelled as Drug. With sufficient training data, the model may learn to assign the label Drug to arbidol in the sentence ""Arbidol was administered once daily per os using a stomach probe"" [11] . This learning approach can lead to general models capable of finding previously unseen candidate molecules in natural language text. The development of effective statistical NER models is complicated by the many contexts in which names can occur. For example, while the contexts just given for ribavirin and arbidol are similar, both are quite different from that quoted for sofosbuvir earlier. Furthermore, authors may use different wordings and sentence structures: e.g., ""given by i.p. injection once daily"" rather than ""administered once daily by the i.p. route."" Thus, statistical NER methods need to do more than learn template word sequences: they need to learn more abstract representations of the context(s) in which words appear. Modern NLP and NER systems do just that [12] . We consider two NER models in this paper, SpaCy and a Keras long-short term memory (LSTM) model. Both models are publicly available on DLHub [13] and GitHub, as described in Section 7. SpaCy is an open source NLP library that provides a pre-trained entity recognizer that can recognize 18 types of entities, including PERSON, ORGANIZATION, LOCATION, and PRODUCT. Its model calculates a probability distribution of a word over the entity types, and outputs the type with the highest probability as the predicted type for that word. When pre-trained on the OntoNotes 5 dataset of over 1.5 million labeled words [14] , the SpaCy entity recognizer can identify supported entities with 85.85% accuracy. However, it does not include drug names as a supported entity class, and thus we would need to retrain the SpaCy model on a drug-specific training corpus. Unfortunately, there is no publicly available corpus of labeled text for drug-like molecules in context. Thus, we need to use other methods to retrain this model (or other NER models), as we describe in Section 4. While SpaCy is easy to use, it lacks flexibility: its end-to-end encapsulation does not expose many tunable parameters. Thus we also explore the use of a Keras-LSTM model that we developed in previous work for identification of polymers in materials science literature [6] . This model is based on the Bidirectional LSTM network with a conditional random field (CRF) layer added on top. It takes training data labeled according to the ""IOB"" schema. The first word in an entity is given the label ""B"" (Beginning), the following words in the same entity are labeled ""I"" (Inside), and non-entity words are labeled ""O"" (outside). During prediction, the Bi-LSTM network tries to assign one of ""IOB"" to each word in the input sentence, but it has no awareness of the validity of the label sequence. The CRF layer is used on top of Bi-LSTM to lower the probability of invalid label sequences (e.g., ""OIO""). We compare the performance of SpaCy and Keras-LSTM models under various conditions in Section 4. We address the lack of labeled training data by using Algorithm 1 (and see Figure 1 ) to assemble a set of human-and machine-labeled data from CORD-19 [3] . In describing this process, we refer to paragraphs labeled automatically via a heuristic or model as silver and to silver paragraphs for which labels have been corrected by human reviewers as gold. We use the Prodigy machine learning annotation tool to manage the review process: reviewers are presented with a silver paragraph, with putative drug entities highlighted; they click on false negative and false positive words to add or remove the highlights and thus produce a gold paragraph. Prodigy saves the corrected labels in standard NER training data format. Our algorithm involves three main phases, as follows. In the first bootstrap phase, we assemble an initial test set of gold paragraphs for use in subsequent data acquisition. We create a first set of silver paragraphs by using a simple heuristic: we select N 0 paragraphs from CORD-19 that contain one or more words in DrugBank with an Anatomical Therapeutic Chemical Classification System (ATC) code, label those words as drugs, and ask human reviewers to correct both false positives and false negatives in our silver paragraphs, creating gold paragraphs. In the subsequent build test set phase, we repeatedly use all gold paragraphs obtained so far to train an NER model; use that model to identify and label additional silver paragraphs, and engage human reviewers to correct false positives and false negatives, creating additional gold paragraphs. We repeat this process until we have N t initial gold paragraphs. In the third build labeled set phase, we repeatedly use an NER model trained on all humanvalidated labels obtained to date, with the N t gold paragraphs from the bootstrap phase used as a test set, to identify and label promising paragraphs in CORD-19 for additional human review. To maximize the utility of this human effort, we present the reviewers only with paragraphs that contain one or more uncertain words, i.e., words that the NER model identifies as drug/nondrug with a confidence in the range [min, max]). We continue this process of model retraining, paragraph selection and labeling, and human review until the F-1 score improves by less than . The behavior of this algorithm is influenced by six parameters: N 0 , N , N t , , min, and max. N 0 and N are the number of paragraphs that are assigned to human reviewers in the first and subsequent steps, respectively. N t is the number of examples in the test set. is a threshold that determines when to stop collecting data. The min and max determine the confidence range from which words are selected for human review. In the experimental studies described below, we used N 0 =278, N =120, N t =500, =0, min=0.45, and max=0.55. The NER model used in the model-in-the-loop annotation workflow to score words might also be viewed as a parameter. In the work reported here, we use SpaCy exclusively for that purpose, as it integrates natively with the Prodigy annotation tool and trains more rapidly. However, as we show below, the Keras-LSTM model is ultimately somewhat more accurate when trained on all of the labeled data generated, and thus is preferred when processing the entire CORD-19 dataset: see Section 5.1 and Section 6. This semi-automated method saves time and effort for human reviewers because they are only asked to verify labels that have already been identified by our model to be uncertain, and thus worth processing. Furthermore, as we show below, we find that we do not need to engage biomedical professionals to label drugs in text: untrained people, armed with contextual information (and online search engines), can spot drug names in text with accuracy comparable to that of experts. We provide further details on the three phases of the algorithm in the following, with numbers in the list referring to line numbers in Algorithm 1. 1 We start with the 2020-03-20 release version of the CORD-19 corpus, which contains 44 220 papers [3] . We create C, a random permutation of its paragraphs from which we will repeatedly fetch paragraphs via next(C). C) Build labeled set 13 We assemble a training set G, using the test set T assembled in the previous phases for testing. This process continues until the F-1 score stops improving (see Section 4). 14-17 Same as Steps 6-9, except that we train on G and test on T , and add new gold paragraphs to G instead of T . As noted in Section 3.2, our model-in-the-loop annotation workflow requires repeated retraining of a SpaCy model. Thus we conducted experiments to understand how SpaCy prediction performance is influenced by model size, quantity of training data, and amount of training performed. As the training data produced by the model-in-the-loop evaluation workflow are to be used to train an NER model that we will apply to the entire CORD-19 dataset, we also evaluate the Keras-LSTM model from the perspectives of big data accuracy and training time. We first need to decide which SpaCy model to use for model-in-the-loop annotation. Model size is a primary factor that affects training time and prediction performance. In general, larger models tend to perform better, but require both more data and more time to train effectively. As our model-in-the-loop annotation strategy requires frequent model retraining, and furthermore will (initially at least) have little data, we hypothesize that a smaller model may be adequate for our purposes. To explore this hypothesis, we study the performance achieved by the SpaCy medium and large models on our initial training set of 278 labeled paragraphs. We show in Figure 2 the performance achieved by the two models as a function of number of training epochs. Focusing on the harmonic mean of precision and recall, the F-1 score (a good measure a model's ability to recognize both true positives and true negatives), we see that the two models achieve similar prediction performance, with the largest difference in F-1 score being around 2%. As the large model takes over eight times longer to train per epoch, we select the medium model for modelin-the-loop data collection.  As data labeling is expensive in both human time and model training time, it is valuable to explore the tradeoff between time spent collecting data and prediction performance. To this end, we manually labeled a set of 500 paragraphs selected at random from CORD-19 [3] as a test set. Then, we used that test set to evaluate the results of training the SpaCy and Keras-LSTM models of Section 3.1 on increasing numbers of the paragraphs produced by our human-in-the-loop annotation process. Figure 3 shows  Prediction performance is also influenced by the number of epochs spent in training. The cost of training is particularly important in a model-in-the-loop setup, as human reviewers cannot work while an model is offline for training. Figure 4 shows the progression of the loss, precision, recall, and F-1 values of the SpaCy model during 100 epochs of training with the initial 278 examples. We can see that the best F-1 score is achieved within 10 to 20 epochs. Increasing the number of epochs does not result in any further improvement. Indeed, F-1 score does not tell us all about the model's performance. Sometimes training for more epochs could lead to lower loss values while other metrics (such as precision, recall, or F-1) no longer improve. That would still be desirable because it means the model is now more ""confident,"" in a sense, about its predictions. However, that is not the case here. As shown in Figure 4 , after around 40 epochs the loss begins to oscillate instead of continuing downwards, suggesting that in this case training for 100 epochs does not result in a better model than only training for 20 epochs. accuracy curves diverge: the training accuracy continues to increase but the validation accuracy plateaus. This trend is suggestive of overfitting, which is corroborated by Figure 5(b) . After about 50 epochs, the validation loss curve turns upwards. Hence we choose to limit the training epochs to 64. After each epoch, if a lower validation loss is achieved, the current model state is saved. After 64 epochs, we test the model with the lowest validation loss on the withheld test set. We conducted experiments to compare the performance of the SpaCy and Keras-LSTM NER models; compare the performance of the models against humans; determine how training data influences model performance; and analyze human and model errors. We used the collected data of Section 3.2 to train both the SpaCy and Keras-LSTM NER models of Section 3.1 to recognize and extract drug-like molecules in text. We find that the trained en core web md SpaCy model achieved a best F-1 score of 77.3%, while the trained Keras-LSTM model achieved a best F-1 score of 80.5%, somewhat outperforming SpaCy. As shown in Figure 3 , the SpaCy model performs better than the Keras-LSTM model when trained with small amounts of training data-perhaps because of the different mechanisms employed by the two methods to generate numerical representations for words. SpaCy's built-in language model, pre-trained on a general corpus of blog posts, news, comments, etc., gives it some knowledge about commonly used words in English, which are likely also to appear in a scientific corpus. On the other hand, the Keras-LSTM model uses custom word embeddings trained solely on an input corpus, which provides it with better understanding of multi-sense words, especially those that have quite different meanings in a scientific corpus. However, without enough raw data to draw contextual information from, custom word embeddings can not accurately reflect the meaning of words. Recognizing drug-like molecules is a difficult task even for humans, especially non-medical professionals (such as our non-expert annotators). To assess the accuracy of the annotators, we asked three people to examine 96 paragraphs, with their associated labels, selected at random from the labeled examples. Two of these reviewers had been involved in creating the labeled dataset; the third had not. For each paragraph, each reviewer decided independently whether each drug molecule entity was labeled correctly (a true positive), was labeled as a drug when it was not (a false positive), or was not labeled (a false negative). If all three reviewers agreed in their opinions on a paragraph (the case for 88 of the 96 paragraphs), we accepted their opinions; if they disagreed (the case for eight paragraphs), we engaged an expert. This process revealed a total of 257 drug molecule entities in the 96 paragraphs, of which the annotators labeled 201 correctly (true positives), labeled 49 incorrectly (false positives), and missed 34 (false negatives). The numbers of true positives and false negatives do not sum up to the total number of drug molecules because in some cases an annotator labeled not to a drug entity but the entity plus extra preceding or succeeding word or punctuation mark (e.g. ""sofosbuvir,"" instead of ""sofosbuvir"") and we count such occurrences as false positives rather than false negatives. In this evaluation, the non-expert annotators achieved an F-1 score of 82.9%, which is comparable to the 80.5% achieved by our automated models, as shown in Figure 3 . In other words, our models have performance on par with that of non-expert humans. We described in the previous section how review of 96 paragraphs labeled by the non-expert annotators revealed an error rate of about 20%. This raises the question of whether model performance could be improved with better training data. To examine this question, we compare the performance of our models when trained on original vs. corrected data. As we only have 96 corrected paragraphs, we restrict our training sets to those 96 paragraphs in each case. We sorted the 96 paragraphs in both datasets so that they are considered in the same order. Then, we split each dataset into five subsets for K-fold cross validation (K =5), with the first four subsets having 19 paragraphs each and the last subset having 20. Since K is set to five, the SpaCy and Keras models are trained five times. In the i -th round, each model is trained on four subsets (excluding the i -th) of each dataset. The i -th subset of the corrected dataset is used as the test set. The i -th subset of the original dataset is not used in the i -th round. We present the K-fold cross validation results in Tables 1 and 2. The models performed reasonably well when trained on the original dataset, with an average F-1 score only 2% less than that achieved with the corrected labels. Given that the expert input required for validation is hard to come by, we believe that using non-expert reviewers is an acceptable tradeoff and probably the only practical way to gather large amounts of training data. Finally, we explore the contexts in which human reviewers and models make mistakes. Specifically, we study the tokens that appear most frequently near to incorrectly labeled entities. To investigate the effects of immediate and long-distance context, we control, as window size, the maximum distance between a token and a entity for that token to be considered as ""context"" for that entity. One difficulty with this analysis is that the most frequent tokens identified in this way were mostly stop words or punctuation marks. For instance, when the window size is set to three, the 10 most frequent tokens around mislabeled words are, in descending order, ""comma(,),"" ""and,"" ""mg,"" ""period(.),"" ""right parenthesis()),"" ""with,"" ""of,"" ""left parenthesis((),"" ""is,"" and ""or."" Only ""mg"" is neither a stop word nor punctuation mark. Those tokens provide little insight as to why human reviewers might have made mistakes, and furthermore are unlikely to have influenced reviewer decisions. Thus we exclude stopwords and punctuation marks when providing, in Table 3 , lists of the 10 most frequent tokens within varying window sizes of words that were incorrectly identified as molecules by human reviewers. We see that there are indeed several deceptive contextual words. With a window size of one, the 10 most frequent tokens include ""oral,"" ""dose,"" and ""intravenous."" It is understandable that an untrained reviewer might label as drugs words that immediately precede or follow such context words. Similar patterns can be seen for window sizes of three and five. Without background knowledge to draw from, non-experts are more likely to rely on their experience gained from labeling previous paragraphs. One may hypothesize that after the reviewers have seen a few dozen to a few hundred paragraphs, those deceptive contextual words must have left a deep impression, so that when those words re-appear they are likely to label the strange unknown word close to them as a drug. To investigate this hypothesis, we also explored the most frequent words around drug entities that are correctly labeled by human reviewers: see Table 4 . Interestingly, we found overlaps between the lists in Tables 3 and 4 : in all, three, four, and two overlaps for window sizes of one, three, and five, respectively, when treating all numerical values as identical. This finding supports our hypothesis that those frequent words around real drug entities may confuse human reviewers when they appear around non-drug entities. Token  Count  Token  Count  Token  Count  1 resistance  176  Tetracycline  230  Tetracycline  230  2 treatment  9  resistance  177  resistance  178  3 mM  4  Trimethoprim  118  Trimethoprim  118  4 oral  3  treatment  11  treatment  14  5 after  3  20∼  7  20∼  8  6 analogue  3  Figure  5  placebo  7  7 responses  3  concentration  5  effects  6  8 antibiotics  2  compared  4  Figure  6  9 exposure  2  100  4  KLK5  6  10 pharmacokinetics  2  mM  4  matriptase  6 We repeat this comparison of context words around human and model errors while considering stopwords and punctuation marks. Tables 5 and 6 show the 20 most frequent tokens in each case. We see that 20-25% of the tokens in Table 5 , but only 5-10% of those in Table 6 , are not stop words or punctuation marks. As the model only learns its word embeddings from the input text, if a token often co-occurs with drug entities in the training corpus the model will treat it as an indication of drug entities near its presence, regardless of whether or not it is a stopword. This apparently leads the model to make incorrect inferences. Humans, on the other hand, are unlikely to think that stopword such as ""the"" is indicative of drug entities, no matter how frequently they appear together.  After training the models with the labeled examples, we applied the trained models to the entire CORD-19 corpus (2020-10-04 version with 198 875 articles) to identify potential drug-like molecules. Processing a single article takes only a few seconds; we adapted our models to use data parallelism to enable rapid processing of these many articles. We ran the SpaCy model on two Intel Skylake 6148 processors with a total of 40 CPU cores; this run took around 80 core-hours and extracted 38 472 entities. We ran the Keras model on four NVidia Tesla V100 GPUs; this run took around 40 GPU-hours and extracted 121 680 entities. We recorded for each entity the number of the times that it has been recognized by each model, and used those numbers as a voting mechanism to further determine which entities are the most likely to be actual drugs. In our experiments, ""balanced"" entities (i.e., those whose numbers of detection by the two models are within a factor of 10 of each other) are most likely to appear in the DrugBank list. As shown in Figure 6 , we sorted all extracted entities in descending order by their total number of detection by both models, and when comparing the the top 100 entities to DrugBank, only 77% were exact matches to drug names or aliases, or 86% if we included partial matches (i.e., the extracted entity is a word within a multi-word drug name or alias in DrugBank). In comparison, among the top 100 ""balanced"" entities, 88% were exact matches to DrugBank, or 91% with partial matches. Although DrugBank provides a reference metric to evaluate the results, it is not an exhaustive ontology. For instance, remdesivir, a drug that has been proposed as a potential cure for COVID-19, is not in DrugBank. We manually checked the top 50 ""balanced"" and top 50 ""imbalanced"" entities not matched to DrugBank, and found that 70% in the ""balanced"" list are actual drugs, but only 26% in the ""imbalanced"" list. Looking at the false positives in these top 50 lists, the ""balanced"" false positives are often understandable. For example, in the sentence ""ELISA plate was coated with . . . and then treated for 1h at 37.8C with dithiothreitol . . . "", the model mistook the redox reagent dithiothreitol for a drug entity, probably due to its context ""treated with."" On the other hand, we found no such plausible explanations for the false positives in the ""imbalanced"" list, where most false positives are chemical elements (e.g., silver, sodium), amino acids (e.g., cysteine, glutamine), or proteins (e.g., lactoferrin, cystatin). Finally, we compared our extraction results to the drugs being used in clinical trials, as listed on the U.S. National Library of Medicine website ( [15] ). We queried the website with ""covid"" as the keyword and manually screened the returned drugs in the ""Interventions"" column to remove stopwords (e.g., tablet, injection, capsule) and dosage information (e.g., 2.5mg, 2.5%) and only kept the drug names. Then we compared the top 50 most frequently appeared drugs to the automatically extracted drugs from literature. The ""balanced"" entities extracted by both models matched to 64% of the top 50 drugs in clinical trial, whereas the ""imbalanced"" entities only matched to 6% in the same list. The results discussed here are available in the repository described in Section 7. We have made our annotated training data, trained models, and the results of applying the models to the CORD-19 corpus publicly available online. [16] . In order to facilitate training of various models, we published the training data in two formats-an unsegmented version in line-delimited JSON (JSONL) format, and a segmented version in Comma Separated Value (CSV) format. The JSONL format contains the most comprehensive information that we have collected on the paragraphs in the dataset. We choose JSONL format rather than a JSON list because it allows for the retrieval of objects without having to parse the entire file. A JSON object in the JSONL file has the following structure: • text: The original paragraph stored as a string without any modification. • tokens: The list of tokens from text after tokenization. text: The text of the token as a string. Another commonly adopted labeling scheme for NER datasets is the ""IOB"" labeling scheme, in which the original text is first tokenized and each token is assigned a label ""I,"" ""O,"" or ""B."" The label ""B(eginning)"" means the corresponding token is the first in a named entity. A label ""I(nside)"" is given to every token in a named entity except for the first token. All other tokens gets the label ""O(utside)"" which means they are not part of any named entity. The aforementioned JSONL data are converted according to the IOB scheme and stored in Comma Separated Value (CSV) files with one training example per line. Each line consists of two columns: a first of tokens that made up of the original texts, and a second of the corresponding IOB labels for those tokens. In addition to a different labeling scheme, the samples in the CSV files are segmented, meaning that each sentence is treated as a training sample instead of an entire paragraph. This structure aligns with that used in standard NER training sets such as CoNLL03 [17] . The trained SpaCy and Keras models and the results of applying the models to the 198 875 articles in the CORD-19 corpus are also available in this GitHub repo. Additionally, the pretrained SpaCy model is provided as a cloud service via DLHub [13, 18] . (The Keras model could not be hosted there due to compatibility issues with DLHub.) This cloud service allows researchers to apply the model to any texts they provide with as few as four lines of code. The datasets analyzed in this study can be found in the Kaggle dataset: https://www.kaggle. com/allen-institute-for-ai/CORD-19-research-challenge. The models used in this work and the datasets generated for this study can be found on GitHub at https://github.com/globus-labs/covid-nlp/tree/master/drug-ner. The models are also available on DLHub [18] . While every effort has been made to produce valid data, by using this data, User acknowledges that neither the Government nor UChicago Argonne LLC makes any warranty, express or implied, of either the accuracy or completeness of this information or assumes any liability or responsibility for the use of this information. Additionally, this information is provided solely for research purposes and is not provided for purposes of offering medical advice. Accordingly, the U.S. Government and UChicago Argonne LLC are not to be liable to any user for any loss or damage, whether in contract, tort (including negligence), breach of statutory duty, or otherwise, even if foreseeable, arising under or in connection with use of or reliance on the content displayed on this site.@story_separate@We have presented a human-machine hybrid pipeline for collecting training data for named entity recognition models. We applied this pipeline to create an automated model for identifying drug-like molecules in COVID-19-related research papers. Our pipeline facilitated efficient use of valuable human resources by presenting human labellers only with samples that were most likely to confuse our model. We explored various trade-offs, including model size, number of training samples, and training epochs, to find the right balance between model performance and time-to-result. In total, human reviewers working with our pipeline validated labels for 278 bootstrap samples, 1000 training samples, and 500 test samples. As this work was performed in conjunction with other tasks, we cannot accurately quantify the total effort taken to collect and annotate the above training and test samples, but it was likely around 100 person-hours. NER models trained with these data achieved a best F-1 score of 80.5% when evaluated on our collected test set. Our models have correctly identified 64% of the top 50 drugs that are in clinical trials for COVID-19. The models were applied to 198 875 articles in the CORD-19 collection, from which we identified 10 912 molecules with potential therapeutic effects against the SARS-CoV-2 coronavirus. The extracted molecule list were subsequently given to scientists at Argonne National Laboratory to be used in computational screening pipelines. The code, model, and extraction results are publicly available. In the future, we hope to further improve NER model performance by integrating our models with more advanced language models.","Researchers worldwide are seeking to repurpose existing drugs or discover new drugs to counter the disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). A promising source of candidates for such studies is molecules that have been reported in the scientific literature to be drug-like in the context of coronavirus research. We report here on a project that leverages both human and artificial intelligence to detect references to drug-like molecules in free text. We engage non-expert humans to create a corpus of labeled text, use this labeled corpus to train a named entity recognition model, and employ the trained model to extract 10912 drug-like molecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of 198875 papers. Performance analyses show that our automated extraction model can achieve performance on par with that of non-expert humans."
"The COVID-19 outbreak started in Wuhan, Hubei Province, China in December 2019 and has now extended across the globe with >400 000 cases and 17 000 deaths as of 22 March 2020. The WHO has declared COVID-19 a pandemic. 1 The Wuhan experience and most recently the Italian experience prove that the health system can be quickly overwhelmed, especially intensive care units (ICUs). 2 3 Healthcare had to redesign its logistical and departmental structure to respond to influx of patients with COVID-19 with acute hypoxaemic distress. In the current COVID-19 pandemic, like any natural disasters or other kinds of mass casualties, local healthcare capacity can become overwhelmed, necessitating a request for external assistance at the national level. 4 On 22 March 2020, there were more than 16 000 cases in France, of which more than 2000 patients require intensive care support. 5 Intensive care capacities were about 5000 beds, 6 and a significant health system reorganisation was needed to increase these capacities. Unfortunately, an uneven regional distribution exists between these capacities and the number of cases. The local health agency (ARS), as a regional medical coordinator, ensures the availability of intensive care beds to guarantee citizens' health and coordinates interhospital transfers. Corsica is one example with a weak intensive care bed to residents ratio of 5:100 000, 6 and its capacity is already overwhelmed. Corsica is an island 165 km from the French continental coast, complicating interhospital transfers of several critical patients. The French government decided to deploy medical military abilities to manage this situation. An amphibious assault ship was deployed on 22 March in Corsica to carry out medical evacuation of 12 critical patients infected with COVID-19 and transfer them to Marseille Hospital's critical care units. It is one of the three French 'Marine Nationale' amphibious assault ships, and is a command ship with projection capacities (helicopters, troops and vehicles) and an on-board hospital capacity used to care for the war-wounded. It is the first time that an amphibious assault ship is engaged in this particular condition. The aim is to evaluate the feasibility and safety of prolonged medical evacuation of critical patients with COVID-19.@story_separate@► Critical COVID-19 evacuation on an amphibious assault ship is feasible and safe. ► The ship needs to prepare a plan and a specialised intensive team and conduct patient screening for prolonged interhospital transfers. This is a retrospective case series of 12 critical patients with COVID-19 who had medical evacuation on a military amphibious assault ship. The requirement for informed consent was waived because the study was observational and the family members were in quarantine. This medical ability is organised for war-wounded care and minor medical or surgical emergency. Usually, there are no permanent ICU beds. The on-board hospital has to be improved and redesigned as an ICU. Hospitalisation capacity has to be reduced to 14 critical care beds. An isolated area, divided into three spaces, was designated for contagious patients with COVID-19, with one airlock entrance for dressing personal protective equipment (PPE) and one airlock exit for undressing. The first space could admit four to five ventilated patients, another space for two to three ventilated patients, and the last for six nonventilated patients with hypoxaemia. Patients with hypoxaemia, who needed ventilation support, could be transferred to the first or second space. Specialised material equipment was upgraded with 2-14 transport ventilators (eight Monnal T60, two Elisée 250 and four Elisée 350), 5-14 patient monitors (Propaq) and two blood gas transport analysers (i-STAT). Inhaled nitric oxide (iNO) was available, but we did not need to use it. Extracorporeal life support was the only ultra-specialised care that we could not perform. The usual medical team (one general physician and two nurses) was reinforced by a civil-military intensivist team (five anaesthetist-intensivist physicians, one intensivist, two residents, one emergency physician, one bacteriologist physician, four anaesthetist nurses, six intensivist nurses, one radiological manipulator and one laboratory assistant). All civilian and military medical teams were intensivist teams that were trained at the hospital in managing patients with COVID-19. The clinician to patient ratio was 1:4. There was a shift rotation every four hours. PPE consisted of goggle protection, long-sleeved water-resistant gowns and gloves, filtering facepiece FFP2, apron, and head and shoe cover. The available oxygen supply was limited to 250 000 L divided into 50 L in 25 oxygen bottles at 200 bar pressure (total oxygen supply=25 bottles×50 L×200 bars). Three portable oxygen concentrators (SeQual Integra 10-OM) were available. We included 12 patients with COVID-19 infection confirmed by a positive test on severe acute respiratory syndrome coronavirus 2 real-time PCR of throat swab specimen. All patients were civilians. Patients were at the Ajaccio Hospital Center: six ventilated patients with acute respiratory distress syndrome (ARDS) 7 8 and six patients with hypoxaemia, defined by oxygen saturation <90% without oxygen supplementation. 9 Exclusion criteria were haemodynamic instability with more than 2 mg/ hour of norepinephrine, and arterial oxygen pressure to fractional inspired oxygen ratio of <100 or continuous haemofiltration indication. ICU has 12 places already blocked in this COVID-19 pandemic situation, so the French government, in collaboration with the Marseille Hospital public assistance and 'service de santé des armées', organised a medical evacuation on an amphibious assault ship. The total transfer (set-up, transport and evacuation) delay was approximately 20 hours. We collected patients' medical records: age, comorbidities, COVID-19 history and diagnosis, ventilation supply and ventilator settings, and blood gas results. Reported data were arterial carbon dioxide (PaCO 2 ), arterial oxygen pressure (PaO 2 ), fractional inspired oxygen concentration (FiO 2 ), PaO 2 to FiO 2 ratio, arterial potential hydrogen (pH), tidal volume, RR, measured minute ventilation (VE), plateau pressure, positive end-expiratory pressure, driving pressure and static respiratory system compliance. We calculated oxygen consumption (OC) considering the measured VE or oxygen flow (non-ventilated patient) and FiO 2 used (OC by hour=oxygen flow or VE L/min×60 min×FiO 2 ). The total OC was calculated by adding up the OC of each patient. We collected the actual OC on the ship (total oxygen supply less total OC measured from the oxygen bottles). We calculated the Sequential Organ Failure Assessment (SOFA) score on admission. Data that were not normally distributed are expressed as median and IQR (25th-75th percentile). Nominal variables are reported as number and proportion (%). Patients' characteristics are presented in Table 1 . Twelve patients (nine male (75%); median age 65 (62-67)) were included: six ventilated patients with ARDS and six patients with hypoxaemia. The median delay from onset of symptoms to hospitalisation in ICU was 8 (7-10) days. All patients had a medical history: obesity (body mass index (BMI) >30 kg/m 2 ), n=2 (16%); overweight (BMI 25-30 kg/m 2 ), n=6 (50%); hypertension, n=5 (42%); diabetes, n=4 (33%); coronary heart disease, n=1 (8%); chronic obstructive pulmonary disease, n=2 (16%); obstructive sleep apnoea syndrome, n=4 (33%); and immunocompromised, n=1 (8%). The median SOFA score on admission was 3 (2-5). Among non-ventilated patients (n=6), two had a non-rebreather mask with oxygen flow between 10 and 15 L/min, and four had nasal oxygen with oxygen flow between 1 and 3 L/min. There was no significant increase in oxygen during ship transport ( Figure 1 ). One ventilated patient required prone positioning to improve oxygenation during ship transport. The calculated OCs are presented in Table 2 . Among ventilated patients, the median calculated OC was 255 L (222-281) by hours and 5270 L (4908-5616) during all ship transport. Among non-ventilated patients, the median calculated OC was 120 L (120-480) by hours and 2400 L (2400-9600) during all ship transport. One non-ventilated patient had 10 L oxygen mask supplied by an oxygen concentrator, which resulted in a calculated oxygen economy of 12 000 L. The total calculated OC during transport was 70 260 L. The total measured OC was 50 000 L. Among non-ventilated patients (n=6) ( Table 3) , only blood gases collected from Ajaccio Hospital were available. The median PaO 2 was 73 mm Hg (66-79) and the median PaCO 2 was 35 mm Hg (35-37). The median pH was 7.44 (7.42-7.45). Blood gas results and ventilator settings for ventilated patients are presented in Table 4 . There was no major respiratory complication, except for one endotracheal tube obstruction requiring gentle suction. The PaO 2 to FiO 2 ratio evolution between admission and arrival is presented in Figure 2 . One patient presented transient atrial fibrillation requiring amiodarone. Two patients needed an increase in norepinephrine requirements. Antibiotic therapy was started in one patient for septic shock with major metabolic acidosis. This retrospective analysis of 12 critical patients with COVID-19 describes the feasibility and safety of a prolonged medical evacuation. It is, to our knowledge, the first published medical experience in this exceptional condition. There are two significant differences in the management of these patients compared with military patients. One, military patients are young and healthy and never present severe lung infections. Respiratory distress is related to thoracic trauma following war injuries, and as a result requires more trauma management than medical treatment. The second difference is operational safety. Evacuation of military patients is carried out in war-affected countries, unlike this mission which has occurred on national territory. As mentioned in several studies, 4 10 11 we report the same characteristics and comorbidities of patients with COVID-19: age more than 60 years old, weight problems, hypertension, diabetes, chronic obstructive pulmonary disease and obstructive sleep apnoea syndrome. 10 Also, we noted the same median delay from onset of symptoms of about one week before the hypoxaemic clinical presentation. 10 We decided to transfer six non-ventilated patients with hypoxaemia because they had clinical and radiological predictive factors for severe respiratory failure. [11] [12] [13] Among ventilated patients, two patients presented mild ARDS and four patients presented moderate ARDS. 14 The main challenge was to quickly improve the on-board hospital used to take care of trauma patients and those with  minor medical or surgical emergency before aeromedical evacuation. We had to redesign areas and management from the beginning to care about many critical respiratory patients with biohazard constraints. This is why the capacity of the hospital had to be reduced from 69 to 14 beds. We also had to create a specialised intensivist civil-military team that could carry out prolonged interhospital critical patient transfer. 15 Compared with usual deployment, we had to improve our ICU bed capacity, particularly in terms of specialised equipment: 2-14 transport ventilators, 5-14 patient monitors, one to two blood gas transport analysers and two iNO bottles. Patients with ARDS require specific ventilatory management. Following a protective ventilation concept, bundle of care is recommended that includes placing the patient in prone position, providing iNO and monitoring the patient's blood gas. 16 Moreover, transportation of critically ill patients, especially patients with ARDS, can be a challenging task. 17 18 A prolonged transfer could be a risk with severely impaired gas exchange. 18 In our study, risks were anticipated and the medical evacuation was prepared. At first, a specialised intensivist civil-military team was deployed which used to manage patients with COVID-19 ARDS. Military intensive patricians are used to taking care of patients with ARDS in isolated conditions without all hospital capacities. 19 Our data confirmed the medical recommendation application in these unusual conditions. We could respect protective ventilation to ventilated patients and perform a prone position to a patient presenting refractory hypoxaemia. We have anticipated the risk and we were in constant communication with Corsican patricians to evaluate the risk of patient transport and confirm the feasibility of patient evacuation. Blood gas results confirmed the safety of this evacuation. The PaO 2 to FiO 2 ratio was constant and even improved during ship transport. Only the patient who needed to be in prone position and who we had to return and prepare for Marseille Hospital transportation had decreased PaO 2 to FiO 2 ratio on arrival. Regarding oxygen supply, it was the primary delay constraint. Oxygen storage was limited to 250 000 L divided into 50 L in 25 oxygen bottles. This capacity was never tested to take care of as many patients with hypoxaemia. When preparing for the mission, we had to calculate the expected OC to secure the interhospital transfer. Thanks to our collected respiratory data, we calculated the total OC that confirmed our forecast and will improve other prolonged medical transfers. We have observed that non-ventilated patients with high oxygen flow consumed the most oxygen. We measured the total effective OC and it was under the total calculated OC. We explain that by concentrator oxygen using and saving oxygen storage. Oxygen concentrators provided to non-ventilated patients were equipped with high oxygen flow. From our military experience, the Elisée 350 turbine transport ventilator with a portable oxygen concentrator can be used as an alternative in an austere environment. 20 In this study, according to our oxygen storage, a four-day transfer delay could be feasible in a safe condition. This study has several limitations. First, it is a retrospective observational report of 12 patients, with only 6 ventilated patients. Second, outcome data could be interesting to evaluate the impact of prolonged interhospital transfers. Third, further studies are still needed to confirm our results. However, this was an exceptional military deployment and publishing a more robust investigation will be complicated. Ventilated patients' PaO 2 to FiO 2 ratio between admission and arrival. FiO 2 , fractional inspired oxygen; PaO 2 , arterial oxygen pressure.@story_separate@In conclusion, the present work contributes to assessing the feasibility and safety of critical COVID-19 evacuation on an amphibious assault ship during an extended transport. The ship needs to prepare a plan and a specialised intensive team and conduct patient screening for prolonged interhospital transfers of patients with COVID-19 with acute respiratory failure. The healthcare system with government management must be able to national adaptation and reorganisation using all available means, both civilian and military. Contributors CN wrote the paper. AM, SB, LS, FJ and P-YC managed the data collection. CV, P-JC, PE, QM, LP and JB participated in critical revision of the manuscript. All authors have contributed to the writing of the manuscript and have approved the final manuscript. CN conceived the study and is its guarantor. Funding The authors have not declared a specific grant for this research from any funding agency in the public, commercial or not-for-profit sectors.","INTRODUCTION: An amphibious assault ship was deployed on 22 March in Corsica to carry out medical evacuation of 12 critical patients infected with COVID-19. The ship has on-board hospital capacity and is the first time that an amphibious assault ship is engaged in this particular condition. The aim is to evaluate the feasibility and safety of prolonged medical evacuation of critical patients with COVID-19. METHODS: We included 12 patients with confirmed COVID-19 infection: six ventilated patients with acute respiratory distress syndrome and six non-ventilated patients with hypoxaemia. Transfer on an amphibious assault ship lasted 20 hours. We collected patients’ medical records: age, comorbidities, COVID-19 history and diagnosis, ventilation supply and ventilator settings, and blood gas results. We calculated oxygen consumption (OC). RESULTS: All patients had a medical history. The median delay from onset of symptoms to hospitalisation was 8 (7–10) days. The median Sequential Organ Failure Assessment score on admission was 3 (2–5). There was no significant increase in oxygen during ship transport and no major respiratory complication. There was no significant increase in arterial oxygen pressure to fractional inspired oxygen ratio among ventilated patients during ship transport. Among ventilated patients, the median calculated OC was 255 L (222–281) by hours and 5270 L (4908–5616) during all ship transport. Among non-ventilated patients, the median calculated OC was 120 L (120–480) by hours and 2400 L (2400–9600) during all ship transport. CONCLUSION: The present work contributes to assessing the feasibility and safety condition of critical COVID-19 evacuation on an amphibious assault ship during an extended transport. The ship needs to prepare a plan and a specialised intensive team and conduct patient screening for prolonged interhospital transfers."
"On March 11, 2020, the World Health Organisation (WHO) called on countries to take urgent and decisive action against the coronavirus disease (COVID-19) [1] . Governments around the world introduced strict public health measures to mitigate the spread of the disease, and while these measures have indeed been effective [2, 3] , there are indications of deleterious mental health effects on children and adults [4] [5] [6] [7] . It is particularly important to examine the effects on children, not only as research is scarce [8] , but also as children are vulnerable to environmental changes and effects may have long-term consequences into adulthood [9] . We propose that effects on children should be studies more holistically by exploring a broader range of reactions rather than focusing on symptomatology of mental health difficulties. To this end, the present study focuses on a broader spectrum of children's emotional reactions, along with children's somatic and cognitive reactions, and worry reactions relating to parents and family. By exploring the normal range of reactions, we are better placed to understanding the breadth of implications of the pandemic on children.@story_separate@The biggest change to children's daily lives under COVID- 19 , might have been the closure of schools and introduction of digital home schooling. School is a place of academic learning, but also an arena for development, socialization and connecting with friends and peers, and for emotional and academic support from teachers, which are all important factors for children's psychological wellbeing and adjustment [10] [11] [12] [13] . School routines further allow children to have regular bed/wake times and physical activity, and restricts sedentary behaviours and/or non-educational screen time [14] . Conversely, school closures under COVID-19 has been associated with academic learning losses [15] and an array of health risk behaviours (e.g., socio-emotional complications, reduced physical activity) [16] . A marked difference between school closure under COVID-19 and more regular school closure (e.g., during holidays, teacher strikes), is that students continued their schoolwork digitally in the absence of physical contact. Children have varied in their experience with the new school day, in terms of among other things, their ability to concentrate on school work, meeting assignment deadlines, and their perceived level of support (or lack thereof) from teachers and parents. For some it may have been a blessing with increased independence, while for others, it would have been a struggle with motivation and self-discipline. And in particular, younger children seem to have done more poorly [17, 18] . Home schooling under COVID-19 was accompanied by strict social isolation measures and thus, children had involuntary restrictions placed on their opportunities to meet friends and peers physically although they may not have adhered (strictly) to these recommendations [19] . Evidence suggests that social isolation during the pandemic was associated with loneliness, negative consequences on mental health and other health-related behaviours for children [20, 21] . For example, two Chinese studies report elevated levels of symptoms of depression and anxiety in children and adolescents during the early phase of the pandemic. Children who worried about virus infection were significantly more likely to experience symptoms of depression, but not anxiety, compared to those that were not or only slightly worried about being infected [5, 22] . Furthermore, research from North American has found that COVID-19-related worry and stress along with digital time spent with friends was associated with more loneliness and depression in adolescents, while time spent doing homework was negatively associated with depression and, therefore, acted as a buffer [23] . From a Scandinavian and European context, a Norwegian study has shown that loneliness and mental health problems in adolescents were associated with social media use and a lack of physical contact with friends [24] , while a Spanish study has shown that home confinement was associated with reduced physical activity and increased screen time and sleep time [21] . These studies point towards some of the risk and (to a lesser extent) protective factors for children and adolescents during social isolation. However, it is possible that the results are not so much about the COVID-19 situation, as it is about having difficulties before and continuing through the pandemic, and that the same factors are associated with these difficulties. To provide stronger empirical evidence, we need longitudinal rather than cross-sectional studies, where it is possible to control for any pre-existing psychological vulnerabilities. The division of labour and daily routines in families changed dramatically during the COVID-19 lockdown [25] , something that may dampen or amplify the effects of school closure on children. Such family disruptions may broadly be described as affecting the family's routines, rituals and rules [26] , which collectively, these fall under the umbrella term of organizational processes according to Walsh's family resilience framework [27] . The sudden changes to family routines included, for example, the reallocation of household tasks, children and parents spending more time at home due to home school and home office/parent being furloughed, and moving between homes for children of divorced parents. Changes to rituals include religious or cultural celebrations, and lastly, rule changes may include parents renegotiating rules for when/if children are able to leave the home or new rules for school in the context of home-schooling [26] . Unsurprisingly, these disruptions have led to increased household tensions [25] and there are reports of increased interparental conflicts [28] , while others report that taking care of children was rated as a positive experience by parents [29] . As the pandemic-related consequences felt by parents may cascade down to children, we might expect to see this reflected in children's reactions and wellbeing [26] . Studies are yet to explore how children's positive and negative reactions to the COVID-19 pandemic relate to concurrent and former family functioning. There has been a disproportionate emphasis on the negative consequences of the measures introduced to mitigate the spread of the pandemic. However, some argue that the consequences might not be all negative and in fact, some children and families have fared better [30] . For example, the lockdown measures may have reduced daily stressors for some children and families, and the sudden increase in family time may have been another positive for some. We agree with Bruning and colleagues [30] in the importance of taking a more holistic approach focusing on the heterogeneity of experiences under COVID-19 and thereby, in our attempt at understanding the impact on children shifting the focus from symptoms of psychopathology and mental health difficulties to the normal range of reactions. This may be achieved by asking more moderate questions like ""I felt sad"" and ""I have had trouble sleeping at night"", rather than ""I felt miserable or unhappy"" and ""I didn't enjoy anything at all"", which have a much stronger affective phrasing. Coupled with a longitudinal study design, we are better placed to providing a more reliable and nuanced picture of the effects of the COVID-19 public health measures on children including any direct effects by exploring children's reactions or wellbeing prior to and during the lockdown period [31] . It is noteworthy, that generally and under COVID-19, the impact of social isolation (and loneliness) on the mental health of children has been disproportionately explored in adolescent and older children [e.g., 5, 20, 23, 24] . Taking a child developmental perspective, the association between isolation and mental health should be stronger in adolescent and older children [32] , given their heightened experience of emotional reactions, underdeveloped self-regulatory mechanisms and heightened motivation for peer affiliation and support. Developmentally, it is a time characterised by increasing independence from parents, increasing autonomy and peer friendships that become closer and more supportive [33] . Thus, there is a gradual shift in focus from the family to peers and friends [34] . The social isolation measures under COVID-19, may have been particularly challenging for older children as these have impeded close physical contact with friends and support from friends. The renegotiation of family rules by parents as mentioned earlier, may also have challenged older children's developmental trajectory towards independence and autonomy. Therefore, to better understand the implications of home schooling and social isolation on children′s reactions, it is paramount to include a broader age-range of children and to explore the moderating effect of children's age (as a proxy for their developmental stage) on any observed relationships. Little is about how children have reacted to the new everyday life under COVID-19 with home schooling and social isolation. The available evidence from cross-sectional studies suggests that elevated levels of depression and anxiety during lockdown are related to variables such as worry about virus infection and social media use. Claims that other variables such as home school experiences and family functioning are related to how children react need a better empirical foundation. Longitudinal studies focusing on younger and older children's reactions more broadly and accounting for any pre-existing psychological vulnerabilities better capture the dynamics of how children have reacted under the COVID-19 pandemic. To this end, we use data from a longitudinal study to explore the following questions: 1. How do children compare their reactions under COVID-19 with home schooling and social isolation to before the lockdown? 2. How are children's reactions under COVID-19 associated with home school experience, perceived stress and instability in the family, screen time use, missing friends, and worry about virus infection? 3. Does children's age moderate any of these associations? The data for this study were drawn from the Norwegian Family Dynamics Study (FamilieForSK), a longitudinal study aimed at increasing knowledge about family dynamics and conflicts in Norwegian families. The FamilieForSK-study has more than 2300 participating families, recruited through family counselling centres from December 2017 to July 2019 when families attended mandatory mediation (in relation to divorce/relationship dissolution), counselling or family therapy. Participating parents and children completed online questionnaires covering a wide range of topics, while trained interviewers interviewed younger children (7-11 years of age). In some families only one or both parents participated, while in other families the parent(s) and their child(ren) participated and finally, in a small number of families only the child(ren) participated. Shortly after the Norwegian government introduced public lockdown measures to mitigate the spread of COVID-19, FamilieForSK initiated an extraordinary data collection (Wave 3) to explore the experience of these measures on families. Parents and children that had already participated in Waves 1 and 2 were invited to participate in Wave 3, while parents and children due to participate in Wave 2 were invited to participate in Waves 2 and 3 at the same time (i.e., Wave 3 survey was joined with Wave 2 survey). The present study uses data from the children who participated at Wave 3 (April 1 to May 25, 2020), of whom nearly 85% also participated at Wave 1. There were no significant differences between children who only participated in Wave 1(n = 573) and children who participated in both Waves 1 and 3 (n = 374) in terms of symptoms of anxiety and depression and whether their parents lived together or lived apart. However, children who participated in Waves 1 and 3 were significantly younger than children who only participated in Wave 1 (M = 10.15 (SD = 2.53) vs. M = 10.91 (SD = 2.50), t(934) = 4.54, p < 0.001). See Table 1 for an overview of the sample characteristics. In Norway, the Government closed all schools on March 12 and digital home schooling was introduced. Schools reopened gradually from April 27 and younger children (up to grade 4) were the first to return to school. The school day was somewhat different to before the pandemic, as class sizes were reduced and children were grouped into smaller cohorts to reduce the possibility of spread of the disease [35] . The present study includes a small number of children who participated after the schools had opened, but note that only four of these children were younger and had potentially returned to school. Furthermore, the majority of children that participated after April 27 did so within just a few days. We decided nonetheless to include all children that had responded up until the point of May 25. The Regional Committee for Medical and Health Research Ethics in Norway approved the study and all study procedures fulfilled the recommendations of the Helsinki Declaration. Parents consented for children to participate in the FamilieForSK-study and children assented before completing the online survey or before being interviewed by trained interviewers. We assessed children's reactions to the new everyday life with home schooling and social isolation with ten statements with the item stem ""After the schools closed in March, I have …"". Items were developed specifically for the study. An initial Principal Component Analysis (PCA) with a promax rotation showed that items formed three components; Emotional Reactions with five items (e.g., ""felt sad"", ""felt angry"", ""felt lonely""), Somatic/cognitive Reactions with three items (e.g., ""had trouble concentrating"", ""had headaches, stomach ache and so on""), and Worry Reactions with two items (e.g., ""worried about my parents""). Children answered items on a scale from 0 (""A lot less than before"") to 4 (""A lot more than before""), with the middle value (2) representing ""As before"". The Emotional and Somatic/cognitive reactions scales had acceptable internal reliability (α = 0.79 and α = 0.66, respectively) and the two worry items were moderately correlated (r polychoric = 0.59, p < 0.05). See Tables 3 for descriptive statistics including item factor loadings. Home school experience was assessed with four statements about how children managed home schooling, their concentration level, and home school support or lack thereof (reverse scored). Items were answered on a scale from 0 (""Not true"") to 2 (""Certainly true"") and internal reliability was acceptable (α = 0.72). Family stress and instability was assessed with three statements tapping children's perception of parent stress levels, and instability and arguments in the family under COVID-19 restrictions. Questions were answered on a scale from 0 (""A lot less than before"") to 4 (""A lot more than before"") and internal reliability was acceptable (α = 0.78). Daily screen time use (including gaming and social media use, but not school work) was assessed with a single question, ""After the schools closed in March, how many hours of screen time have you had each day?"" with the response options ""0-1 h"", ""2-3 h"", ""4-5 h"" and ""more than 5 h"". Missing friends and worry about virus infection were assess with two statements, namely, ""After the school closed in March, I have missed seeing my friends"" and ""After the schools closed in March, I have been worried about being infected with the coronavirus or infecting others with the coronavirus"". Items were answered on a scale from 0 (""Not true"") to 2 (""Certainly true""). As an index of children's psychological vulnerability, we used their scores on the Short Mood and Feelings Questionnaire (SMFQ) [36] and five items from the Screen for Child Anxiety Related Disorders (SCARED) [37] when they first participated in the study (around 18 months earlier). The SMFQ is a 13-item self-report measure of depressive symptoms over the past 2 weeks, while SCARED is a self-report measure of anxiety symptoms over the past 3 months. Both scales have demonstrated good psychometric properties [36] [37] [38] [39] and in the present study, internal reliability was 0.85 and.51 for SMFQ and Table 3 Descriptive statistics for individual reaction items included in children's reaction dimensions Children answered the reaction items on a scale from 0 (""A lot less than before"") to 4 (""A lot more than before"") Test statistics testing if responses are significantly different to before COVID-19 (i.e., score = 2 (""As before"")) Tables 2 and 3 for an overview of the primary variables in the study. Data analyses were performed in R [40] using the mice [41] , sjPlot [42] , polycor [43] , miceadds [44] and psych [45] packages. We performed initial item and scale inspections by calculated descriptive statistics and bivariate correlations. We then used a series of t-tests to explore if children' rated their reactions (at the item level and scale level) as significantly different to before. This was achieved by specifying the mu argument to be equal to two (i.e., the value of the response option corresponding to ""As before""). Prior to the main analyses, we imputed missing data on predictors, covariates and outcomes using multiple imputation by chained equations [41] . The percentage of missing data was generally low (< 3%), with the exception of MFQ and SCARED, where missingness was 17%. Seventy-three to 74% of the 442 children would have been available for the main analyses under the traditional listwise deletion method. Five imputed datasets were generated and regression analyses run on each dataset was pooled according to Rubin's rules [46] . Regression results did not differ when we used incomplete data with listwise deletion or complete cases only, and thus, to utilise all available data we present the results from imputed data. In the main analyses, we performed a series of hierarchical linear regressions with Emotional Reactions, Somatic/ cognitive Reactions and Worry Reactions as outcome, respectively, and background variables entered in Step 1, and COVID-19 predictor variables entered in Step 2. Finally, we explored age interactions in a series of regression models, where background variables and COVID-19 predictors were entered in Step 1 and each age interaction entered in Step 2. Table 2 provides means, standard deviations, frequencies and correlations for the primary variables in the study. Unsurprising, the majority of children (78%) reported that they missed their friends and 51.25% worried about being infected or infecting others with the coronavirus. Over half the children reported that their daily screen time usage was four hours or more. Using t-tests we explored if children's reactions were significantly different to before (i.e., a test value of 2 = ""As before"") and found that this was indeed the case for most items, with the exception of ""had headache, stomach ache and so on"", ""worried about my parents"" and ""worried about my family's future"" (see Table 3 ). This suggests that children felt less sad, scared/uneasy, angry and unsafe (as mean scores were < 2), but more lonely and had more difficulty concentrating and sleeping at night (as mean scores were > 2) compared to before the government initiated the schools closures. Furthermore, at the scale level, we observed significant results for Emotional Reactions and Somatic/cognitive Reactions, t(440) = -3.57, p < 0.001 and t(440) = 3.01, p < 0.01, respectively. As the average for Emotional Reactions was 1.89, this means that children on average reported fewer emotional reactions compared to before. For Somatic/cognitive Reactions the average was 2.10 and thus, children on average reported more somatic/cognitive reactions compared to before (see Table 2 ). To explore how children's Emotional, Somatic/cognitive and Worry reactions, respectively, are associated their experiences and living situation during the pandemic, three hierarchical regression models were estimated (one for each outcome). In the first two models, we found that home school experience and perceived stress and instability in the family during COVID-19 restrictions were associated with children's Emotional and Somatic/cognitive Reactions, respectively, after controlling for background variables and other predictors in the models. Children who had a more positive home school experiences reported lower Emotional and Somatic/cognitive Reactions, respectively, while children who experienced higher levels of stress and instability in the family reported more Emotional and Somatic/cognitive Reactions. Increased perceived stress and instability in the family was also associated with more Worry Reactions. Furthermore, we found that compared to children who did not miss their friends, those that did miss their friends reported significantly higher Emotional Reactions on average. Finally, compared to children who said they were not worried about virus infection, those that said they were certainly worried about virus infection reported significantly higher Emotional and Worry Reactions, respectively. The three models, respectively, accounted for 46, 33 and 23% of the explained variance in Emotional, Somatic/cognitive and Worry Reactions during lockdown. See Table 4 for an overview of the results. Results were similar when we used the initial dataset with listwise deletion or complete cases only, exception for missing friends, which was non-significant possibly due to a lack of statistical power. Finally, from our exploration of age as a moderator of the relationship between COVID-19 related predictors and children's reactions, we found several significant interaction effects after controlling for the main effects of the covariates and other predictors (see Table 5 ). First, age moderated the association between family stress and all three reaction dimensions. Thus, the older children were the more negatively impacted they were by family stress and instability in terms of their reactions to the new everyday life under COVID-19. Age also moderated the association between screen time use and Somatic/ cognitive Reactions with a stronger association for older compared with younger children. Furthermore, we found a significant age by missing friend's interaction for Somatic/cognitive Reactions, while for Worry Reactions the effects was marginally significant. Thus, the association between age and missing friends was generally stronger for older children when one compared those that missed their friends most to those that did not miss their friends. Finally, we found a significant age by worry about virus infection interaction for Somatic/cognitive Reactions and Worry Reactions. This suggests that for older children, the magnitude of the effect of worry about virus infection on Somatic/cognitive and Worry Reactions is stronger when one compared children who were For ease of presentation interaction effects are presented together for each outcome, although we note that each interaction was tested in a separate model adjusted for background variables and all other predictors (i.e., models akin to those reported in Table 4  In this study, we use data from a longitudinal study to shed light on children's reactions to the new everyday life under COVID-19 with home school and social isolation. We focused on children's reactions more broadly, as this allowed us to investigate the normal range of reactions and gives a more nuanced view on the implications of the pandemic for children. Specifically, we explored children's Emotional, Somatic/cognitive and Worry Reactions, and how each of these reaction dimensions relate to variables expected to be pertinent to change under the COVID-19 restrictions. We asked children how they compared their reactions under COVID-19 with home school and social isolation to before the schools were closed and found that children reported fewer emotional reactions, but more somatic/cognitive reactions. That is, children on average coped better emotionally as they felt less sad, scared, angry and unsafe, but did more poorly in terms of sleep and concentration. That children should experience fewer emotional reactions is in line with certain findings from adults showing only mild levels and no increases in anxiety and depression symptomology [47, 48] . While our results contrast with studies showing increased levels of anxiety and depression in children and adolescents [5, 22] , it does, however, provide empirical support for the notion that child wellbeing might be improved under COVID-19 [30] . One possible explanation for this is that children received more attention and support than usual from their parents as families spent more time together. Alternatively, school closure, albeit with the introduction of digital home schooling, might have provided children with a break or respite from schoolrelated worries and pressures (e.g., keeping up with others, complex social relations). As to why children reported significantly more somatic/cognitive reactions compared to before, this may relate to the changes in daily routines for children such as a shift in bed/wake times or less physical activity [14, 16] . Children's worry reactions pertaining to their parents and family were unchanged relative to before, which we tentatively see as positive. Although, we cannot rule out that children had a high level of concern for their family and parents prior and maintained this during the pandemic, as we did not ask children to rate their level of worry per se. Almost all of the COVID-19 related predictors were associated with children reactions during the pandemic. The strongest predictor of child reactions was children's perceived family stress and instability, which was significantly and positively associated with all three childreaction dimensions. Given the interrelatedness of family subsystems [49] and evidenced relationship between child adjustment and general family climate [50] , the effects of parent stress and family instability on children under COVID-19 is not surprising. Following Prime and colleagues [26] , the effects might have cascading through to children resulting in them reporting more negative reactions (i.e., higher reaction scores) for all three dimensions. We emphasize that in the present study, we controlled for children's pre-pandemic psychological wellbeing and thus, we have been able to ""eliminate"" the effect family stress and difficulties usually have on children's wellbeing. Interestingly, we note that children on average rated the level of family stress and instability to be similar to before the pandemic using our retrospective measure. Why might this be, if families experienced substantial disruptions particularly to family routines and rules? The gravity and extraordinary nature of the COVID-19 situation might somehow have enabled families to mobilize resources to protect the family and its subsystems in the face of pandemic-related stressors [51, 52] or while purely speculative, families might have felt some ""comfort"" in knowing that they were not alone in their experiences. Screen time was the only predictor that was not significantly associated with any of the reaction-dimensions. At least one study has found that social media use, but not online gaming, is predictive of loneliness and symptoms of anxiety and depression in youths during pandemic lockdown [20] . We do not know what type of activities children in our study were doing on screens. This, along with study differences in terms of screen time measures and samples, and the fact that we partialled out the effect of pre-pandemic psychological vulnerability might collectively explain the divergent results. During the pandemic, meeting friends digitally was for many children the only opportunity to meet, and thus, the association between screen time and reactions might have been weaker during the pandemic relative to the ""normal situation"", where children and adolescents can still meet physically. We hypothesized that possibly the biggest change for children was the closure of schools and introduction of digital home school. Our results indicate that positive home school experiences acted as a buffer on children's reactions to the new everyday life; children who did better with home schooling reported fewer emotional and somatic/cognitive reactions. Home schooling likely gave children more autonomy over their day, and it would have required a high level of self-discipline and motivation to establish good routines and succeed with home schooling. One might wonder if children who succeeded at this, were generally well-adjusted and this reflected in their reported reactions. However, our results counter this argument as we controlled for children's prior psychological wellbeing (or vulnerability), and thus, the observed effect is above and beyond any effect of children's general adjustment. If a more positive experience of home school has the potential to buffer children against more negative reactions, then school administrations and teachers must ensure that home schooling during a crisis-situation like COVID-19 is optimally put together and delivered to meets students' needs including teacher support. Naturally, many children missed their friends and our results indicate that children who missed their friends also reported significantly higher levels of emotional reactions than children who did not miss their friends. Friendships play a large role in children's lives, not least in terms of a means of support, and our result might indicate that children's need for emotional support from friends was not met due to the social isolation measures and the absence of usual contact at school, and therefore, they experience heightened emotional reactions. Finally, our results indicate that children who worried about virus infection reported more emotional and worry Reactions, respectively, compared to children who were not worried about virus infection. This could not be attributed to children's general emotional vulnerability as we controlled for this in the analyses. Thus, children's concerns about the coronavirus seem to have direct implications for their emotional response and worries for their family and parents. The association with children's emotional reactions is particularly important as it demonstrates, for the first time that worry about virus infection is associated with a broader spectre of emotional reactions and not just symptoms of mental health difficulties [5, 22] . Taking a child developmental perspective, we explored if children's age moderated any of the relationships between COVID-19 predictors and children's reactions. We did indeed find that age moderated the relationship between family stress and instability and all three reaction-dimensions. Age also moderated the relationship between screen time and somatic/cognitive reactions, and the relationship between missing friends and worry about virus infection and somatic/cognitive and worry reactions, respectively. All significant coefficients were positive, suggesting that relationships were stronger for older children compared to younger children. That family stress and instability is more strongly associated with emotional reactions in older children fits with the developmental perspective of adolescence as a time of sensitivity and of heightened emotional reactions [34] . Another possibility is that older children may be less exposed to and dependent on family dynamics as they have more opportunity to seek support elsewhere if they experience difficulties at home. This is in line with the idea of a gradual shift in focus from the family to friends [34] . When we in the present study actually control for children's psychological vulnerabilities, it is possible that the effects are exacerbated, because for older children the support from friends is even more important and at the same time, the everyday changes restricted physical contact with friends. A clear strength of the present study, is the use of longitudinal data that allowed us to control for children's psychological vulnerability (i.e., symptoms of depression and anxiety assessed prior to the pandemic). In contrast to previous cross-sectional studies, we have been able to rule out confounding effects of children's general adjustment. Another strength is the focus on children's reactions more broadly with the opportunity to examine the normal range of reactions, including positive and negative reactions. However, the study also has some limitations that deserve mentioning. First, to assess children's reactions, we asked children to rate their reactions in comparison to before the pandemic. We acknowledge that the reliability of retrospective questionnaires may be subject to memory or recall bias, particularly when assessing personal life events. However, we assessed children's reactions, which might be less subject to bias and being able to assess a change in children's reactions outweigh the probability of any measurement error. Second, our measure of screen time use included both social media use and online gaming. We may have missed an opportunity to see a relationship with children's reactions, as we did not assess these two types of screen time separately. We, therefore, encourage future studies to use more nuanced measures that, for example, probe social media use and online gaming separately. It would also be interesting to explore how much communication children have with other gamers or friends during online gaming sessions. We speculate that children may use gaming as a way of connecting and communicating with friends, and thus, gaming might have protective mechanisms on children's reactions [53] . Third, we have eluded to the fact that children may have met their friends physically despite the public health recommendations, something we did not ask children about. Finally, we urge caution in generalizing the results to the general population, as our sample may be characterised as a nonrepresentative convenience sample and further, data for the present study were drawn from the XXX study, where families were recruited when parents attended family welfare centres for mediation, counselling or family therapy (i.e., vulnerable families).@story_separate@In summary, the present study found both positive and negative consequences of the pandemic on children; children reported fewer emotional reactions and more somatic/cognitive reactions. We observed associations between most of the COVID-19 related predictors and children's reactions, and further, age moderated several of these associations; older children were more severely impacted by the changes than were younger children. This fits with a developmental perspective of adolescence as a time of heightened emotional sensitivity and developing autonomy. Going forward, it will be important to replicate or even extend the present study by focusing on an even broader spectrum of child reactions to the pandemic, and to explore what the impact of school re-opening (and closing and re-opening again) has on children as the pandemic continues on.","For children the consequences of the COVID-19 public health measures may have long-term effects into adulthood. By exploring children’s reactions more broadly, we are better placed to understanding the breadth of implications of home school and social isolation under COVID-19. The present study explored how COVID-19 related variables, namely, home school experience, child perceived family stress and instability, screen time use, missing friends and worry about virus infection are associated with children’s emotional, somatic/cognitive and worry reactions, respectively. A total of 442 children (M = 11.43 years, SD = 2.59) from the longitudinal FamilieForSK-study participated and a series of hierarchical linear regression models were applied controlling for background variables including children’s psychological vulnerability. Results showed significant associations between all COVID-19 related predictors, except screen time use, and the three outcomes. Family stress and instability had the strongest effects with standardised betas ranging from .356 to .555 and collectively, predictors explained between 20.7 and 44.1% of variance in outcomes. Furthermore, several associations were moderated by age and older children were more negatively impacted (i.e., higher level of reported reactions). The present study provides more conclusive evidence of the effects of home school and social isolation under COVID-19 on children. It also exemplifies the importance of focusing on children’s reactions more broadly, as there was evidence that children on average had fewer emotional reactions compared to before the pandemic."
"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), as the causative agent of coronavirus disease 2019, also known as COVID-19, is a beta-coronavirus which belongs to the family of Coronaviridae and is currently responsible for the third human coronavirus outbreak in the past 20 years, after SARS (now often referred to as SARS-CoV-1) in 2002/03 and MERS (Middle east respiratory syndrome) in 2012 (1) . SARS-CoV-2 was first identified in Wuhan, China in December 2019 (2, 3) . This COVID-19 pandemic has caused unprecedented morbidity, mortality and global economic instability. SARS-CoV-2 is highly pathogenic and is believed to spread mainly through respiratory droplets and aerosols. The current preventive measures include quarantine, isolation and physical social distancing. Thus far, therapeutic drugs are of limited use in the clinic, and no specific vaccine is available yet, therefore calling for an urgent need for development of effective vaccines to restrict disease as well as viral spread. More than hundred candidate vaccines, consisting of multiple vaccine types such as recombinant viral epitopes (surface glycoprotein), adenovirus-based vectors (e.g. recombinant replication incompetent HAdV-C5), purified inactivated or live-attenuated virus, virus like particles (VLPs) and DNA or RNA based vaccine formulations, are currently being investigated (4, 5) . At present mRNA-based vaccines formulated in lipid nanoparticles, recombinant protein-based and inactivated virus-based vaccines as well as viral vector-based vaccines have reached late stage of clinical development, entering phase 3 testing. For these vaccines, pre-clinical data in animal models has also been generated supporting the hypothesis that these vaccines can effectively prevent viral infection. However, little is known about whether recombinant protein vaccines are capable of conferring protective immunity. In contrast to the aforementioned mRNA and viral vector-based vaccines, recombinant protein vaccines are simpler as they consist of a single entity antigen and -in contrast to viral vectors -do not require antigen expression in the vaccinees. Compared to mRNA vaccines, recombinant protein vaccines do not require complex (lipid) nanoparticle formulations to overcome the formidable barrier of the endosomal membrane before reaching the cytoplasm which is the subcellular target compartment for the antigen-expressing mRNA. Moreover, thus far no mRNA-based vaccine has been licensed, which might pose additional hurdles in view of mass manufacturing in world-wide immunization campaigns. Hence, exploring the viability of a recombinant protein COVID-19 vaccine might be of considerable relevance. SARS-CoV-2 consists of over 30 kb single-stranded positive strand RNA genome which encodes four major structural proteins, spike (S), membrane (M), nucleocapsid (N) and envelope (E). The spike protein comprises a homotrimeric structure which is present on the surface of the virus and facilitates the viral attachment and entry into the host cells. Like SARS-CoV-1, SARS-CoV-2 S protein gains entry into host cells via human angiotensin-converting enzyme 2 (hACE-2) receptors on the host cell surface via its receptor-binding domain (RBD) (1) (6) . Subsequently, membrane-associated serine proteases such as transmembrane protease, serine 2 (TMPRSS2) or endosomal-associated proteases such as cathepsins cleave the S protein, thereby promoting efficient fusion of the viral membrane to the host cell membrane, followed by release of viral content into the cell cytoplasm, where the virus subsequently replicates. The viral infection usually begins in the oral/nasal cavity and once released, it gradually establishes itself in type-II pneumocytes of the lower respiratory air tract and enterocytes in the gastrointestinal tract (7, 8) . Due to its involvement in viral entry, the S protein is a major target for current vaccine development against SARS-CoV-2 (5) . Therefore, in this study we explored the recombinant SARS-CoV-2 S protein as a potential vaccine candidate. As recombinant protein antigens are poorly immunogenic and are incapable of mounting antigen-specific immunity of sufficient quality, amplitude and duration, co-administration of adjuvants that shape B cell and T cell responses are indispensable. Adjuvants like alum and oil-in-water emulsions can act through a multitude of mechanisms. More defined small molecule adjuvants that potently activate innate immune cells by triggering specific innate immune receptors might be more relevant for anti-viral vaccine design. The Toll-like receptors 7 and 8 (TLR7/8) are widely distributed amongst innate immune cell subsets over a broad range of species (9) . Akin to be an endosomal pattern recognition receptor for viral RNA, triggering of these receptors provokes robust type I interferon production that can skew a Th1-type adaptive immune response against co-administered antigen (10) . The latter are characterized by robust antibody titers capable of inducing viral neutralization through a variety of mechanisms, including Fc-mediated innate immune killing as well as inducing CD4and CD8 T-cell based immunological memory. Moreover, vaccines adjuvanted with TLR7/8 ligands have been shown to confer enhanced protective immunity in both mouse and non-human primate models (11, 12) . Being well-defined small molecules, imidazoquinolines are a class of TLR7/8 agonists (13) that hold a massive technological advantage in terms of production and physicochemical stability. However, their pharmacokinetic profile is characterized by rapid systemic dissemination upon local (e.g. subcutaneous or intramuscular) administration, thereby causing unwanted innate immune activation at multiple distal tissues (14) , which is currently a strong limitation for applying imidazoquinoline TLR7/8 agonists in mass immunization campaigns. We and others have reported on strategies to alter the bio-distribution of imidazoquinolines through chemical conjugation to a synthetic carrier that limits systemic circulation but confers robust translocation to immuneinducing sites in sentinel lymph nodes (14) (15) (16) (17) (18) . In the present work, we report on a novel amphiphilic carrier for imidazoquinoline (IMDQ) TLR7/8 agonists with high translational potential, based on conjugation of a single imidazoquinoline to the chain end of a cholesterylpolyethylene glycol macromolecular amphiphile (IMDQ-PEG-CHOL; Figure 1A ). This design mediates binding to serum proteins such as albumin (15, 19) (Figure 1B) and in contrast to pure lipidation, the conjugate is well water-soluble. As a result, mobility in tissue is achieved without depot formation, with potential loss in adjuvant efficacy, hence avoiding the need for additional formulation. Here we report that IMDQ-PEG-CHOL is a potent adjuvant candidate which can enhance vaccine efficiency and induce robust Th1 skewed antibody responses in mice when delivered as a single shot with either admixed S protein (for SARS-CoV-2) or seasonal quadrivalent inactivated influenza virus vaccine (QIV, for influenza) . Moreover, IMDQ-PEG-CHOL was able to infer protection in SARS-CoV-2 or influenza virus (H1N1)-infected infected mice. In this context, it is noteworthy to mention that a major limitation in COVID19-vaccine development is the lack of susceptible small animal models for pre-clinical assessment and evaluation of its efficacy. Reportedly, in contrast to human ACE-2, murine ACE-2 is not targeted by wild type SARS-CoV-2 virus because of species-specific variations in ACE-2 receptors between mouse and human. Here we made use of a mouse model where hACE-2 was introduced through an adenoviral vector (Ad5-hACE2), which allows for subsequent replication of SARS-CoV-2 upon infection in the airways of transduced mice (20) . Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), as the causative agent of coronavirus disease 2019, also known as COVID-19, is a beta-coronavirus which belongs to the family of Coronaviridae and is currently responsible for the third human coronavirus outbreak in the past 20 years, after SARS (now often referred to as SARS-CoV-1) in 2002/03 and MERS (Middle east respiratory syndrome) in 2012 (1) . SARS-CoV-2 was first identified in Wuhan, China in December 2019 (2, 3) . This COVID-19 pandemic has caused unprecedented morbidity, mortality and global economic instability. SARS-CoV-2 is highly pathogenic and is believed to spread mainly through respiratory droplets and aerosols. The current preventive measures include quarantine, isolation and physical social distancing. Thus far, therapeutic drugs are of limited use in the clinic, and no specific vaccine is available yet, therefore calling for an urgent need for development of effective vaccines to restrict disease as well as viral spread. More than hundred candidate vaccines, consisting of multiple vaccine types such as recombinant viral epitopes (surface glycoprotein), adenovirus-based vectors (e.g. recombinant replication incompetent HAdV-C5), purified inactivated or live-attenuated virus, virus like particles (VLPs) and DNA or RNA based vaccine formulations, are currently being investigated (4, 5) . At present mRNA-based vaccines formulated in lipid nanoparticles, recombinant protein-based and inactivated virus-based vaccines as well as viral vector-based vaccines have reached late stage of clinical development, entering phase 3 testing. For these vaccines, pre-clinical data in animal models has also been generated supporting the hypothesis that these vaccines can effectively prevent viral infection. However, little is known about whether recombinant protein vaccines are capable of conferring protective immunity. In contrast to the aforementioned mRNA and viral vector-based vaccines, recombinant protein vaccines are simpler as they consist of a single entity antigen and -in contrast to viral vectors -do not require antigen expression in the vaccinees. Compared to mRNA vaccines, recombinant protein vaccines do not require complex (lipid) nanoparticle formulations to overcome the formidable barrier of the endosomal membrane before reaching the cytoplasm which is the subcellular target compartment for the antigen-expressing mRNA. Moreover, thus far no mRNA-based vaccine has been licensed, which might pose additional hurdles in view of mass manufacturing in world-wide immunization campaigns. Hence, exploring the viability of a recombinant protein COVID-19 vaccine might be of considerable relevance. SARS-CoV-2 consists of over 30 kb single-stranded positive strand RNA genome which encodes four major structural proteins, spike (S), membrane (M), nucleocapsid (N) and envelope (E). The spike protein comprises a homotrimeric structure which is present on the surface of the virus and facilitates the viral attachment and entry into the host cells. Like SARS-CoV-1, SARS-CoV-2 S protein gains entry into host cells via human angiotensin-converting enzyme 2 (hACE-2) receptors on the host cell surface via its receptor-binding domain (RBD) (1) (6) . Subsequently, membrane-associated serine proteases such as transmembrane protease, serine 2 (TMPRSS2) or endosomal-associated proteases such as cathepsins cleave the S protein, thereby promoting efficient fusion of the viral membrane to the host cell membrane, followed by release of viral content into the cell cytoplasm, where the virus subsequently replicates. The viral infection usually begins in the oral/nasal cavity and once released, it gradually establishes itself in type-II pneumocytes of the lower respiratory air tract and enterocytes in the gastrointestinal tract (7, 8) . Due to its involvement in viral entry, the S protein is a major target for current vaccine development against SARS-CoV-2 (5) . Therefore, in this study we explored the recombinant SARS-CoV-2 S protein as a potential vaccine candidate. As recombinant protein antigens are poorly immunogenic and are incapable of mounting antigen-specific immunity of sufficient quality, amplitude and duration, co-administration of adjuvants that shape B cell and T cell responses are indispensable. Adjuvants like alum and oil-in-water emulsions can act through a multitude of mechanisms. More defined small molecule adjuvants that potently activate innate immune cells by triggering specific innate immune receptors might be more relevant for anti-viral vaccine design. The Toll-like receptors 7 and 8 (TLR7/8) are widely distributed amongst innate immune cell subsets over a broad range of species (9) . Akin to be an endosomal pattern recognition receptor for viral RNA, triggering of these receptors provokes robust type I interferon production that can skew a Th1-type adaptive immune response against co-administered antigen (10) . The latter are characterized by robust antibody titers capable of inducing viral neutralization through a variety of mechanisms, including Fc-mediated innate immune killing as well as inducing CD4and CD8 T-cell based immunological memory. Moreover, vaccines adjuvanted with TLR7/8 ligands have been shown to confer enhanced protective immunity in both mouse and non-human primate models (11, 12) . Being well-defined small molecules, imidazoquinolines are a class of TLR7/8 agonists (13) that hold a massive technological advantage in terms of production and physicochemical stability. However, their pharmacokinetic profile is characterized by rapid systemic dissemination upon local (e.g. subcutaneous or intramuscular) administration, thereby causing unwanted innate immune activation at multiple distal tissues (14) , which is currently a strong limitation for applying imidazoquinoline TLR7/8 agonists in mass immunization campaigns. We and others have reported on strategies to alter the bio-distribution of imidazoquinolines through chemical conjugation to a synthetic carrier that limits systemic circulation but confers robust translocation to immuneinducing sites in sentinel lymph nodes (14) (15) (16) (17) (18) . In the present work, we report on a novel amphiphilic carrier for imidazoquinoline (IMDQ) TLR7/8 agonists with high translational potential, based on conjugation of a single imidazoquinoline to the chain end of a cholesterylpolyethylene glycol macromolecular amphiphile (IMDQ-PEG-CHOL; Figure 1A ). This design mediates binding to serum proteins such as albumin (15, 19) (Figure 1B) and in contrast to pure lipidation, the conjugate is well water-soluble. As a result, mobility in tissue is achieved without depot formation, with potential loss in adjuvant efficacy, hence avoiding the need for additional formulation. Here we report that IMDQ-PEG-CHOL is a potent adjuvant candidate which can enhance vaccine efficiency and induce robust Th1 skewed antibody responses in mice when delivered as a single shot with either admixed S protein (for SARS-CoV-2) or seasonal quadrivalent inactivated influenza virus vaccine (QIV, for influenza) . Moreover, IMDQ-PEG-CHOL was able to infer protection in SARS-CoV-2 or influenza virus (H1N1)-infected infected mice. In this context, it is noteworthy to mention that a major limitation in COVID19-vaccine development is the lack of susceptible small animal models for pre-clinical assessment and evaluation of its efficacy. Reportedly, in contrast to human ACE-2, murine ACE-2 is not targeted by wild type SARS-CoV-2 virus because of species-specific variations in ACE-2 receptors between mouse and human. Here we made use of a mouse model where hACE-2 was introduced through an adenoviral vector (Ad5-hACE2), which allows for subsequent replication of SARS-CoV-2 upon infection in the airways of transduced mice (20) .@story_separate@The imidazoquinoline 1-(4-(aminomethyl)benzyl)-2-butyl-1H-imidazo [4,5-c] quinolin-4-amine (IMDQ) (21) was conjugated to cholesteryl-poly(ethylene glycol) (CHOL-PEG), yielding IMDQ-PEG-CHOL. As a control, non-amphiphilic IMDQ-PEG was synthesized. (Figure 1A ) PEG with a molecular weight of 3 kDa was chosen as an optimal compromise between water solubility and drug load. Characterization of the conjugate was performed by matrix assisted laser desorption/ionization -time of flight (MALDI-ToF) (Supplementary Figure S1 ) analysis whereas high pressure liquid chromatography (HPLC) analysis (Supplementary Figure S2) proved absence of free soluble non-conjugated IMDQ. Both IMDQ-PEG-CHOL and IMDQ-PEG were watersoluble, but only IMDQ-PEG-CHOL showed affinity towards albumin as measured by biolayer interferometry (Figure 2A ). On the in vitro level, the presence of the CHOL motif dramatically improved cellular uptake by DC2.4 (Figure 2B -C; note that for imaging purpose, IMDQ was replaced by the fluorescent probe Cynanine5), a murine model mouse dendritic cell line, and was more potent in inducing NF-kB activation in a reporter cell line (Figure 2D) , while being nontoxic within the tested experimental window ( Figure 2E ). We attribute this to the ability of the cholesterol motif to interact with the phospholipid cell membrane. On the in vivo level, using a transgenic luciferase-reporter mouse model for IFN b-production (22), we found that local administration (i.e. subcutaneous injection into the footpad) of IMDQ-PEG-CHOL, in contrast to unformulated IMDQ, dramatically reduced systemic innate immune activation, while focusing its activity to the site of injection and the draining (popliteal) lymph node ( Figure 3A) . For quantification of the luminescence imaging data we refer to Supplementary Figure S3 . Interestingly, the CHOL motif appeared crucial for mediating lymphatic translocation as the IMDQ-PEG control induced very limited activity in the draining lymph node. To further support this, we performed microscopic ( Figure 3B1 ) and flow cytometry ( Figure 3B2 ) analysis of popliteal lymph nodes of mice that received fluorescent Cyanine5-PEG-CHOL or Cyanine-PEG, respectively. These experiments revealed a dramatic increase in fluorescence when the conjugates contained the CHOL motif. A more detailed analysis of immune cells subsets in the draining lymph node revealed that vast percentages of lymphocytes, notably over 50% of dendritic cells (DCs) and macrophages (Mf), as well as 40% of B cells, were targeted by Cyanine5-PEG-CHOL ( Figure 3C) . In a similar experimental setting, IMDQ-PEG-CHOL induced recruitment ( Figure 3D1 ) and robust activation ( Figure 3D2 ) of immune cells. Taken together, these data support our hypothesis that IMDQ-PEG-CHOL is a potent adjuvant that focuses its activity to draining lymphoid tissue, combined with a promising safety profile.  We evaluated the potential of IMDQ-PEG-CHOL to adjuvant a licensed vaccine, i.e. the quadrivalent influenza vaccine (QIV), in a well-established preclinical vaccination-infection model. Hereto we vaccinated BALB/c mice with each of 1.5 µg of QIV with or without 100 µg of IMDQ-PEG-CHOL or PEG-CHOL as a control. The study protocol is outlined in Figure 4A . Six mice in each group received a total of 100 µl vaccine-adjuvant mixture, intramuscularly, divided over both hind legs and the blood was collected 3 weeks post vaccination, followed by serological assays. For detection of influenza-specific antibodies induced by the QIV vaccines, we used vaccine antigen to coat enzyme-linked immunosorbent assay (ELISA) plates. The total IgG antibody titers in mice which received QIV only or QIV+ PEG-CHOL were very low as compared to the mice vaccinated with QIV+ IMDQ-PEG-CHOL (also shown as area under curve (AUC) in Supplementary Figure S4) . Unadjuvanted QIV and PEG-CHOL admixed QIV resulted mainly in vaccine-specific IgG1 antibodies, whereas IMDQ-PEG-CHOL resulted in a balanced IgG1/IgG2a response as shown in Figure 4B . Interestingly, QIV + PEG-CHOL resulted in even lower antibody responses than QIV alone, an observation we confirmed in an independent vaccination experiment (data not shown). Four out of six mice that received QIV + IMDQ-PEG-CHOL could efficiently inhibit hemagglutination of chicken red blood cells (RBC) in vitro, by A/Singapore/gp1908/2015 IVR-180, the H1N1 virus component in QIV, with hemagglutination inhibition (HI) titers outperforming those of the other immunized groups ( Figure 4C ). Next, the immunized mice were challenged with a hundred-fold half-lethal dose (LD50) of IVR-180 (H1N1) virus to examine the magnitude of protection against viral infection in vivo. The lungs were harvested from three mice in each group 5 days post challenge to determine lung virus titers. Consistent with the ELISA and HI data, mice immunized with QIV + IMDQ-PEG-CHOL exhibited best reduction in viral lung titers as evidenced by an almost negligible number of plaques when compared to other groups ( Figure 4E) . This was also reflected in the optimal protection from body weight loss of QIV + IMDQ-PEG-CHOL mice after viral challenge ( Figure 4D ). In conclusion, our novel adjuvant IMDQ-PEG-CHOL was able to offer excellent control of viral infection and therefore, in combination with the right antigen, might also hold promise to confer protective immunity against other respiratory viruses such as SARS-CoV-2.  We next investigated the potential of IMDQ-PEG-CHOL to adjuvant recombinant SARS-CoV-2 S protein. For this purpose, BALB/c mice were immunized intramuscularly with 6 µg of recombinant trimeric spike protein either unadjuvanted or adjuvanted with IMDQ-PEG-CHOL or with equivalent amounts of MF59-like water-in-oil vaccine AddaVax as a control established vaccine adjuvant. The recombinant vaccine consisted of the ectodomain of the SARS-CoV-2 spike protein from which the polybasic cleavage site was removed. Stabilizing prolines were added at positions 986 and 987 and trimerization was promoted by fusion to a T4 trimerization domain (see methods section for more details). The study protocol is outlined in Figure 5A . Serum was collected after 21 days post immunization and analyzed for Spike protein specific IgG titers. Whereas non-immunized mice evidently did not show any detectable Spike protein-specific titers in their sera, immunization with S protein induced Spike protein-specific titers in all groups (Figure 5B) , also shown as area under the curve (AUC) titers in Supplementary Figure 54 . The total S protein-specific IgG titers were found to be the highest in the IMDQ-PEG-CHOL adjuvanted group. Additionally, Spike protein + IMDQ-PEG-CHOL immunization resulted in a higher IgG2a/IgG1 ratio, suggesting a more potent Th1 immune response and more efficient class switching towards IgG2a as compared to spike protein only or spike protein + AddaVax immunization. Next, the sera from vaccinated mice were used to test the ability to inhibit SARS-CoV-2 infection in vitro. Although immunization with non-adjuvanted S protein was able to induce some IgG titers, it was found ineffective in neutralizing viral infection of Vero E6 cells in vitro in a microneutralization assay (Figure 5C1-2) . By contrast, serum of mice immunized with spike protein + IMDQ-PEG-CHOL was able to neutralize >50% of SARS-CoV-2 virus infection in this assay, which was also significantly higher than the serum of mice immunized with spike protein + AddaVax. Finally, we investigated to what extent S protein + IMDQ-PEG-CHOL immunization is able to confer protection against a SARS-CoV-2 viral challenge. As mice do not express the hACE-2 receptor that is needed for the virus to infect the host, we first transduced immunized mice with an adenoviral vector encoding for hACE-2 by intranasal installation. Four days later, mice we challenged with SARS-CoV-2 virus and again 4 days later, lungs were harvested, and the residual viral infection was quantified by a plaque assay. Interestingly, whereas non-adjuvanted Spike protein could not confer any protection, relative to the non-immunized group, Spike protein + IMDQ-PEG-CHOL vaccination conferred sterilizing immunity against the SARS-CoV-2 infection with plaque numbers below the detection limit (Figure 5D) , and performed significantly better than spike protein + AddaVax immunization, which correlates with the higher microneutralization titers observed in the Spike protein + IMDQ-PEG-CHOL group (Figure 5C1-2) .  All chemicals for synthesis were purchased from Sigma-Aldrich or TCI, unless noted otherwise. 6-8 weeks old female BALB/c mice were obtained from Charles River Laboratories, MA and were housed in a specified pathogen-free facility at Icahn school of medicine at Mount Sinai, with food and water ad libitum, adhering to the guidelines from Institutional Animal Care and Use Committee. Madin-Darby Canine Kidney Cells (MDCK, ATCC-CCL 34) and Vero-E6 (ATTC-CRL 1586, clone E6) cells are routinely cultured in the laboratory. Both cells were maintained in Dulbecco's Modified Eagle's Medium supplemented with 10% Fetal bovine serum (FBS) and additionally with 1% non-essential amino acids for Vero-E6 cells. DC2.4 mouse dendritic cells were cultured in RPMI-glutamax supplemented with 10 % fetal bovine serum (FBS), antibiotics (50 units/mL penicillin and 50 µg/mL streptomycin) and 1 mM sodium pyruvate. Murine RAW blue 264.7 macrophages were cultured in DMEM medium supplemented with 10 % heat-inactivated FBS, antibiotics (50 units/mL penicillin and 50 µg/mL streptomycin), 2 mM L-glutamine and 0.01 % Zeocin. Cells were incubated at 37 °C in a controlled and sterile environment of 95 % relative humidity and 5 % CO 2 . Blood was collected twenty days post vaccination via submandibular bleeding and serum was prepared by allowing the blood to clot at room temperature. Anti-HA antibody responses were measured by enzyme linked immunosorbent assay (ELISA) and hemagglutination inhibition (HI) assay. For quantification of HA-specific total IgG levels by ELISA, 96 well NUNC Maxisorp plates were coated with QIV (2 μg/ml HA equivalent for each HA) in bicarbonate buffer at 4 °C overnight. After washing and blocking with 4% milk for 1 h at room temperature, serum samples 3-fold diluted starting at 1/100 in PBS with 0.05% Tween20 were allowed to bind ELISA antigen for 1.5 h at room temperature. Plates were washed three times with PBS (0.05% Tween20) and incubated with sheep-derived anti-mouse total IgG (GE Healthcare, Amersham, UK), IgG1 or IgG2a (Invitrogen) serum conjugated to horse-radish peroxidase. After a final washing step, tetramethylbenzidine (TMB) substrate (Sigma-Aldrich, San Diego, CA, USA) was used to estimate levels of HA-specific mouse IgG by measuring the OD 450 with the OD 650 as a reference after stopping the colorimetric reaction with 1M H 2 SO 4 . Hemagglutination inhibition was performed as previously described (23) . Briefly, four volumes of receptor destroying enzyme (RDE, Vibrio cholera filtrate, Sigma Aldrich, San Diego, CA, USA) were added to each volume of mouse serum. After overnight incubation at 37 °C, sera were heatinactivated at 56 °C for 30 min in sodium citrate buffer. Four hemagglutination units of IVR-180 H1N1 virus were mixed with twofold dilutions of treated sera in a final volume of 50 μL. Mixtures of virus and diluted serum were allowed to bind for 1h at room temperature before 50 μL of 0.5% chicken red blood cell suspension was added. HI titers were read after 1h incubation on ice. Trimeric recombinant SARS-CoV-2 spike protein was produced as previously described: only the ectodomain of the spike protein (GenBank: MN908947.3) was cloned into a mammalian expression plasmid and the cleavage site was removed and stabilizing prolines were added at position 986 and 987 (24) (25) (26) . A hexa-histidine tag as well as a T4 foldon trimerization domain was present in the plasmid for ease of purification. The spike protein was expressed in 293F cells, using the ExpiFectamine 293 Transfection Kit (Thermo Fisher). Supernatant was collected on day 3 post transfection and Ni-NTA agarose (Qiagen) was used to purify the protein. This protocol has been described in much greater detail earlier (26) . Vaccine (6 μg/mouse) was mixed with adjuvant as described below and injected once via the intramuscular route with a BD 300 μL insulin syringe in the hamstring muscles of both hind legs (50 μL/leg). Anti-SARS-CoV-2 spike protein ELISA was performed to estimate spike-specific antibody responses upon vaccination. Briefly, maxisorp Nunc 96-well microtiter plates were coated with 50 µl per well of recombinant spike protein, diluted to a concentration of 2 µg/ml in carbonate/bicarbonate buffer and incubated overnight at 4°C. Three-fold serially diluted serum samples, starting from 1:100, were added to the antigen-coated plates followed by overnight incubation at 4°C. The plates were then washed in 1X PBS + 0.01% Tween20 and again incubated with appropriate horse-radish peroxidase (HRP)-conjugated secondary antibodies targeting total IgG, IgG1 or IgG2a antibodies (GE Healthcare). The plates were washed and developed with 50 µl of TMB substrate per well until blue color appeared. The reaction was terminated with 50 µl 1M H 2 SO 4 and the absorbance was measured at 450nm with 650 nm as a reference. To measure the neutralizing potential of SARS-CoV-2 vaccine-induced sera, an in vitro microneutralization assay was performed similar to the protocol described in (27) . Briefly, the Spike ± adjuvant-vaccinated mice sera were inactivated at 56°C for 30 min. Serum samples were serially diluted 2-fold starting from 1:10 dilution in infection medium (DMEM+ 2% FBS+ 1X non-essential amino acids). The samples were incubated with 100 tissue culture infective dose 50 (TCID50) which equals 40 plaque forming units (PFU) of SARS-CoV2 virus for 1 hour in an incubator at 37°C, 5% CO 2 and then transfer on pre-seeded Vero-E6 cells in 96-well cell-culture plates. The plates were incubated at 37°C for 48 hours and fixed in 4% formaldehyde. The cells were washed with 1XPBS and blocked in 5% milk in 1XPBS+ 0.1% Tween20 for 1 hour at room temperature. After blocking, the cells were permeabilized with 0.1% TritonX100, washed and incubated with anti-SARS-CoV-2-nucleoprotein and anti-SARS-CoV-2-Spike monoclonal antibodies, mixed in 1:1 ratio, for 1.5 hours at room temperature. The cells were washed again and incubated with HRP-conjugated anti-mouse IgG secondary antibody for 1 hour at room temperature followed by a brief PBS wash. Finally, 50 µl tetramethyl benzidine (TMB) substrate was added and incubated until blue color appeared and the reaction was terminated with 50 µl 1M H 2 SO 4 . Absorbance at 450nm was recorded and percentage inhibition calculated. Anti-mouse SARS-CoV-2-nucleoprotein and anti-mouse SARS-CoV-2-Spike antibodies were obtained from the Center for Therapeutic Antibody Development at the Icahn School of Medicine at Mount Sinai, New York. Adjuvants: AddaVax was purchased from Invivogen and mixed at a 3:1 ratio vaccine:AddaVax per the manufacturer's recommendation. IMDQ adjuvants were mixed with vaccine at an equivalent of 10 μg core IMDQ (100 μg of IMDQ-PEG-CHOL, see below) per mouse. QIV vaccinated mice were infected 24 days post vaccination with 100 lethal dose 50 (18,000 PFU) of egg-grown influenza IVR-180 H1N1 virus, a vaccine strain that contains the surface antigens of influenza A/Singapore/gp1908/2015 (H1N1) virus. Morbidity and mortality were monitored for eight days. A group of age-matched naïve animals was added to the experiment to confirm the dose of virus was lethal to unvaccinated animals. In order to make SARS-CoV-2 Spike-vaccinated BALB/c mice susceptible to challenge with wild type SARS-CoV-2 virus, airway expression of human ACE-2, the receptor for SARS-CoV-2, was obtained by intranasal transduction of mice with 2.5x10 8 PFU of adenovirus expressing h-ACE-2 (Ad5-hACE2), 4.5-weeks post-vaccination as described in (28) . Five days after transduction with Ad5-hACE2, mice were challenged with 5x10 4 PFU of SARS-CoV2 isolate USA-WA1/2020 (BEI resources; NR-52281) per mice. Body weights were recorded to assess the morbidity during the days post challenge. Plaque assays were performed to quantify and compare the lung viral titers in vaccinated versus unvaccinated mice. As described previously (23) , whole lungs were harvested from the mice and homogenized in 1 ml 1XPBS. After brief centrifugation, the tissue debris was discarded and the supernatant was 10-fold serially diluted starting from 1:10 dilution. For IVR-180, MDCK cells were incubated with the lung homogenate dilutions for 1 hour at 37°C, 5% CO 2 and then overlaid with a mixture of 2% oxoid agar and 2X minimal essential medium (MEM) supplemented with 1% diethyl-aminoethyl (DEAE)-dextran and 1 μg/ml tosylamide-2-phenylethyl chloro-methyl ketone (TPCK)-treated trypsin. After 48 hours of incubation at 37°C, 5% CO 2 , the plates were fixed in 4% formaldehyde and immune-stained with IVR-180-post-challenge polyclonal serum. Similarly, For SARS-CoV-2, pre-seeded Vero-E6 cells were incubated with diluted lung homogenates for 1 hour at room temperature and then overlayed with a 1ml mixture of 2% oxoid agar and 2X MEM supplemented with 2% FBS. After 72 hours of incubation at 37°C, 5% CO 2 , the plates were fixed in 4% formaldehyde, followed by immune-staining of infected cells with anti-mouse SARS-CoV-2 nucleoprotein and anti-mouse SARS-CoV-2 spike monoclonal antibodies. After incubation in primary antibodies, HRP-conjugated anti-mouse secondary antibody was added for 1 hour. Finally, the plaques were developed with TrueBlue substrate (KPL-Seracare). The final viral titers were calculated in terms of plaque forming units (PFU)/ml. IMDQ was synthesized according to literature (18) . First, the alcoholic hydroxyl group of cholesterol was transformed to an azide through a Mitsunobu reaction in the presence of diphenylphosphoryl azide (DPPA). Cholesterol (2.0 g, 5.17 mmol) was dissolved in a round bottom flask equipped with a stirring bar containing anhydrous THF (20 mL). Triphenylphosphine (PPh 3 , 1.63 g, 6.21 mmol) and diisopropyl azodicarboxylate (DIAD, 1.22 mL, 6.21 mmol) was added to the round bottom flask. Upon addition of DIAD, the reaction mixture developed a yellow colour. After 10 minutes, DPPA (1.34 mL, 6.21 mmol) was added and the mixture stirred overnight at room temperature under inert atmosphere. The reaction mixture was reduced under vacuum and further purified by column chromatography (cyclohexane), to yield a purified withe powder (yield = 60 %). The resulting product cholesteryl-N 3 was analysed by 1 H-NMR and ATR-IR. Next, a Staudinger reduction was executed to reduce the azide group to a primary amine function with PPh 3 . The obtained cholesteryl-N 3 (400 mg, 0.97 mmol) was transferred into a round bottom flask containing a stirring bar and dissolved in anhydrous THF (2.0 mL) under inert atmosphere. A solution of PPh 3 (2.55 g, 9.72 mmol) in dry THF (5.0 mL) was added. After 30 min, 2 mL water was added and the reaction mixture stirred overnight at room temperature equipped with a balloon to trap the released nitrogen gas. The reaction mixture was diluted extensively with toluene before being reduced under vacuum by 50 °C. The crude product was purified by column chromatography using a gradient (from 95: An equal amount of trifluoroacetic acid (TFA, 2 mL) was added and the solution was stirred for 2 h opened to ambient air and temperature. Prior to concentration under vacuum, a large excess of toluene was added to the reaction mixture. Finally, the product was transferred to dialysis membranes and dialyzed against 0.1 % v/v ammonium hydroxide solution in demineralized water for multiple days and one day against demineralized water. After lyophilization, the white fluffy powder NH 2 -PEG-CHOL was characterized by 1 H-NMR and MALDI-ToF. In a round bottom flask equipped with a stirring bar, p-nitrobenzyl chloroformate (2.02 g, 10 mmol) was dissolved in anhydrous DCM and cooled on ice. A mixture of diethylene glycol (424.5 mg, 4 mmol) and TEA (1.67 mL, 12 mmol) in 10 mL anhydrous DCM were added dropwise and stirred for an additional 30 minutes on ice. After 2 h on room temperature, the reaction mixture was concentrated under vacuum, dissolved in EtOAc and filtered. After evaporation of the solvent under reduced pressure, the linker was analyzed by 1 H-NMR and MS. In the second step, intermediate 1 (50 mg, 0.014 mmol) and IMDQ (9.5 mg, 0.22 mmol) were weighed into a round bottom flask with stirring bar. The compounds were dissolved in 2.3 mL anhydrous 1,4-dioxane and anhydrous TEA (9.76 µL, 0.07 mmol) was added to solution under vigorous stirring. After 3 h at room temperature, a few drops of dry methanol were added and the reaction was stirred overnight. Next, the solution was transferred into a dialysis membrane (1 kDa) and dialyzed for multiple days against demineralized water. After freeze drying, the with fluffyIMDQ-PEG-CHOL powder was characterized by 1 H-NMR, HPLC and MALDI-ToF. HPLC conditions to verify absence of freely soluble IMDQ: LiChroCart® C18 column 250-4, mobile phase H 2 O/ ACN 65:35 with 0.1% TFA, flow rate at 1 mL/min and detection at 250nm. Note that IMDQ-PEG was synthesized in similar fashion, but omitting the conjugation of cholesterylamine. NH 2 -PEG-CHOL (25 mg, 7.49 µmol) was weighted into a Schlenk tube equipped with a magnetic stirring bar and dissolved in 2.5 mL dry DMSO under inert atmosphere. Then, 0.21 mL of cyanine5 N-hydroxysuccinimide ester (stock solution of 25 mg/mL in anhydrous DMSO, 7.86 µmol) and anhydrous TEA (5.2 µL,37.42 µmol) were added to the Schlenk tube and further stirred overnight at room temperature. After dialyzed for three days against demineralized water, Cyanine5-PEG-CHOL was isolated as a fluffy blueish powder after lyophilization. Bovine serum albumin (BSA) was biotinylated by reacting it with 5:1 excess of biotin-NHS followed by dialysis and lyophilization. Hydrated streptavidin sensors were dipped in PBS to record a baseline for 60 seconds, followed by dipping into biotinylated BSA (12.5 nM, 66.5 kDa) in PBS for 300 s, and dipping for 30 s in PBS for washing. Next, a second baseline was recorded by dipping in fresh PBS for 120 s. Association of IMDQ-PEG-CHOL was measured by dipping into a solution of IMDQ-PEG-CHOL in PBS for 600 s. Note that the experiment was ran in parallel for different concentrations of IMDQ-PEG-CHOL. Dissociation of IMDQ-PEG-CHOL was recorded by dipping in PBs for 600 s. The experiment was performed in a black flat bottom 96 well plate set at 30 °C by 1000 rpm, using an Octet RED96 model (Pall Fortébio). Data processing was done by the FortéBio software package. Cell cytotoxicity (MTT) assay DC 2.4 cells were plated seeded in 96-well plates at a density of 8 000 cells per well in 200 µL culture medium. 50 µL of sample (dilution series in PBS, ranging from 10 -4 mg/mL to 0.5 mg/mL), PBS (negative control, 100 % viability) and DMSO (positive control, 0 % viability) were added to the wells. After 72 h, the medium was aspirated and cells were washed with 200 µL PBS followed by addition of 100 µL of diluted MTT stock solution. After 1h, the solution was removed and the formed formazan crystals were dissolved in 50 µL DMSO. Quantification was done by measuring the absorbance at 590 nm using a microplate reader. Note, 3-(4,5dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT, 50 mg) was dissolved in 10 mL sterile PBS, filtrated (membrane 0.22 µm) and 1/5 diluted in culture medium prior to use in this assay. Confocal microscopy DC 2.4 cells were seeded in Willco-Dish glass bottom at a concentration of 10 000 cells in 180 µL culture medium and allowed to adhere overnight. Cells were pulsed overnight with 20 µL of a 1 mg/mL Cyanine5-PEG-CHOL or Cynanine5-PEG solution in PBS. Next, the culture medium was aspirated and cells were fixated with 4% paraformaldehyde (PFA) for 30 min followed by washing with PBS and confocal imaging using a Leica DMI6000B microscope (63x 1.40 NA objective) coupled to an AndorDSD2 confocal scanner and a Zyla5.5 CMOS camera. Image processing was done using the ImageJ software package. DC 2.4 cells were seeded out in 24-well plate at a concentration of 200 000 cells per well in 450 µL of culture medium. Cells were pulsed with samples and incubated overnight at 37 °C. Afterwards, the supernatants were removed, cells were washed with PBS and detached with cell dissociation buffer (0.5 mL, 15 min, 37 °C). The content of the wells was transferred to an Eppendorf and centrifuged (5 min, 300 G, 4 °C). After aspiration of the supernatant, the cell pellets were resuspended in PBS and analyzed using a BD Accuri Flow Cytometer. Data were processed using the FlowJo software package. RAW blue 264.7 macrophages were seeded in flat-bottom 96 well plate at a density of 70.000 cells per well, suspended in 180 µL culture medium and pulsed with 20 µL of sample for 24h at 37 °C at different concentrations of IMDQ-PEG-CHOL, IMDQ-PEG, IMDQ and PBS. Subsequently, 50 µL of supernatant was transfer to a new flat-bottom 96 well plate followed by addition of 150 µL of QUANTI-Blue TM reagent solution, prepared according to the manufacturer's instruction (Invivogen). After 30 minutes at 37 °C, the SEAP levels were determined by UV-Vis spectrophotometry at 620 nm using a microplate reader. Note, the colorimetric quantification of the samples was obtained relative to the negative control and each concentration was performed in fivefold. 20 μL (1 mg/mL in PBS) of Cyanine5-PEG-CHOL or Cyanine5-PEG were injected into the footpad of female C57BL/6 WT mice. Two mice were used per group and injected in both footpads. At the designated time point, mice where sacrificed and popliteal lymph nodes where isolated for flow cytometry and confocal imaging. A single cell suspension was prepared from the dissected popliteal lymph nodes for analysis by flow cytometry. Isolated lymph nodes were collected in ice cold PBS, dissociated through 70 μm cell strainers, washed with PBS and stained with a fixable dead/live-staining. 123count ebeads were added to determine cellularity prior to analysis by a BD FACS Quanto flow cytometer. Data were processed using the FlowJo software package. For confocal imaging popliteal lymph nodes where frozen in OCT cryomedium (Sakura, 4583). frozen sections (8-μm) were cut by cryostat. These sections where fixed for 4 min in PFA 2% (v/v), and washed with PBS. Images were acquired on a Zeiss LSM710 confocal microscope equipped with 488-nm, 561-nm and 633-nm lasers and with a tunable two-photon laser. Confocal imaging was done using a Leica DMI6000B microscope (10x 0.70 NA objective) coupled to an AndorDSD2 confocal scanner and a Zyla5.5 CMOS camera. Image processing was done using the ImageJ software package. Luciferase reporter mice (IFNβ+/Δβ-luc) with a Balb/c background, aged 7-9 weeks, were housed in individual ventilated cages and given ad libitum access to food and water. 20 mL of IMDQ-PEG-CHOL, IMDQ-PEG or IMDQwere injected subcutaneously in the footpad (n=3) at an equivalent IMDQ dose of 2 mg. For in vivo imaging at the given time points, mice were injected subcutaneously with 200 μL D-luciferin and in vivo luminescence imaging was recorded 12 min later using the IVIS Lumina II imaging system. Local (DLN and DLN + foot pad) luminescence and full-body luminescence were quantified using the Living Image 4.4 software. Supplementary Fig. 3 : Quantification of the total photon flux from the draining popliteal lymph node and the whole body, and the ratio of both. Quantification was done based on the bioluminescence images ( Figure 3A ) of luciferase reporter mice (IFNβ+/Δβ-luc) recorded 4, 24 and 48 h post footpad injection of IMDQ-PEG-CHOL, IMDQ-PEG and native IMDQ ) . ) / The imidazoquinoline 1-(4-(aminomethyl)benzyl)-2-butyl-1H-imidazo [4,5-c] quinolin-4-amine (IMDQ) (21) was conjugated to cholesteryl-poly(ethylene glycol) (CHOL-PEG), yielding IMDQ-PEG-CHOL. As a control, non-amphiphilic IMDQ-PEG was synthesized. (Figure 1A ) PEG with a molecular weight of 3 kDa was chosen as an optimal compromise between water solubility and drug load. Characterization of the conjugate was performed by matrix assisted laser desorption/ionization -time of flight (MALDI-ToF) (Supplementary Figure S1 ) analysis whereas high pressure liquid chromatography (HPLC) analysis (Supplementary Figure S2) proved absence of free soluble non-conjugated IMDQ. Both IMDQ-PEG-CHOL and IMDQ-PEG were watersoluble, but only IMDQ-PEG-CHOL showed affinity towards albumin as measured by biolayer interferometry (Figure 2A ). On the in vitro level, the presence of the CHOL motif dramatically improved cellular uptake by DC2.4 (Figure 2B -C; note that for imaging purpose, IMDQ was replaced by the fluorescent probe Cynanine5), a murine model mouse dendritic cell line, and was more potent in inducing NF-kB activation in a reporter cell line (Figure 2D) , while being nontoxic within the tested experimental window ( Figure 2E ). We attribute this to the ability of the cholesterol motif to interact with the phospholipid cell membrane. On the in vivo level, using a transgenic luciferase-reporter mouse model for IFN b-production (22), we found that local administration (i.e. subcutaneous injection into the footpad) of IMDQ-PEG-CHOL, in contrast to unformulated IMDQ, dramatically reduced systemic innate immune activation, while focusing its activity to the site of injection and the draining (popliteal) lymph node ( Figure 3A) . For quantification of the luminescence imaging data we refer to Supplementary Figure S3 . Interestingly, the CHOL motif appeared crucial for mediating lymphatic translocation as the IMDQ-PEG control induced very limited activity in the draining lymph node. To further support this, we performed microscopic ( Figure 3B1 ) and flow cytometry ( Figure 3B2 ) analysis of popliteal lymph nodes of mice that received fluorescent Cyanine5-PEG-CHOL or Cyanine-PEG, respectively. These experiments revealed a dramatic increase in fluorescence when the conjugates contained the CHOL motif. A more detailed analysis of immune cells subsets in the draining lymph node revealed that vast percentages of lymphocytes, notably over 50% of dendritic cells (DCs) and macrophages (Mf), as well as 40% of B cells, were targeted by Cyanine5-PEG-CHOL ( Figure 3C) . In a similar experimental setting, IMDQ-PEG-CHOL induced recruitment ( Figure 3D1 ) and robust activation ( Figure 3D2 ) of immune cells. Taken together, these data support our hypothesis that IMDQ-PEG-CHOL is a potent adjuvant that focuses its activity to draining lymphoid tissue, combined with a promising safety profile. . CC-BY-ND 4.0 International license available under a (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted October 23, 2020. ; . CC-BY-ND 4.0 International license available under a (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted October 23, 2020. ; https://doi.org/10.1101/2020.10.23.344085 doi: bioRxiv preprint We evaluated the potential of IMDQ-PEG-CHOL to adjuvant a licensed vaccine, i.e. the quadrivalent influenza vaccine (QIV), in a well-established preclinical vaccination-infection model. Hereto we vaccinated BALB/c mice with each of 1.5 µg of QIV with or without 100 µg of IMDQ-PEG-CHOL or PEG-CHOL as a control. The study protocol is outlined in Figure 4A . Six mice in each group received a total of 100 µl vaccine-adjuvant mixture, intramuscularly, divided over both hind legs and the blood was collected 3 weeks post vaccination, followed by serological assays. For detection of influenza-specific antibodies induced by the QIV vaccines, we used vaccine antigen to coat enzyme-linked immunosorbent assay (ELISA) plates. The total IgG antibody titers in mice which received QIV only or QIV+ PEG-CHOL were very low as compared to the mice vaccinated with QIV+ IMDQ-PEG-CHOL (also shown as area under curve (AUC) in Supplementary Figure S4) . Unadjuvanted QIV and PEG-CHOL admixed QIV resulted mainly in vaccine-specific IgG1 antibodies, whereas IMDQ-PEG-CHOL resulted in a balanced IgG1/IgG2a response as shown in Figure 4B . Interestingly, QIV + PEG-CHOL resulted in even lower antibody responses than QIV alone, an observation we confirmed in an independent vaccination experiment (data not shown). Four out of six mice that received QIV + IMDQ-PEG-CHOL could efficiently inhibit hemagglutination of chicken red blood cells (RBC) in vitro, by A/Singapore/gp1908/2015 IVR-180, the H1N1 virus component in QIV, with hemagglutination inhibition (HI) titers outperforming those of the other immunized groups ( Figure 4C ). Next, the immunized mice were challenged with a hundred-fold half-lethal dose (LD50) of IVR-180 (H1N1) virus to examine the magnitude of protection against viral infection in vivo. The lungs were harvested from three mice in each group 5 days post challenge to determine lung virus titers. Consistent with the ELISA and HI data, mice immunized with QIV + IMDQ-PEG-CHOL exhibited best reduction in viral lung titers as evidenced by an almost negligible number of plaques when compared to other groups ( Figure 4E) . This was also reflected in the optimal protection from body weight loss of QIV + IMDQ-PEG-CHOL mice after viral challenge ( Figure 4D ). In conclusion, our novel adjuvant IMDQ-PEG-CHOL was able to offer excellent control of viral infection and therefore, in combination with the right antigen, might also hold promise to confer protective immunity against other respiratory viruses such as SARS-CoV-2. . CC-BY-ND 4.0 International license available under a (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted October 23, 2020. ;  We next investigated the potential of IMDQ-PEG-CHOL to adjuvant recombinant SARS-CoV-2 S protein. For this purpose, BALB/c mice were immunized intramuscularly with 6 µg of recombinant trimeric spike protein either unadjuvanted or adjuvanted with IMDQ-PEG-CHOL or with equivalent amounts of MF59-like water-in-oil vaccine AddaVax as a control established vaccine adjuvant. The recombinant vaccine consisted of the ectodomain of the SARS-CoV-2 spike protein from which the polybasic cleavage site was removed. Stabilizing prolines were added at positions 986 and 987 and trimerization was promoted by fusion to a T4 trimerization domain (see methods section for more details). The study protocol is outlined in Figure 5A . Serum was collected after 21 days post immunization and analyzed for Spike protein specific IgG titers. Whereas non-immunized mice evidently did not show any detectable Spike protein-specific titers in their sera, immunization with S protein induced Spike protein-specific titers in all groups (Figure 5B) , also shown as area under the curve (AUC) titers in Supplementary Figure 54 . The total S protein-specific IgG titers were found to be the highest in the IMDQ-PEG-CHOL adjuvanted group. Additionally, Spike protein + IMDQ-PEG-CHOL immunization resulted in a higher IgG2a/IgG1 ratio, suggesting a more potent Th1 immune response and more efficient class switching towards IgG2a as compared to spike protein only or spike protein + AddaVax immunization. Next, the sera from vaccinated mice were used to test the ability to inhibit SARS-CoV-2 infection in vitro. Although immunization with non-adjuvanted S protein was able to induce some IgG titers, it was found ineffective in neutralizing viral infection of Vero E6 cells in vitro in a microneutralization assay (Figure 5C1-2) . By contrast, serum of mice immunized with spike protein + IMDQ-PEG-CHOL was able to neutralize >50% of SARS-CoV-2 virus infection in this assay, which was also significantly higher than the serum of mice immunized with spike protein + AddaVax. Finally, we investigated to what extent S protein + IMDQ-PEG-CHOL immunization is able to confer protection against a SARS-CoV-2 viral challenge. As mice do not express the hACE-2 receptor that is needed for the virus to infect the host, we first transduced immunized mice with an adenoviral vector encoding for hACE-2 by intranasal installation. Four days later, mice we challenged with SARS-CoV-2 virus and again 4 days later, lungs were harvested, and the residual viral infection was quantified by a plaque assay. Interestingly, whereas non-adjuvanted Spike protein could not confer any protection, relative to the non-immunized group, Spike protein + IMDQ-PEG-CHOL vaccination conferred sterilizing immunity against the SARS-CoV-2 infection with plaque numbers below the detection limit (Figure 5D) , and performed significantly better than spike protein + AddaVax immunization, which correlates with the higher microneutralization titers observed in the Spike protein + IMDQ-PEG-CHOL group (Figure 5C1-2) . . CC-BY-ND 4.0 International license available under a (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted October 23, 2020. ;  All chemicals for synthesis were purchased from Sigma-Aldrich or TCI, unless noted otherwise. 6-8 weeks old female BALB/c mice were obtained from Charles River Laboratories, MA and were housed in a specified pathogen-free facility at Icahn school of medicine at Mount Sinai, with food and water ad libitum, adhering to the guidelines from Institutional Animal Care and Use Committee. Madin-Darby Canine Kidney Cells (MDCK, ATCC-CCL 34) and Vero-E6 (ATTC-CRL 1586, clone E6) cells are routinely cultured in the laboratory. Both cells were maintained in Dulbecco's Modified Eagle's Medium supplemented with 10% Fetal bovine serum (FBS) and additionally with 1% non-essential amino acids for Vero-E6 cells. DC2.4 mouse dendritic cells were cultured in RPMI-glutamax supplemented with 10 % fetal bovine serum (FBS), antibiotics (50 units/mL penicillin and 50 µg/mL streptomycin) and 1 mM sodium pyruvate. Murine RAW blue 264.7 macrophages were cultured in DMEM medium supplemented with 10 % heat-inactivated FBS, antibiotics (50 units/mL penicillin and 50 µg/mL streptomycin), 2 mM L-glutamine and 0.01 % Zeocin. Cells were incubated at 37 °C in a controlled and sterile environment of 95 % relative humidity and 5 % CO 2 . Blood was collected twenty days post vaccination via submandibular bleeding and serum was prepared by allowing the blood to clot at room temperature. Anti-HA antibody responses were measured by enzyme linked immunosorbent assay (ELISA) and hemagglutination inhibition (HI) assay. For quantification of HA-specific total IgG levels by ELISA, 96 well NUNC Maxisorp plates were coated with QIV (2 μg/ml HA equivalent for each HA) in bicarbonate buffer at 4 °C overnight. After washing and blocking with 4% milk for 1 h at room temperature, serum samples 3-fold diluted starting at 1/100 in PBS with 0.05% Tween20 were allowed to bind ELISA antigen for 1.5 h at room temperature. Plates were washed three times with PBS (0.05% Tween20) and incubated with sheep-derived anti-mouse total IgG (GE Healthcare, Amersham, UK), IgG1 or IgG2a (Invitrogen) serum conjugated to horse-radish peroxidase. After a final washing step, tetramethylbenzidine (TMB) substrate (Sigma-Aldrich, San Diego, CA, USA) was used to estimate levels of HA-specific mouse IgG by measuring the OD 450 with the OD 650 as a reference after stopping the colorimetric reaction with 1M H 2 SO 4 . Hemagglutination inhibition was performed as previously described (23) . Briefly, four volumes of receptor destroying enzyme (RDE, Vibrio cholera filtrate, Sigma Aldrich, San Diego, CA, USA) were added to each volume of mouse serum. After overnight incubation at 37 °C, sera were heatinactivated at 56 °C for 30 min in sodium citrate buffer. Four hemagglutination units of IVR-180 H1N1 virus were mixed with twofold dilutions of treated sera in a final volume of 50 μL. Mixtures of virus and diluted serum were allowed to bind for 1h at room temperature before 50 μL of 0.5% chicken red blood cell suspension was added. HI titers were read after 1h incubation on ice. Trimeric recombinant SARS-CoV-2 spike protein was produced as previously described: only the ectodomain of the spike protein (GenBank: MN908947.3) was cloned into a mammalian expression plasmid and the cleavage site was removed and stabilizing prolines were added at position 986 and 987 (24) (25) (26) . A hexa-histidine tag as well as a T4 foldon trimerization domain was present in the plasmid for ease of purification. The spike protein was expressed in 293F cells, using the ExpiFectamine 293 Transfection Kit (Thermo Fisher). Supernatant was collected on day 3 post transfection and Ni-NTA agarose (Qiagen) was used to purify the protein. This protocol has been described in much greater detail earlier (26) . Vaccine (6 μg/mouse) was mixed with adjuvant as described below and injected once via the intramuscular route with a BD 300 μL insulin syringe in the hamstring muscles of both hind legs (50 μL/leg). Anti-SARS-CoV-2 spike protein ELISA was performed to estimate spike-specific antibody responses upon vaccination. Briefly, maxisorp Nunc 96-well microtiter plates were coated with 50 µl per well of recombinant spike protein, diluted to a concentration of 2 µg/ml in carbonate/bicarbonate buffer and incubated overnight at 4°C. Three-fold serially diluted serum samples, starting from 1:100, were added to the antigen-coated plates followed by overnight incubation at 4°C. The plates were then washed in 1X PBS + 0.01% Tween20 and again incubated with appropriate horse-radish peroxidase (HRP)-conjugated secondary antibodies targeting total IgG, IgG1 or IgG2a antibodies (GE Healthcare). The plates were washed and developed with 50 µl of TMB substrate per well until blue color appeared. The reaction was terminated with 50 µl 1M H 2 SO 4 and the absorbance was measured at 450nm with 650 nm as a reference. To measure the neutralizing potential of SARS-CoV-2 vaccine-induced sera, an in vitro microneutralization assay was performed similar to the protocol described in (27) . Briefly, the Spike ± adjuvant-vaccinated mice sera were inactivated at 56°C for 30 min. Serum samples were serially diluted 2-fold starting from 1:10 dilution in infection medium (DMEM+ 2% FBS+ 1X non-essential amino acids). The samples were incubated with 100 tissue culture infective dose 50 (TCID50) which equals 40 plaque forming units (PFU) of SARS-CoV2 virus for 1 hour in an incubator at 37°C, 5% CO 2 and then transfer on pre-seeded Vero-E6 cells in 96-well cell-culture plates. The plates were incubated at 37°C for 48 hours and fixed in 4% formaldehyde. The cells were washed with 1XPBS and blocked in 5% milk in 1XPBS+ 0.1% Tween20 for 1 hour at room temperature. After blocking, the cells were permeabilized with 0.1% TritonX100, washed and incubated with anti-SARS-CoV-2-nucleoprotein and anti-SARS-CoV-2-Spike monoclonal antibodies, mixed in 1:1 ratio, for 1.5 hours at room temperature. The cells were washed again and incubated with HRP-conjugated anti-mouse IgG secondary antibody for 1 hour at room temperature followed by a brief PBS wash. Finally, 50 µl tetramethyl benzidine (TMB) substrate was added and incubated until blue color appeared and the reaction was terminated with 50 µl 1M H 2 SO 4 . Absorbance at 450nm was recorded and percentage inhibition calculated. Anti-mouse SARS-CoV-2-nucleoprotein and anti-mouse SARS-CoV-2-Spike antibodies were obtained from the Center for Therapeutic Antibody Development at the Icahn School of Medicine at Mount Sinai, New York. Adjuvants: AddaVax was purchased from Invivogen and mixed at a 3:1 ratio vaccine:AddaVax per the manufacturer's recommendation. IMDQ adjuvants were mixed with vaccine at an equivalent of 10 μg core IMDQ (100 μg of IMDQ-PEG-CHOL, see below) per mouse. QIV vaccinated mice were infected 24 days post vaccination with 100 lethal dose 50 (18,000 PFU) of egg-grown influenza IVR-180 H1N1 virus, a vaccine strain that contains the surface antigens of influenza A/Singapore/gp1908/2015 (H1N1) virus. Morbidity and mortality were monitored for eight days. A group of age-matched naïve animals was added to the experiment to confirm the dose of virus was lethal to unvaccinated animals. In order to make SARS-CoV-2 Spike-vaccinated BALB/c mice susceptible to challenge with wild type SARS-CoV-2 virus, airway expression of human ACE-2, the receptor for SARS-CoV-2, was obtained by intranasal transduction of mice with 2.5x10 8 PFU of adenovirus expressing h-ACE-2 (Ad5-hACE2), 4.5-weeks post-vaccination as described in (28) . Five days after transduction with Ad5-hACE2, mice were challenged with 5x10 4 PFU of SARS-CoV2 isolate USA-WA1/2020 (BEI resources; NR-52281) per mice. Body weights were recorded to assess the morbidity during the days post challenge. Plaque assays were performed to quantify and compare the lung viral titers in vaccinated versus unvaccinated mice. As described previously (23) , whole lungs were harvested from the mice and homogenized in 1 ml 1XPBS. After brief centrifugation, the tissue debris was discarded and the supernatant was 10-fold serially diluted starting from 1:10 dilution. For IVR-180, MDCK cells were incubated with the lung homogenate dilutions for 1 hour at 37°C, 5% CO 2 and then overlaid with a mixture of 2% oxoid agar and 2X minimal essential medium (MEM) supplemented with 1% diethyl-aminoethyl (DEAE)-dextran and 1 μg/ml tosylamide-2-phenylethyl chloro-methyl ketone (TPCK)-treated trypsin. After 48 hours of incubation at 37°C, 5% CO 2 , the plates were fixed in 4% formaldehyde and immune-stained with IVR-180-post-challenge polyclonal serum. Similarly, For SARS-CoV-2, pre-seeded Vero-E6 cells were incubated with diluted lung homogenates for 1 hour at room temperature and then overlayed with a 1ml mixture of 2% oxoid agar and 2X MEM supplemented with 2% FBS. After 72 hours of incubation at 37°C, 5% CO 2 , the plates were fixed in 4% formaldehyde, followed by immune-staining of infected cells with anti-mouse SARS-CoV-2 nucleoprotein and anti-mouse SARS-CoV-2 spike monoclonal antibodies. After incubation in primary antibodies, HRP-conjugated anti-mouse secondary antibody was added for 1 hour. Finally, the plaques were developed with TrueBlue substrate (KPL-Seracare). The final viral titers were calculated in terms of plaque forming units (PFU)/ml. IMDQ was synthesized according to literature (18) . First, the alcoholic hydroxyl group of cholesterol was transformed to an azide through a Mitsunobu reaction in the presence of diphenylphosphoryl azide (DPPA). Cholesterol (2.0 g, 5.17 mmol) was dissolved in a round bottom flask equipped with a stirring bar containing anhydrous THF (20 mL). Triphenylphosphine (PPh 3 , 1.63 g, 6.21 mmol) and diisopropyl azodicarboxylate (DIAD, 1.22 mL, 6.21 mmol) was added to the round bottom flask. Upon addition of DIAD, the reaction mixture developed a yellow colour. After 10 minutes, DPPA (1.34 mL, 6.21 mmol) was added and the mixture stirred overnight at room temperature under inert atmosphere. The reaction mixture was reduced under vacuum and further purified by column chromatography (cyclohexane), to yield a purified withe powder (yield = 60 %). The resulting product cholesteryl-N 3 was analysed by 1 H-NMR and ATR-IR. Next, a Staudinger reduction was executed to reduce the azide group to a primary amine function with PPh 3 . The obtained cholesteryl-N 3 (400 mg, 0.97 mmol) was transferred into a round bottom flask containing a stirring bar and dissolved in anhydrous THF (2.0 mL) under inert atmosphere. A solution of PPh 3 (2.55 g, 9.72 mmol) in dry THF (5.0 mL) was added. After 30 min, 2 mL water was added and the reaction mixture stirred overnight at room temperature equipped with a balloon to trap the released nitrogen gas. The reaction mixture was diluted extensively with toluene before being reduced under vacuum by 50 °C. The crude product was purified by column chromatography using a gradient (from 95: An equal amount of trifluoroacetic acid (TFA, 2 mL) was added and the solution was stirred for 2 h opened to ambient air and temperature. Prior to concentration under vacuum, a large excess of toluene was added to the reaction mixture. Finally, the product was transferred to dialysis membranes and dialyzed against 0.1 % v/v ammonium hydroxide solution in demineralized water for multiple days and one day against demineralized water. After lyophilization, the white fluffy powder NH 2 -PEG-CHOL was characterized by 1 H-NMR and MALDI-ToF. In a round bottom flask equipped with a stirring bar, p-nitrobenzyl chloroformate (2.02 g, 10 mmol) was dissolved in anhydrous DCM and cooled on ice. A mixture of diethylene glycol (424.5 mg, 4 mmol) and TEA (1.67 mL, 12 mmol) in 10 mL anhydrous DCM were added dropwise and stirred for an additional 30 minutes on ice. After 2 h on room temperature, the reaction mixture was concentrated under vacuum, dissolved in EtOAc and filtered. After evaporation of the solvent under reduced pressure, the linker was analyzed by 1 H-NMR and MS. In the second step, intermediate 1 (50 mg, 0.014 mmol) and IMDQ (9.5 mg, 0.22 mmol) were weighed into a round bottom flask with stirring bar. The compounds were dissolved in 2.3 mL anhydrous 1,4-dioxane and anhydrous TEA (9.76 µL, 0.07 mmol) was added to solution under vigorous stirring. After 3 h at room temperature, a few drops of dry methanol were added and the reaction was stirred overnight. Next, the solution was transferred into a dialysis membrane (1 kDa) and dialyzed for multiple days against demineralized water. After freeze drying, the with fluffyIMDQ-PEG-CHOL powder was characterized by 1 H-NMR, HPLC and MALDI-ToF. HPLC conditions to verify absence of freely soluble IMDQ: LiChroCart® C18 column 250-4, mobile phase H 2 O/ ACN 65:35 with 0.1% TFA, flow rate at 1 mL/min and detection at 250nm. Note that IMDQ-PEG was synthesized in similar fashion, but omitting the conjugation of cholesterylamine. NH 2 -PEG-CHOL (25 mg, 7.49 µmol) was weighted into a Schlenk tube equipped with a magnetic stirring bar and dissolved in 2.5 mL dry DMSO under inert atmosphere. Then, 0.21 mL of cyanine5 N-hydroxysuccinimide ester (stock solution of 25 mg/mL in anhydrous DMSO, 7.86 µmol) and anhydrous TEA (5.2 µL,37.42 µmol) were added to the Schlenk tube and further stirred overnight at room temperature. After dialyzed for three days against demineralized water, Cyanine5-PEG-CHOL was isolated as a fluffy blueish powder after lyophilization. Bovine serum albumin (BSA) was biotinylated by reacting it with 5:1 excess of biotin-NHS followed by dialysis and lyophilization. Hydrated streptavidin sensors were dipped in PBS to record a baseline for 60 seconds, followed by dipping into biotinylated BSA (12.5 nM, 66.5 kDa) in PBS for 300 s, and dipping for 30 s in PBS for washing. Next, a second baseline was recorded by dipping in fresh PBS for 120 s. Association of IMDQ-PEG-CHOL was measured by dipping into a solution of IMDQ-PEG-CHOL in PBS for 600 s. Note that the experiment was ran in parallel for different concentrations of IMDQ-PEG-CHOL. Dissociation of IMDQ-PEG-CHOL was recorded by dipping in PBs for 600 s. The experiment was performed in a black flat bottom 96 well plate set at 30 °C by 1000 rpm, using an Octet RED96 model (Pall Fortébio). Data processing was done by the FortéBio software package. Cell cytotoxicity (MTT) assay DC 2.4 cells were plated seeded in 96-well plates at a density of 8 000 cells per well in 200 µL culture medium. 50 µL of sample (dilution series in PBS, ranging from 10 -4 mg/mL to 0.5 mg/mL), PBS (negative control, 100 % viability) and DMSO (positive control, 0 % viability) were added to the wells. After 72 h, the medium was aspirated and cells were washed with 200 µL PBS followed by addition of 100 µL of diluted MTT stock solution. After 1h, the solution was removed and the formed formazan crystals were dissolved in 50 µL DMSO. Quantification was done by measuring the absorbance at 590 nm using a microplate reader. Note, 3-(4,5dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide (MTT, 50 mg) was dissolved in 10 mL sterile PBS, filtrated (membrane 0.22 µm) and 1/5 diluted in culture medium prior to use in this assay. Confocal microscopy DC 2.4 cells were seeded in Willco-Dish glass bottom at a concentration of 10 000 cells in 180 µL culture medium and allowed to adhere overnight. Cells were pulsed overnight with 20 µL of a 1 mg/mL Cyanine5-PEG-CHOL or Cynanine5-PEG solution in PBS. Next, the culture medium was aspirated and cells were fixated with 4% paraformaldehyde (PFA) for 30 min followed by washing with PBS and confocal imaging using a Leica DMI6000B microscope (63x 1.40 NA objective) coupled to an AndorDSD2 confocal scanner and a Zyla5.5 CMOS camera. Image processing was done using the ImageJ software package. DC 2.4 cells were seeded out in 24-well plate at a concentration of 200 000 cells per well in 450 µL of culture medium. Cells were pulsed with samples and incubated overnight at 37 °C. Afterwards, the supernatants were removed, cells were washed with PBS and detached with cell dissociation buffer (0.5 mL, 15 min, 37 °C). The content of the wells was transferred to an Eppendorf and centrifuged (5 min, 300 G, 4 °C). After aspiration of the supernatant, the cell pellets were resuspended in PBS and analyzed using a BD Accuri Flow Cytometer. Data were processed using the FlowJo software package. RAW blue 264.7 macrophages were seeded in flat-bottom 96 well plate at a density of 70.000 cells per well, suspended in 180 µL culture medium and pulsed with 20 µL of sample for 24h at 37 °C at different concentrations of IMDQ-PEG-CHOL, IMDQ-PEG, IMDQ and PBS. Subsequently, 50 µL of supernatant was transfer to a new flat-bottom 96 well plate followed by addition of 150 µL of QUANTI-Blue TM reagent solution, prepared according to the manufacturer's instruction (Invivogen). After 30 minutes at 37 °C, the SEAP levels were determined by UV-Vis spectrophotometry at 620 nm using a microplate reader. Note, the colorimetric quantification of the samples was obtained relative to the negative control and each concentration was performed in fivefold. 20 μL (1 mg/mL in PBS) of Cyanine5-PEG-CHOL or Cyanine5-PEG were injected into the footpad of female C57BL/6 WT mice. Two mice were used per group and injected in both footpads. At the designated time point, mice where sacrificed and popliteal lymph nodes where isolated for flow cytometry and confocal imaging. A single cell suspension was prepared from the dissected popliteal lymph nodes for analysis by flow cytometry. Isolated lymph nodes were collected in ice cold PBS, dissociated through 70 μm cell strainers, washed with PBS and stained with a fixable dead/live-staining. 123count ebeads were added to determine cellularity prior to analysis by a BD FACS Quanto flow cytometer. Data were processed using the FlowJo software package. For confocal imaging popliteal lymph nodes where frozen in OCT cryomedium (Sakura, 4583). frozen sections (8-μm) were cut by cryostat. These sections where fixed for 4 min in PFA 2% (v/v), and washed with PBS. Images were acquired on a Zeiss LSM710 confocal microscope equipped with 488-nm, 561-nm and 633-nm lasers and with a tunable two-photon laser. Confocal imaging was done using a Leica DMI6000B microscope (10x 0.70 NA objective) coupled to an AndorDSD2 confocal scanner and a Zyla5.5 CMOS camera. Image processing was done using the ImageJ software package. Luciferase reporter mice (IFNβ+/Δβ-luc) with a Balb/c background, aged 7-9 weeks, were housed in individual ventilated cages and given ad libitum access to food and water. 20 mL of IMDQ-PEG-CHOL, IMDQ-PEG or IMDQwere injected subcutaneously in the footpad (n=3) at an equivalent IMDQ dose of 2 mg. For in vivo imaging at the given time points, mice were injected subcutaneously with 200 μL D-luciferin and in vivo luminescence imaging was recorded 12 min later using the IVIS Lumina II imaging system. Local (DLN and DLN + foot pad) luminescence and full-body luminescence were quantified using the Living Image 4.4 software.@story_separate@In summary, we have shown in this work that IMDQ-PEG-CHOL is a potent adjuvant with enhanced safety profile that induced innate immune activation in lymphoid tissue upon local administration. Whereas IMDQ in soluble, unformulated form, rapidly enters systemic circulation, conjugation to a lipid-polymer amphiphile prevents the latter while promoting translocation to the draining lymph node, likely through binding to albumin in the interstitial flow. In mouse vaccination/challenge models for influenza and SARS-CoV-2, we have demonstrated that a single immunization with QIV or S protein adjuvanted with IMDQ-PEG-CHOL induced robust Th1 skewed antibody responses, as evidenced by higher IgG2a/IgG1 ratios. Importantly, vaccination with QIV and S protein adjuvanted with IMDQ-PEG-CHOL resulted in virus-specific neutralizing antibodies and control of viral infection after challenge with influenza and SARS-CoV-2 viruses, respectively. Since IgG2a subclass is known to engage Fcg receptors that are involved in antiviral protection mechanisms like antibody-mediated cellular cytotoxicity and phagocytosis, IMDQ-PEG-CHOL might be beneficial to promote such responses. Whereas we are aware of the limitations of the present studies, we do believe that the overarching message that single vaccination with a properly adjuvanted recombinant S protein based vaccine is able to induce protective immunity in a mouse model, is of great relevance with regard to broadening the arsenal of emerging COVID-19 vaccines. Safe adjuvants like IMDQ-PEG-CHOL described in our study may help enhance vaccine efficiency if deemed necessary from ongoing clinical trials, similar to the recent development of MF59-adjuvanted influenza virus vaccines for the elderly. Use of efficient adjuvants may also reduce the amount of vaccine needed to induce a protective immune response, which is important in case there is vaccine shortage, as is the case during this COVID19 pandemic. In summary, we have shown in this work that IMDQ-PEG-CHOL is a potent adjuvant with enhanced safety profile that induced innate immune activation in lymphoid tissue upon local administration. Whereas IMDQ in soluble, unformulated form, rapidly enters systemic circulation, conjugation to a lipid-polymer amphiphile prevents the latter while promoting translocation to the draining lymph node, likely through binding to albumin in the interstitial flow. In mouse vaccination/challenge models for influenza and SARS-CoV-2, we have demonstrated that a single immunization with QIV or S protein adjuvanted with IMDQ-PEG-CHOL induced robust Th1 skewed antibody responses, as evidenced by higher IgG2a/IgG1 ratios. Importantly, vaccination with QIV and S protein adjuvanted with IMDQ-PEG-CHOL resulted in virus-specific neutralizing antibodies and control of viral infection after challenge with influenza and SARS-CoV-2 viruses, respectively. Since IgG2a subclass is known to engage Fcg receptors that are involved in antiviral protection mechanisms like antibody-mediated cellular cytotoxicity and phagocytosis, IMDQ-PEG-CHOL might be beneficial to promote such responses. Whereas we are aware of the limitations of the present studies, we do believe that the overarching message that single vaccination with a properly adjuvanted recombinant S protein based vaccine is able to induce protective immunity in a mouse model, is of great relevance with regard to broadening the arsenal of emerging COVID-19 vaccines. Safe adjuvants like IMDQ-PEG-CHOL described in our study may help enhance vaccine efficiency if deemed necessary from ongoing clinical trials, similar to the recent development of MF59-adjuvanted influenza virus vaccines for the elderly. Use of efficient adjuvants may also reduce the amount of vaccine needed to induce a protective immune response, which is important in case there is vaccine shortage, as is the case during this COVID19 pandemic.","The search for vaccines that protect from severe morbidity and mortality as a result of infection with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes coronavirus disease 2019 (COVID-19) is a race against the clock and the virus. Several vaccine candidates are currently being tested in the clinic. Inactivated virus and recombinant protein vaccines can be safe options but may require adjuvants to induce robust immune responses efficiently. In this work we describe the use of a novel amphiphilic imidazoquinoline (IMDQ-PEG-CHOL) TLR7/8 adjuvant, consisting of an imidazoquinoline conjugated to the chain end of a cholesterol-poly(ethylene glycol) macromolecular amphiphile). This amphiphile is water soluble and exhibits massive translocation to lymph nodes upon local administration, likely through binding to albumin. IMDQ-PEG-CHOL is used to induce a protective immune response against SARS-CoV-2 after single vaccination with trimeric recombinant SARS-CoV-2 spike protein in the BALB/c mouse model. Inclusion of amphiphilic IMDQ-PEG-CHOL in the SARS-CoV-2 spike vaccine formulation resulted in enhanced immune cell recruitment and activation in the draining lymph node. IMDQ-PEG-CHOL has a better safety profile compared to native soluble IMDQ as the former induces a more localized immune response upon local injection, preventing systemic inflammation. Moreover, IMDQ-PEG-CHOL adjuvanted vaccine induced enhanced ELISA and in vitro microneutralization titers, and a more balanced IgG2a/IgG1 response. To correlate vaccine responses with control of virus replication in vivo, vaccinated mice were challenged with SARS-CoV-2 virus after being sensitized by intranasal adenovirus-mediated expression of the human angiotensin converting enzyme 2 (ACE2) gene. Animals vaccinated with trimeric recombinant spike protein vaccine without adjuvant had lung virus titers comparable to non-vaccinated control mice, whereas animals vaccinated with IMDQ-PEG-CHOL-adjuvanted vaccine controlled viral replication and infectious viruses could not be recovered from their lungs at day 4 post infection. In order to test whether IMDQ-PEG-CHOL could also be used to adjuvant vaccines currently licensed for use in humans, proof of concept was also provided by using the same IMDQ-PEG-CHOL to adjuvant human quadrivalent inactivated influenza virus split vaccine, which resulted in enhanced hemagglutination inhibition titers and a more balanced IgG2a/IgG1 antibody response. Enhanced influenza vaccine responses correlated with better virus control when mice were given a lethal influenza virus challenge. Our results underscore the potential use of IMDQ-PEG-CHOL as an adjuvant to achieve protection after single immunization with recombinant protein and inactivated vaccines against respiratory viruses, such as SARS-CoV-2 and influenza viruses."
"Healthcare-associated infections (HAIs) are the most frequent adverse event in healthcare delivery worldwide, and constitute a serious and preventable threat to patient safety Rothe et al., 2013) . They lead to increased use of antibiotics, increased healthcare costs, longer hospital stays and higher morbidity and mortality rates (Gupta et al., 2011; Umscheid et al., 2011; Schmier et al., 2016) . Increased length of stay associated with HAIs varies between 5 and 30 days in low-and middle-income countries (LMICs) (WHO, 2011) . Costs associated with HAIs vary from US$865-US$13 000 as individual costs for various HAIs in LMICs (Pada et al., 2011; Ha and Ha, 2012) to overall costs of e7 billion annually in Europe (WHO, 2011) . A study conducted in a tertiary hospital in Ghana reported that the HAI treatment cost an additional US$1985 per patient, and those patients with HAIs paid twice as much as those without HAIs. The estimated annual cost of an HAI to the hospital was US$700 000 and it cost the broader society almost US$900 000 (Fenny et al., 2020) . The risk of developing HAIs in health facilities in LMICs is higher than in high-income countries (Rothe et al., 2013) . A study by Labi et al. (2019) reported that the overall prevalence of HAIs among hospitalized patients in Ghana was 8.2% (range: 3.5-14.4%). Patients in the intensive care unit tend to have a higher prevalence of HAIs than those admitted to other units of the hospital (WHO, 2011) . The neonatal intensive care unit (NICU) can pose a higher threat to patient safety due to its unique complexities, and factors such as understaffing, limited resources and ineffective organization of service delivery, which undermines the quality of care in LMICs Samra et al., 2011; Enweronu-Laryea et al., 2018) . The burden of HAIs can be reduced through appropriate infection prevention and control (IPC) interventions and adherence to hand hygiene (HH) practices (Umscheid et al., 2011; Rothe et al., 2013) . Compliance with HH guidelines among healthcare providers (HPs) is 38.7% (WHO, 2009), and ranges from 9.2% to 57% among doctors and 9.6% to 54% among nurses in Ghana (Yawson and Hesse, 2013) . The Ministry of Health (MOH), Ghana, has taken steps to improve IPC by introducing the National IPC Guidelines (MOH, 2015) , manuals and protocols to improve the quality of care (Escribano-Ferrer et al., 2017) . The IPC guidelines provide information to HPs on standard precautions including HH, use of personal protective equipment (PPE), environmental cleanliness and waste management. These guidelines aim to promote excellence in clientcentred care and maximize protection against infections for HPs and clients (MOH, 2015) . Strategies aimed at reducing HAIs are however centred mostly on HPs, with little consideration for the role of patients' relatives (caregivers). There are no clear policy guidelines on the roles of caregivers, who contribute to the basic care of hospitalized patients (Agbenyefia, 2017) . Role ambiguity between HPs and caregivers could lead to frustrations in the hospital environment, where caregivers are unclear about patients' needs and do not know whether they are contributing positively to care (Ricciardelli, 2012; Agbenyefia, 2017; Alshahrani et al., 2018) . The participation of caregivers in IPC promotion has been recommended as a promising strategy and there has been a call for increased caregiver engagement, which is critical to patient safety (Agbenyefia, 2017; Alshahrani et al., 2018) . Meaningful caregiver involvement in the joint endeavour of preventing infections is complex, and potential barriers reported by caregivers include feelings of inadequacy, fear of the consequences, having different beliefs from HPs and a desire to avoid interrupting busy HPs (Jackson et al., 2003; Latour et al., 2010; Rainey et al., 2015; Sutton et al., 2015) . Caregivers may feel unprepared for IPC roles due to lack of training and little guidance from HPs (Reinhard et al., 2008; Sapountzi-Krepia et al., 2008) . It is therefore critical for HPs to support the role of mothers as their babies' primary caregivers (Nyqvist and Engvall, 2009) . Healthcare systems are increasingly involving families as partners, and many NICUs now promote family-centred care (Reinhard et al., 2008; Sapountzi-Krepia et al., 2008; Skene et al., 2016; Ottosen et al., 2019) . Some studies in high-income countries have explored familycentred care and the perspectives and roles of caregivers (Rainey et al., 2015; Ottosen et al., 2019; Sutton et al., 2019) , but such studies are sparse in sub-Saharan Africa. Studies in Bangladesh, Indonesia and South Korea have shown that recognition of caregiver involvement in IPC strategies was not included in the national guidelines (Horng et al., 2016; Park et al., 2020) . Some studies in Ghana have explored mothers' experiences in the maternity and NICU wards (Yevoo et al., 2018; Dugle et al., 2020; Lomotey et al., 2020) and HPs' perceptions of the quality of neonatal care (Elikplim Pomevor and Adomah-Afari, 2016) . These studies, however, were not focused on the interactions between HPs and mothers in NICUs and did not explore HAIs. Other studies addressing HAIs in NICUs in Ghana were mostly focused on incidence, epidemiology and mortality (Annan and Asiedu, 2018; Labi et al., 2018 Labi et al., , 2020 . In the face of resource and financial constraints in LMICs, infection control is a cost-effective intervention that will decrease morbidity and mortality by reducing HAIs in NICUs (Srivastava and Shetty, 2007) , where mothers are important stakeholders.@story_separate@• Reducing the burden of healthcare-associated infections is a responsibility for both healthcare providers and caregivers. Thus, there is a need to improve communication and interaction between healthcare providers and carers towards achieving this goal. • Infection prevention and control in health facilities can be more effectively observed if health facilities provide the needed resources to enable health providers to undertake such measures. • Regular monitoring and supervision in the wards can contribute to proper infection prevention and control, which will help to reduce healthcare-associated infections, especially in the neonatal intensive care units of the various hospitals. • Pre-and post-training of health workers in health training institutions and hospitals on infection prevention and control can contribute to health providers inculcating the positive habit of strict observation of infection control measures at work. This can help to reduce healthcare-associated infections in the wards, including in neonatal intensive care units. Furthermore, the recent COVID-19 pandemic has prompted concerns about adherence to IPC guidelines (Houghton et al., 2020) , hence a need to examine factors contributing to IPC compliance, to help identify strategies that will support caregivers and HPs observe IPC practices at such a critical period in global healthcare. Local data are critical for developing and implementing evidence-based context-appropriate guidelines and protocols for IPC. To provide data to guide local policy on IPC practices, this hospital ethnographic study examined the factors that influence caregiving in the NICU, how lay mothers negotiate their roles with health professionals within the hospital context and how these interactions influence the practice of IPC and the reduction of HAIs. Ghana currently has 162 district-level hospitals, 10 regional-level hospitals and five teaching hospitals (tertiary-level) in the public health sector. District hospitals form the first referral point from health centres and polyclinics, regional hospitals form the secondary-level referral point and teaching hospitals provide complex tertiary-level care (Nsiah-Asare, 2017) . This study was conducted in the NICU of a tertiary-level hospital (TH) and a secondary-level hospital (SH) in Southern Ghana. The study was conducted within the context of a larger hospital-based project investigating Healthcare-Associated Infections in Ghana (HAI-Ghana project). In this article, we present the findings of a cross-sectional study that focuses on perspectives and practices on HAI among HPs and mothers. The study sites, TH and SH, provide similar levels of neonatal care (including intravenous infusions, parenteral medicines and neonatal resuscitation). TH and SH cater to the medical needs of babies in populations of 5 million and 3 million, respectively. TH was selected to provide insight in the context of a larger facility, while SH provided insight from the perspective of a secondary-level health facility. The NICU of TH has a nominal capacity of 60 cots, warming platforms and incubators, and that of SH has a nominal capacity of 30. Most of the babies admitted to both NICUs are preterm and critically ill babies. The average HAI prevalence at the hospitals was 10.2% (Labi et al., 2019) . TH employs 12 doctors, 40 nurses and other technical staff in the NICU, while the NICU in SH has around five doctors and 20 nurses. Work is organized around a similar shift pattern in both hospitals, with three shifts running (morning, afternoon and night). In this study, we consider the hospital an organizational cultural environment, with HPs, who have the biomedical and technical knowledge, and mothers from the wider Ghanaian cultural environment (Assimeng, 1999) . Thus, differences and similarities in context, norms and rules are bound to conform and clash. HPs with medical expertize execute their roles while interacting with mothers in often stressful situations and this can create a huge cultural and communication chasm (Ruben, 2016) . Medical professionals have jealously guarded their exclusive rights to medical knowledge from time immemorial, and have therefore used their professional status to exclude others who do not belong to the group (Freidson, 1988) . In the clinical encounter, the major concern of HPs is to ensure clinical care. The caregiver who has a highly personal and emotional involvement in the child's illness may hold different perspectives due to the lack of technical expertize (Jones and Jones, 1975) . So, whereas for HPs, infections and morbidity may just be passing clinical events, these have consequences that resonate beyond the medical realm for mothers, who are critical stakeholders. This oppositional view sets the stage for the 'clash of cultures'. The lack of trust between HPs and mothers mainly stems from these opposing views. Coe (1970) explains how the communication process, which is core to the medical encounter, is asymmetric between HPs and caregivers. This inherent asymmetry is reinforced by the medical profession's socialization practices which ground a relationship of domination, reflected in the management of information exchange and utilization of medical jargon (Filc, 2006) . In the absence of clear lines of communication, anxious caregivers produce their own scripts to assuage their anxiety over the health status of their patients (Senah, 2002) . Caregivers often accept these patriarchal attitudes of HPs without questioning, as a reflection of the broader society, where questioning authority is perceived as insubordination (Zaman, 2004) . Communication between HPs and caregivers can lead to an improvement in several areas of health and well-being, while the lack of communication or poor communication could result in poor compliance with guidelines (Jones and Jones, 1975) . Under a broader paradigm of sociocultural theory, Bourdieu (1991) emphasizes that when individuals interact, they do so in a specific social context, 'the field', which shapes their practices, perceptions and attitudes. Social fields in medicine include the field of health provider-client interactions (Emmerich, 2013) , where positions of power are determined by medical knowledge, professional prestige, etc. Power is present in all interpersonal relationships, is relevant in healthcare and 'comes into being' when it is put into action through 'strategies' such as expressions through language and communication (Foucault, 1982) . We used an ethnographic approach involving qualitative interviews with mothers and HPs, participant observation, informal meetings and discussions. An ethnographic approach allows us to obtain rich details of social phenomena, and requires long periods in the field to actively study, experience and represent the lives of participants in their natural setting (van der Geest and Sarkodie, 1998; Emerson et al., 2011) . In-depth interviews and focus group discussions were used to collect data. Women 15 years and older, whose babies had been hospitalized in the NICU for a minimum of 48 h during the study period, were eligible to participate in the study. Purposive sampling was used to recruit mothers to share their perspectives and experiences of care in the NICU. A total of 22 mothers participated in the in-depth interviews, and 24 mothers participated in four focus group discussions with between four and eight mothers per group: (TH: 15 interviews and two focus groups [n ¼ 12]; SH: seven interviews and two focus groups [n ¼ 12]). Sixteen HPs participated in the in-depth interviews. A cross-section of frontline HPs, health managers and IPC coordinators were purposively selected to achieve diversity in terms of staff cadre and level of experience. Qualitative interview guides were developed to capture nuanced contextual information related to the topic. A range of relevant literature was reviewed to develop the question guides consisting of semi-structured questions and probes to address the objectives of the study. The question guides were slightly revised for clarity, comprehensiveness and relevance, following a pilot test with three mothers and three HPs in a similar ward setting who were not included in the study. A health facility checklist was developed based on the review of the WHO ward infrastructure survey and existing literature (WHO, 2009; Yawson and Hesse, 2013) to support data collection. The checklist captured the available HH facilities on the wards. Both the qualitative interview guides and checklists were developed in English. The ethnographic study was conducted in both hospitals between January and June 2018. Interviews lasted 45 min to one hour and the focus group discussions lasted one hour to an hour and a half. Interviews were conducted face-to-face in the hospital in a calm location as per the convenience of participants, and participants were interviewed alone. Demographic information was collected, and participants spoke about their experiences of IPC practices and interactions in the ward. The first author, GSM, conducted interviews with HPs in the English medium. GSM is a medical doctor and a PhD student experienced in qualitative research. GSM understands issues related to caregiving and used her student-researcher identity to observe care and interactions in the ward. Two trained female research assistants who were graduate students in health-related fields and with qualitative research experience assisted with data collection. The researchers were not familiar to the participants prior to the study. All researchers were fluent in the local Akan language. Some mothers' interviews were conducted in English and others in Akan by GSM and the research assistants. GSM conducted the FGDs, while a research assistant took observational field notes. Participants were able to freely speak English or Akan, so they could express themselves comfortably. Probes were incorporated, but participants did not need much prompting to share their experiences and ideas. Participants were offered refreshments after the interviews. The interviews were audio-recorded, transcribed verbatim and those in Akan were translated into English by a research assistant. The translation was verified by a second research assistant. Data saturation was achieved. Field notes were documented, reconstructed and expanded following each ward visit, and data were incorporated into further ethnographic analyses (Emerson et al., 2011) . More than 100 h of participant observation and informal interactions with mothers and HPs were also conducted, to observe activities and interactions relating to IPC and HH. Personal HH practices observed included HH upon arrival and before leaving work at the end of the day or duty shift. Quantitative data on HH compliance (WHO, 2009) were captured and are reported elsewhere. Transcripts and notes were kept confidential in password-protected files. Transcripts were read by two team members (GSM, BPT) to develop a coding structure reflecting issues arising from the data. Coding of the transcripts was done using NVivo, and commonly occurring themes and subthemes were identified. We read and reread the transcripts for the overall experiences being presented and coded to develop open, focused and theoretical codes to describe dimensions of participants' experiences and interactions. This study takes a constructivist epistemological approach, where knowledge is dependent on perception and experience, and drew on inductive thematic coding, memo writing and reflexivity (Charmaz, 2001) . We used a grounded theory approach for data analysis. This enables in-depth exploration of multiple subjective experiences, provides explicit, sequential guidelines for conducting qualitative research and helps the researcher to streamline and integrate the data collection and data analysis process. Grounded theory allows the results to be 'grounded' to the data collected (Glaser et al., 1968; Chun Tie et al., 2019) . The preliminary findings of the study were presented to HPs and managers in both hospitals in seminars to return the results for verification and validation of the study. Comments and suggestions received during the seminar were incorporated into the final report. The presentation of our findings was guided by the Social Ecological Model (SEM). SEM has been recognized and accepted for use broadly in the efforts of enhancing health and well-being, and is widely used to better understand the health behaviours of individuals. SEM acknowledges that an individual's behaviour is shaped through multilevel factors. In general, five hierarchical levels of SEM have been recommended and used in social science, psychology and health science sectors: individual, interpersonal, community, organizational and policy levels (Newes-Adeyi et al., 2000; Lounsbury and Mitchell, 2009; Rawal et al., 2020) . Themes denoting factors influencing the practice of IPC to reduce HAIs were categorized under the various SEM levels, and other arising themes were also integrated ( Figure 1 ). SEM offers a holistic understanding of the factors influencing IPC practices of HPs and mothers. Strategies were employed to ensure the trustworthiness of the findings, such as checking the data for accuracy and completeness and using team meetings to establish coding consensus (Shenton, 2004; Houghton et al., 2013) . Reflexivity was employed, such as GSM taking note of her own preconceived ideas as a medical doctor which could influence observations in the study settings. Researchers examined personal biases and the effect of the researcher on the research process and interpretation of findings. We used the COREQ approach (Tong et al., 2007) to report on the characteristics of the research team, study design, data collection, data analysis and other strategies (Supplementary File). Ethical clearance was obtained for this study (GHS-ERC 07/03/ 2017). Written informed consent was obtained from interview participants who were informed about the study objectives, and all ethical procedures were followed. For confidentiality, direct quotes from participants are identified by codes (Doctor, D; Nurse, N; Manager, MG; Mother, MT; PA, Physician Assistant). HPs who participated in the study included six males and 10 females, aged 21-60 years. There were eight HPs from each hospital, including two managers, two IPC coordinators, four doctors, one physician assistant and seven nurses, with 50% of HPs having worked five years or less in the NICU. Mothers were between the ages of 15 and 49 years, and >50% of them had secondary school education or higher. Table 1 presents the characteristics of mothers in this study. Knowledge of HPs and mothers on the relevance of IPC All HPs agreed that knowledge of HAIs is important, and that promoting IPC in the ward is critical (Figure 1 , Individual-level factors). HPs described a clear association between observing IPC measures and reducing HAIs. HPs mentioned HH, waste segregation and disinfection as some measures to reduce HAIs. The national IPC policy document was not available in the wards, although there were clinical protocols and HH messages on posters in both NICUs. During an observation session, nurses were seen debating which detergent to use for cleaning incubators (Observation#21TH), and this was later clarified by a manager who said the information was in the ward protocol. The manager stated: 'People should familiarize themselves with and use the protocols and posters'. The manager also complained that knowledge of HAIs among staff was low. Mothers were aware of the possibility of acquiring infections in the NICU and described infections with terminologies in Twi such as 'mmuawa' (germs) and 'yareE/yadeE' (diseases). Mothers were observed washing their hands before entering the NICU, which they explained was to avoid contaminating their breastmilk or transferring germs to their babies. A mother said: 'Babies are quite delicate; their immune system is not built to term'. Mothers said they heard about 'infections' through talks at antenatal clinics, and from the television and radio. A mother whose baby had previously acquired an HAI mentioned that she was motivated to wash her hands to avoid expenses associated with HAIs: With my first child I didn't listen to what the nurses said, I was stubborn. So, I had to keep visiting the hospital several times. This time, I wash my hands and do exactly as I am told so that no disease will affect my child. Yes, because right now, there is no money (MT9). HPs did not strictly follow protocols and were seen using their discretion during some procedures (Figure 1 , Individual-level factors). A nurse who was observed administering medications with only one gloved hand explained that she was 'saving gloves', as gloves were scarce on the ward (Observation#24TH). Some senior nurses felt that student nurses who used gloves while changing soiled cot sheets were wasting the limited supplies. Some HPs also used normal examination gloves and sterile gloves interchangeably, although there were guidelines for the use of each type of glove. HPs who were observed performing HH used soap and water stored in veronica buckets (improvised buckets with a tap) (Veronica Bucket, 2020) when running water was not available in the ward. In both NICUs, <50% of observed HPs performed the recommended hand washing steps correctly, according to WHO guidelines. However, HPs in TH were more compliant with HH and use of the alcohol hand rubs than HPs in SH (Table 2) . HPs referred with concern to instances of babies acquiring HAIs from other babies especially when two or three unrelated newborns share an incubator for warmth or a cot for phototherapy. A mother F o r P e e r R e v i e w  Many HPs focused on protecting themselves from HAIs and mentioned that they did not want to take any infections from the hospital to their homes. HPs reported performing HH because of fear of becoming infected themselves. One HP said: 'I think what motivates most people, including myself, is not cross-infection. It is always about personal protection'. Some HPs perceived that mothers were not interested in IPC. However, mothers did observe and scrutinize IPC practices among HPs, and formed ideas and clues about IPC from what they saw. Mothers mentioned that they observed HPs wearing gloves to protect themselves and the babies from infections. Mothers described their own habits of handwashing before eating, after using the bathroom and before touching their babies. There were more specialist paediatricians and neonatal nurses in TH, and there was frequent training on neonatal care for the HPs. TH had a full-time IPC nurse who was focused on IPC in the wards, while SH had an IPC nurse who had to fulfil other clinical roles. IPC training had been conducted for HPs who had worked in the NICUs for more than a year, but not for HPs and students who joined the wards subsequently or for short rotations. Doctors were generally responsible for invasive procedures like insertion of intravenous cannulas, but nurses also performed these procedures in SH. Seven per cent of mothers had no formal education at all, while 41% of mothers had attended school up to the primary level (Table 1 ), but most were not able to understand or read English well. This presented a challenge with the use of written media as a channel of IPC communication, as HH posters and instructions were mostly in English. Mothers expressed the desire to receive IPC information via simplified messages on social media, using visual illustrations and/or in the local languages (Figure 1 , Individual-level factors). Some mothers reported that they were not instructed about HH in the NICU. One mother said: 'Nobody has taught us how to wash our hands, so we just wash them anyhow'. The influence of peers on IPC practices HPs mentioned that they are often inspired or reminded by colleagues to perform HH (Figure 1 , Interpersonal-level factors). One HP mentioned that 'some people will take reminders in good faith and change their behaviour; some will not'. Our observations in TH showed that HPs had a practice of engagement in shared breaks and meals in a staff room in the NICU (Observation#23TH). This provided an environment where HPs interacted and shared information on a range of topics, including IPC. Some mothers said that they acquired knowledge of HH by watching other mothers. Mothers held conversations in the waiting areas and exchanged knowledge by sharing experiences. HPs argued that due to the high turnover of mothers and babies, it was not possible to provide education on IPC to every mother, although most mothers received some orientation. With reference to Figure 1 , communication on the interpersonal level is very crucial to the reduction of HAIs. However, from our observations, communication between HPs and mothers was limited. Mothers craved carerelated information, and expected explanations regarding decisions taken concerning their babies. A mother was told that 'we tell you only what is important for you to know' when she approached a doctor for information on her baby. Another mother complained that the doctor was 'more interested in laboratory tests which were to be done for the baby'. Although laboratory tests are an essential component of clinical care, the mother wanted a social discussion while the HP approached it from a biomedical perspective. HPs' patriarchal style of communicating with mothers and distrust of mothers' ability to comprehend IPC Interactions between HPs and mothers were more of a one-way dialogue when they occurred, with HPs instructing the mothers on what to do, or mothers reporting back to HPs on specific issues. HPs mentioned that some of the mothers were not competent enough to process technical information about IPC. Some HPs mentioned that some mothers do not know how to use sinks and toilets, because they were brought up in villages where such facilities are mostly unavailable, and that these mothers have also not been trained on hygiene practices. One HP stated: 'some of them are villagers. . .it is the way they are trained'. Some HPs perceived mothers as potential sources of infections. A nurse stated: 'they sit on the floor on the corridor downstairs, then come here with the dirty cloth'. Some HPs mentioned that mothers or their relatives were capable of sneaking in herbs to be applied to the babies' umbilicus, contrary to the hospital protocol of using chlorhexidine, which was not known to most mothers. During FGDs, mothers discussed the use of spirit, gel or local herbs on their babies' umbilical cords as part of traditional newborn protective care. A mother complained: I came here last night and up till now they haven't given me spirit to clean the baby's navel, so this can also cause infection (MT7). Mothers also discussed that in caring for their babies, they sometimes received conflicting messages because 'nurses will say one thing, and grandmothers will say something else'. Ward rounds were regularly conducted as part of the routines in both NICUs, where HPs would give a detailed account of each baby to a supervising consultant who would then lead an academic discussion. Ward rounds represented an avenue for interaction where shared values on IPC came into play (Figure 1 , Community-level factors). We observed that HPs were more likely to perform HH during ward rounds when the leading consultant paid attention to HH (Observation#22TH, #39SH). Mothers had no role in ward rounds, and HPs preferred that they would be absent during this period to avoid interfering with questions and unsolicited comments. Mothers were termed 'difficult' if they did not comply. Mothers sometimes needed more time to complete care activities. One mother said: When leaving NICU you are tired and frustrated because you did not finish feeding your baby, and you are wondering if the nurses will continue feeding them for you or not (MT22). There are restrictions on visits by family and friends in both NICUs. Staff explained that this was an IPC measure. However, the reason for this restriction was not understood by most mothers. These mothers were opposed to these restrictions, as the local culture encourages family members to celebrate the arrival of a new baby by seeing the newborn. One complained: My sister came all the way from Cape Coast (Central region) but she hasn't seen the baby yet. . . nobody else has seen the baby, which is worrying (MT14). A mother complained that when she tried to get a nurse's attention to see to her baby, she was told casually that 'as for pre-terms their condition can change at any time'. A manager later explained how some cultural beliefs reflect in HPs' attitudes towards the babies: Culturally people think the babies still belong to the spirit world before day seven. . . the way they start treating them changes afterward; less effort is needed to convince staff to go the extra mile after day seven (MG1). Human and material resource deficits that affect commitment to IPC Managers emphasized the need to have the necessary human and material resource allocations for optimal IPC practice (Figure 1 , Organizational-level factors). HPs expressed the need for more HH stations and supplies in the NICU. Some HPs mentioned that due to the scarcity of PPE such as aprons, masks and boots, some PPE intended for single use are used multiple times. The NICUs lack an adequate supply of gloves, and HPs sometimes had to borrow gloves from other cubicles and wards or improvise by using a single glove at a time rather than a pair. On other occasions, HPs wore double pairs of gloves, explaining that they could not trust the quality of some types of gloves. Staff purchased and brought their own scrubs (PPE) to work and were responsible for cleaning them. HPs reported on the struggle to make IPC a priority because of clinical demands, including several new admissions daily and timeconsuming clinical responsibilities. A doctor in SH said: 'A doctor's work is clinical care, and if the clinical workload is heavy, sometimes it's only natural that you'll overlook other things'. The health facility checklist was used to assess ward infrastructure. The NICU in TH had three cubicles, with two sinks which were not always functional. SH had a much smaller NICU space, with two cubicles with a sink in each. Neither of the NICUs had a steady supply of soap, water or towels at the sinks, and the sinks designated for handwashing by mothers generally had the least supplies. HPs sometimes had to move out of the cubicles to the nursing station to access a sink with running water, and this was reported as a barrier to HH compliance (Table 3) . One HP complained: We use kitchen liquid soap to wash our hands, and it is so diluted. Disinfectant for cleaning equipment is also so diluted that it's meaningless. So when we clean the incubators, we're only redistributing the germs, because we don't have the right disinfectants (D2). Although a national IPC policy exists, it is not applied optimally in the NICUs. Only a few HPs said they had seen it previously or attempted to read it (Figure 1 , Policy-level factors). HPs wanted soft copies or summaries of essential practical portions of the bulky guideline in the form of posters or smaller protocols that can easily be assessed and utilized on the wards. There was no structured HAI surveillance in the NICU wards, so HPs were not aware of or able to keep track of HAI rates. Although both hospitals had microbiology laboratories that could identify infectious agents to treat babies who develop HAIs, mothers had to bear the costs of this, which some could not afford. Training and supervision to improve IPC practices Managers mentioned that there is a need for supervision to improve adherence to IPC guidelines in the wards. Managers also mentioned that senior nurses should enforce policies by being on the frontlines to work with the HPs and supervise them. As one manager said, 'If you don't war with them, you can't tell them how to fight' (MG2). Managers suggested the need for regular IPC training, which should not only be about the technical aspects of HAIs but should also cover the basics such as communication with clients. One said: 'Medical students should be taught to respect patients and relatives, even before they graduate'. Managers in both hospitals expressed the need to have a team of dedicated staff to oversee IPC activities and make IPC teams fully operational. Staff also undergo yearly appraisals; however, IPC is not a critical part of this appraisal. A manager mentioned that it would be useful to include IPC compliance as part of the criteria for staff appraisals and promotions (Figure 1, Policy-level factors) . Partnership to improve IPC in the NICU Mothers or family members are required to convey specimens to the laboratory, retrieve laboratory results and arrange the purchase of medicines for their babies. A partnership is crucial in this context because if mothers failed to fulfil this expectation, treatment could be delayed. Sometimes, mothers delayed in providing funds for laboratory tests due to a lack of understanding of the need for these tests in diagnosis (Observation#41SH). A mother explained that she would rather prioritize the use of her funds to buy medicine to cure her baby's illness than for tests that provide no cure. Mothers perceived partnership as HPs being present and attentive in interacting with them and their babies. Mothers and nurses performed common care activities for babies such as bathing, changing nappies and feeding. Mothers of preterm or low-birth-weight babies practised 'skin-to-skin' or kangaroo mother care in assigned rooms, which offered the opportunity to interact with HPs, especially in TH where an assigned nurse was present during the day shift. Nurses who were perceived to be friendly and showed positive attitudes towards mothers became the preferred ones whom most mothers would approach for interactions. Mothers received instructions from nurses on care practices, but this was often circumstantial and unstructured. Mothers referred to specific behaviours such as frowning, which made them feel unwelcome to interact with some HPs. Mothers expressed the need to be treated with respect irrespective of their background, as some felt that they were probably older than some HPs, which is especially a factor in Ghanaian society where seniority by age is given cognizance. A mother said: 'We are all human beings. . .so you should treat us as sisters. . .or friends'. When researchers enquired whether mothers would like to have an IPC-related role such as reminding staff to wash their hands, the responses suggested that mothers felt reluctant to participate in such roles. Mothers indicated that they did not want to be perceived as interrupting the provision of care. A mother said: 'When you try to do that, they will tell you that you are trying to tell them how to do their job'. Another mother who happened to be a doctor also said: As soon as you wear a patient's coat, you become a patient. . . so sometimes, you wouldn't want to offend the one taking care of your baby, because you feel that this person is taking care of my baby and what if she leaves my baby? (MT2). However, some mothers said they recognized the need to assume more responsibility to protect their babies. A mother who had lost one of her twins following an HAI believed it was the fault of the HPs and blamed the NICU practice of nursing twins together in the same incubator. She had concerns about the safety of the second twin and stated: If the one on duty is not doing well with my baby, I will complain; even if the person gets annoyed, I don't care! (MT6). One outspoken mother mentioned that some of the nurses found her irritating for being rather assertive: I mean once I find out the thing is not properly handled, I am not going to tolerate that, so they felt that I was irritating (MT8). HPs perceived that their authority would be challenged or mothers would lose confidence in them if mothers were empowered to take up the role of reminding them about HH. Some direct quotes reflecting HPs' perceptions are captured in Table 4 . HPs mentioned that it would require resources to promote IPC among mothers, e.g. the provision of aprons for mothers' use, to minimize infection risks to the babies. HPs added that they needed mothers to be compliant in caring for their babies. One HP said: When we are fortunate to get 'correct' mothers who know how to feed and handle their babies properly, the burden goes down. . .they pay for their labs and they are here to show love to their babies (N8). This study explored the perceptions of HPs and mothers on HAIs across a secondary and tertiary hospital in two NICUs in Ghana and provided contextual information about IPC practices. The findings of this study that HPs have modest levels of knowledge of HAIs are comparable with findings in previous studies in Ghana and THC1  18  0  2  1  1  1  1  4  2  8  0  THC2  15  1  2  1  1  1  1  3  2  6  0  THC3  22  2  2  2  1  0  0  2  1  8  0  THKMC  5  1  3  3  3  1  1  1  1  2  0  SHC1  10  0 AHR, alcohol hand rub; C1, C2, C3, cubicles 1, 2 and 3; HPs, health care providers; KMC, kangaroo mother care, where mothers are roomed in with their preterm babies to do skin-to-skin nursing; MS, mothers' HH area (at entrance); NS, nursing station (for use by HPs only); SH, secondary hospital; TH, tertiary hospital. elsewhere (Ocran and Tagoe, 2014; Ogoina et al., 2015; Akagbo et al., 2017; Wahdan et al., 2019) . There were key barriers and facilitators to IPC practices to reduce HAIs. The barriers include contextual factors such as resource constraints, HPs' distrust of mothers, the negative attitudes of some HPs and HPs' fear of having their authority undermined by mothers. Facilitators included the positive and approachable attitudes of some HPs, influence from colleagues to perform IPC and mothers learning from other mothers in the NICU. This study further used the socio-ecological model to present how personal-, interpersonal-, community-, institutionaland policy-level factors interact to influence IPC practices. While HPs reported that they gave mothers some information and orientation, they also admitted that heavy workloads and resource constraints hindered their ability to communicate IPC practices to mothers. Yet, they blamed mothers for some practices that they perceived as not hygienic enough. Mothers, on the other hand, reported that they were willing to learn hygienic practices since their interest was to protect their babies. Similarly, Aboungo et al. (2020) found that mothers were often blamed for negative health outcomes, and that blame is often directed at the actions or inactions of mothers or other factors that concern mothers. Blaming mothers may be a way of diverting responsibilities from HPs and other stakeholders. Our findings revealed a cultural clash between HPs and mothers, as HPs sometimes adopted a patriarchal approach, where mothers were given instructions to comply with but were not given the opportunity to ask questions or to comment on hygiene practices. Also, HPs expressed some level of distrust of mothers' ability to adapt to the hospital culture of hygiene practices and the use of hospital facilities, as there was the belief that some mothers came from villages that lacked such facilities and so were not familiar with their use. Similarly, Andersen's (2004) study in a regional hospital in Ghana revealed differential treatment towards clients who were considered poor, ignorant and uneducated, summed up in the term 'villagers'. A barrier that hindered HPs' communication on IPC with mothers was the fear that sharing professional and technical knowledge could compromise their authority in the NICU. HPs, therefore, minimized the exchange of information with mothers. Abraham and Shanley (1992) described HPs as 'authority figures' who engage in this behaviour to ensure that their authority and expertize remain unchallenged. McCann et al. (2008) also reported that fear of loss of power and control on the part HPs contributed to limitations being placed on parental interactions and involvement in care. Other studies have shown that HPs derive immense power from their knowledge, skills and access to clients, in the social field of the ward (Lipsky, 1980; Mintzberg, 1983) . Our findings show a gap in readiness on the part of most HPs to have empowering dialogues with mothers. Contrary to our findings, Aston et al. (2015) found that HPs challenged a health discourse that situated HPs as authority figures, and chose to develop relationships in ways that would build mothers' confidence and improve partnership. Bodenheimer et al. (2002) differentiated strength-based discourses, focused on mothers identifying and making healthcarerelated decisions, from the historical medical discourse that positions HPs as experts who assess and judge mothers' actions and ultimately tell them what to do. This suggests a need for transformation of HPs' perspectives and approach to dialogues with mothers in NICUs in Ghana, as the implementation of IPC practices to reduce HAIs is influenced by building and nurturing trust to improve collaboration between HPs and mothers. Mothers, irrespective of their background, felt powerless when their babies were admitted into the NICU because this was a different cultural context. Mothers felt compelled to submit to the higher authority of HPs in the interest of receiving quality care for their babies. This reflects the wider Ghanaian society, where traditional and institutional authority is obeyed and not questioned (Assimeng, 1999) . Such a practice was detrimental to mothers' ability to communicate and seek clarification from HPs, which led to safety concerns among mothers. Also, Zaman (2004) noted that the values and norms of society are expressed in the hospital wards, where people socialize hierarchically, and caregivers, who are mainly from poor economic backgrounds, are at the bottom of the hierarchy. The organizational culture in the NICU, which focused on biomedicine and thus dealt with technicalities and appropriate ways of holding babies or refraining from holding them as a form of IPC practice, was at variance with the typical Ghanaian culture that encourages parents and family members to hold and show affection to newborn babies. Sometimes HPs distrusted mothers and perceived them as a potential risk of infection to the babies, and this hindered positive and clear interaction between HPs and mothers. As the cultural ethos of each group presents a set of expectations and interpretations often at variance with one another, this adds new twists to the clash of cultures (Senah, 2002) . The limited communication further engendered mistrust among mothers of the good intention of HPs to protect their babies. Some mothers also felt disrespected by HPs due to their language, actions or inactions. However, respect did not appear to be the focus when HPs were dealing with issues relating to quality of care. Coe (1970) described Table 4 Direct quotes by HPs on perceptions of caregiver involvement in IPC in the NICU When you give them [mothers] that chance, the way they will talk to you might provoke you. . .but we as nurses should know what we are about (N1). It will bring problems because some of the mothers might think they know better than us. . . They will never have confidence in you. They will think you don't know your job. . . It brings down your morale (N2). Some of them. . .they are rude. It depends on how you will talk to me. If you are trying to teach me my work, then I will also give you what you also don't know (N3). In our setting, it will be difficult for a patient to tell a nurse to wash their hands. . .probably a health worker will feel offended when a patient says something like that, unless maybe it is said in a playful way (D1). It will be beneficial to them in the long run because when they go home it will also help them (N6). I think it will also help you the health worker when they draw your attention to these things to keep you in check (N7). If it is true you haven't washed your hands then you should take it cool. I don't think there is the need for me to get upset. . . I don't know about my other colleagues (PA1). It's all about continuous education. At least when we are always reminded about a precaution. . .we also have to involve the relatives in the education (D2). the lack of effective communication between HPs and clients as a great source of discontent in hospitals. Mothers were comfortable interacting and engaging with HPs who exhibited positive attitudes. This suggests that mothers are interested in gaining more knowledge and collaborating with HPs in the interest of their babies' health. However, they were also influenced by cultural beliefs and experienced a dualistic sense of responsibility to satisfy both cultural and hospital expectations when caring for their babies. This is similar to findings from previous studies in Zambia and Ghana (Moyer et al., 2014; Buser et al., 2020) . To address the varying cultural perspectives that engender distrust between HPs and mothers, further engagement and negotiations between HPs and mothers would be beneficial. Also, grandparents and other family and community stakeholders who influence mothers' decisions in newborn care should be engaged during educational sessions at the community level. One barrier to hygiene practice were resource constraints, which led to improvising such as gloving one hand instead of two when there were glove shortages. This also affected the HPs' ability to offer resources to mothers to encourage them to observe IPC practices. HPs had more access to HH resources than mothers, similar to findings in other LMICs (Horng et al., 2016) . Other studies have shown that when HPs are offered limited resources in the provision of health care, they exercise discretionary power by improvising and modifying policies, thereby influencing how policies are enacted (Walker and Gilson, 2004; Aberese-Ako et al., 2014) . Similarly, a study in Ghana found that it was common for HPs to improvise or modify protocols when basic supplies, logistics and infrastructure needed for adherence were inappropriate or not available (Yevoo et al., 2020) . For HPs to be able to respond to the needs of clients, there is the need for their requirements for essential resources, supplies and infrastructure to be addressed (Enweronu-Laryea et al., 2015; Aberese-Ako, 2016) , as these concerns compete with their focus on HAI concerns. This study illustrates the importance of discussing a partnership between HPs and mothers and negotiating the role of mothers. In doing this, attitudes, socio-cultural norms and the power distance wherein HPs and mothers operate in a super-and subordinate relationship (Senah, 2002) should not be overlooked. HPs should be aware of how their positions of expertize within the NICU affect interactions with mothers. A deeper understanding of personal, social and institutional aspects of IPC and HAIs will provide opportunities to reflect upon and change practices to support and involve mothers. Partnerships foster improved adherence, and ultimately improve healthcare outcomes (Martin et al., 2005) . Participation, engagement, negotiation and sometimes compromise enhance opportunities for interactions in which mothers, as key stakeholders, take responsibility for their part in promoting IPC to reduce HAIs. The findings of this study showed that IPC practices have not been implemented effectively in the NICUs. These findings suggest that communication and partnership that encourage caregiver involvement in IPC should be developed through interactions. Similar to our findings, other studies have pointed out the need for the medical and nursing curricula to emphasize interpersonal communication in healthcare, and to incorporate trainings that allow HPs to learn, practise and reflect on their provision of respectful care and communication (Afulani et al., 2019; Lim et al., 2019) . These trainings should be incorporated into the pre-service and in-service training of HPs to improve mothers' experiences in NICUs in Ghana. Our findings outline the current challenges associated with the effective practice of IPC, which should guide policymakers to strengthen measures to improve the implementation of existing IPC policies in the NICU. Findings from this study provide insights to inform strategies to raise the priority of IPC and limit harm from HAIs in Ghana. Interviews with mothers were conducted within the hospital setting, and mothers may be unwilling to be critical of HPs who are caring for their hospitalized babies. We took steps to build trusting relationships with the mothers and to assure them of confidentiality. We also spent long periods building rapport with HPs to minimize the Hawthorne effect. There is the potential for losing meaning and nuance in the interviews which were conducted in Akan and translated into English. Transcripts were doubled checked by a second research assistant to ensure that original meanings were retained as much as possible. This study explores attitudes and general beliefs, and presented only a few examples of actual cases of HAIs. An important next step in research would be to link attitudes, beliefs and practices to the occurrence of HAIs. Supplementary data are available at Health Policy and Planning online.@story_separate@HPs and mothers demonstrated a modest level of understanding about HAIs and IPC practices. Some key barriers and facilitators to knowledge and observance of IPC practices to reduce HAIs were identified. The barriers included non-adherence to protocols, negative and patronizing attitudes of some HPs towards mothers, fear of loss of authority, resource constraints in the hospital systems and poor supervision and implementation of IPC policies. Facilitators included positive and approachable attitudes exhibited by some HPs within the NICU, influence from colleagues to perform IPC, mothers receiving information on IPC from the antenatal clinics and peer support from other mothers. There is the potential to form a partnership between HPs and mothers in promoting IPC practices in Ghanaian health facilities. This is critical considering that Ghana is a low-resource country with limited budgets for health care, so improving IPC could reduce infections and thus save facilities and families from extended hospital stays, with consequent costs of treatment. However, this requires partnerships where mothers are seen as part of the solution, for if mothers are perceived as distrustful and seeking to undermine the authority of HPs, this common objective will not be achieved. Effective communication between HPs and mothers should be a key area of focus in promoting partnerships to reduce the burden of HAIs, particularly among neonates in Ghana. This requires clearly defined policies and strategies that define, acknowledge and value mothers' roles as caregivers, and encourage partnership between HPs and mothers. There is a need for maintaining standard precautions and practices more effectively and efficiently. HPs need to make deliberate efforts to go beyond personal and professional barriers, to acknowledge the role of mothers in patient safety and to empower mothers and caregivers in promoting IPC. There is a need for hospitals to improve the supervision and monitoring of HPs, as some of the gaps in IPC compliance were noted to be due to limited supervision and follow-up. In addition, there is the need for hospitals to devote more funds to providing equipment and hygiene-related medical supplies, which will help to improve hygiene conditions. Also, IPC guidelines should be made available to all staff, and training on HAIs and IPC should be provided regularly to incoming staff and students. Structured training at health facilities must aim to both provide both technical knowledge and develop HPs' interpersonal communication skills, to help bridge the gap between HPs and caregivers. It is also important that medical and nursing curricula emphasize interpersonal communication and patient-centred care.","Healthcare-associated infections (HAIs) remain a serious threat to patient safety worldwide, particularly in low- and middle-income countries. Reducing the burden of HAIs through the observation and enforcement of infection prevention and control (IPC) practices remains a priority. Despite growing emphasis on HAI prevention in low- and middle-income countries, limited evidence is available to improve IPC practices to reduce HAIs. This study examined the perspectives of healthcare providers (HPs) and mothers in the neonatal intensive care unit on HAIs and determined the major barriers and facilitators to promoting standard IPC practices. This study draws on data from an ethnographic study using 38 in-depth interviews, four focus group discussions and participant observation conducted among HPs and mothers in neonatal intensive care units of a secondary- and tertiary-level hospital in Ghana. The qualitative data were analysed using a grounded theory approach, and NVivo 12 to facilitate coding. HPs and mothers demonstrated a modest level of understanding about HAIs. Personal, interpersonal, community, organizational and policy-level factors interacted in complex ways to influence IPC practices. HPs sometimes considered HAI concerns to be secondary in the face of a heavy clinical workload, a lack of structured systems and the quest to protect professional authority. The positive attitudes of some HPs, and peer interactions promoted standard IPC practices. Mothers expressed interest in participation in IPC activities. It however requires systematic efforts by HPs to partner with mothers in IPC. Training and capacity building of HPs, provision of adequate resources and improving communication between HPs and mothers were recommended to improve standard IPC practices. We conclude that there is a need for institutionalizing IPC policies and strengthening strategies that acknowledge and value mothers’ roles as caregivers and partners in IPC. To ensure this, HPs should be better equipped to prioritize communication and collaboration with mothers to reduce the burden of HAIs."
"Fungi are the second largest group of eukaryotes that play a significant role in human health. The widespread prevalence of fungi in the environment and food chain makes them hazardous for humans. Mycotoxins contamination of agricultural produce is a serious threat to human health [1] . The ingestion of mycotoxins contaminated food, results acute and chronic toxicity to the humans and animals. Food and Agricultural Organization (FAO) suggested that about 25 % of the global food crops were contaminated by mycotoxins [2] . Approximately 300-400 mycotoxins have been identified, nevertheless, Aspergillus-derived mycotoxins have attracted the greatest attention to human, animal, and plant health (Fig. 1) . The assessment of hazardous mycotoxin production and toxigenic fungal species is critical in assessing food safety and quality [3, 4] . World Health Organization (WHO) and FAO, addressed global problem of mycotoxin contamination in food by adopting strict regulatory guidelines [5, 6] . The joint scientific advisory committee expressed the responsibility for the evaluation of health risks from mycotoxins (WHO/FAO) [2] [3] [4] [5] . Aspergillus species produce various life-threatening biotoxins such as aflatoxins (AFTs), ochratoxins (OTA), patulin (PAT), citrinin (CIT), aflatrem (AT), secalonic acids (SA), cyclopiazonic acid (CPA), terrein (TR), sterigmatocystin (ST) and gliotoxin (GT), and other characteristic molecules [6, 7] . AFTs outbreaks was reported in India and stands for the 30 % food contamination globally. AFTs are thermostable, genotoxic, hepatotoxic, mutagenic, teratogenic, and carcinogenic, even nanogram levels. AFB1, AFB2, AFG1, and AFG2 that tainting various agronomic crops, food and feed and pose a potential risk to wellbeing's. AFB1 metabolized as AFM1 in mammals. AFG2 and AFB2 are metabolized AFG1 and AFB1 after ingestion, respectively. OTA and CIT synergistically causative agent of Balkan Endemic Nephropathy (BEN), attenuate the RNA synthesis in renal disorders. AT reported to cause staggers syndromes, and neurodegenerative disorders in both animals and humans. Moreover, PAT produced by Penicillium, Aspergillus, Paecilomyces, and Byssochlamys, and contaminates various food and fruits. PAT prompts ulcers, inflammation, and intestinal hemorrhage. Similarly, CPA, GT, STC, TA and other small molecules/natural metabolites produced by species of Aspergillus exhibited extended toxicity to the humans and animals. Regrettably, various countries have failed to regulate the presence of toxins in food and feed. Aspergillus species are widely distributed, grow on almost all humid substrates, and threaten public health in indoor environments. More than 600 fungal species are in human contact and about 50 species are widely recognized and characterized in epidemiological studies. Inhalation is a primary route of human exposure to fungal propagules. Indoor fungi cause irritative disorders such as allergy and asthma. Biological airborne particles such as fungi, bacteria, viruses, allergens, and biological fragments are present abundantly known as bioaerosols. Filamentous fungi is a significant genera of Aspergillus, Fusarium, Penicillium, Mucor, and Scedosporium present in the environment causing acute and chronic toxicity in humans. Fungal bioaerosols are readily breathable, consisting of spores and hyphal fragments, and are active elicitors of bronchial irritation and allergy. Besides, specific antigens from this pathogenic fungus in the environment induce hypersensitivity (HST). The fungal spores or occupational contaminants mediate HST and activate signs of pneumonia, inducing acute or chronic lung disease. Also, these spores are ingested along with food, and they can even come in contact with skin, leading to several conditions. Influenza-like fever, respiratory symptoms, organic dust toxic syndrome (ODTS), bronchopulmonary aspergillosis, invasive aspergillosis, pulmonary aspergilloma are some of the infectious diseases caused by large fungal spores in the atmosphere. Furthermore, several researchers are working on methods ranging from traditional densitometer thin-layer chromatography (TLC) to advanced and precise detection of mycotoxins. Researchers have developed aptamer (APT)-based diagnostics in recent years, there have been no attempts to adapt current technologies to prepare POC diagnostic platforms. APTs are single-stranded oligonucleotides (ssDNA) that bind to their targets in a precise manner, ranging from small organic molecules to biological macromolecules. Specific APT are generated by systematic evolution of ligands through exponential enrichment (SELEX) processes. The word ""rapid process"" generally refers to a method that is significantly faster than the reference method and has a proclivity to promote the method. Many PoC test instruments are made up of simple membrane-based test strips that come with a test cassette for the rapid detection of various toxigenic fungi and their mycotoxins. In this current review, authors are highlighted the Aspergillus derived mycotoxins in various agrarians produce, processing foods, fruits, meat, milk, alcoholic beverages, oil seeds, and indoor air. Besides its global occurrence, various toxicity such as liver, HCC, human hepatocytes, esophageal epithelial cells, alveolar type II (AT-II) cells, AC3F1 mouse, and AC3F1 mouse models, Kidney, liver cells, neurotoxic cell lines (SHSY5Y, neuro 2 a, HepG2 Cells), HT29, Caco-2, HEK293, yeast model, fibroblasts, a pulmonary tumor cell line, and human gastric epithelial cells (Chk1) was reviewed for the understanding the toxicity of mycotoxins. Furthermore, proteomics, genomics, transcriptomics, and other OMICS approaches for the characterization, and precise detection of various toxins also discussed. Interestingly, aptamer-based methods, and other new technologies used in the study of mycotoxins was also discussed.@story_separate@The current reviews the published research and review literature about the Aspergillus derived mycotoxins such as effects of aflatoxins (AFTs), ochratoxins (OTA), patulin (PAT), citrinin (CIT), aflatrem (AFT), secalonic acids (SA), cyclopiazonic acid (CPA), terrein (TR), sterigmatocystin (ST) and gliotoxin (GT). This systematic review included fungal contamination of food and feed and effects of Aspergillus-derived toxins on food safety and human health. For inclusion criteria, the data obtained from diverse toxigenic species of Aspergillus is tabulated with specific sources of world-wide occurrence production of mycotoxins in food and environmental samples. The pivotal aim of the present review is to understand the prevalence and toxicity of Aspergillus in the food feed. Moreover, the non-toxic Aspergillus were excluded in this review. Owing to the medical nature of the question, the search was confined to PubMed, Scopus, Web of Science, and Google Scholar. About 300 abstracts, full text, Graphical abstract published from 1960 to 2020. Samples of various forms of foodstuffs, outdoor air for the isolation of toxigenic fungi in this study. Mold poisoning due to ergot alkaloid is known to occur for many decades, although acquisition notoriety only after the epoch-making discovery of AFTs in 1961. The severity of the toxin and its effects are possibly shared by nutrient scarcity, caloric deficit, alcoholism abuse, and contagious disease. Susceptibility to microbial infections augments the effects of malnutrition. Many countries have established permissible confines for such toxins in food and feed intended for consumption because of the life-threatening implications of these toxins. The Scientific Committee on Food (SCF) provided a very similar strategy to the European Union (EU), which resulted in scientific opinions for the regulation of mycotoxins. Nevertheless, no specific maximum limits are defined in major markets globally such as India. Along with the high stability and accumulation of mycotoxins during grain storage and processing, the lack of identification of these toxins at the point of care (PoC) centers is of great concern. PoC are basic medical diagnoses (tests) performed close to the patient's point of treatment in order to obtain real-time, lab-quality outcomes in minutes. It provides users with fast, convenient transportation that should accurate and affordable. AFTs are the world's leading food and environmental species of Aspergillus which account for approximately 30 % contamination on their own [8] . In India, there have been many mycotoxicosis outbreaks over the past 40 years, such as AFTs hepatitis [9] . Entero-ergotism outbreak in Rajasthan, Maharashtra, and Gujarat in 1976 due to the ingestion of bajra infected with ergot alkaloids caused degnala disease in buffaloes and cattle. Childhood cirrhosis [10] , inclusion body hepatitis was found in poultry in Northern India. The extreme aflatoxicosis outbreak in chicken occurred in Himachal Pradesh. Gujarat and Rajasthan were affected in western India, and 106 died during 1974 from the consumption of contaminated grains with toxins. A survey reported a total of 19,757 mycotoxins in feedstuffs in 2004, whereas, AFTs were more widespread in Southeast Asia [11] . Of all major mycotoxins, AFTs, which are a group of furanocoumarins derived polyketides, are the most toxic and carcinogenic. AFB1, AFB2, AFG1, and AFG2 are major AFTs that contaminate various agricultural produce and pose a potential risk to livestock and human health. The biosynthetic pathway of AFTs is a complex system coded by a 70 kb DNA sequence ( Fig. 2) with 25 genes or open reading frames (ORFs) representing a well-defined AFTs biosynthetic pathway gene cluster. The cluster of genes for the pathway is completely annotated in A. parasiticus containing 2.8 kb of chromosomal DNA [9] . So far, 15 structurally and well-established intermediates and at least 23 enzymatic reactions have been reported for AFTs biosynthetic pathway [12, 5] . Aflatoxins are toxic metabolites produced by various Aspergillus species, primarily A. flavus and A.parasiticus that pose a serious threat to humans and livestock health [13] . AFTs were first discovered as a causative agent for the disease ""turkey X"" in 1960 in England. These toxins also occur naturally in foodstuffs such as groundnuts [14] , maize, rice [15, 16] , cotton seeds, legumes, cereals [17] , spices [18] , crude vegetable oils [19] , and cocoa beans [20] . AFTs are classified into aflatoxin B1, B2, G1, and G2 [21] . AFT-induced epidemics have killed many turkeys, pheasants, and [198] . ducklings alike. Originally, traces of AFTs were found in the chick feed, which included Brazilian groundnut food [22] . Afterward, the term AFTs was coined, symbolizing A. flavus [23] . In Kenya, too, few acute aflatoxicosis patients were recorded in 1981, when a drought was followed by heavy rainfall [24] . The AFTs' classification is based on their fluorescence property. AFB1 and AFB2 belong to the blue fluorescent (B) group in which the lactone ring of the coumarin moiety is fused to the cyclopentenone ring. Whereas the members of the green fluorescent (G) AFG1 and AFG2 toxins are formed by the fusion of lactone ring with cyclopentenone ring [23] . AFG2 and AFB2 are both harmless until they are metabolized after ingestion into AFG1 and AFB1, respectively. AFB1 in mammals is further metabolized to various hydroxylation products, such as AFM1 (""milk toxin""), which is further excreted in milk [24, 25] . AFB1 can also be converted into AFQ1, AFP1, AFB2a, AFH1, and AFL [26, 27] . AFTs are genotoxic, hepatotoxic [28] , mutagenic [29] , teratogenic [30] , and carcinogenic [31] . Specifically, the transversion mutation, G→T is caused by AFB1 activity. Patients who are already diagnosed with the hepatitis B virus (HBV) are more likely to develop hepatocellular carcinoma (HCC) when exposed to AFB1 [32] . However, for longer periods, even lower doses of AFTs can result in both immunosuppression and nutritional interference [5] . Genotoxicity of AFTs was evaluated using the γH2AX assay in HepG2 human hepatoblastoma cells, human renal cell adenocarcinoma cells, and LS-174 T human epithelial colorectal adenocarcinoma cells. AFB1 can increase the expression of transcription factor Nrf2 and decrease the expression of liver Acc, disrupting hepatic mitochondrial lipid production and antioxidant capability [33] . AFB1 may change the proportion of DNA bases and may cause G: C to T: A and G: C to A: T transversions and transitions mutations, respectively in the liver cells [34] . A study found that 11 % of the 480 Chinese spices comprised noticeable amounts of AFTs, especially at higher levels in chili, prickly ash, and pepper [35] . Contamination with AFTB1 has been observed in Korean meju (crushed fermented soybean cake) at concentrations of 6.9 μg/kg [36] . The average tolerance for AFTs in soybean, as well as groundnut, is 4 μg/kg according to the European Union (EU). The concentration of AFB1 found in feed ranged from 4.22 and 10.54 μg/kg [37] . Climate change leads to an increase in the AFB1 concentration in maize and dairy feed samples [38, 39] . AFB1 exhibits carcinogenic, teratogenic, and mutagenic effects when compared with other toxins [40] . Mice deficient in the xerodermapigmentosum (XPA) gene exposed to AFB1 are more susceptible to both natural tumor development and hepatocarcinogenesis (HCC) [41] . AFTs are at the highest degree of contamination in butter, sugar, and dark chocolate [42] . The food fermenting A. oryzae M2040 strain isolated from Korean Meju may inhibit the development of AFB1 and the spread of toxigenic A. flavus in vitro and peanuts [43] . Yeasts, bacteria cells, proteins, etc. most widely used in animal feed as a binder to mitigate the harm caused by AFTs [44] . AFTs are commonly found in maize and other crops which are grown in warmer climates and present a serious threat to health in many regions of the world [45] . AFG1 and AFG2 are produced by several species of Aspergillus. In most cases, AFG1 is documented to be at higher levels of contamination than AFB2 and AFG2. Interestingly, no production of AFB2, as observed during the sense of AFG1, AFG2 [46] . AFB1 exhibits higher toxicity and carcinogenicity followed by AFG1, AFB2, and AFG2. These contaminants are not eliminated during industrial food processing, due to their high-temperature stability, as a result, they harbor even in bakery products and foods for infants and children [47] . Across China, a higher amount of AFG1 is detected in the population with elevated cases of gastric carcinoma and esophageal carcinoma [48] . AFG1 oral administration to mice, rodents, and hamsters has reduced altered hepatocytes, hepatocellular adenomas, carcinomas, and renal-cell tumors of the kidney cells. Severe outcomes, including elevated serum triglycerides, excessive inflammation in the liver cells, neutral fat accumulation, sudden autolysis of cells, death due to ingestion of food contaminated with AFG1 have been reported [49, 50] . Feeding animals, affected by the consumption of toxin-contaminated groundnut cake (AFB1, AFB2, AFG1, and AFG2) showed the spread of connective tissue destroying hepatocytes and liver damage following clinical diagnosis [51, 52] . AFG1 induced inflammatory response of the TNF-α in lung cells and caused in vitro oxidative DNA damage that may lead to lung carcinogenicity [53] 3.1.4. Aflatoxin M1 (AFM1) and M2 (AFM2) AFM1 and AFM2 are usually detected after the ingestion of contaminated milk and milk products by humans. AFM1 is a by-product of AFB1 that is also reported to be toxic and carcinogenic and functions as a hydroxylated AFB1 metabolite in humans and animals [54, 55] . Since cytochrome P450 (in microsome) is abundant in the liver, M1 is derived from AFB1 and is present in animal milk [56] . It is known to be hazardous to humans and is associated with carcinogenicity, genotoxicity, mutagenicity [57] . AFB1 and AFB2 metabolites are hydroxylated into AFM1 and AFM2 and are usually detected in milk and milk products derived from animals fed on infected grains [58] . Ingestion of excessive quantities of AFTs or long-term intake has led to the death of milch animals. Also, AFTs have been reported for milk production defects, immune system suppression followed by reproductive efficiency, and resulting in the development of bovine cancers [59] . The carcinogenicity of in-vivo AFM1 is about 10 % higher than that of AFB1, AFM1 is characterized by DNA-damage, one-third compared to that of AFB1 [60] . Similarly, in dairy products, AFM2 is a toxic metabolite, which is a 4-dihydroxy derivative of AFB2 [61] . The AFM2 residue levels which are not governed by dairy cattle regulations was around 15 times higher than AFM1 residue levels. On the other hand, the AFM2 toxicity spectrum may be lower than that of AFM1 [62] . Acute aflatoxicosis causes persistent symptoms of fatigue, loss of appetite, fatty liver, jaundice, decreased milk production in dairy cattle. Nonetheless, the US Food and Drug Administration (USFDA), set the maximum amount of AFM1 in milk as 0.05 μg/kg, [63] . Aflatrem (AT) is a potent tremorgenic toxin (indole-diterpene) produced by A. flavus and the diminutive amount by A. minisclerotigenes. These strains are capable to produce paspalitrems, paspaline, terpendoles, shearinines, penitrems, lolitrems, janthitrems, paxilline, and supinates [64] . AT is known to cause neurological disorders and is visible as noxious food decay that grows on a variety of products [65] . Geranylgeranyl diphosphate (GGPP) is a precursor of all of these metabolites and they also have an indole moiety derived from tryptophan [66] . AT has been described to cause staggers syndromes, which include a variety of neurodegenerative disorders characterized by muscle tremors and hyperexcitability, and therefore is a health hazard for both animals and humans [67] . Sequences of genes that are highly similar to paxillin synthesis were found in the sequence data consisting of complete genomes of A.flavus NRRL3357 and A. oryzae RIB40. The genes atmG, atmC, and atmM which are homologous to paxG, paxC, and paxM respectively are required for AT production [68] . Nonetheless, the ATM1 locus expresses putative orthologs of only three of the seven genes required for paxilline biosynthesis. The remaining genes similar to the paxilline biosynthesis genes paxA, paxB, paxP, and paxQ were identified at the second locus, ATM2, and constituted a 25 kb gene cluster [69] (Fig. 3 ). Ochratoxins are secondary metabolites of fungal origin which are chemically known as OTA, OTB, and OTC. The OTB and OTC are less toxic, because of the absence of chlorine [70] . OTA is derived from a β-phenylalanine-associated polyketide synthase (PKS) (dihydrocoumarin family) [71] . While there is a great deal of knowledge about toxigenic properties of OTA, unlike other important mycotoxins, A detailed biosynthetic pathway of OTA in any fungal species (Fig. 4) . The isocoumarin group is widely believed to be a pentapeptide formed from acetate and malonate throughsynthetic PKS pathways. OTA biosynthesis requires a PKS gene which is known to be the main enzyme [72] . The heterocyclic component of OTA is similar in structure to mullein produced by A. ochraceus, A. westerdijkiae, and A. melleus. OTA is produced primarily by the species of Aspergillus and Penicillium, which are distributed worldwide [53] .It is a significant and detrimental toxin [54] , which contaminates a variety of foodstuffs, such as grapes [55] , coffee [56] , cocoa, nuts [57] , infant food [58] , wine [59] , corn [60] , rice [61] , wheat [62] , meat [63] , cheese [64] , beer [65] , feedstuffs [66] , oilseeds [62] and indoor air [1] . OTA is produced during crop storage and is responsible for various cyanogenic effects in animals. This toxin primarily affects the kidneys and also harms the immune system. Contrary to strong evidence of renal organ toxicity and renal organ cancer in animals exposed to OTA, there is no evidence of damage of renal organs in humans, but effects on the renal organs are incontestable. Furthermore, OTA is also confirmed to be, neurotoxic, hepatotoxic, immunotoxic, genotoxic, embryotoxic, teratogenic, and carcinogenic in animals and humans [67, 68] . Humans are exposed to OTA by numerous routes such as dietary route, dermal contact, and by inhalation [69] . International Agency for Research on Cancer (IARC), classified OTA to a human Group 2B carcinogen (IARC, 1993). OTA has also been detected in animal and human body fluids and kidneys [69, 70] . OTA is not completely removed during cooking [72] . It can also withstand 3 h of sterilization at 121 • C and higher temperatures and can be only partially degraded at 250 • C [73] OTA absorption occurs in the stomach, which plays a crucial role in enterohepatic circulation. Moreover, OTA decreases the ability of the kidney to absorb the filtrate and has detrimental effects on the glomerular filtration rate which impairs the function of the kidneys epithelial cells [74] . The majority of animals affected by the consumption of contaminated feed from OTA are horses, cattle, goats, pigs, sheep, poultry, swine [75] , and birds [76] . Laying chicks had exhibited medical symptoms of OTA intoxication. In poultry birds, reduction as well as delay in egg and weight development, increased number of discolored eggs, decalcification of eggshells, shape change, high urates content resulting diarrhea, refusal of feed, frailty, and even death [77] . Geno-toxicity of OTA treatment was induced increased levels of apoptosis, expression of oxidative stress genes studied on male Wistar rat's kidney [78, 79] . Also, an increased percentage of DNA in the tail observed in Vero-E6 cell lines [80] . The combined toxicity of OTA, AFTs, and OTA, PAT exhibited the significant DNA strand break upon exposure of 60 min studied on human peripheral blood lymphocytes [81, 82] . OTA has been isolated from A. ochraceus, but studies have shown that diverse fungal species are also capable of producing OTA [83] . A. carbonarius, A. ochraceus, and A. westerdijkiae produce a huge quantity of OTA in grape products [84, 85] and coffee beans [73, 86, 87] . Also, A. niger aggregates have been reported as OTA producers on natural substrates and section Nigri produces a smaller amount of OTA than A. carbonarius [88, 89] . A. lacticoffeatus and A. sclerotioniger also produce OTA [90] . A. pseudoelegans, A.cretensis, A. roseoglobulosus, A. flocculosus, A. sclerotiorum, A. sulphurous, A.ochraceushave been reported as OTA producers [91] [92] [93] . And details of OTA producing Aspergillusspecies are depicted in Table 1 . OTA is a causative agent of Balkan Endemic Nephropathy (BEN), a progressive disorder that results in irreversible human kidney failure. Moreover, due to its strong binding to human serum macromolecules, it has a prolonged serum half-life which delays its removal from the body [159] . OTA biotransformation can be brought about by Cytochrome P450 3A4 (CYP 3A4), Cytochrome P450 Family 1 Subfamily A Member 1 (CYP 1A1), and Cytochrome P450 2C9 (CYP 2C9-1) [160] . DNA adducts may also occur in animals that are exposed to OTA [161] . Due to OTA toxicity; oxidative stress, liver toxicity, nephropathy, cell apoptosis, cell autophagy, calcium homeostasis, protein synthesis inhibition, etc. have been observed [75] . The mTOR/AKT pathways are remarkably decontrolled in rodents after exposure to OTA and this contributes to the carcinogenicity of kidney cells [162] . Citrinin (CIT) is a polyketide metabolite of P. citrinum and is characterized as an antibiotic that acts against bacteria, bacteriophages, sarcomas, protozoa, and animal cells [163] . It is a renal toxin that affects poultry birds, domestic animals, and humans [164] , CIT is involved in the etiology of endemic nephropathy, and is also genotoxic, embryocidal, and fetotoxic although the CIT molecular mechanism of toxicity is not completely unknown [165] . It shows structural similarity to OTA. Several species can produce CIT, among them are A. alabamensis, A. carneus, A. floccose A. allahabadii, A. hortai, A. neoindicus, A. pseudoterreus, A. niveus, and A. flavipesare important species [94, 103] . CIT and OTA both function synergistically to attenuate the activity of RNA synthesis in renal tissue [166, 167] and causes renal disorders as a result of the development of DNA adduct with an increase in the formation of C-C8dG-OTA adduct [168] . Interestingly, the possibility of carcinogenesis in humans is significantly increased by CIT and OTA [169] . M. ruber is capable of biosynthesis of CIT along with natural red dye [170] . Moreover, Aspergillus and Penicillium, synthesizing CIT indicate a potential difference in the CIT biosynthetic pathway from that of M. ruber (Fig. 5 ), but they don't produce any pigment. CIT is formed by the condensation of a single acetyl-CoA molecule with four malonyl CoA accompanied by the addition of three methyl units in Aspergillus species [171] . Patulin (PAT) is a toxic metabolites produced by about 30 genera belonging to Penicillium, Aspergillus, Paecilomyces, and Byssochlamys, etc which in food and fruits [124, 172] . Genus Aspergillus, Clavati group: A. clavatus, A. giganteus, and A. longivesica can producePAT [120] . It was evaluated for human medicinal purposes under the drug forename, Tercinin as a probable antibiotic but had been abandoned due to its toxicity to humans and animals [173] . Due to its suspected toxicity, PAT has been included in the list of mycotoxins and its level in foods is limited in several countries. Permissible amounts of PAT in juices (50 μg/L), solid apple products (25 μg/L) have been laid down, and foods intended for infants and children [174] . Structurally PAT has a strong affinity to the sulfhydryl groups (S -H) which describes its inhibition of various enzymes [175] . It induces ulcers, inflammation, and intestinal hemorrhage [176] , as well as reduction of TEER (trans-endothelial electrical resistance), mediated inactivation of protein tyrosine phosphatase in human intestinal cell lines HT29 and Caco-2 [175] . PAT affects human embryonic renal cell development (HEK293) resulting in increased oxidative stress and eventually apoptosis [172, 177] . It also results in increased levels of Th2 cytokine and elevated production of IFN-gamma, causes airway hyperactivity, hemorrhage, enlarged interstitial tissue, cortex dilation and fibrosis [178] , increased serum ALT (alanine transaminase), AST (aspartate transaminase), lipid peroxidation and leads to cell damage [179] . On another hand, it leads to reduced activity of glutathione peroxidase and glutathione reductase activity [179] which leads to type 2 diabetes and is further associated with diabetic nephropathy. Mitochondrial ATP depletion and lysosomal failure were diagnosed with PAT exposure [180] . Expression of p53, bax, and cytochrome C was observed when rats were exposed to PAT, along with the downregulation of bcl2 in kidney cells [181] . PAT also leads to glomeruli disintegration and hemorrhage of the kidney [182] . Biosynthetic gene clusters linked to PAT biosynthesis have been established. PAT biosynthesis is catalyzed by 6-methyl salicylic acid synthase (6MSAS). The isoepoxydon dehydrogenase (IDH) gene which is encoding the seventh enzyme involved in PAT biosynthesis in P. griseofulvum. A cluster of 15 genes located in the 40 kb region is involved in PAT biosynthesis in A. clavatus [119] . The formation of 6-methyl salicylic acid (6MSA) by condensation of one acetyl-CoA and three malonyl-CoA units is carried out by acetyl and malonyl transferase, ketoacyl synthase, ketoreductase, and dehydratase [183] , and the complete biosynthetic pathway is depicted in Fig. 6 . Terrein (Ter A) is a secondary, toxic metabolite isolated from several species of Aspergillus viz, A. terreus, A. lentulus, A. novofumigatus, A. fischeri, A. stellatus [147, 148] . The complete biosynthetic pathway is not clearly defined, but there are 11 putative genes and their role in TR biosynthesis was elucidated [184] . Ter A has several effects, including anti-inflammatory anti-oxidant [63] , anti-proliferative, and skin-whitening properties [35] . Ter A demonstrated angiogenesis inhibition in the androgen-dependent cell line (LNCaP-CR) of prostate cancer [185] . The biosynthetic pathway of Ter A is shown in Fig. 7 . Initially, TerA produces compounds 5 (4-HMP; 4 hydroxy 6 methylpyranone), 4 (OA; orsellinic acid), and 6 (2,3-dehydro-6-HM; 6-hydroxymellein) by condensing acetyl-CoA with two, three, or four malonyl-CoA units. 6-HM (6-hydroxymellein) serves as a precursor for terrein production [184] . Ter A also functions as a proteasome inhibitor by reducing chymotrypsin activity and encourages apoptotic cell fatality in tumoral cell lines of the human lung (NCI-H292) [186] . It also inhibits human breast cancer cell proliferation [187] . The Ter A toxicity study of human lung and Zaehleenocarcinoma epithelial cell line showed inhibition of cell viability, proliferation, and morphological changes [177] . It also leads to the secretion of vascular endothelial growth factor (VEGF) and phosphorylation of STAT3, ERK1/2, and JNK1/2 in HGFs [188] . Gliotoxin (GT) belongs to a class of cyclic dipeptides of fungal metabolites epipolythiodioxopiperazin (ETP) initially discovered in Gliocladium fimbriatum [189] [190] [191] . Later production of GT was identified in A. fumigatus, Eurotium chevalieri, Trichoderma, and Penicillium. GT biosynthetic gene is responsible for ETP biosynthesis [192] and currently, 12 biosynthetic pathway genes that are responsible for GT biosynthesis have been identified in A. fumigatus. The ETP biosynthesis genes code for sirodesmin biosynthesis and other ETP-type toxins are gliovirin, epicoccin A, sirodesmin A, and sporidesmin A. The GT gene cluster comprises 13 genes consisting of gliZ, gliI, gliJ, gliP, gliC, gliF, gliM, gliG, gliK, gliA, gliN, gliT, gliH [193] . However, GT biosynthesis continues to revolve around several open issues in GT biosynthesis (Fig. 8) . The GT has various adverse reactions including genotoxicity, immunosuppression, apoptosis, and cytotoxicity. This toxin also demonstrated strenuous genotoxic effects, DNA damage, and inhibition Table 1 Worldwide occurrence of Aspergillus species and production of mycotoxins in food and the environment. [ of human lymphocyte development [194] . Sterigmatocystin (STC) is a toxic metabolite belonging to fungal polyketides, a precursor for AFB1, and is one of the most significant carcinogenic toxins. STC was isolated in 1957 for the first time from A. versicolor but it is also produced by several Aspergillus species. STC contamination occurs in several crops and is detected frequently in food grains, green coffee beans, spices, and dairy products [195, 196] . Furthermore, agricultural commodities contaminated with these fungi contain elevated concentrations of STC. A. flavus and A. parasiticus infestation are responsible for trace amounts of STC, which is converted into AFTs [87] . The structure of the STC is closely related to AFB1, but the lethal potency of the STC is about one-tenth (1/10 th ) of AFB1 [197] . The STC biosynthesis pathway includes a 60-kb genome region containing a cluster of 25 genes required for STC biosynthesis (Fig. 9 ) [198] . It has many toxic effects such as immuno-modulatory activity [193] , mutagenic [200] , chromosomal damages [201, 202] , cytotoxicity [203] , inhibition of cell-cycle [204, 205] , oxidative stress in liver of chicks [206] . DNA damage in the human liver [207] and reactive oxygen species (ROS) that leads to lipid peroxidation [208] . There is no regulation for the maximum allowed limit of STC in the food chain. Nevertheless, from a scientific point of view, the European Food Safety Authority (EFSA) acknowledged the possibilities of STC contamination in food and feed [209] . Besides, STC contamination of rice has been reported globally [196] . Cyclopiazonic acid (CPA) is a secondary metabolite (indoletetrameric acid) isolated from species of Aspergillus and Penicillium [210] , [304] . originally discovered in P. cyclopium Westling (Synonyms: P. griseofulvum Dierckx). P. cyclopium was isolated from groundnuts that induced acute toxicosis in ducklings and rats [134, 211] . Historically, CPA has also been reported to occur in food commodities of plant origin and is frequently detected in peanuts and maize. Prevalence of CPA has been observed in corn, peanuts, Kodo millet, sunflower seed, rice, cheese, poultry quail feed, and is associated with alleged field outbreaks of CPA toxicity [212, 213, 210] . CPA is a common mycotoxin and co-occurs with AFTs and is identified to be the causative agent of Turkey X disease. Apart from being harmful to rats, pigs, guinea pigs, chickens, dogs, CPA is also carcinogenic to humans. In addition to CPA, P. cyclopium also produces non-toxic indole derivatives, such as α-cyclopiazonic acid-imine (α-CPA-imine), and bissecodehydrocyclopiazonic acid (β-CPA) [204] . CPA has been isolated from the Kodo millet seed (Paspalum scrobiculatum) which causes symptoms of 'Kodua poisoning' in humans [214] . It results in sleepiness and tremors. Kodo millet is a staple food in North India, when contaminated with A. flavus and A. tamari, its ingestion was often found to cause intoxication and poisoning [215, 216] . Unintended household CPA consumption in Uttar Pradesh, India has expressed signs of giddiness and nausea [217] . Intra-peritoneal injection of CPA showed depression and mobility defects. Also, cattle poisoning is characterized by signs of deficiency in muscle strength, overwhelming gait, and depressive disorders. Cattle usually recover after a few days but sometimes CPA poisoning is fatal [218] . Upon ingesting contaminated feed with CPA, animals displayed rigorous gastrointestinal upsets and neurodegenerative disorders [128] . CPA also showed adverse effects on the liver, kidney, heart, digestive tract along with degenerative changes, necrosis, accumulation in the skeletal muscle of rats and chickens [213] . Humans are exposed to this toxin through the ingestion of dairy products such as cheese, milk, eggs, and meat showing toxic effects [219] . Contaminated milk affects weight loss, necrosis and viscera, seizure, and death [220, 221] . Synergistic activity of AFTs and CPA could adversely affect the performance of broiler chicken causing high mortality [222] . CPA is harmful when given orally to swine, guinea pigs, and dogs that target the alimentary tract, liver, kidneys, and skeletal muscle. CPA is a major contaminant of maize (51 %) in the USA with an average level of up to 2.8 mg/kg. About 90 % of the peanut samples showed visible damage [223] . P. camemberti is a major food and feed contaminants and 20 commercial cheese product which is capable of producing CPA. P. camemberti and A. oryzae are used globally for the production of fermented foods [224] . The tetramide biosynthetic gene cluster is responsible for CPA biosynthesis. CPA-related cyclopiazonate scaffold is derived from cycloacetoacetyl L-tryptophan (cAATrp) and β-CPA, which are assembled in a three-enzyme pathway Fig. 10 [225] . The immediate precursor of α-CPA is the tricyclic β-CPA, this conversion is catalyzed by oxidocyclase (CpaO), whereas dimethyl allyltransferase (CpaD) catalyzes the conversion of cyclo-acetayl -L-tryptophan (cAATrp) to β-CPA. The first enzyme is a hybrid two-module PKS-NRPS (CpaS), homologous to other sequenced fungal tetramate synthetases, that is responsible for the synthesis of tetramate cAATrp [226] is shown (Fig. 11 ). Secalonic acid (SA) is an important natural and versatile secondary metabolite of fungal species. SA has been isolated from the ergot fungus Claviceps purpurea in 1906 and reported by Kraft in 1906. Twenty-two members of SA were structurally identified as dimers of six monoxanthones, A-F [227, 228] . SAA, SAB, SAC, SAD were isolated from Claviceps purpurea, P. oxalicum, and A. ochraceus [228, 229] . SAA attenuates the cytotoxicity of colchicine in rat cortical neurons [230] . SAA, SAE, and SAG are known as yellow pigments isolated from P. terrestris. SA's exhibits extensive biological activity such as anticancer, antimicrobial, antitumor, and anti-HIV [231] [232] [233] . Furthermore, SA is closely related to ergofalvin and ergochrysin A that are collectively referred to as ergochromes which grow on ryegrasses [231] . Antitumor activities of SA against Ehrlich ascites carcinoma, sarcoma-180, and mice tumors induced by Rous sarcoma virus have been documented [234] . SAD is highly toxic, teratogenic, and weakly mutagenic mycotoxin and is a common contaminant in the United States. SAD, a teratogenic toxin has effects on pregnant mice and its progeny and acts in a dose-dependent response that leads to neurotoxicity [235] . SA with dimeric tetrahydroxanthenone skeleton is less toxic to humans but has a wide variety of anticancer and antimicrobial activities, including the inhibition of topoisomerase 1 and Protein kinase C [236, 61] . SAD could inhibit VEGF-mediated angiogenesis through the Akt/mTOR pathway in breast cancer [237] . SAD not only inhibits responsive cell growth and induced leukemia but also inhibits multidrug-resistant cells [139, 238] . Moreover, SAD produces symmetrical tetrahydroxanthone derivatives, which are part of novel DNA topoisomerase I inhibitors [239] , which regulates the conformational alterations in DNA topology. SAD a comparatively low toxic molecule shows a promising antitumor, anticancer activity, and relatively safe for exploration [240] . SAF has anticancer activity, prevents proliferation, and promotes the apoptosis of HepG2 cells. Nevertheless, the underlying mechanisms and other biological activities of SAF remain unknown. Mycotoxins produced mainly by Aspergillus, Penicillium, and Fusarium have intensive toxic effects on humans, plants, and animals. Owing to the dynamic biosynthetic pathway genes, these toxins are diverse in chemical structures and biological activities and can be integrated into several ways. Such mycotoxins are often involved in the entire food chain therefore they have to be systematically identified and monitored. The co-occurrence of the various toxins in agricultural fields, which makes it necessary for the development of coherent detection methods. Conventional approaches such as LC-MS, HPLC, HRMS, etc. must be replaced with modern methodologies that can easily detect the toxins. OMICs tools like genomics, proteomics, transcriptomics, and metabolomics have been used to classify and quantify the biosynthetic genes for mycotoxins and can be used for their detection in the food chain [241] . Metabolomics is the study of chemical processes and products of metabolisms that includes small molecules and other various metabolites. It is based on targeted or non-targeted approaches [242, 243] and analyzed with the help of several databases such as METLIN, Chem-Spider, and PubChem. In 1970 Scott et al. performed thin layer chromatography (TLC) as the first traditional method in which 18 metabolites including aflatoxins B1, B2, G1, G2, and OTA were identified [244] . Mycotoxins can be identified quantitatively as well as qualitatively using LC-MS/MS [245] , due to their high selectivity and [193] . V. Navale et al. sensitivity in nanogram levels (ng) [246] . Later, ultra-high-pressure liquid chromatography (UHPLC) coupled with SCIEX triple quad MS system (QDMS) was performed to detect 26 mycotoxins in commercially available finished grain or nut products [247] . LC-MS/MS and LC-HRMS were used to detect 24 mycotoxins that were identified from pigs, broiler chickens, and biological matrices [248] . Time-of-Flight (TOF) and Orbitrap HR-MS are the most widely used techniques for the evaluation of untargeted toxin-metabolites [249] with the utmost sensitivity, selectivity, and precise mass resolution. Furthermore, HRMS has been used to classify 28 different toxins and 245 fungal, as well as bacterial metabolites in pet food [250] . The MS-based protein analysis technique is very effective and improves rapidly in terms of specificity and accuracy [251] . Several researchers have identified a wide range of microbes such as bacteria, yeast, and fungi, and their role in toxicity [252] . The analysis of mycotoxin-producing species involves the study of the genomes of these organisms, the comparison of the sequenced genome with the related organisms, and the identification of the corresponding homologous proteins [253] . The first analysis was performed by using USDA/ARS (United States Department of Agriculture/ Agriculture Research Service) Expressed Sequence Tags (EST) genome of A. flavus [254] . Recently, the full mitochondrial genome analysis of AFB and AFG producing A. parasiticus has been achieved using sophisticated bioinformatics tools [255] . The J. Craig Venter Institute, USA could identify more than 12,000 functional genomes in A. flavus by using their bioinformatics software [256] . In recent years, the use of different genomic tools such as microarray, Ion Torrent Personal Genome Machine (PGM), quantitative reverse transcription-PCR (qRT-PCR), and whole-genome sequencing (WGS), have been used to pursue various research [257] . Genome sequencing of AFTs producing fungi A. arachidicola of Argentinian peanut was rendered using BLAST2GO [258] . Besides, genome analysis of clinically isolated A. flavus was performed in Japan [259] . Furthermore, a comparative genomic analysis of A. flavus as a model for understanding mycotoxin biosynthesis and plant pathogenicity has been reported [257] . Genome sequencing helped to identify the target genes for the production of AFTs in field fungal isolates. The genomic study was conducted using a Next-Generation Sequencing analysis of 240 Aspergillus strains in peanut seeds where nine clades were identified, three clades were non-aflatoxigenic and five were aflatoxigenic [260] . Gilbert et al. [261] developed a methodology through a functional genomics study that can assist to forecast the impact of climatic change on A. flavus, AFTs production, and expression of biosynthetic regulatory genes [260] . More than 50 secondary polyketide synthase (PKS) and nonribosomal peptide synthase (NRPS) genes were located in the OTA biosynthetic gene cluster genome of A. westerdijkiae [262] . Genes including 633 carbohydrate-active enzymes, 716 cytochrome P450 enzymes, and 377 proteases along with two-hybrid t1pks-nrps gene clusters were involved in OTA biosynthesis in A. westerdijkiae [263] . Fig. 9 . Biosynthesis of sterigmatocystin (STC) and, depending on the fungal species, further to aflatoxins [196] . Recently, PAT biosynthesis has shown that all the 15 genes, including VelA, VelB, and VelC, but not VosA in the cluster, are involved in PAT biosynthesis and allow localization of subcellular proteins [264] . Transcriptomics is highly useful in the field of agriculture, in medicine for early-stage diagnosis and treatment, as well as an understanding of complex biological systems [265] . It is also useful in crop advancement to study the regulation of large networks of biological processes [266, 267] . Genes transcribed from mycotoxins-infected plant cells are different from not-affected cells; hence they can be subjected to transcriptional profiling. It involves quantifying the gene expression of several genes in given conditions. Numerous techniques such as serial analysis of the gene (SAGE), RT-qPCR, nylon membrane arrays, and northern blots are prominently used for gene profiling. Also, whole transcriptome shotgun sequencing (WTSS) and gene expression microarray are rapidly being used for food safety consideration [268] . Certain approaches that have been recently reported are shotgun analysis (RNA-seq) and RT-qPCR [269] . The transcriptomic analysis of various mycotoxins producing strains has helped to understand the mechanism of plant-fungus crosstalk of mycotoxin toxicity as well as the abiotic factors affecting mycotoxin production. The induction of resistance genes in Z. mays by A. flavusemploys a variety of mechanisms [270] . Which are likely to contribute to the development of resistant varieties. Transcriptomic profiling resulting in differentiation of A. flavus gene response and susceptible peanut genotypes [271] . Analysis of transcriptomics of A. flavus isolates containing higher levels of AFTs showcased few differentially expressed genes under environmental stress [272] . Furthermore, transcriptomics does not elucidate the mode of action of mycotoxin but has bestowed appropriate toxicological details [273] . In an attempt to identify biomarkers for AFTs production in A. flavus during oxidative stress, 220 out of about 1000 proteins were found to be differentially expressed [274] . Protein signals in response to mycotoxin production have been used as biomarkers for the enhancement of plant resistance as well as fungal stress tolerance that contributes to interactions between host-pathogen [275, 276] . Degola et al. [277] documented the modification of sclerotial production of cuminaldehyde thiosemicarbazone, an inhibitor of AFTs biosynthesis in A. flavus. However, there were several problems with the detection of undefined peptides, as well as the proteins. The use of 2D gel electrophoresis in proteomics addresses the complexity of the sample protein mixtures by separating the proteins into smaller groups or individual proteins [278] . Tryptic digestion is also used to achieve a high output of less complex or length optimum peptides for the analysis. Recently, relative and absolute protein quantitation was achieved using gel electrophoresis (2D) along with isobaric tags (iTRAQ) to classify biomarkers using the number of determined proteins [279] . Following the digestion, the identification is performed using tandem mass spectrometry (MS/MS) with the aid of UniProt and NCBI applications. Proteomics helps to boost other types of omics such as transcriptomics and genomics [280] . Globally, several researchers are actively engaged in the development of methods ranging from conventional densitometer thin-layer chromatography (TLC) to advanced immunosensors for the detection of mycotoxins in food and other matrices. Chromatographic methods such as HPLC, HPTLC, GC, LC-MS/MS, Fluorescence Spectrophotometry, Frontier Infrared Spectroscopy, fluorometer, Fourier-transform infrared spectroscopy (FTIR), radioimmunoassay (RIA), ELISA, lateral flow devices (Immunodipstick), surface plasmon resonance (SPR), electrochemical immunosensors are commonly used for the detection and quantification of mycotoxins in agricultural food crops [281] . Monoclonal/ polyclonal antibodies have been used to identify several toxins, but cross-reactivity is a major obstacle, resulting in uncertainty. The detection of mycotoxins in various cereal-based foods using immunoassay techniques has increased over the last decade [282] , including field-based immune-chromatographic toxin interaction test strips and antibody-coated nano-materials. Lateral-flow Devices (LFDs) are emerging and are used commercially in agricultural produce to detect toxins. Advances in portable photometric strip readers have enhanced the quantitative detection of mycotoxins in food and feedstuffs [130] . Moreover, several researchers targeting AFB1, FB1, and OTA have also developed aptamer-based diagnostic in recent years, but no attempts have been made to adapt existing technologies to prepare POC diagnostic platforms [283] . Rather than conventional methods, detection of these enigmatic toxins is more feasible using sensitive and field-deployable rapid POC diagnostics using aptamers. They are short single-stranded oligonucleotides that bind to their targets ranging from tiny organic molecules to biological Fig. 11 . Biosynthetic gene cluster identified in Aspergillus species including two CPA producers and non-producers [226] . macromolecules in a precise manner. APTs are synthetic DNA/RNA/ XNA molecules and consist of short strands of oligonucleotides sequences. Specific APT was developed by systematic evolution of ligands by exponential enrichment (SELEX) processes for synthetic materials [284] . APTs are an alternative to antibody-based systems and have several advantages, particularly thermal and chemical stability, practical synthesis, as well as the increased binding affinity of the target, are also flexible to modification with functional groups such as thiols and amines. These unique characteristics provide great potential for the detection of biomolecules. Such novel properties make APTs the material of choice for highly sensitive biosensing platforms. The APT is conjugated with nano-materials with highly specific recognition abilities and a unique way to analyze target analytes in food and feed samples (Fig. 12) . APTs are third-generation molecular probes and can be easily synthesized in the laboratory. At one time, several billion copies of selected aptamers can be generated. Animals or high-end in vitro animal cell culture facilities are not required. Fungal toxins are non-protein organic compounds for which generating precise and adaptive antibodies is often difficult and has limitations. On the other hand, APT probes for these molecules are easy to generate in the lab in a limited period and are very cost-effective when compared to the current probes such as antibodies and sensors. These are versatile and minimize the crossreactions that can lead to false results. Until now, only a few detection methods and no POC detection methods for fungal toxins are available in India. Since these platforms are easy to fabricate, replication is possible and user-friendly to use and interpret the results. In the present scenario, the detection of FDA approved aflatoxins kits such as Aflatest (VICAM Co), Agriscreen (NEOGEN Crop), AflaCup 10 (ROMER LABS Inc), Afla-Cup 20 (ROMER LABS Inc.), EZ-Screen (MEDTOX) are available in the market and are very expensive. Most of the food industries prefer to use other toxin determination tests as the above kits are uneconomical. It is therefore important to establish simple techniques that are open to all kinds of food manufacturing industries. Environmental opportunistic pathogens (EOPs) are a wide class of pathogens capable of persisting and evolving outside most environments and entering the host under favorable. EOPs are highly contagious, that which normal circumstances do not affect the host, but leads to adverse conditions when host resistance declines. Human aspergillosis results in systemic and localized immune-suppression mainly by A. flavus and A. fumigatus. Aspergillomas and invasive pulmonary disease are severe Aspergillosis-related infections [285] . Approximately 300 species of Aspergillus can cause various diseases including invasive aspergillosis (IA), rhinosinusitis, bronchopulmonary and chronic pulmonary aspergillosis, keratitis, otomycos, and infections in trauma or burn wounds [286] [287] . A. fumigatus is a widespread species responsible for human aspergillosis with a mortality rate of 40-90 % in immune-compromised patients. Approximately 90 % of human IA infections have been identified [288] .Furthermore, A. flavus causes about 30 % of all aspergillosis cases in the United States [289] , affecting around 11 million patients annually. Many therapies have also emerged for these infections. Human aspergillosis occurs in about one in 100,000 In the United States, which means that seven people are infected every day, and patients suffering from this infection spend an average of $95,000 on medications. A. fumigatus is an environmental fungal pathogen that may cause severe asthma, sinusitis, hematological malignancies, hematopoietic stem cell transplantation, leukemia, or lymphoma [290] . The spores of A. fumigatus can reach the respiratory system quickly and trigger an infection that can evolve into an angioinvasive disease by penetrating the liver, kidneys, and brain [291] . In extreme cases, systemic infections may lead to death in patients previously diagnosed with hematological malignancies, organ transplants, cancer, prolonged steroid treatments, and HIV. A. fumigatus produce virulence, surprisingly this strain is capable of producing 226 metabolites that act as an immunosuppressant [292] . However, the extension of the infection by crossing the blood-brain barrier (BBB) to the central nervous system (CNS). Certain obstructions may include edema, alveolar flooding, and lack of oxygen supply, which causes the fungus to develop a hypoxic environment for its survival in the inflamed tissue and different organs. Complementary systems and phagocytic cells aid in defensive mechanisms against various invasions by the pathogen. EOPs bind to the host complement regulators thereby overriding the immune system and downregulating the complement system which can also contribute to many specific diseases. Luis et al. [293] isolated the environmental strains which are more virulent than the clinical strains. The water used in the hospital in which patients with hematological malignancies were admitted, showed the presence of Aspergillus and other fungal species at the concentration of 16.1 CFU/m 3 in bathrooms, 7 CFU/m 3 in inpatient rooms, and 8.6 CFU/m 3 in hallways, which symbolizes that the aerosol present in the hospitals was created from the infected water and can adversely infect the patients as they emerge [286] . Furthermore, the widespread occurrence of various filamentous fungal spores in the environment of allergic patients and persons with impaired immunity makes them more vulnerable to secondary inhalation infections. Pulmonary tuberculosis and pulmonary fungal infections have similar clinical characteristics due to which pulmonary tuberculosis is misdiagnosed. Patients with prior tuberculosis are affected by A. fumigatus and A. flavus causing various secondary diseases. A recent study showed that 12.3 % of positive patients with tuberculosis (TB) had co-infected TB with secondary fungal pulmonary infections [294] . Sivasankari et al. [295] reported that 8 out of 80 sputum samples obtained from patients with TB were positive for Aspergillus species, indicating the extent of the secondary fungal invasion infection in Kanchipuram state, India. In Uganda, patients who were diagnosed with residual chest x-ray cavitation pulmonary TB were resurveyed after 2 years using computed tomography, the results showed that 14 out of 285 patients were positive for cyclopiazonic acid (CPA) [296] . The continuous subjection to mycotoxins is creating havoc in human life. Nowadays infants and children are exposed to diverse types of toxins through various forms of food supplements. Consumption of such highly contaminated food results in different toxic effects right from the infant stage, including growth impairment, stunting, underweight, which could be further exacerbated immune deficiencies, and other infectious diseases. The co-occurrence of the mycotoxins in infant foods such as wheat, barley, corn, banana, apples, and sweet potatoes leads to episodes of toxicity. According to the European Commission (EC), the overall allowable level for the specific toxins in baby food is 0.5-200 ppb [172] . An infant cereal, one with cocoa has demonstrated the highest level of AFTs. Cereals containing dehydrated fruits and gluten-free cereals have shown an intermediate level in both milk and honey-based cereals. Control of the aflatoxin during the production and processing of infant food is very important for infant food safety [297] . AFTs and CIT have been found in relatively high amounts in processed foods as well as in native homemade formulated foodstuffs such as Tom bran (native Nigerian food) leading to health risks in infants and young children (IYC) [33] . In young infants near Cleveland, Ohio, a study reported idiopathic pulmonary hemorrhage (PH) due to indoor air exposure to Stachybotrys chartarum. This fungus has been thriving in flooding, plumbing leakage, or even roof leaks in homes as it requires water-soaked cellulose to grow. It is known, infants are highly susceptible to the mycotoxins spores as their lungs expand very rapidly. The prevalence of environmental tobacco smoke that has prominently triggered hemorrhage, had also led to the worsening of the disease. About 101 cases of this disease occurred in the United States between 1993-1998 [298] . The presence of molds on the indoor walls of the homes in Poland led to a deficiency in the intelligence quotient of infants who were residing in these homes for more than 2 years. These cases provide an insight into the magnitude of the effect of mycotoxins, especially on infants [299] . Another study included the occurrence of AFT-albumin adducts up to 720 pg AFT-lysine equivalent per mg albumin in Gambian children serum samples for malaria patients. In the children with hepatitis B surface antigen (HBsAg) and Plasmodium falciparum, the amount of AFT-albumin adducts was much higher than their control groups [300] . AFM1 measured 0.16-0.33 μg/kg in the breast milk of the lactating mothers in Nigeria's Ogun State. Also, 82 % of the breast milk collected from the state samples was positive for AFM1 [301] . This article does not contain any studies with human or animal subjects performed by any of the authors. The authors report no declarations of interest.@story_separate@Mycotoxin contamination has been a global concern since the early days of human existence and management of mycotoxin production is limited and challenging. Environmental factors play an important role in the development of mycotoxins that enters the food chain and the interaction of toxigenic fungi is a major concern. The continuous and over, period of exposure of toxin developing pandemonium in human life. Also, various forms of food supplements highly contaminated with toxins right from the infant stage are lead to outbreaks of toxicity. However, no quantitative data available for several mycotoxins, and more studied are needed globally to know the exact degree of contamination of mycotoxins in food and feed. Unpredictably, the metabolic pathway, and toxicity of numerous molecules are yet to understand, which are urgently considered for the for safety and public health concerns. As described Aspergillus is the one of the major genera of filamentous fungi in terms of food, agriculture, and pharma industries for their wide ranges of applications. In addition to the mycotoxins producers, also most prevalent EOPs that directly affect individuals with weakened immune system leading to mortality risk. Also, pulmonary TB and fungal infections had similar clinical characteristics, and is misdiagnosed. Coronavirus pandemic, pulmonary diseases caused by fungal bioaerosols might misdiagnosed as COVID-19 which misleads to the physicians for wrong prescription of the medicines. AFTs, OTA, CIT, PAT, CPA, Ter A, STC, TA and other induced toxins, and their combined toxicity was studied in various mammalian cell line models, and animals species exhibited Geno-toxicity, and increased levels of apoptosis, expression of oxidative stress genes. The technological capability of toxin chemotypes for detection using various analytical tools are commonly used for the detection and quantification. Genome, proteomes, and transcriptional studies are imperative for the genome level organization. Till date, no POC detection methods have been developed for mycotoxins are available in India to detect mycotoxin in agricultural food and environmental samples. APTs may complement to the traditional methods, and open up new technological solutions to the rapid and robust detection of mycotoxins. The early, cost effective detection of mycotoxins and eco-friendly management approaches are very imperative. Paper-based APT test kits are quick, inexpensive and no equipment or laboratory facilities are required which are used for early detection of mycotoxins need to be explored. Of various management approaches, such as physical, and chemical, biological control agents (BCA), help to neutralization and/ or degradation of mycotoxins in food.","Aspergillus species are the paramount ubiquitous fungi that contaminate various food substrates and produce biochemicals known as mycotoxins. Aflatoxins (AFTs), ochratoxin A (OTA), patulin (PAT), citrinin (CIT), aflatrem (AT), secalonic acids (SA), cyclopiazonic acid (CPA), terrein (TR), sterigmatocystin (ST) and gliotoxin (GT), and other toxins produced by species of Aspergillus plays a major role in food and human health. Mycotoxins exhibited wide range of toxicity to the humans and animal models even at nanomolar (nM) concentration. Consumption of detrimental mycotoxins adulterated foodstuffs affects human and animal health even trace amounts. Bioaerosols consisting of spores and hyphal fragments are active elicitors of bronchial irritation and allergy, and challenging to the public health. Aspergillus is the furthermost predominant environmental contaminant unswervingly defile lives with a 40–90 % mortality risk in patients with conceded immunity. Genomics, proteomics, transcriptomics, and metabolomics approaches useful for mycotoxins’ detection which are expensive. Antibody based detection of toxins chemotypes may result in cross-reactivity and uncertainty. Aptamers (APT) are single stranded DNA (ssDNA/RNA), are specifically binds to the target molecules can be generated by systematic evolution of ligands through exponential enrichment (SELEX). APT are fast, sensitive, simple, in-expensive, and field-deployable rapid point of care (POC) detection of toxins, and a better alternative to antibodies."
"Upper gastrointestinal (GI) cancers, mainly including gastric cancer (8.2% of total cancer deaths) and esophageal cancer (5.3% of total cancer deaths), are the leading cause of cancer-related deaths worldwide [1] . Previous studies have shown that upper GI cancers always go through the stages of precancerous lesions, which can be defined as common conditions associated with a higher risk of developing cancers over time [2] [3] [4] . The detection of the precancerous lesions before cancer occurs could significantly reduce morbidity and mortality rates [5, 6] . Currently, the main approach for the diagnosis of disorders or issues in the upper GI tract is endoscopy [7, 8] . Compared with GI cancers, which usually show typical morphological characteristics, the precancerous lesions often appear in flat mucosa and exhibit few morphological changes. Manual screening through endoscopy is labor-intensive, time-consuming and relies heavily on clinical experience. Computer-assisted diagnosis based on artificial intelligence (AI) can overcome these dilemmas. Over the past few decades, AI techniques such as machine learning (ML) and deep learning (DL) have been widely used in endoscopic imaging to improve the diagnostic accuracy and efficiency of various GI lesions [9] [10] [11] [12] [13] . The exact definition of AI, ML and DL can be misunderstood by physicians. AI, ML and DL are overlapping disciplines ( Figure 1 ). AI is a hierarchy that encompasses ML and DL; it describes a computerized solution to address the issues of human cognitive defined by McCarthy in 1956[14] . ML is a subset of AI in which algorithms can execute complex tasks, but it needs handcrafted feature extraction. ML originated around the 1980s and focuses on patterns and inference [15] . DL is a subset of ML and became feasible in the 2010s; it is focused specifically on deep neural networks. A convolutional neural network (CNN) is the primary DL algorithm for image processing [16, 17] . The diagnostic process of an AI model is similar to the human brain. We take our previous research as an example to illustrate the diagnostic process of ML, DL and human experts. When an input image with gastric intestinal metaplasia (GIM), a precancerous lesion of gastric cancer, is fed into the ML system, it usually needs a manual feature extraction step, while the handcrafted features are unable to discern slight variations in the endoscopic image ( Figure 2) [15]. Unlike conventional ML algorithms, CNNs can automatically learn representative features from the endoscopic images [17] . When we apply a CNN model to detect GIM, it performs better than conventional ML models and is comparable to experienced endoscopists [18] . For a broad variety of image processing activities in endoscopy, CNNs also show excellent results, and some CNN-based algorithms have been used in clinical practice [19] [20] [21] . However, DL, especially CNN, has some limitations. First, DL requires a lot of data and easily leads to overfitting. Second, the diagnostic accuracy of DL relies on the training data, but the clinical data of different types of diseases are always imbalanced, which easily causes diagnosis bias. In addition, a DL model is complex and requires a huge calculation, so most researchers can only use the ready-made model. Despite the above limitations, DL-based AI systems are revolutionizing GI endoscopy. While there are several surveys on DL for GI cancers[9-13], no specific review on the application of DL in the endoscopic diagnosis of precancerous lesions is available in the literature. Therefore, the performance of DL on gastroenterology is summarized in this review, with an emphasis on the automatic diagnosis of precancerous lesions in the upper GI tract. GI cancers are out of the scope of this review. Specifically, we review the status of intelligent diagnoses of esophageal and gastric precancerous lesions. The challenges and recommendations based on the findings of the review are comprehensively analyzed to advance the field. @story_separate@Esophageal cancer is the eighth most prevalent form of cancer and the sixth most lethal cancer globally [1] .  Low-grade and high-grade intraepithelial neoplasms, collectively referred to as ESD, are deemed as precancerous lesions of ESCC. Early and accurate detection of ESD is essential but also full of challenges [23] [24] [25] . DL is reliably able to depict ESD in realtime upper endoscopy. Cai et al [30] designed a novel computer-assisted diagnosis system to localize and identify early ESCC, including low-grade and high-grade intraepithelial neoplasia, through real-time white light endoscopy (WLE). The system achieved a sensitivity, specificity and accuracy of 97.8%, 85.4% and 91.4%, respectively. They also demonstrated that when referring to the results of the system, the overall diagnostic capability of the endoscopist has been increased. This research paved the way for the real-time diagnosis of ESD and ESCC. Following this work, Guo et al [31] applied 6473 narrow band (NB) images to train a real-time automated computer-assisted diagnosis system to support non-experts in the detection of ESD and ESCC. The system serves as a ""second observer"" in an endoscopic examination and achieves a sensitivity of 98.04% and specificity of 95.30% on NB images. The perframe sensitivity was 96.10% for magnifying narrow band imaging (M-NBI) videos and 60.80% for non-M-NBI videos. The per lesion sensitivity was 100% in M-NBI videos. BE is a disorder in which the lining of the esophagus is damaged by gastric acid. The critical purpose of endoscopic Barrett's surveillance is early detection of BE-related dysplasia[4,26-28]. Recently, there have been many studies on the DL-based diagnosis of BE, and we review some representative studies. de Groof et al [32] performed one of the first pilot studies to assess the performance of a DL-based system during live endoscopic procedures of patients with or without BE dysplasia. The system demonstrated 90% accuracy, 91% sensitivity and 89% specificity in a per-level analysis. Following up this work, they improved this system using stepwise transfer learning and five independent endoscopy data sets. The enhanced system obtained higher accuracy than non-expert endoscopists and with comparable delineation performance [33] . Furthermore, their team also demonstrated the feasibility of a DLbased system for tissue characterization of NBI endoscopy in BE, and the system achieved a promising diagnostic accuracy [34] . Hashimoto et al [35] borrowed from the Inception-ResNet-v2 algorithm to develop a model for real-time classification of early esophageal neoplasia in BE, and they also applied YOLO-v2 to draw localization boxes around regions classified as dysplasia. For detection of neoplasia, the system achieved a sensitivity of 96.4%, specificity of 94.2% and accuracy of 95.4%. Hussein et al [36] built a CNN model to diagnose dysplastic BE mucosa with a sensitivity of 88.3% and specificity of 80.0%. The results preliminarily indicated that the diagnostic performance of the CNN model was close to that of experienced endoscopists. Ebigbo et al [37] exploited the use of a CNN-based system to classify and segment cancer in BE. The system achieved an accuracy of 89.9% in 14 patients with neoplastic BE. DL has also achieved excellent results in distinguishing multiple types of esophageal lesions, including BE. Liu et al [38] explored the use of a CNN model to distinguish esophageal cancers from BE. The model was trained and evaluated on 1272 images captured by WLE. After pre-processing and data augmentation, the average sensitivity, specificity and accuracy of the CNN model were 94.23%, 94.67% and 85.83%, respectively. Wu et al [39] developed a CNN-based framework named ELNet for automatic esophageal lesion (i.e. EAC, BE and inflammation) classification and segmentation, the ELNet achieved a classification sensitivity of 90.34%, specificity of 97.18% and accuracy of 96.28%. The segmentation sensitivity, specificity and accuracy were 80.18%, 96.55% and 94.62%, respectively. A similar study was proposed by Ghatwary et al [40] , who applied a CNN algorithm to detect BE, EAC and ESCC from endoscopic videos and obtained a high sensitivity of 93.7% and a high F-measure of 93.2%. The studies exploring the creation of DL algorithms for the diagnosis of precancerous lesions in esophageal mucosa are summarized in Table 1 . Gastric cancer is the fifth most prevalent form of cancer and the third most lethal cancer globally [1] . Even though the prevalence of gastric cancer has declined during the last few decades, gastric cancer remains a significant clinical problem, especially in developing countries. This is because most patients are diagnosed in late stages with poor prognosis and restricted therapeutic choices [41] . The pathogenesis of gastric cancer involves a series of events starting with Helicobacter pylori-induced (H. pyloriinduced) chronic inflammation, progressing towards atrophic gastritis, GIM, dysplasia and eventually gastric cancer [42] . Patients with the precancerous lesions (e.g., H. pyloriinduced chronic inflammation, atrophic gastritis, GIM and dysplasia) are at considerable risk of gastric cancer [3, 6, 43] . It has been argued that the detection of such precancerous lesions may significantly reduce the incidence of gastric cancer. However, endoscopic examination is difficult to identify these precancerous lesions, and the diagnostic result also has high interobserver variability due to their subtle morphological changes in the mucosa and lack of experienced endoscopists [44, 45] . Currently, many researchers are trying to use DL-based methods to detect gastric precancerous lesions; here, we review these studies in detail. Most of the gastric precancerous lesions are correlated with long-term infections with H. pylori [46] . Shichijo et al[47] performed one of the pioneering studies to apply CNNs in the diagnosis of H. pylori infection. The CNNs were built on GoogLeNet and trained on 32208 WLE images. One of their CNN models has higher accuracy than endoscopists. The study showed the feasibility of using CNN to diagnose H. pylori from endoscopic images. After this study, Itoh et al [48] developed a CNN model to detect H. pylori infection in WLE images and showed a sensitivity of 86.7% and specificity of 86.7% in the test dataset. A similar model was developed by Zheng et al [49] to evaluate H. pylori infection status, and the per-patient sensitivity, specificity and accuracy of the model were 91.6%, 98.6% and 93.8%, respectively. Besides WLE, blue laser imaging-bright and linked color imaging systems were prospectively applied by Nakashima et al [50] to collect endoscopic images. With these images, they fine-tuned a pre-trained GoogLeNet to predict H. pylori infection status. As compared with linked color imaging, the model achieved the highest sensitivity (96.7%) and specificity (86.7%) when using blue laser imaging-bright. Nakashima et al [51] also did a single center prospective study to build a CNN model to identify the status of H. pylori in uninfected, currently infected and post-eradication patients. The area under the receiver operating characteristic curve for the uninfected, currently infected and post-eradication categories was 0.90, 0.82 and 0.77, respectively. Atrophic gastritis is a form of chronic inflammation of the gastric mucosa; accurate endoscopic diagnosis is difficult [52] . Guimarães et al[53] reported the application of CNN to detect atrophic gastritis; the system achieved an accuracy of 93% and performed better than expert endoscopists. Recently, another CNN-based system for detecting atrophic gastritis was reported by Zhang et al [54] . The CNN model was trained and tested on a dataset containing 3042 images with atrophic gastritis and 2428 without atrophic gastritis. The diagnostic accuracy, sensitivity and specificity of the model were 94.2%, 94.5% and 94.0%, respectively, which were better than those of the experts. More recently, Horiuchi et al [55] explored the diagnostic ability of the CNN model to distinguish early gastric cancer and gastritis through M-NBI; the 22-layer CNN was built on GoogleNet and pretrained using 2570 endoscopic images, and the sensitivity, specificity and accuracy on 258 images were 95.4%, 71.0% and 85.3%, respectively. Except for high sensitivity, the CNN model also showed an overall test speed of 0.02 s per image, which was faster than human experts.  GIM is the replacement of gastric-type mucinous epithelial cells with intestinal-type cells, which is a precancerous lesion with a worldwide prevalence of 25% [56] . The morphological characteristics of GIM are subtle and difficult to observe, so the manual diagnosis of GIM is full of challenges. Wang et al [57] reported the first instance of an AI system for localizing and identifying GIM from WLE images. The system achieved a high classification accuracy and a satisfactory segmentation result. A recent study developed a CNN-based diagnosis system that can detect atrophic gastritis and GIM from WLE images[58], and the detection sensitivity and specificity for atrophic gastritis were 87.2% and 91.1%, respectively. For detection of GIM, the system also achieved a sensitivity of 90.3% and a specificity of 93.7%. Recently, our team also developed a novel DL-based diagnostic system for detection of GIM in endoscopic images [18] . The difference from the previous research is that our system is composed of three independent CNNs, which can identify GIM from either NBI or M-NBI. The per-patient sensitivity, specificity and accuracy of the system were 91.9%, 86.0% and 88.8%, respectively. The diagnostic performance showed no significant differences as compared with human experts. Our research showed that the integration of NBI and M-NBI into the DL system could achieve satisfactory diagnostic performance for GIM. Gastric dysplasia is the penultimate step of gastric carcinogenesis, and accurate diagnosis of this lesion remains controversial [59] . To accurately classify advanced lowgrade dysplasia, high-grade dysplasia, early gastric cancer and gastric cancer, Cho et al [60] established three CNN models based on 5017 endoscopic images. They found that the Inception-Resnet-v2 model performed the best, while it showed lower fiveclass accuracy compared with the endoscopists (76.4% vs 87.6%). Inoue et al [61] constructed a detection system using the Single-Shot Multibox Detector, which can automatically detect duodenal adenomas and high-grade dysplasia from WLE or NBI. The system detected 94.7% adenomas and 100% high-grade dysplasia on a dataset containing 1080 endoscopic images within only 31 s. Although most of the AI-assisted system can achieve high accuracy on endoscopic diagnosis, no study has investigated the role of AI in the training of junior endoscopists. To evaluate the role of AI in the training of junior endoscopists in predicting histology of endoscopic gastric lesions, including dysplasia, Lui et al [62] designed and validated a CNN classifier based on 3000 NB images. The classifier achieved an overall accuracy of 91.0%, sensitivity of 97.1% and specificity of 85.9%, which was superior to all junior endoscopists. They also demonstrated that with the feedback from the CNN classifier, the learning curve of junior endoscopists was improved in predicting histology of gastric lesions. The studies exploring the creation of DL algorithms for the diagnosis of precancerous lesions in gastric mucosa are summarized in Table 2 . AI has gained much attention in recent years. In the field of GI endoscopy, DL is also a promising innovation in the identification and characterization of lesions[9-13]. Many successful studies have focused on GI cancers. Accurate detection of precancerous lesions such as ESD, BE, H. pylori-induced chronic inflammation, atrophic gastritis, GIM and gastric dysplasia can greatly reduce the incidence of cancers and require less cancer treatment. DL-assisted detection of these precancerous lesions has increasingly emerged in the last 5 yrs. To perform a systematic review of the status of DL for diagnosis of precancerous lesions of the upper GI tract, we conducted a comprehensive search for all original publications on this target between January 1, 2017 and December 30, 2020. A variety of published papers has verified the outstanding performance of DL-assisted systems, several challenges remain from the viewpoint of physicians and algorithm engineers. The challenges and our recommendations on future research directions are outlined below. The current literature reveals that most studies were designed in a retrospective manner with a strong probability of bias. In these retrospective studies, researchers tended to collect high-quality endoscopic images that showed typical characteristics of the detected lesions from a single medical center, while they excluded common lowquality images. This kind of selection bias may jeopardize the precision and lead to lower generalization of the DL models. Thus, data collected from multicenter studies with uninformative frames are necessary to build robust DL models, and prospective studies are needed to properly verify the accuracy of AI in clinical practice. Overfitting means an AI model performs well on the training set but has high error on unseen data. The deep CNN architectures usually contain several convolutional layers and fully connected layers, which produce millions of parameters that easily lead to strong overfitting [16, 17] . Training these parameters needs large-scale well-annotated data. However, well-annotated data are costly and hard to obtain in the clinical community. Possible solutions for overcoming the lack of well-annotated data to avoid overfitting mainly include data augmentation [63] , transfer learning [17, 64] , semisupervised learning[65] and data synthesis using generative adversarial networks [66] . Data augmentation is a common method to train CNNs to reduce overfitting [63] . According to current literature, almost all studies use data augmentation. Data augmentation is performed by using several image transformations such as random image rotation, flipping, shifting, scaling and their combinations are shown in Figure 3 . Transfer learning involves transfer knowledge learned from a large source domain to a target domain [17, 64] . This technique is usually performed by initializing the CNN using the weights pretrained on ImageNet dataset. As there are many  Lack of interpretability (i.e. the ""black box"" nature), which is the nature of DL technology, is another gap between studies and clinical applications in the field of precancerous lesion detection from endoscopic images. The black box nature means that the decision-making process by the DL model is not clearly demonstrated, which may reduce the willingness of doctors to use it. Although attention maps can help explain the dominant areas by highlighting them, they are constrained in that they do not thoroughly explain how the algorithm comes to its final decision [71] . The attention maps are displayed as heat maps overlaid upon the original images, where warmer colors mean higher contributions to the decision making, which usually correspond to lesions. However, the attention maps also have some defects such as inaccurate display of lesions as shown in Figure 4 , where the attention maps only cover partial areas associated with BE and GIM. This is the inherent shortcoming of attention maps. Therefore, understanding the mechanism used by the DL model for prediction is a hot research topic. The network dissection [72] , an empirical method to identify the semantics of individual hidden nodes in the DL model, may be a feasible solution to improve interpretability. In @story_separate@Upper GI cancers are a major cause of cancer-related deaths worldwide. Early detection of precancerous lesions could significantly reduce cancer incidence. Upper GI endoscopy is a gold standard procedure for identifying precancerous lesions in the upper GI tract. DL-based endoscopic systems can provide an easier, faster and more reliable endoscopic method. We have conducted a thorough review of detection of precancerous lesions of the upper GI tract using DL approaches since 2017. This is the first review on the DL-based diagnosis of precancerous lesions of the upper GI tract. The status, challenges and recommendations summarized in this review can provide guidance for intelligent diagnosis of other GI tract diseases, which can help engineers develop perfect AI products to assist clinical decision making. Despite the success of DL algorithms in upper GI endoscopy, prospective studies and clinical validation are still needed. Creation of large public databases, adoption of comprehensive overfitting prevention strategies and application of more advanced interpretable methods and networks are also necessary to encourage clinical application of AI for medical diagnosis. May","Upper gastrointestinal (GI) cancers are the leading cause of cancer-related deaths worldwide. Early identification of precancerous lesions has been shown to minimize the incidence of GI cancers and substantiate the vital role of screening endoscopy. However, unlike GI cancers, precancerous lesions in the upper GI tract can be subtle and difficult to detect. Artificial intelligence techniques, especially deep learning algorithms with convolutional neural networks, might help endoscopists identify the precancerous lesions and reduce interobserver variability. In this review, a systematic literature search was undertaken of the Web of Science, PubMed, Cochrane Library and Embase, with an emphasis on the deep learning-based diagnosis of precancerous lesions in the upper GI tract. The status of deep learning algorithms in upper GI precancerous lesions has been systematically summarized. The challenges and recommendations targeting this field are comprehensively analyzed for future research."
"The abundance of biomolecular sequence information (generated as a result of the ever-increasing number of large-scale sequencing projects), together with a relatively high cost of ""wet lab"" experimentation, calls for powerful and efficient computational tools as primary means for high-throughput genomic proteomic investigations. Therefore, computational methods of biological sequence analysis become an indispensable part of the modern scientist's research arsenal. 1 In protein studies, the results of sequence similarity searches in databases help generate reasonable hypotheses concerning structural and functional properties of proteins. 2, 3 On the DNA level, sequence analysis techniques make it possible to identify genes and functional elements in newly sequenced genomes. Phylogenetic analysis [4] [5] [6] [7] [8] [9] not only provides us evolutionary relations among the sequences but also provides useful information for pharmaceutical researchers to determine which medicinal species share the same medical qualities. But, these efficient computational methods rely heavily on sequence comparison. Because of the importance of sequence comparison, numerous methods have been developed. A typical approach to sequence comparison is based on sequence alignment. Waterman 10 and Durbin et al. 11 provided comprehensive reviews about this method. The search for optimal solutions using alignment-based method encounters difficulties in: (i) computational load with regard to large databases; 12 (ii) choosing the scoring schemes. 27 Because of the critical limitations of alignment method, the emergence of research into alignment-free methods is apparent and necessary. Many alignment-free methods have been proposed, but they are still in the early development compared with alignment-based method. Comparison methods based on k-word frequencies may be the most well-developed alignment-free methods. Reinert et al. 26 studied the statistical and probabilistic properties of words in sequences, with emphasis on the deductions of exact distributions and evaluation of its asymptotic approximations. Word-based methods were recently reviewed by Vinga and Almeida. 27 Among these word-based methods, each sequence is mapped into an n-dimensional vector according to its k-word frequencies. The similarity score between sequences represented in vector spaces is further defined by Euclidean distance, 28 Mahalanobis distance, 29 Kullback-Leibler discrepancy, 30 Cosine distance 31 between their corresponding vectors. Recently, several novel word-based methods have been designed for sequence comparison, such as D2z( 32 ), Gdis.k, 33 D 2 and D 3 . 34 This work presents a novel method for biological sequence comparison based on Gaussian model. Instead of comparing the k-word frequencies of two sequences directly, we evaluate their k-word frequencies in a probabilistic framework. Our method was evaluated by extensive tests such as similarity search, evaluation on functionally related genes, and phylogenetic analysis. A comparison of performance between the proposed method and several typical alignment-based or alignment-free methods was taken. The results demonstrate that it is a promising word-method for sequence comparison with potential application in improvement on structure and function prediction.@story_separate@There is a large body of literatures on word statistics, 26 where sequences are interpreted as a succession of symbols and are further analyzed by representing the frequencies of its small segments. A k-word is a series of k consecutive letters in a sequence. The k-word statistical analysis consists of counting occurrences of k-words in a given sequence. For a sequence s, the count of a k-word w, denoted by c(w), is the number of occurrence of w in the sequence s. The standard approach for counting k-words in a sequence of length m is to use a sliding window of length k, shifting the frame one base at a time from position 1 to m−k+1. In this method, k-words are allowed to overlap in the sequence. In this way, a sequence can be represented by an n-dimensional vector C s k made up of k-word counts where n is the total number of all possible k-words. The frequencies of k-words, F s k , can he calculated by For example, consider the DNA sequence s = AAAGGA, we can obtain the vectors made up of 2-word counts and frequencies In asymptotic cases, Gaussian, Poisson, and compound Poisson approximations have been derived for word counts; the type of approximation depends on the word length and on the method of counting word occurrences. In particular, if m is the length of the sequence, then, for large m, the distribution of counts of a word can be approximated by the normal distribution; this approximation is good when the length of the word is relatively small compared to the sequence length. 1 The simplest method of assessing normality is to look at the frequency distribution histogram. For example, the 3-word frequency histogram of HSLIPAS (Human mRNA for lipoprotein lipase) sequence appears in Figure 1 . The most important things to look at are the symmetry and peak of the curve. Figure 1 shows that the distribution of 3-word frequencies of HSLIPAS sequence approximately follows the Gaussian distribution. Visual appraisals can only be used as an indication of the distribution and subsequently better methods must be used. To test formally for normality we use a Kolmogorov-Smirnov test. Kolmogorov-Smirnov test is a goodness-of-fit test for any statistical distribution. The test relies on the fact that the value of the sample cumulative density function is asymptotically normally distributed. To apply the Kolmogorov-Smirnov test, the main operations are as follows: (1) calculate the cumulative frequency (normalized by the sample size) of the observations as a function of class; (2) calculate the cumulative frequency for a true distribution (most commonly, the Gaussian distribution); (3) find the greatest discrepancy between the observed and expected cumulative frequencies, which is called the ""D-statistic."" The Kolmogorov-Smirnov statistic (D) is defined as where F(x) is a given cumulative distribution function, and F n (x) is a empirical distribution function for n iid observations X i , which is defined as . . , f (w k,n ) with some unknown distribution P and we would like to test the hypothesis that P is equal to a Gaussian distribution P 0 , i.e., decide between the following hypotheses: The p value obtained by Kolmogorov-Smirnov test tells us whether the data is significantly different from the Gaussian distribution or not. We reject the hypothesis if the test is significant at the 0.05 level. That is to say, if p < 0.05, we reject H 0 , do not reject H 0 otherwise. We also take the 3-word frequencies of HSLIPAS sequence for example and perform Kolmogorov-Smirnov test. Since the p-value is 0.63857, we accept H 0 . In addition, the way Kolmogorov-Smirnov test work is by generating a normal probability plot, 35 it is a graphical technique for assessing whether or not a data set is approximately normally distributed. Figure 2 is the normal probability plot of 3word frequencies of HSLIPAS sequence. The straight line on Figure  2 is the null hypothesis of normality, the points on this plot form a nearly linear pattern, which indicates that the Gaussian distribution is a good model for the 3-word frequencies of HSLIPAS sequence. It is worthwhile pointing out that Kolmogorov-Smirnov test is designed to test a simple hypothesis P = P 0 for a given normal distribution P 0 . But, if we estimated this distribution, N(μ,σ 2 ) from the data f (w k,1 ), f (w k,2 ), . . . , f (w k,n ), formally, Kolmogorov-Smirnov test is inaccurate in this case. There is a version of Kolmogorov-Smirnov test, called Lilliefors test, 36 that tests normality of the distribution by comparing the data with a fitted Gaussian distribution as we did above, but with a correction to give a more accurate approximation of the distribution of the test statistic. The test proceeds as follows: (1) estimate the population mean and population variance based on the data; (2) find the maximum discrepancy between the empirical distribution function and the cumulative distribution function (CDF) of the normal distribution with the estimated mean and estimated variance, just as in the Kolmogorov-Smirnov test, this will be the test statistic; (3) confront the question of whether the maximum discrepancy is large enough to be statistically significant, thus requiring rejection of the null hypothesis. We also take the 3word frequencies of HSLIPAS sequence for example and perform Lilliefors test. First, we estimate the population meanμ = 0.0156 and population varianceσ 2 = 0.0066 based on the 3-word frequencies of HSLIPAS sequence. Then, we perform Lilliefors test that the 3-word frequencies of HSLIPAS sequence comes from the distribution N(0.0156, 0.0066). At the 0.05 significance level, we accept the normality of 3-word frequencies of HSLIPAS sequence with p-value 0.19537. Many methods for sequence comparison are to fix a short word length k, compute the frequencies of all k-words in each sequence, and assess the similarity of the two frequency vectors. For example, the dissimilarity score between two sequences X and Y are the Euclidian distance 28 or cosine of the angle 31 between their k-word frequency vectors F X k and F Y k . Sometimes, these simple methods are not satisfying for sequence comparison, because (i) they treat all word types equally, despite that they have different background, and (ii) it does not take into account the fact that, for a given k-word, the probability is not a linear function of the number of occurrences. To overcome the problems, the Mahalanobis and standard Euclidean distance, which take into account the data covariance structure, were proposed for sequence comparison. 29 In this article, we treat the above two problems by using a probabilistic model of k-word frequencies. The Kolmogorov-Smirnov test indicates that the k-word frequencies of biological sequences can be approximated by Gaussian distribution. This approximation is good when the length of the word is relatively small compared to the sequence length. 1 In what follows we will explore sequence comparison method on the basis of the Gaussian distribution of word frequencies. The Gaussian distribution, also called the normal distribution, is an important family of continuous probability distributions, applicable in many fields. Each member of the family may be defined by two parameters, location and scale: the mean (""average,"" µ) and variance (standard deviation squared, σ 2 ) respectively. The standard Gaussian distribution is the Gaussian distribution with a mean of zero and a variance of one. To indicate that a real-valued random variable X is normally distributed with mean µ and variance σ 2 ≥ 0, we write There are various ways to characterize a probability distribution. The most widely used one is probability density function (PDF). The probability density function of the Gaussian distribution is where σ > 0 is the standard deviation, the real parameter µ is the expected value, and is the density function of the ""standard"" Gaussian distribution: i.e., the Gaussian distribution with µ = 0 and σ = 1. The distribution function of the Gaussian distribution is expressed in terms of the density function as follows: The standard Gaussian distribution function is just the general distribution function evaluated with µ = 0 and σ = 1: A biological sequence s, of length m, is defined as a linear succession of symbols from a finite alphabet A , with size of |A |. All possible sequences of length k with symbol from the alphabet A compose a k-word set, which corresponds to a k-word frequencies set F k . Suppose F k is a sample space and the frequency of each kword is a random variable denoted by f w k,i , the frequency of k-word is approximately followed by the Gaussian distribution with mean µ and variance σ 2 . That is to say, Give two biological sequences X and Y , the frequencies of k-word f w k,i in sequences X and Y follow two different Gaussian models According to distribution function of the Gaussian distribution, we have Note that a word is called highly expressed if its observed frequency is more than its expected frequency, and called low expressed otherwise. In this sense, the probability µX ,σ 2 corresponds to low expression of word w k,i , and large value of We define the probability distance between X and Y as The d Nor (X, Y ) has the following properties: (i) it is a distance measure, because it satisfies positivity, symmetry and triangle inequality; (ii) background information is incorporated into the measure; (iii) kwords with identical frequency in two sequences may have different expression levels. Since the mean µ and variance σ 2 are priori unknown, we have to estimate them according to the observed sequences. Here, we estimate the parameters of Gaussian model by using the maximum likelihood method. Give a biological sequence, its k-word frequencies are are independent and each is normally distributed with expectation µ and variance σ 2 > 0. These observed values of these n random variables make up a ""sample of size n from a normally distributed population."" It is desired to estimate the ""population mean"" µ and the ""population standard deviation"" σ , based on the observed values of this sample. The continuous joint probability density function of these n independent random variables is As a function of µ and σ , the likelihood function based on the with some constant C > 0. In the method of maximum likelihood, the values of µ and σ that maximize the likelihood function are taken as estimates of the population parameters µ and σ . Usually in maximizing a function of two variables, one might consider partial derivatives. But here we will exploit the fact that the value of µ that maximizes the likelihood function with σ fixed does not depend on σ . Therefore, we can find Journal of Computational Chemistry DOI 10.1002/jcc that value of µ, then substitute it for µ in the likelihood function, and finally find the value of σ that maximizes the resulting expression. It is evident that the likelihood function is a decreasing function of the sum So we want the value of µ that minimizes this sum. Let be the ""sample mean"" based on the n observations. Observe that Only the last term depends on µ and it is minimized bŷ That is the maximum-likelihood estimate of µ based on the n observations f (w k,1 ), f (w k,2 ), . . . , f (w k,n ). When we substitute that estimate for µ into the likelihood function, we get It is conventional to denote the ""log-likelihood function,"" i.e., the logarithm of the likelihood function, by a lower-case , and we have and then The proposed method is evaluated by extensive experiments such as similarity search, evaluation on functionally related genes, and phylogenetic analysis. We presently grouped our experiments into two sets. The first one, performed via ROC (receiver operating curve) analysis, aims at assessing the intrinsic ability of our method to search for similar sequences from a database and discriminate functionally related genes from unrelated sequences. The second one aims at assessing how well our method is used for phylogenetic analysis. The method that will be used here to evaluate performance of the presented method is based on the analysis of ROC curves. ROC goes back to signal detection and classification problems and is now widely used. 37 This approach is employed in binary classification of continuous data, usually categorized as positive (1)  A ROC curve is simply the plot of sensitivity versus (1specificity) for different threshold values. The area under a ROC curve (AUC) is a widely employed parameter to quantify the quality of a classificator because it is a threshold independent performance measure and is closely related to the Wilcoxon signed-rank test. 38 For a perfect classifier, the AUC is 1 and for a random classifier the AUC is 0.5. For additional results and comprehensive discussion on AUC measure, see ref. 39 . The proposed method is used to search for similar sequences of a query sequence from a database of 39 library sequences, of which 20 sequences are known to be similar in biological function to the query sequence, and the remaining 19 sequences are known as being not similar in biological function to the query sequence. This data set has been studied in refs. 12,30 and 40. These 39 sequences were selected from mammals, viruses, plants, etc., of which lengths vary from 322 to 14121 bases. The query sequence is HSLIPAS (Human mRNA ROC curves are computed to evaluate and compare the performance of our measure with other measures. The evaluated measures are as follows: the similarity measures based on Clustal W, Euclidean distance (eu), 28 Mahalanobis distance (md), 29 standard Euclidean distance (sd), 29 Kullback-Leibler discrepancy (kld), 30 Cosine distance (cos), 31 D2z, 32 D 2 , 34 D 3 34 and our measure d Nor . All measures based on k-word frequencies run with k from 2 to 5. For each measures, separate tests are done with each combination of parameter values, and the best combination is chosen to represent that score in the performance. The ROC curves obtained for the similarity search are presented in Figure 3 . The AUC value is typically used as a measure of overall discrimination accuracy. Table 1 provides the areas under ROC curves (AUC) obtained from all the measures. Figure 3 and Table 1 Among the similarity measures based on k-word distributions, D2z.5 is clearly more efficient than other measures. The main surprise of this analysis is that when we explore the distribution information of k-word frequencies in our way, d Nor .4 performs better than other similarity measures based on k-word frequencies. The inspection of the ROC curves themselves (Fig. 3) further illustrates this comparison between similarity measures. The proposed Gaussian model of k-word frequencies is further tested to evaluate if functionally or evolutionarily related gene pairs are scored better than unrelated pairs of random sequences. To assess the performance on functionally related genes, we construct data sets as follows. We selected three sets of genes, each involved in a particular pathway: nitrogen metabolism (NIT family, 31 genes), phosphate utilization (PHO family, 13 genes), and methionine biosynthesis (MET family, 20 genes). They are well studied in ref. 41 . We retrieved the 800 bp sequence upstream the start codon of each gene as ""positive"" sets. As ""negative"" sets, we generated random sequences with lengths matching the sequence in ""positive"" sets. Each pair of sequences in the positive set is compared, and so is each pair in the negative set. The evaluation procedure is based on a binary classification of each sequence pair, where 1 corresponds to the pairs from positive set, 0 corresponds to the pairs from negative set. Let n be the number of sequences in the positive set, all the pairs constitute a vector of length 2 n 2 , which is used as prediction. Also, we can get a vector of length 2 n 2 consisting of 1 and 0 as class labels. A perfect measure would completely separate negative from positive set. Of course, this does not happen in practice, and the classes are interspersed. The ROC curves permit to assess the level of accuracy of this separation without choosing any distance threshold for the separation point. In particular, the AUC will give us a unique number of the relative accuracy of each measure. The similarity measures evaluated here are as follows: the similarity measures based on alignment, Euclidean distance (eu), 28 Mahalanobis distance (md), 29 standard Euclidean distance(sd), 29 Kullback Leibler discrepancy(kld), 30 Cosine distance (cos), 31 D2z, 32 D 2 , 34 D 3 , 34 and our measure d Nor , where the similarity measures based on alignment are Needleman-Wunsch (global alignment) or Smith-Waterman (local alignment) raw scores, with no correction for statistical significance, using linear gap penalties or affine gap penalties, with a gap penalty of 2. All measures based on k-word distributions run with k from 2 to 5. For each measures, separate tests are done with each combination of parameter values, and the best combination is chosen to represent that score in the performance. ROC curves are computed to evaluate and compare the performances of our measures and other measures. The ROC curves obtained for NIT, Met, and PHO are presented in Figures 4 and 5. Table 2 summarizes the AUCs obtained from all the measures for three data sets. In the MET experiment, d Nor .4 performs better than other alignment-based and word-based measures, with the area under ROC curve 1.000. The next best measure is kld.2, and the other measures lag behind. In the NIT experiment, d Nor .5 measure is better than all other measures, and its area under ROC curve is 1.000. In the MUSCLE experiment, d Nor .3 outperforms other methods, with the area under ROC curve 1.000. It is followed by kld.5. From the three experiments, we can see that d Nor , exploring the distribution of k-word frequencies, performs better than other measures. The inspection of the ROC curves themselves (Figs. 4 and 5) further illustrates these comparisons among similarity measures. The highly significant results of our method demonstrate that the d Nor measure is successful at detecting the functional similarity of genes from the random sequences. Since the different genes are only functionally related and not orthologous, the gene search algorithm requires a method that can discern functional similarity among candidate genes based on their sequence similarity. From Table 2 , we can note that the alignment-based methods lag behind some alignment-free methods. Since the outbreak of atypical pneumonia referred to as severe acute respiratory syndrome (SARS), more attentions [42] [43] [44] [45] have been paid to the relationships between the SARS-CoVs and the other coronaviruses, which would be helpful to discover drugs and develop vaccines against the virus. Generally, coronaviruses can be divided into three groups according to serotypes. Group I and group II contain mammalian viruses, while group II coronaviruses contain a hemagglutinin esterase gene homologous to that of Influenza C virus. 46 Group III contains only avian. Based on the Gaussian model of k-word frequencies, we next consider to infer the phylogenetic relationships of coronaviruses with the complete coronavirus genomes. The 24 complete coronavirus genomes used in this article were downloaded from GenBank, of which 12 are SARS-CoVs and 12 are from other groups of coronaviruses. The name, accession number, abbreviation, and genome length for the 24 genomes are listed in Table 3 . Given a set of biological sequences, their phylogenetic tree can be obtained through the following main operations: firstly, we construct the Gaussian model for biological sequences; secondly, we calculate their similarity degree by using our measure d Nor . Thirdly, by arranging all the similarity degree into a matrix, we obtain a pair-wise distance matrix. Finally, we put the pair-wise distance matrix into the neighbor-joining program in the PHYLIP package. 47 We obtain the phylogenetic relationships drawn by MEGA program (9) . In Figure 6 , we present the unrooted phylogenetic tree belonging to 24 species. Figure 6 shows that our results are quite consistent with the accepted taxonomy and authoritative ones [42] [43] [44] [45] in the following four aspects. First, all SARS-CoVs are grouped in a separate branch, which appear different from the other three groups of coronaviruses. Secondly, BCOV, BCOVL, BCOVM, BCOVQ, MHV, MHV2, MHVM, and MHVP are grouped into a branch, which is consonant with that they belong to group II. Thirdly, HCoV-229E, TGEV, and PEDV are closely related to each other, which is consistent with the fact that they belong to group I. 28 Finally, IBV forms a distinct branch within the genus Coronavirus, because it belongs to group III. Grigoriev 43 found that the mutational patterns in SARS-CoV genome were strikingly different from the other coronaviruses in terms of mutation rates. Phylogenetic analysis based on codon usage pattern suggested that SARS-CoV was diverged far from all the three known groups of coronavirus. 44 Rota et al. 42 found out that the overall level of similarity between SARS-CoVs and the other coronaviruses is low. Our tree also reconfirms that SARS-CoVs are not closely related to any previously isolated coronaviruses and form a new group, which indicates that the SARS-CoVs have undergone an independent evolution path after the divergence from the other coronaviruses. Whole genome-based phylogenetic analysis is appealing because single gene sequences generally do not possess enough information to construct an evolutionary history of organisms. Now phylogenetic analysis based on sequence alignments is well developed. However, it can hardly be applied to complete genomes, because the computational load of multiple alignment increases with the increasing length of sequence. Being different from the sequence alignment method, the current method is more simple and yields results reasonably. Figure 6 . The unrooted consensus species tree for 24 coronavirus by our distance d Nor at k = 6 using whole genomes.@story_separate@Sequence comparison is rapidly becoming an essential tool for bioinformatics applications. It has been used to support other types of analyses, from searching a database with a query DNA sequence to the phylogenetic tree construction. Despite the prevalence of alignment-based methods, it is noteworthy that alignment-based method is computationally intensive and consequently unpractical for querying large data sets, which forces the use of some heuristics to reduce the running times, as exemplified by BLAST. Alignmentfree comparison method is therefore of great value as it reduces the technical constraints of alignments. A novel alignment-free method for sequence comparison is proposed in this work. We assume that the frequencies of a given k-word in a biological sequence follows the Gaussian distribution. The similarity between two sequences can be evaluated by the difference between their corresponding Gaussian models. In contrast to the traditional word-based methods based on frequencies of fixed k-words, our method takes distribution information of k-word frequencies into account. In other words, our method has the ability to adjust the background information for similarity measure using k-word frequencies. The test of our methods are to perform similarity search and evaluate the functionally related genes. To evaluate this method, we compare it with alignment-based or word-based methods. The comparison demonstrates that our method, intending to explore kword frequency distribution information, gives more competitive results (Tables 1 and 2 ). In addition, the reasonable results of phylogenetic tree construction illustrate the validity of our method for phylogenetic analysis. In summary, this work presented a new and effective computational framework for sequence comparison. It can be used as another useful tool in addition to existing alignment-based and alignment-free methods for the research community of bioinformatics. The results also indicated that it is a necessity for alignment-free methods to extract more information in order to have a good comparison performance. This understanding can then be used to guide development of more powerful sequence comparison method for potential improvement on evolutionary study, structure and function prediction.","One of the major tasks in biological sequence analysis is to compare biological sequences, which could serve as evidence of structural and functional conservation, as well as of evolutionary relations among the sequences. Numerous efficient methods have been developed for sequence comparison, but challenges remain. In this article, we proposed a novel method to compare biological sequences based on Gaussian model. Instead of comparing the frequencies of k‐words in biological sequences directly, we considered the k‐word frequency distribution under Gaussian model which gives the different expression levels of k‐words. The proposed method was tested by similarity search, evaluation on functionally related genes, and phylogenetic analysis. The performance of our method was further compared with alignment‐based and alignment‐free methods. The results demonstrate that Gaussian model provides more information about k‐word frequencies and improves the efficiency of sequence comparison. © 2009 Wiley Periodicals, Inc. J Comput Chem, 2010"
"While YouTube has revolutionized the way people discover and consume video content online, it has also enabled the spread of inappropriate and hateful content. The platform, and in particular its recommendation algorithm, has been repeatedly accused of promoting offensive and dangerous content, and even of helping radicalize users [53, 65, 68, 75] . One fringe community active on YouTube are the so-called Involuntary Celibates, or Incels [46] . While not particularly structured, Incel ideology revolves around the idea of the ""blackpill"" -a bitter and painful truth about society -which roughly postulates that life trajectories are determined by how attractive one is and that things that are largely out of personal control, like facial structure, are more ""valuable"" than those under our control, like the fitness level. Incels are one of the most * To appear at the 24th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2021). Please cite the CSCW version. extreme communities of the Manosphere [7] , a larger collection of movements discussing men's issues [28] (see Section 2) . When taken to the extreme, these beliefs can lead to a dystopian outlook on society, where the only solution is a radical, potentially violent shift towards traditionalism, especially in terms of women's role in society [18] . Overall, Incel ideology is often associated with misogyny and anti-feminist viewpoints, and it has also been linked to multiple mass murders and violent offenses [14, 22] . In May 2014, Elliot Rodger killed six people and himself in Isla Vista, CA. This incident was a harbinger of things to come. Rodger uploaded a video on YouTube with his ""manifesto,"" as he planned to commit mass murder due to his belief in what is now generally understood to be Incel ideology [78] . He served as an apparent ""mentor"" to another mass murderer who shot nine people at Umpqua Community College in Oregon the following year [69] . In 2018, another mass murderer drove his van into a crowd in Toronto, killing nine people, and after his interrogation, the police claimed he had been radicalized online by Incel ideology [13] . More recently, 22-year-old Jake Davison shot and killed five people, including a 3-year-old girl, in Plymouth, England [77] . Thus, while the concepts underpinning Incels' principles may seem absurd, they also have grievous real-world consequences [9, 32, 58] . Motivation. Online platforms like Reddit became aware of the problem and banned several Incel-related communities on the platform [31] . However, prior work suggests that banning subreddits and their users for hate speech does not solve the problem, but instead makes these users someone else's problem [15] , as banned communities migrate to other platforms [55] . Indeed, the Incel community comprising several banned subreddits ended up migrating to various other online communities such as new subreddits, stand-alone forums, and YouTube channels [63, 64] . The research community has mostly studied the Incel community and the broader Manosphere on Reddit, 4chan, and online discussion forums like Incels.me or Incels.co [23, 38, 50, 54, 63, 64] . However, the fact that YouTube has been repeatedly accused of user radicalization and promoting offensive and inappropriate content [40, 53, 56, 65, 68] prompts the need to study the extent to which Incels are exploiting the YouTube platform to spread their views. Research Questions. With this motivation in mind, this pa-per explores the footprint of the Incel community on YouTube. More precisely, we identify two main research questions: 1. RQ1: How has the Incel community evolved on YouTube over the last decade? 2. RQ2: Does YouTube's recommendation algorithm contribute to steering users towards Incel communities? Methods. We collect a set of 6.5K YouTube videos shared on Incel-related subreddits (e.g., /r/incels, /r/braincels, etc.), as well as a set of 5.7K random videos as a baseline. We then build a lexicon of 200 Incel-related terms via manual annotation, using expressions found on the Incel Wiki. We use the lexicon to label videos as ""Incel-related,"" based on the appearance of terms in the transcript, which describes the video's content, and comments on the videos. Next, we use several tools, including temporal and graph analysis, to investigate the evolution of the Incel community on YouTube and whether YouTube's recommendation algorithm contributes to steering users towards Incel content. To build our graphs, we use the YouTube Data API, which lets us analyze YouTube's recommendation algorithm's output based on video item-to-item similarities, as well as general user engagement and satisfaction metrics [81] . Main Findings. Overall, our study yields the following main findings: • We find an increase in Incel-related activity on YouTube over the past few years and in particular concerning Incelrelated videos, as well as comments that include pertinent terms. This indicates that Incels are increasingly exploiting the YouTube platform to broadcast and discuss their views. • Random walks on the YouTube's recommendation graph using the Data API and without personalization reveal that with a 6.3% probability a user will encounter an Incelrelated video within five hops if they start from a random non-Incel-related video posted on Reddit. Simultaneously, Incel-related videos are more likely to be recommended within the first two to four hops than in the subsequent hops. • We also find a 9.4% chance that a user will encounter an Incel-related video within three hops if they have visited Incel-related videos in the previous two hops. This means that a user who purposefully and consecutively watches two or more Incel-related videos is likely to continue being recommended such content and with higher frequency. Overall, our findings indicate that Incels are increasingly exploiting YouTube to spread their ideology and express their misogynistic views. They also indicate that the threat of recommendation algorithms nudging users towards extreme content is real and that platforms and researchers need to address and mitigate these issues. Paper Organization. We organize the rest of the paper as follows. The next section presents an overview of Incel ideology and the Manosphere and a review of the related work. Section 3 provides information about our data collection and video annotation methodology, while Section 4 analyzes the evolution of the Incel community on YouTube. Section 5 presents our analysis of how YouTube's recommendation algorithm behaves with respect to Incel-related videos. Finally, we discuss our findings and possible design implications for social media platforms, and conclude the paper in Section 6.@story_separate@Incels are a part of the broader ""Manosphere,"" a loose collection of groups revolving around a common shared interest in ""men's rights"" in society [28] . While we focus on Incels, understanding the overall Manosphere movement provides relevant context. In this section, we provide background information about Incels and the Manosphere. We also review related work focusing on understanding Incels on the Web, YouTube's recommendation algorithm and user radicalization, as well as harmful activity on YouTube. The Manosphere. The emergence of the so-called Web 2.0 and popular social media platforms have been crucial in enabling the Manosphere [47] . Although the Manosphere had roots in anti-feminism [24, 52] , it is ultimately a reactionary community, with its ideology evolving and spreading mainly on the Web [28] . Blais et al. [11] analyze the beliefs concerning the Manosphere from a sociological perspective and refer to it as masculinism. They conclude that masculinism is: ""a trend within the anti-feminist counter-movement mobilized not only against the feminist movement but also for the defense of a non-egalitarian social and political system, that is, patriarchy."" Subgroups within the Manosphere actually differ significantly. For instance, Men Going Their Own Way (MGTOWs) are hyper-focused on a particular set of men's rights, often in the context of a bad relationship with a woman. These subgroups should not be seen as distinct units. Instead, they are interconnected nodes in a network of misogynistic discourses and beliefs [12] . According to Marwick and Lewis [47] , what binds the manosphere subgroups is ""the idea that men and boys are victimized; that feminists, in particular, are the perpetrators of such attacks."" Overall, research studying the Manosphere has been mostly theoretical and qualitative in nature [28, 30, 33, 43] . These qualitative studies are important because they guide our study in terms of framework and conceptualization while motivating large-scale data-driven work like ours. Incels. Incels are arguably the most extreme subgroup of the Manosphere [7] . Incels appear disarmingly honest about what is causing their grievances compared to other radical ideologies. They openly put their sexual deprivation, which is supposedly caused by their unattractive appearance, at the forefront, thus rendering their radical movement potentially more persuasive and insidious [50] . Incel ideology differs from the other Manosphere subgroups in the significance of the ""involuntary"" aspect of their celibacy. They believe that society is rigged against them in terms of sexual activity, and there is no solution at a personal level for the systemic dating problems of men [35, 51, 62] . Further, Incel ideology differs from, for example, MGTOW, in the idea of voluntary vs. involuntary celibacy. MGTOWs are choosing to not partake in sexual activities, while Incels believe that society adversarially deprives them of sexual activity. This difference is crucial, as it gives rise to some of their more violent tendencies [28] . Incels believe to be doomed from birth to suffer in a modern society where women are not only able but encouraged to focus on superficial aspects of potential mates, e.g., facial structure or racial attributes. Some of the earliest studies of ""involuntary celibacy"" note that celibates tend to be more introverted and that, unlike women, celibate men in their 30s tend to be poorer or even unemployed [41] . In this distorted view of reality, men with these desirable attributes (colloquially nicknamed Chads by Incels) are placed at the top of society's hierarchy. While a perusal of influential people in the world would perhaps lend credence to the idea that ""handsome"" white men are indeed at the top, the Incel ideology takes it to the extreme. Incels rarely hesitate to call for violence [4] . For example, when they seek advice from other Incels about their physical appearance using the phrase ""How over is it?,"" they may be encouraged to ""rope"" (to hang oneself) [17] . Occasionally they call for outright gendercide. Zimmerman et al. [82] associate Incel ideology to white-supremacy, highlighting how it should be taken as seriously as other forms of violent extremism. Incels and the Web. Massanari [48] performs a qualitative study of how Reddit's algorithms, policies, and general community structure enables, and even supports, toxic culture. She focuses on the #GamerGate and Fappening incidents, both of which had primarily female victims, and argues that specific design decisions make it even worse for victims. For instance, the default ordering of posts on Reddit favors mobs of users promoting content over a smaller set of victims attempting to have it removed. She notes that these issues are exacerbated in the context of online misogyny because many of the perpetrators are extraordinarily techno-literate and thus able to exploit more advanced features of social media platforms. Baele et al. [4] study content shared by members of the Incel community, focusing on how support and motivation for violence result from their worldview. Farell et al. [23] perform a large-scale quantitative study of the misogynistic language across the Manosphere on Reddit. They create nine lexicons of misogynistic terms to investigate how misogynistic language is used in 6M posts from Manosphere-related subreddits. Jaki et al. [38] study misogyny on the Incels.me forum, analyzing users' language and detecting misogyny instances, homophobia, and racism using a deep learning classifier that achieves up to 95% accuracy. Furthermore, Ribeiro et al. [63] focus on the evolution of the broader Manosphere and perform a large-scale characterization of multiple Manosphere communities mainly on Reddit and six other Web forums associated with these communities. They find that older Manosphere communities, such as Men's Rights Activists and Pick Up Artists, are becoming less pop-ular and active. In comparison, newer communities like Incels and MGTOWs attract more attention. They also find a substantial migration of users from old communities to new ones, and that newer communities harbor more toxic and extreme ideologies. In another study, Ribeiro et al. [64] investigate whether platform migration of toxic online communities compromises content moderation. To do this, they focus on two communities on Reddit, namely, /r/Incels and /r/The Donald, and use them to assess whether community-level moderation measures were effective in reducing the negative impact of toxic communities. They conclude that a given platforms' moderation measures may create even more radical communities on other platforms. Instead, in our work we focus on the most extreme subgroup of the Manosphere, the Incel community, and we provide the first study of this community on YouTube, a platform where misogynistic ideologies, like Incel ideology, are relatively unstudied. We focus on analyzing the footprint of this community on YouTube aiming to quantify its growth over the last decade. More importantly, we also investigate how the opaque nature of YouTube's recommendation algorithm enables the discovery of Incel-related content by both random users of the platform and users who purposefully choose to see such content. Harmful Activity on YouTube. YouTube's role in harmful activity has been studied mostly in the context of detection. Agarwal et al. [3] present a binary classifier trained with user and video features to detect videos promoting hate and extremism on YouTube, while Giannakopoulos et al. [27] develop a knearest classifier trained with video, audio, and textual features to detect violence on YouTube videos. Jiang et al. [39] investigate how channel partisanship and video misinformation affect comment moderation on YouTube, finding that comments are more likely to be moderated if the video channel is ideologically extreme. Sureka et al. [72] use data mining and social network analysis techniques to discover hateful YouTube videos, while Ottoni et al. [59] analyze video content and user comments on alt-right channels. Zannettou et al. [80] present a deep learning classifier for detecting videos that use manipulative techniques to increase their views, i.e., clickbait. Papadamou et al. [60] , and Tahir et al. [73] focus on detecting inappropriate videos targeting children on YouTube. Mariconti et al. [45] build a classifier to predict, at upload time, whether or not a YouTube video will be ""raided"" by hateful users. Additional studies point to the need for a better understanding of misogynistic content on YouTube. Wotanis et al. [79] show that more negative feedback is given to female than male YouTubers by analyzing hostile and sexist comments on the platform. Döring et al. [21] build on this study by empirically investigating male dominance and sexism on YouTube, concluding that male YouTubers dominate YouTube, and that female content producers are prone to receiving more negative and hostile video comments. To the best of our knowledge, our work is the first to provide a large-scale understanding and analysis of misogynistic content on YouTube generated by the Manosphere subgroups. In particular, we investigate the role of YouTube's recommendation algorithm in disseminating Incel-related content on the platform. YouTube Recommendations. YouTube determines the ranks of the videos recommended to users based on various user engagement (e.g., user clicks, degree of engagement with recommended videos, etc.) and satisfaction metrics (e.g., likes, dislikes, etc.). Aiming to increase the time that a user spends watching a particular video, the platform also considers various other user personalization factors, such as demographics, geolocation, or the watch history of the user [81] . Covington et al. [19] describe YouTube's recommendation algorithm, using a deep candidate generation model to retrieve a small subset of videos from a large corpus and a deep ranking model to rank those videos based on their relevance to the user's activity. Zhao et al. [81] propose a large-scale ranking system for YouTube recommendations. The proposed model ranks the candidate recommendations based on user engagement and satisfaction metrics. Others focus on analyzing YouTube recommendations on specific topics. Ribeiro et al. [65] perform a large-scale audit of user radicalization on YouTube: they analyze videos from Intellectual Dark Web, Alt-lite, and Alt-right channels, showing that they increasingly share the same user base. They also analyze YouTube's recommendation algorithm finding that Altright channels can be reached from both Intellectual Dark Web and Alt-lite channels. Stöcker et al. [70] analyze the effect of extreme recommendations on YouTube, finding that YouTube's auto-play feature is problematic. They conclude that preventing inappropriate personalized recommendations is technically infeasible due to the nature of the recommendation algorithm. Finally, [34] focus on measuring misinformation on YouTube and perform audit experiments considering five popular topics like 9/11 and chemtrail conspiracy theories to investigate whether personalization contributes to amplifying misinformation. They audit three YouTube features: search results, Up-next video, and Top 5 video recommendations, finding a filter bubble effect [61] in the video recommendations section for almost all the topics they analyze. In contrast to the above studies, we focus on a different societal problem on YouTube. We explore the footprint of the Incel community, and we analyze the role of the recommendation algorithm in nudging users towards them. To the best of our knowledge, our work is the first to study the Incel community on YouTube and the role of YouTube's recommendation algorithm in the circulation of Incel-related content on the platform. We devise a methodology for annotating videos on the platform as Incel-related and using several tools, including text and graph analysis. We study the Incel community's footprint on YouTube and assess how YouTube's recommendation algorithm behaves with respect to Incel-related videos. We now present our data collection and annotation process to identify Incel-related videos. To collect Incel-related videos on YouTube, we look for YouTube links on Reddit, since recent work [63] highlighted that Incels are particularly active on Reddit. We start by creating a list of subreddits that are relevant to Incels. To do so, we inspect around 15 posts on the Incel Wiki [37] looking for references to subreddits and compile a list 1 of 19 Incel-related subreddits. This list also includes a set of communities relevant to Incel ideology (even possibly anti-incel like /r/Inceltears) to capture a broader collection of relevant videos. We collect all submissions and comments made between June 1, 2005, and April 30, 2019, on the 19 Incel-related subreddits using the Reddit monthly dumps from Pushshift [6] . We parse them to gather links to YouTube videos, extracting 5M posts, including 6.5K unique links to YouTube videos that are still online and have a transcript available by YouTube to download. Next, we collect the metadata of each YouTube video using the YouTube Data API [29] . Specifically, we collect: 1) transcript; 2) title and description; 3) a set of tags defined by the uploader; 4) video statistics such as the number of views, likes, etc.; and 5) the top 1K comments, defined by YouTube's relevance metric, and their replies. Throughout the rest of this paper, we refer to this set of videos, which is derived from Incelrelated subreddits, as ""Incel-derived"" videos. Table 1 reports the total number of users, posts, linked YouTube videos, and the period of available information for each subreddit. Although recently created, /r/Braincels has the largest number of posts and YouTube videos. Also, even though it was banned in November 2017 for inciting violence against women [31] , /r/Incels is fourth in terms of YouTube videos shared. Lastly, note that most of the subreddits in our sample were created between 2015 and 2018, which already suggests a trend of increasing popularity for the Incel community. Control Set. We also collect a dataset of random videos and use it as a control to capture more general trends on YouTube videos shared on Reddit as the Incel-derived set includes only videos posted on Incel communities on Reddit. To collect Control videos, we parse all submissions and comments made on Reddit between June 1, 2005, and April 30, 2019, using the Reddit monthly dumps from Pushshift, and we gather all links 1 Available at https://bit.ly/incel-related-subreddits-list. Step 1 Step 2 Step 3 Count Incel-related terms in the transcript and comments of the reviewed videos Label videos using multiple combinations of the min. number of Incel-related terms in the transcript and comments Using the labels from Step 2 calculate the performance metrics of each possible combination in Step 4 and find the optimal combination Step 4 Step 5 Annotate all videos in the dataset using the optimal combination of Incel-related terms Step 6 Figure 1 : Overview of our video annotation methodology. to YouTube videos. From them, we randomly select 5,793 links shared in 2,154 subreddits 2 for which we collect their metadata using the YouTube Data API. We choose to use a randomly selected set of videos shared on Reddit as our Control set for a more fair comparison since our Incel-derived set also includes videos shared on this platform. We collect random videos instead of videos relevant to another sensitive topic because this allows us to study the amount of Incel-related content that can generally be found on YouTube. At the same time, videos relevant to another sensitive topic or community (e.g., MGTOW) may have strong similarities with Incel-related videos, hence they may not be able to capture more general trends on YouTube. The analysis of Incel-related content on YouTube differs from analyzing other types of inappropriate content on the platform. So far, there is no prior study exploring the main themes involved in videos that Incels find of interest. This renders the task of annotating the actual video rather cumbersome. Besides, annotating the video footage does not by itself allow us to study the footprint of the Incel community on YouTube effectively. When it comes to this community, it is not only the video's content that may be relevant. Rather, the language that the community members use in their videos or comments for or against their views is also of interest. For example, there are videos featuring women talking about feminism, which are heavily commented on by Incels. Building a Lexicon. To capture the variety of aspects of the problem, we devise an annotation methodology based on a lexicon of terms that are routinely used by members of the Incel community and use it to annotate the videos in our dataset. To create the lexicon (Step 1 in Figure 1 ), we first crawl the ""glossary"" available on the Incels Wiki page [36] , gathering 395 terms. Since the glossary includes several words that can also be regarded as general-purpose (e.g., fuel, hole, legit, etc.), we employ three human annotators to determine whether each term is specific to the Incel community. We note that all annotators label all the 395 terms of the glossary. The three annotators are authors of this paper and they are familiar with scholarly articles on the Incel community and the Manosphere in general. Before the annotation task, a discussion took place to frame the task and the annotators were told to consider a term relevant only if it expresses hate, misogyny, or is directly associated with Incel ideology. For example, the phrase ""Beta male"" or any Incel-related incident (e.g., ""supreme gentleman,"" an indirect reference to the Isla Vista killer Elliot Rodgers [78] ). We note that, during the labeling, the annotators had no discussion or communication whatsoever about the task at hand. We then create our lexicon by only considering the terms annotated as relevant, based on all the annotators' majority agreement, which yields a 200 Incel-related term dictionary 3 . We also compute the Fleiss' Kappa Score [26] to assess the agreement between the annotators, finding it to be 0.69, which is considered ""substantial"" agreement [42] . Labeling. Next, we use the lexicon to label the videos in our dataset. We look for these terms in the transcript, title, tags, and comments of our dataset videos. Most matches are from the transcript and the videos' comments; thus, we decide to use these to determine whether a video is Incel-related. To select the minimum number of Incel-related terms that transcripts and comments should contain to be labeled as ""Incel-related,"" we devise the following methodology: 1. We randomly select 1K videos from the Incel-derived set, which the first author of this paper manually annotates as ""Incel-related"" or ""Other"" by watching them and looking at the metadata. Note that Incel-related videos are a subset of Incel-derived ones (Step 2 in Figure 1 ). We count the number of Incel-related terms in the transcript and the annotated videos' comments (Step 3 in Figure 1 ). 3. For each possible combination of the minimum number of Incel-related terms in the transcript and the comments, we label each video as Incel-related or not, and calculate the accuracy, precision, recall, and F1 score based on the labels assigned to the videos during the manual annotation (Steps 4 and 5 in Figure 1 ). Table 2 shows the performance metrics for the top five combinations of the number of Incel-related terms in the transcript and the comments. We pick the one yielding the best F1 score (to balance between false positives and false negatives), which is reached if we label a video as Incel-related when there is at least one Incel-related term in the transcript and at least three in the comments. Using this rule, we annotate all the videos in our dataset (Steps 5 and 6 in Figure 1 ). Table 1 reports the label statistics of the Incel-derived videos per subreddit. Our final labeled dataset includes 290 Incelrelated and 6, 162 Other videos in the Incel-derived set, and 66 Incel-related and 5, 727 Other videos in the Control set. Overall, we follow standard ethical guidelines [20, 66] regarding information research and the use of shared measurement data. In this work, we only collect and process publicly available data, make no attempt to de-anonymize users, and our data collection does not violate the terms of use of the APIs we employ. More precisely, we ensure compliance with GDPR's ""Right of Access"" [1] and ""Right to be Forgotten"" [2] principles. For the former, we give users the right to obtain a copy of any data that we maintain about them for the purposes of this research, while for the former we ensure that we delete and not share with any unauthorized party any information that has been deleted from the public repositories from which we obtain our data. We also note that we do not share with anyone any sensitive personal data, such as the actual content of the Figure 3 : Percentage of videos published per month for both Incelderived and Control videos. We also depict the date when Reddit decided to ban the /r/Incels subreddit. comments that we analyze or the usernames of the commenting users. Instead, we make publicly available for reproducibility and research purposes all the metadata of the collected and annotated videos 4 that do not include any personal data, as well as the unique identifiers of the comments that we analyze while ensuring that we abide by GDPR's ""Right to be Forgotten"" [2] principle. Furthermore, our video annotation methodology abides by the ethical guidelines defined by the Association of Internet Researchers (AoIR) for the protection of researchers [57] . Note that in our video annotation methodology we do not engage any human subjects other than the three authors of this paper. Since the annotators are authors of this paper, we do not take into consideration harmful effects on random human annotators due to inappropriate content. However, we still consider the effect of the content that we study on the authors and especially the student authors. We address this with continuous monitoring and open discussions with members of the research team, as well as by properly applying best practices from the psychological and social scientific literature on the topic, e.g., [5, 8, 10] . One of the primary goals is to minimize the risk that the researchers become de-sensitized with respect to such content. Finally, we believe that studying misogynistic and hateful communities in depth is bound to be beneficial for society at large, as well as for victims of such abuse. This section explores how the Incel communities on YouTube and Reddit have evolved in terms of videos and comments posted. We start by studying the ""evolution"" of the Incel communities concerning the number of videos they share. First, we look at the frequency with which YouTube videos are shared on various Incel-related subreddits per month; see Figure 2 . of each community. After June 2016, we observe that Incelrelated subreddits users start linking to YouTube videos more frequently and more in 2018. This trend is more pronounced on /r/Braincels in both the absolute number of videos shared and the number of videos shared per active user; see /r/Braincels in Figure 2 (a) and Figure 2 (b). This indicates that the use of YouTube to spread Incel ideology is increasing. Note that the sharp drop of /r/Incels activity is due to Reddit's decision to ban this subreddit for inciting violence against women in November 2017 [31] (see annotation in Figure 2 (a) and Figure 2 (b)). However, the sharp increase of /r/Braincels activity after this period questions the efficacy of Reddit's decision to ban /r/Incels, and it can be considered as evidence that the ban was ineffective in terms of suppressing the activity of the Incel community on the platform. It also worths noting that Reddit decided to ban /r/Braincels in September 2019 [67] . In Figure 3 , we plot the percentage of videos published per month for both Incel-derived and Control videos, while we also depict the date when Reddit decided to ban the /r/Incels subreddit. While the increase in the number of Other videos remains relatively constant over the years for both sets of videos, this is not the case for Incel-related ones, as 81% and 64% of them in the Incel-derived and Control sets, respectively, published after December 2014. Overall, there is a steady increase in Incel activity, especially after 2016, which is particularly worrisome as we have several examples of users who were radicalized online and have gone to undertake deadly attacks [13] . An even higher increase in Incel-activity is also observed after the ban of the /r/Incels subreddit. Figure 6 : Self-similarity of commenting users in adjacent months for both Incel-derived and Control videos. We also depict the date when Reddit decided to ban the /r/Incels subreddit. Next, we study the commenting activity on both Reddit and YouTube. Figure 4 shows the number of comments posted per month for both YouTube Incel-derived and Control videos, and Reddit. Activity on both platforms starts to markedly increase after 2016, and more after the ban of /r/Incels in November 2017, with Reddit and YouTube Incel-derived videos having substantially more comments than the Control videos. Once again, the sharp increase in the commenting activity over the last few years signals an increase in the Incel user base's size. To further analyze this trend, we look at the number of unique commenting users per month on both platforms; see Figure 5 . On Reddit, we observe that the number of unique users remains steady over the years, increasing from 10K in August 2017 to 25K in April 2019. This is mainly because most of the subreddits in our dataset (58%) were created after 2016. On the other hand, for the Incel-derived videos on YouTube, there is a substantial increase from 30K in February 2017 to 132K in April 2019. We also observe an increase of the Control videos' unique commenting users (from 18K in February 2017 to 53K in April 2019). However, the increase is not as sharp as that of the Incel-derived videos; 483% vs. 1, 040% increase in the average unique commenting users per month after January 2017 in Control and Incel-derived videos, respectively. To assess whether the sharp increase in unique commenting users of the Incel-derived and Control videos after 2017 is due to the increased interest by random users or to an increased interest in those videos and their discussions by the same users over the years, we use the Overlap Coefficient similarity metric [76] ; it measures user retention over time for the videos in our dataset. Specifically, we calculate, for each month, the similarity of commenting users with those doing so the month before, for both Incel-related and Other videos in the Incel-derived and Control sets. Note that if the set of commenting users of a specific month is a subset of the previous month's commenting users or the converse, the overlap coefficient is equal to 1. The results of this calculation are shown in Figure 6 , in which we again depict the date when Reddit decided to ban /r/Incels. Interestingly, for the Incel-related videos of the Incel-derived set, we find a sharp growth in user retention right after the ban of the /r/Incels subreddit in November 2017, while this is not the case for the Incel-related videos of the Control set. For the Incelrelated videos of the Control set, we observe a more steady in- crease in user retention over time. Once again, this might be related to the increased popularity of the Incel communities and might indicate that the ban of /r/Incels energized the community and made participants more persistent. Also, the higher user retention of Other videos in both sets is likely due to the much higher proportion of Other videos in each set. Last, we observe a spike in user retention for the Incel-related videos of the Control set during 2009. However, after checking the publication dates of these videos in our dataset, we only find three Incel-related videos in the Control set uploaded before July 2009. Hence, it might be the case that the same users repeatedly commented on those videos during 2008 and 2009. At the same time, no other Incel-related videos in the Control was uploaded between July 2009 and July 2010, hence the drop in user retention after July 2009. Next, we present an analysis of how YouTube's recommendation algorithm behaves with respect to Incel-related videos. More specifically, 1) we investigate how likely it is for YouTube to recommend an Incel-related video; 2) we simulate the behavior of a user who views videos based on the recommendations by performing random walks on YouTube's recommendation graph to measure the probability of such a user discovering Incel-related content; and 3) we investigate whether the frequency with which Incel-related videos are recommended increase for users who choose to see the content. To build the recommendation graphs used for our analysis, we use functionality provided by the YouTube Data API. For each video in the Incel-derived and Control sets, we collect the top 10 recommended videos associated with it. Note that the use of the YouTube Data API is associated with a specific account only for authentication to the API, and that the API does not maintain a watch history nor any cookies. Thus, our data collection does not capture how specific account features or the viewing history affect personalized recommendations. Instead, the YouTube Data API allows us to collect recommendations provided by YouTube's recommendation algorithm based on video item-to-item similarity, as well as general user engagement and satisfaction metrics [81] . The collected recommendations are similar to the recommendations presented to a non-logged-in user who watches videos on YouTube. We collect the recommendations for the Incel-derived videos between September 20 and October 4, 2019, and the Control between October 15 and November 1, 2019. To annotate the collected videos, we follow the same approach described in Section 3.2. Since our video annotation is based on the videos' transcripts, we only consider the videos that have one when building our recommendations graphs. Next, we build a directed graph for each set of recommendations, where nodes are videos (either our dataset videos or their recommendations), and edges between nodes indicate the recommendations between all videos (up to ten). For instance, if video2 is recommended via video1, then we add an edge from video1 to video2. Throughout the rest of this paper, we refer to each set of videos' collected recommendations as separate recommendation graphs. First, we investigate the prevalence of Incel-related videos in each recommendation graph. Table 3 reports the number of Incel-related and Other videos in each graph. For the Incelderived graph, we find 36,7K (97.1%) Other and 1K (2.9%) Incel-related videos, while in the Control graph, we find 28,9K (98.5%) Other and 428 (1.5%) Incel-related videos. These findings highlight that despite the proportion of Incel-related video recommendations in the Control graph being smaller, there is still a non-negligible amount recommended to users. Also, note that we reject the null hypothesis that the differences between the two graphs are due to chance via the Fisher's exact test (p < 0.001) [25] . How likely is it for YouTube to recommend an Incel-related Video? Next, to understand how frequently YouTube recommends an Incel-related video, we study the interplay between the Incel-related and Other videos in each recommendation graph. For each video, we calculate the out-degree in terms of Incel-related and Other labeled nodes. We can then count the number of transitions the graph makes between differently labeled nodes. Table 4 reports the percentage of each transition between the different types of videos for both graphs. Perhaps unsurprisingly, most of the transitions, 93.2% and 97.0%, respectively, in the Incel-derived and Control recommendation graphs are between Other videos, but this is mainly because of the large number of Other videos in each graph. We also find a high percentage of transitions between Other and Incelrelated videos. When a user watches an Other video, if they randomly follow one of the top ten recommended videos, there is a 2.9% and 1.5% probability in the Incel-derived and Control graphs, respectively, that they will end up at an Incelrelated video. Interestingly, in both graphs, Incel-related videos are more often recommended by Other videos than by Incelrelated videos. On the one hand, this might be due to the larger number of Other videos compared to Incel-related videos in both recommendation graphs. On the other hand, this may indi- Figure 7 : Percentage of random walks where the random walker encounters at least one Incel-related video for both starting scenarios. Note that the random walker selects, at each hop, the next video to watch at random. Figure 8 : Percentage of Incel-related videos across all unique videos that the random walk encounters at hop k for both starting scenarios. Note that the random walker selects, at each hop, the next video to watch at random. cate that YouTube's recommendation algorithm cannot discern Incel-related videos, which are likely misogynistic. contribute to steering users towards Incel communities? We then study how YouTube's recommendation algorithm behaves with respect to discovering Incel-related videos. Through our graph analysis, we showed that the problem of Incel-related videos on YouTube is quite prevalent. However, it is still unclear how often YouTube's recommendation algorithm leads users to this type of content. To measure this, we perform experiments considering a ""random walker."" This allows us to simulate a random user who starts from one video and then watches several videos according to the recommendations. More precisely, since we build our recommendation graphs using the YouTube Data API, the random walker simulates non-logged-in users who watch videos on YouTube. The random walker begins from a randomly selected node and navigates the graph choosing edges at random for five hops. We repeat this process for 1, 000 random walks considering two starting scenarios. In the first scenario, the starting node is restricted to Incel-related videos. In the sec-ond, it is restricted to Other. We perform the same experiment on both the Incel-derived and Control recommendations graphs. Next, for the random walks of each recommendation graph, we calculate two metrics: 1) the percentage of random walks where the random walker finds at least one Incel-related video in the k-th hop; and 2) the percentage of Incel-related videos over all unique videos that the random walker encounters up to the k-th hop for both starting scenarios. The two metrics, at each hop are shown in Figure 7 and 8 for both recommendation graphs. When starting from an Other video, there is, respectively, a 10.8% and 6.3% probability to encounter at least one Incelrelated video after five hops in the Incel-derived and Control recommendation graphs (see Figure 7 (a)). When starting from an Incel-related video, we find at least one Incel-related in 43.4% and 36.5% of the random walks performed on the Incelderived and Control recommendation graphs, respectively (see Figure 7 (b)). Also, when starting from Other videos, most of the Incel-related videos are found early in our random walks (i.e., at the first hop), and this number remains almost the same as the number of hops increases (see Figure 8 (a)). The same stands when starting from Incel-related videos, but in this case, the percentage of Incel-related videos decreases as the number of hops increases for both recommendation graphs (see Figure 8(b) ). As expected, in all cases, the probability of encountering Incel-related videos in random walks performed on the Incel-derived recommendation graph is higher than in the random walks performed on the Control recommendation graph. We also verify that the difference between the distribution of Incel-related videos encountered in the random walks of the two recommendation graphs is statistically significant via the Kolmogorov-Smirnov test [49] (p < 0.05). Overall, we find that Incel-related videos are usually recommended within the two first hops. However, in subsequent hops, the number of encountered Incel-related videos decreases. This indicates that in the absence of personalization (e.g., for a non-logged-in user), a user casually browsing YouTube videos is unlikely to end up in a region dominated by Incel-related videos. videos are recommended increase for users who choose to see the content? So far, we have simulated the scenario where a user browses the recommendation graph randomly, i.e., they do not select Incel-related videos according to their interests or other cues nudging them to view certain content. Next, we simulate the behavior of a user who chooses to watch a few Incel-related videos and investigate whether or not he will get recommended Incel-related videos with a higher probability within the next few hops. Table 5 reports how likely it is for a user to encounter Incelrelated videos assuming he has already watched a few. To do so, we use the random walks performed on the Incel-derived and Control recommendation graphs in section 5.2. We consider only the random walks started from an Incel-related video, and we zero in on those where the user watches consecutive Incelrelated videos. Specifically, we report two metrics: 1) the probability that a user encounters at least one Incel-related video in 5 − M hops, having already seen M consecutive Incel-related videos; and 2) the probability that the user will encounter an Incel-related video on the M + 1 hop, assuming he has already seen M consecutive Incel-related videos. Note that, at each hop M of a random walk, we calculate both metrics by only considering the random walks for which all the videos encountered in the first M hops of the walk were Incel-related. These metrics allow us to understand whether the recommendation algorithm keeps recommending Incel-related videos to a user who starts watching a few of them. At every hop M, there is a ≥ 43.4% and ≥ 36.5% chance to encounter at least one Incel-related video within 5 − M hops in the Incel-derived and Control recommendation graphs, respectively (second and fourth column in Table 5 ). Furthermore, by looking at the probability of encountering an Incel-related video at hop M + 1, having already watched M Incel-related videos (third and right-most column in Table 5 ), we find an increasingly higher chance as the number of consecutive Incelrelated increases. Specifically, for the Incel-derived recommendation graph, the probability rises from 4.1% at the first hop to 30.1% for the last hop. For the Control recommendation graph, it rises from 2.1% to 17.7%. These findings unveil that as users watch Incel-related videos, the algorithm recommends other Incel-related content with increasing frequency. In Figure 9 , we plot the CDF of the percentage of Incel-related recommendations for each node in both recommendation graphs. In the Incel-derived recommendation graph, 4.6% of the Incel-related videos have more than 80.0% Incel-related recommendations, while 10.0% of the Incel-related videos have more than 50.0% Incel-related recommendations. The percentage of Other videos that have more than 50.0% Incel-related recommendations is negligible. Although the percentage of Incel-related recommendations is lower, we see similar trends for the Control recommendation graph: 8.6% of the Incel-related videos have more than 50.0% Incel-related recommendations. Arguably, the effect we observe may be a contributor to the anecdotally reported echo chamber effect. This effect entails a viewer who begins to engage with this type of content and likely falls into an algorithmic rabbit hole, with recommendations becoming increasingly dominated by such harmful content and beliefs, which also becomes increasingly extreme [16, 53, 56, 65, 68] . However, the degree to which the above-inferred algorithm characteristics contribute to a possible echo chamber effect depends on: 1) personalization factors; and 2) the ability to measure whether recommendations become increasingly extreme. Overall, our analysis of YouTube's recommendation algorithm yields the following main findings: 1. We find a non-negligible amount of Incel-related videos (2.9%) within YouTube's recommendation graph being recommended to users (see Table 3 ); 2. When a user watches a non-Incel-related video, if they randomly follow one of the top ten recommended videos, there is a 2.8% chance they will end up with an Incelrelated video (see Table 4 ); 3. By performing random walks on YouTube's recommendation graph, we find that when starting from a random non-Incel-related video, there is a 6.3% probability to encounter at least one Incel-related video within five hops (see Figure 7 (a)); 4. As users choose to watch Incel-related videos, the algorithm recommends other Incel-related videos with increasing frequency (see the third and the right-most column of Table 5 ). Our analysis points to an increase in Incel-related activity on YouTube over the past few years. More importantly, our recommendation graph analysis shows that Incel-related videos are recommended with increasing frequency to users who keep watching them. This indicates that recommendation algorithms, to an extent indeed, nudge users towards extreme content. This section discusses our results in more detail and how they align with existing research in the area. We also discuss the technical challenges we faced and how we addressed them and highlight limitations. Our data collection and annotation efforts faced many challenges. First, there was no available dataset of YouTube videos related to the Incel community or any other Manosphere groups. Guided by other studies using Reddit as a source for collecting and analyzing YouTube videos [60] , and based on evidence suggesting that Incels are particularly active on Reddit [23, 63] , we build our dataset by collecting videos shared on Incel-related communities on Reddit. Second, devising a methodology for the annotation of the collected videos is not trivial. Due to the nature of the problem, we hypothesize that using a classifier on the video footage will not capture the various aspects of Incel-related activity on YouTube. This is because the misogynistic views of Incels may force them to heavily comment on a seemingly benign video (e.g., a video featuring a group of women discussing gender issues) [21] . Hence, we devise a methodology to detect Incel-related videos based on a lexicon of Incel-related terms that considers both the video's transcript and its comments. We believe that the scientific community can use our textbased approach to study other misogynistic ideologies on the platform, which tend to have their particular glossary. Our video annotation methodology might flag some benign videos as Incel-related. This can be a false positive or due to Incels that heavily comment on (or even raid [45] ) a benign video (e.g., a video featuring a group of women discussing gender issues). However, by considering the video's transcript in our video annotation methodology, we can achieve an acceptable detection accuracy that uncovers a substantial proportion of Incel-related videos (see Section 3.2). Despite this limitation, we believe that our video annotation methodology allows us to capture and analyze various aspects of Incel-related activity on the platform. Another limitation of this approach is that we may miss some Incel-related videos. One reason for this is that the members of web-based misogynistic communities often shift or obscure their language to avoid being detected. Notwithstanding such limitation, our approach approaches the lower bound of the Incel-related videos available in our dataset, allowing us to conclude that the implications of YouTube's recommendation algorithm on disseminating misogynistic content are at least as profound as we observe. Moreover, our work does not consider per-user personalization; the video recommendations we collect represent only some of the recommendation system's facets. More precisely, we analyze YouTube recommendations generated based on content relevance and the user base's engagement in aggregate. However, we believe that the recommendation graphs we obtain do allow us to understand how YouTube's recommendation system is behaving in our scenario. Also, note that a similar methodology for auditing YouTube's recommendation algorithm has been used in previous work [65] . As mentioned earlier, prior work suggests that Reddit's decision to ban subreddits did not solve the problem [15] , as users migrated to other platforms [55, 64] . At the same time, other studies show that Incels are particularly active on Reddit [24, 63] , pinpointing the need to develop methodologies that identify and characterize Manosphere-related activities on YouTube and other social media platforms. Realizing the threat, Reddit took measures to tackle the problem by banning several subreddits associated with the Incel community and the Manosphere in general. Driven by that, we set out to study the evolution of the Incel community, over the last decade, on other platforms like YouTube. Our results show that Incel-related activity on YouTube increased over the past few years, in particular, concerning the publication of Incel-related videos, as well as in comments that include pertinent terms. This indicates that Incels are increasingly exploiting YouTube to spread their ideology and express their misogynistic views. Although we do not know whether these users are banned Reddit users that migrated to YouTube or whether this increase in Incel-related activity is associated with the increased interest in Incel-related communities on Reddit over the past few years, our findings are still worrisome. Also, Reddit's decision to ban /r/Incels for inciting violence against women [31] and the observed sharp increase in Incel-related activity on YouTube after this period aligns with the theoretical framework proposed by Chandrasekharan et al. [15] . The increase in Incel-related activity also indicates that Reddit's decision may have energized the community and made its members more persistent. Despite YouTube's attempts to tackle hate [74] , our results show that the threat is clear and present. Also, considering that the Incel ideology is often associated with misogyny, and antifeminist views, as well as with multiple mass murders and violent offenses [14, 22] , we urge that YouTube develops effective content moderation strategies to tackle misogynistic content on the platform. Driven by the fact that members of the Incel community are prone to radicalization [13] and that YouTube has been repeatedly accused of contributing to user radicalization and promoting offensive content [40, 56] , we set out to assess whether YouTube's recommendation algorithm nudges users towards Incel communities. Using graph analysis, we analyze snapshots of YouTube's recommendation graph, finding that there is a non-negligible amount of Incel-related content being suggested to users. Also, by simulating a user who casually browses YouTube, we see a high chance that a user will encounter at least one Incel-related video five hops after he starts from a non-Incel-related video. Next, we simulate a user who, upon encountering an Incel-related video, becomes interested in this content and purposefully starts watching these types of videos. We do this to determine whether YouTube's recommendation graph steers such users into regions where a substantial portion of the recommended videos are Incel-related. Once users enter such regions, they are likely to consider such content as increasingly legitimate as they experience social proof of these narratives. They may find it difficult to escape to more benign content [68] . Interestingly, we find that once a user follows Incelrelated videos, the algorithm recommends other Incel-related videos to him with increasing frequency. Our results point to the echo chamber effect [16, 44] . However, the echo chamber effect definition includes the notion that the extremist nature of the improper videos increases along with the frequency with which they are recommended. Since we do not assess whether the videos suggested in subsequent hops are becoming increasingly extreme, we cannot conclude that we find a statistically significant indication of this effect. Nevertheless, even if we do not find strong evidence of an echo chamber, our findings are worrisome especially when considering the extreme misogynistic beliefs of the Incel community. To mitigate the harm caused to users by certain recommended videos and to incorporate community well-being into the objectives of its recommendation algorithm [71] , YouTube introduced ""user satisfaction"" metrics as input to the recommendation algorithm [81] . However, our findings show that misogynistic and harmful content is still being recommended to users and the recommendation algorithm is not able to discern and marginalize such content. Hence, we believe that more effort is required by researchers and platforms to effectively detect and suppress such content in a proactive and timely manner. Prior work has shown apparent user migration to increasingly extreme subcommunities within the Manosphere on Reddit [63] , and indications that YouTube recommendations serve as a pathway to radicalization. When taken along with our results, a more complete picture with respect to online extremist communities begins to emerge. Radicalization and online extremism is clearly a multiplatform problem. Social media platforms like Reddit, designed to allow organic creation and discovery of subcommunities, play a role, and so do platforms with algorithmic content recommendation systems. The immediate take away is that while the radicalization process and the spread of extremist content generalize (at least to some extent) across different online extremist communities, the specific mechanism likely does not generalize across different platforms, which has implications for the design of moderation systems and strategies. In particular, it implies that platform oriented-solutions should not exist in a vacuum, and indeed it is quite likely that information sharing between platforms could bolster overall effectiveness. For example, an approach that could benefit both platforms we study involves using Reddit activity to help tune the YouTube recommendation algorithm and using information from the recommendation algorithm to help Reddit perform content moderation. In such a hypothetical arrangement, Reddit, whose content moderation team is intimately familiar with the troublesome communities, could help YouTube understand how the content these communities consume fits within the recommendation graph. Similarly, Reddit's moderation efforts could be bolstered with information from the YouTube recommendation graph. The discovery of emerging dangerous communities could be aided by understanding where the content posted by them fits within the YouTube recommendation graph compared to the content posted by known troublesome communities. At the same time, our findings suggest that researchers who study radicalization and online extremism can benefit by performing cross-platform analysis as studying across multiple platforms can help in better understanding the footprint and evolvement of emerging dangerous communities. We plan to extend our work by studying other Manosphere communities on YouTube (e.g., Men Going Their Own Way) and user migration between Manosphere and other reactionary communities. We also plan to implement crawlers that will allow us to simulate real users and perform random walks on YouTube with user personalization. This will enable measurements of YouTube's recommendation graph while also assessing the effect of various personalization factors (e.g., gender, a user's watch history, etc.) on the amount of misogynistic content being recommended to a user. Note that this task is not straightforward as it requires understanding and replicating multiple meaningful characteristics of Incels' behavior. Another interesting direction for future research is to perform a survey study on YouTube with real users and even collecting their qualitative feedback. Last, an important direction for future work is to study the effect of the COVID-19 pandemic on the growth of web-based misogynistic communities.@story_separate@This paper presented a large-scale data-driven characterization of the Incel community on YouTube. We collected 6.5K YouTube videos shared by users in Incel-related communities within Reddit. We used them to understand how Incel ideology spreads on YouTube and study the evolution of the community. We found a non-negligible growth in Incel-related activity on YouTube over the past few years, both in terms of Incel-related videos published and comments likely posted by Incels. This result suggests that users gravitating around the Incel community are increasingly using YouTube to disseminate their views. Overall, our study is a first step towards understanding the Incel community and other misogynistic ideologies on YouTube. We argue that it is crucial to protect potential radicalization ""victims"" by developing methods and tools to detect Incelrelated videos and other misogynistic activities on YouTube. Our analysis shows growth in Incel-related activities on Reddit and highlights how the Incel community operates on multiple platforms and Web communities. This also prompts the need to perform more multi-platform studies to understand Manosphere communities further. We also analyzed how YouTube's recommendation algorithm behaves with respect to Incel-related videos. By performing random walks on the recommendation graph, we estimated a 6.3% chance for a user who starts by watching non-Incelrelated videos to be recommended Incel-related ones within five recommendation hops. At the same time, users who have seen two or three Incel-related videos at the start of their walk see recommendations that consist of 9.4% and 11.4% Incel-related videos, respectively. Moreover, the portion of Incel-related recommendations increases substantially as the user watches an increasing number of consecutive Incel-related videos. Our results highlight the pressing need to further study and understand the role of YouTube's recommendation algorithm in users' radicalization and content consumption patterns. Ideally, a recommendation algorithm should avoid recommending potentially harmful or extreme videos. However, our analysis confirms prior work showing that this is not always the case on YouTube [65] .","YouTube is by far the largest host of user-generated video content worldwide. Alas, the platform has also come under fire for hosting inappropriate, toxic, and hateful content. One community that has often been linked to sharing and publishing hateful and misogynistic content are the Involuntary Celibates (Incels), a loosely defined movement ostensibly focusing on men's issues. In this paper, we set out to analyze the Incel community on YouTube by focusing on this community's evolution over the last decade and understanding whether YouTube's recommendation algorithm steers users towards Incel-related videos. We collect videos shared on Incel communities within Reddit and perform a data-driven characterization of the content posted on YouTube. Among other things, we find that the Incel community on YouTube is getting traction and that, during the last decade, the number of Incel-related videos and comments rose substantially. We also find that users have a 6.3% chance of being suggested an Incel-related video by YouTube's recommendation algorithm within five hops when starting from a non Incel-related video. Overall, our findings paint an alarming picture of online radicalization: not only Incel activity is increasing over time, but platforms may also play an active role in steering users towards such extreme content."
"Orthotopic liver transplantation (OLT) remains the only curative modality for patients with end-stage liver disease. Since the first liver transplant in 1963, significant advances have occurred in the intensive care unit (ICU) management of patients, largely due to innovations in surgical technique, advances in anesthesia and perioperative care, and improvements in immunosuppression. Patients now experience shorter ICU stays, fewer readmissions, and improved overall survival. Indications for liver transplant and patient presentations vary, each influencing the immediate postoperative course. Transplant surgery occurs in specialized centers following rigorous work-up by multidisciplinary teams who go on to play a role in the patient's ongoing care. The initial ICU postoperative period following transplantation is influenced by a number of factors: the patient's underlying pathology, disease severity, comorbidities, quality of donor graft, and the intraoperative course [1] . All must be taken into account by the intensivist. Following a thorough handover and stabilization, attention is given to assessment of adequate graft function, provision of immune and infection prophylaxis, and adequate nutrition. Intensivists must be aware of complications that may initially arise in the ICU requiring early detection and management. Attention to detail with adherence to institution-specific evidence-based protocols is helpful in reducing ICU length of stay, readmission, and overall morbidity and mortality.@story_separate@Of great importance when admitting a liver transplant recipient is the information received at handover. The quality of the donor liver and the intraoperative course have great implication on immediate postoperative care. While the optimal deceased donor organ is that of a sizematched previously healthy donor following fatal brain injury [2] , organ supply shortages and growing transplant waiting lists have led to the increased use of marginal donors. The donor risk index [3] identified donor characteristics predictive of increased risk of graft failure thereby allowing better determination of donor-recipient pairing suitability. In addition, a prolonged warm ischemia time, donation after circulatory death, macrosteatosis [30 %, advanced donor age, and donor hypernatremia have been described as increasing the risk of impaired allograft function, rejection, and primary nonfunction [1] . Ultimately the intensivist's knowledge of donor organ quality proves valuable in anticipating potential pitfalls and predicting poor function. The intraoperative course is a useful predictor of initial intensive care course. Surgeons are questioned on graft quality, their assessment of function, operative anatomy, surgical approach, and anticipated concerns. The anesthesia team conveys features pertinent to the overall care of the patient, including blood loss, inotropic support, product replacement, coagulation status, and complications or instability. Intraoperatively, acid clearance, hemodynamic stability, glucose and bile production, and improvement in coagulation are all initial signs of stable and successful graft function. With this information in hand, attention may be turned to assessment and care of the patient. As with any admission to the ICU, an overall assessment of airway, breathing, and circulation must be performed. A systematic approach is particularly important for liver transplant recipients who have potential for instability within any of these domains. In assessment of ''airway and breathing,'' and in conjunction with the operative team, the intensivist determines the need for ventilation and timing of extubation. The practice of immediate extubation in the operating room versus later in the ICU, varies among transplant centers. Once considered unconventional, a number of centers now adopt a ''Fast Track'' approach to initial postoperative care with immediate or early extubation for patients meeting defined criteria [4] [5] [6] [7] . Others advocate a period of postoperative ventilation until assurance of hemodynamic stability, confirmation of graft function, and exclusion of need for return to the operating room. Proponents of immediate/early extubation cite numerous advantages including reduced length of ICU and hospital stay, earlier return of graft function, and lower costs and resource consumption [8] . Disadvantages to postoperative ventilation include increased risk of ventilator-associated lung injury and pneumonia, worsening venous congestion of the graft, and reduction in splanchnic flow. Mandell et al. found no negative impact on long-term outcome from early extubation, with 1-and 3-year survival rates remaining above national average [5] . Furthermore, a lack of evidence exists showing that routine postoperative ventilation actually improves outcome [9] . Opponents of immediate extubation cite the practice as unsafe, adding unnecessary risk. Studies have yet to show overall patient or graft survival is improved by this practice [10] . Additionally, success is institution-and resourcespecific. An existing multi-center trial indeed showed wide variation in successful extubation rates (5-67 %) despite attempts at uniform criteria [4, 11] . Agreement exists on the benefit of maintaining a period of mechanical ventilation for patients with significant encephalopathy, hypoxemia, hemodynamic instability, unstable coagulopathy, large volume product administration, high-risk of graft dysfunction, respiratory complications, and increased risk for return to surgery. Ultimately, each center must follow its own protocol regarding timing of extubation. A selective approach may be best, with emphasis on avoiding unnecessary delay in time to extubation. Patients should be extubated if stable, with adequate graft function ascertained and the need for emergent return to the operating room having been excluded [10] . The assessment of ''circulation'' and hemodynamics in liver transplant recipients is complex, often influenced by bleeding, third spacing, intraoperative resuscitation, and an underlying high-output, vasodilated state. In assessing patients, the intravascular volume status, underlying cardiac function and systemic vascular resistance (SVR) must be considered [1] . Assessment should commence with thorough clinical examination taking into account hemodynamic parameters, blood loss, product/fluid replacement, and urine output. Patient comorbidities such as renal dysfunction, cardiac failure, pulmonary hypertension, and right ventricular failure add to the complexity. Assessment and cessation of any ongoing bleeding should be ensured at this point. A variety of hemodynamic monitoring tools exist though use varies and is often influenced by those utilized intraoperatively. Arterial blood pressure monitoring and central venous line insertion are standard. Agreement exists, however, that central venous pressure is an unreliable indicator of intravascular and stroke volume [12, 13] . Transesophageal echocardiography provides real-time monitoring of preload status, cardiac contractility, and the differentiation of various cardiac pathologies. Its use in the ICU is limited by cost, availability, the need for expertise in interpretation, and the potential for esophageal or variceal injury/bleeding from probe insertion. Pulmonary artery catheters (PAC) provide information on cardiac filling pressures. Once common place, their use is decreasing and controversial, as insertion is not without risk [14] and numerous studies have shown wedge pressure to be a poor predictor of fluid responsiveness [13, 15, 16 • ]. Mixed venous oxygen saturation allows an indirect measure of cardiac output, and some PAC devices utilize rapidresponse thermistor calculation of continuous cardiac output and right ventricular end-diastolic volume. A significant advantage of the PAC lies in its ability to directly measure pulmonary arterial pressures and thereby guide management of high-risk patients with portopulmonary hypertension. Arterial pressure waveform analysis provides continuous measurement of stroke volume variation and pulse pressure variation to enable assessment of fluid responsiveness and cardiac output. Advantages include ease of interpretation, continuous beat-to-beat analysis, and minimal invasiveness. Limitations, however, include varied reliability during hemodynamically unstable conditions, particularly when vascular resistance changes to a large extent, as occurs with OLT recipients [17] . Hemodynamic optimization following OLT should ensure adequate cardiac filling, central blood volume, and end organ perfusion. Avoidance of excessive fluid is essential to prevent pulmonary congestion, subsequent graft edema, third spacing, and capillary leak [1] . While cirrhotic patients exhibit a hyperdynamic, high cardiac output state, some have poor cardiac contractility which may manifest following transplantation. Optimizing oxygen delivery through adequate cardiac output should be the principal focus with caution to avoid over resuscitating or under resuscitating the unstable patient [18] . Blood transfusion to maintain hemoglobin between 8 and 10 g/dL and hematocrit 25-30 % achieves adequate oxygen delivery to the graft [19] while reducing risk of vessel thrombosis from increased viscosity at higher hemoglobin levels. Vasopressor support maintains organ perfusion in patients with inadequate mean arterial pressure despite adequate volume replacement. Choice of agent varies and should be tailored to the patient. Norepinephrine is commonly utilized due to the low SVR state of end-stage liver disease patients. An accurate fluid balance is necessary as abnormalities may occur from massive fluid shifts, prolonged surgery, and ongoing bleeding. In the hemodynamically stable recipient, an initial negative fluid balance may decrease early pulmonary complications and improve oxygen delivery to the graft [20] . In a retrospective review by Levy et al., cardiopulmonary dysfunction was the primary etiology of ICU readmission following OLT, with fluid overload as the main cause on subgroup analysis [21] . Recipients with significant renal dysfunction requiring renal replacement therapy (RRT) necessitate even stricter fluid balance for prevention of volume overload while maintaining perfusion. Assessment of graft function is required early in the ICU admission in order to detect and correct any dysfunction. Assessment is based on clinical, laboratory, and radiological parameters. Clinically, adequate graft function is determined by stabilization of hemodynamics, production of bile, an increasing urine output and improving mentation with reversal of encephalopathy. An unexplained failure to reduce vasoactive support is often indicative of poor graft function. Lab assessment shows improving acid-base status, decreasing lactate, rising blood glucose (often requiring insulin), and improvement of coagulation with normalization of prothrombin time. Serial transaminase levels assess hepatocyte death and display a rise and peak (due to preservation injury) during the first 24-48 h before falling [1] . A persistent elevation or significant rise in AST and ALT suggests parenchymal injury warranting further investigation. Bilirubin, alkaline phosphatase (ALP), and gamma glutamyl transpeptidase (GGT) assess hepatic secretory function. They can remain normal up to day 5 before peaking day 7 to 14 due to reperfusion injury [22] . Radiological assessment of graft function involves routine postoperative doppler ultrasonography to determine graft inflow hemodynamics (patency of hepatic artery and portal vein) and outflow hemodynamics (hepatic vein). If vascular compromise is detected, surgical exploration or angiography may be warranted to correct underlying pathology. Immunosuppression Improvements in immunosuppression have made the greatest impact on survival rates following liver transplantation. Most centers commence calcineurin inhibitors (CNI) and corticosteroids with or without an anti-proliferative agent. Induction antibody therapy is increasingly utilized where a period of CNI-free treatment is desirable. In determining the appropriate regimen, intensivists are aided by hepatologists and institution-based protocols. Consensus among transplant centers has yet to be reached. Tacrolimus (a CNI that inhibits interleukin-2 (IL2) and interferon gamma) has become the mainstay immunosuppression agent. Superiority in preventing acute rejection, steroid-resistant rejection, graft loss and postoperative death [23, 24] makes this the first line agent, replacing cyclosporine. Side effects include diabetes, hypertension, nephrotoxity, hyperkalemia, hemolytic uremic syndrome, neurotoxicity and nausea/vomiting. The potential for drug interactions must be considered given it is cytochrome P-450 metabolism. Dosage should be guided by therapeutic drug monitoring with higher initial target levels for the first 6-8 weeks post transplant [25] and subsequent lower levels in the event of no rejection. Target ranges differ between transplant centers. Corticosteroids remain a cornerstone of initial immunosuppression protocols with an additional role during acute rejection. Weaning patients where possible avoids side effects of diabetes, fluid retention, hypertension, delirium, osteoporosis, poor wound healing, and adrenal suppression. Steroids have also been implicated in hepatitis C recurrence [26] . Most centers utilize 500 mg or 1 g methylprednisone at induction with tapered lower intravenous (IV) doses postoperatively until eating. A period of oral prednisone at slowly reducing doses is then given over 3-6 months. Steroid-free immunosuppression has been shown possible [27] and may benefit patients with hepatitis C, diabetes, and hypertension. Mycophenolate and azathioprine are antimetabolites that selectively inhibit T-cell and B-cell proliferation. Their role lies in reduction or discontinuation of CNIs to treat side effects of renal and neurological toxicity. Azathioprine is preferentially used in pregnancy due to increased safety experience. Sirolimus and everolimus are mammalian target of rapamycin (mTOR) inhibitors that prevent T-cell proliferation by inhibiting IL-2 transduction causing cell cycle arrest at the G1 to S phase. Initial concerns were raised regarding risk of hepatic arterial thrombosis resulting in an FDA black box warning [28] . Subsequent studies have disproven this, though avoidance of early and large loading doses is still advised [25] . Their utility lies in their safety in renal dysfunction. Other side effects include leukopenia, thrombocytopenia, hypercholesterolemia, anemia, and gastrointestinal dysfunction. Antibody therapy plays a role in steroid-resistant rejection and as CNI-sparing agents for patients with pretransplant renal failure. Basiliximab is a chimeric mousehuman monoclonal antibody against the IL-2 receptor that prevents T-cell proliferation [29] . Polyclonal antibody therapies such as antithymocyte globulin are less commonly used following liver transplantation. They are usually only considered in the setting of recurrent steroidresistant rejection. Liver transplant recipients carry a high infection risk, contributed to by immunosuppression, poor nutritional status, prolonged hospitalization, and the presence of catheters, lines, and drains. Sepsis represents the leading cause of critical illness, morbidity, and 1-year mortality in liver transplantation [22, 30] . The intensivist's role lies in ensuring attention to strict infection control and provision of appropriate prophylaxis and treatment where necessary. Infections include surgical site infections, pneumonias, catheter-related bloodstream infections, urinary tract infections, abdominal collections, and cholangitis. Risk is increased by acute liver failure, reoperation, and complicated biliary anastomosis [30] . Treatment often involves cautious reduction of immunosuppression, identification of causative organisms, and anti-infectious therapy. Prophylaxis covering bacterial, fungal, and viral pathogens varies among centers. Antibacterial prophylaxis utilizes pre-incision IV antibiotics for surgical site infection with broad spectrum gram-positive and gram-negative coverage 24 h postoperatively. Broader coverage (e.g., meropenem and vancomycin) may be initiated for higher risk patients. Trimethoprim-sulfamethoxazole is given as prophylaxis for Pneumocystis jiroveci pneumonia. Candida is the predominant fungal infection following liver transplantation; however, Aspergillus infection and others may also occur. Most centers utilize oral fluconazole or liposomal amphotericin B for high-risk recipients (i.e., renal failure, acute liver failure, prolonged preoperative hospitalization, large transfusion requirements, reoperation, or retransplantation) [31] . Herpes simplex virus reactivation and cytomegalovirus (CMV) are early opportunistic viral infections following transplant [22, 30] . Prophylaxis has lead to reduction in incidence. Management approach varies including universal prophylaxis, prophylaxis for high-risk patients only (e.g., CMV positive donor organ), or preemptive therapy in established infection [22] . IV ganciclovir and oral valganciclovir are mainstays of antiviral therapy. The presence of infection following liver transplantation may lead to poor graft function, prolonged ICU stay, and increased risk of multi-organ failure [19] . Drug interactions between anti-infectious agents and immunosuppressants often increase complexity of management. Ultimately adherence to established protocols with appropriate input from transplant infectious disease specialists is key [32] . Attention to nutritional support following liver transplantation is essential in the ICU to aid postoperative recovery. Malnutrition contributes to infection, respiratory complications, prolonged ICU stay, and decreased survival [33] . Liver transplant patients have diverse abnormalities of carbohydrate, lipid, and protein metabolism [19] , so specialist dietician input is fundamental. Nutritional therapy should ensure adequate protein, calories, vitamins, and minerals without contributing to pre-existing complications of ascites, encephalopathy, or metabolic derangement [34] . The catabolic state of the post-liver transplant patient necessitates protein intake of 1.5-2.0 g/kg dry weight [19, 34, 35] . The presence of encephalopathy requires enrichment of branched chain amino acids rather than reduction in protein content. Some centers encourage immediate return to oral feeding if permitted by gastrointestinal (GI) function. Nasojejunal or nasogastric feeding is utilized in the early postoperative period when delays in return of GI function occur. Total parenteral nutrition is usually unnecessary and avoided. While immediate postoperative nutrition is aimed at correcting deficiencies, long-term management should be tailored to prevent common posttransplant metabolic complications of diabetes, obesity, hypercholesterolemia, and osteoporosis. Continued input from dietitians on discharge from ICU is therefore necessary. The postoperative liver transplant recipient faces a number of potential early complications. Responsibility for initial detection, prevention, and management lies with the intensive care team. Common high-risk early complications include bleeding, graft nonfunction/dysfunction, vascular thrombosis, rejection, biliary complications, and respiratory, renal, or neurological dysfunction. Most bleeding complications present early in the ICU admission with management being part of initial hemodynamic stabilization. End-stage liver disease alters primary hemostasis, coagulation, and fibrinolysis. Coagulopathy may be predicted from the patient's operative course and laboratory coagulation parameters. Hypothermia, acidosis, and hypocalcemia should be avoided. Blood products are continued where clinically indicated while awaiting return of graft function. In situations of treatmentresistant nonsurgical bleeding, the off-label use of factor VIIa (90 IU/kg) has been shown to be of potential benefit [36] . Etiological factors leading to bleeding include underlying poor graft function and coagulopathy, massive transfusion, poor hemostasis, inadequate product replacement, heparin release from the implanted graft, and postreperfusion syndrome [19] . In patients with portal hypertension, fibrinolysis and thrombocytopenia may also be contributing factors. Management of coagulopathy and transfusion practice varies. The use of thromboelastography (TEG) or rotational thromboelastometry allows point-of-care assessment of coagulation and the ability to correct specific deficiencies [37 • ]. Studies have shown reduction in product transfusion through TEG with less allogenic blood product exposure [38, 39] . Evidence also exists for TEG-guided detection of hypercoagulable states with reduction in thrombotic complications [40] . Despite this, consensus is lacking on how best to monitor and manage bleeding following liver transplant [37 • ] with \30 % of centers using viscoelastic tests routinely [41] . Overall, a delicate and complex balance between bleeding and thrombosis exists in the liver transplant recipient [42 • ]. The patient's underlying clinical condition must be taken into account. Ultimately, applying clinical judgment to each presentation and ''treating the patient'' is fundamental. Primary graft nonfunction (PNF) is a rare and catastrophic event associated with increased length of ICU stay, morbidity, and mortality. It is often immediately evident presenting with hemodynamic instability, acute renal failure, treatment-resistant coagulopathy, hypoglycemia, and lactic acidosis [43] . Terminology surrounding graft dysfunction varies. The United Network for Organ Sharing defines PNF as irreversible graft function requiring retransplantation within 7 days of implantation. Graft failure requiring retransplantation after 7 days can be termed delayed PNF. Petrowski and Busuttil categorize risk factors into donor, procurement, and recipient related [44] . Donor factors include advanced donor age, liver macrosteatosis, and warm ischemia after circulatory death. Procurement factors include poor organ flush or cooling after cross clamp, inappropriate preservation, and cold ischemia [12 h. Recipient factors are poor vascular inflow, prolonged warm ischemia, retransplantation or cardiac arrest after reperfusion [44] [45] [46] . It is important to differentiate PNF from delayed graft function which eventually improves. Delayed graft function that progressively improves (also known as initial poor graft function) refers to dysfunction not resulting in retransplantation or death. While no universally accepted definition or criteria exits, all generally include an elevated aspartate aminotransferase (AST)/alanine aminotransferase (ALT) [2000 units/L within 7 days. Presentation is similar to PNF with central nervous system (CNS) changes, resistant coagulopathy, oliguria, hypoglycemia, and elevated transaminases. Treatment is supportive involving administration of FFP, dextrose to control hypoglycemia, hemodynamic support, and correction of metabolic disturbances. Novel supportive therapies have been described using prostaglandin E1, N-acetylcysteine, and liver assist devices [19, 44] . Although, in most cases, graft function returns to normal, close clinical observation is required to monitor for progression to PNF or delayed PNF requiring retransplantation [44] . Hepatic artery thrombosis (HAT) is a complication with potential for graft loss, morbidity, and prolonged ICU stay. Early doppler ultrasonography is routinely used to evaluate artery patency. Contributing factors include hemoconcentration, hypercoagulability, poor arterial flow, increased sinusoidal resistance, and anastomotic stenosis [19] . Divided into early and late thrombosis, the former usually presents with problems related to graft function. Late thrombosis ([30 days post transplant) [47 • ] often presents with biliary complications and a milder clinical course. HAT has been reported to occur in up to 9 % of adult recipients [44] with an increased incidence in children and grafts where size discrepancy exists between donor artery and native vessel [19, 48] . Operative exploration is the gold standard for diagnosis with surgical treatment including thrombectomy with anastomotic revision, aortic conduit graft, or arterial/vein interposition graft [49 • ]. Endovascular treatment using intra-arterial thrombolysis, embolization, or percutaneous transluminal angioplasty has lower success rates but may be appropriate in some patients [50, 51] . Early detection and management are essential for improved treatment outcomes and better prognosis [47 • ]. Lack of improvement after 48 h warrants consideration of retransplantation. Portal vein thrombosis in adult recipients is rare but catastrophic, with an estimated incidence of *2 % [52] . It is often predisposed to by anastomotic issues. Presentation may involve massive transaminitis with ascites, gastric, and variceal bleeding [1] . Treatment requires expedited surgical thrombectomy, though emergent retransplantation may be necessary. Interventional thrombolysis carries high risk of reocclusion and anastomotic injury [52] . The advent of CNI's along with advances in immunosuppression has reduced the incidence of morbidity and mortality from graft rejection. Rejection usually presents following discharge from the ICU and is classified as acute, late acute, and chronic [53] . Acute rejection is most common with an incidence ranging from 25 to 46 % within the first year [53, 54] . Risk factors include inadequate immunosuppression, underlying autoimmune disease, female recipients of male donors, and fewer human leukocyte antigen (HLA) matches at the DR locus [53] . Patients initially present with elevated liver enzymes followed later by nonspecific clinical signs such as fever, malaise, abdominal pain, jaundice, and decreased bile. Exclusion of hepatic artery or portal vein thrombosis, biliary leak, CMV infection and delayed graft function are necessary. Percutaneous liver biopsy is the gold standard for diagnosis with some centers instigating protocol biopsies allowing for early management. Treatment involves optimization of maintenance immunosuppression with an increased dose and additional agent. High-dose corticosteroids are often commenced. If no improvement is seen, an IL-2 receptor antagonist may be commenced [54] . In severe treatment-resistant disease, retransplantation may be necessary. Biliary complications are the most common technical complication following transplant with increased incidence in living donor transplants. Presentations include lack of bile, elevated cholestatic enzymes, and leukocytosis [19] . Pathology often relates to anastomotic leak or obstruction from stenosis or stricture. Cholangiography is required for diagnostic confirmation and assessment of severity. Treatment depends on clinical status and may be conservative, surgical (repair) or interventional (ERCP or percutaneous drainage/stenting/dilation). Respiratory dysfunction following OLT carries implications of prolonged ventilation, graft dysfunction, increased length of ICU stay, and patient morbidity and mortality. Preoperative predisposing factors include increased disease severity, high-grade encephalopathy, large volume ascites, pleural effusions, severe pulmonary artery hypertension, and pre-existing hypoxia from ventilation/perfusion mismatch or hepatopulmonary syndrome [55 • ]. Intraoperatively, a large volume transfusion, positive fluid balance, and excessive use of fresh frozen plasma or platelets may contribute to pulmonary edema and potential lung injury [56] . Postoperatively, respiratory dysfunction may arise from atelectasis, pleural effusion, volume overload, infection, adult respiratory distress syndrome (ARDS), and transfusion-related acute lung injury [55 • ]. Management of respiratory dysfunction is generally supportive. Specific causes are targeted where possible. Patients with severe pulmonary artery hypertension may benefit from pulmonary vasodilators. Pulmonary edema warrants diuretic therapy and reduction in preload. Pneumonias require isolation of responsible microorganism with prompt instigation of appropriately targeted antibiotic therapy [55 • ]. Ventilation parameters should be tailored to the patients underlying dysfunction. For pulmonary edema and ARDS, low tidal volumes (6 mL/kg), avoidance of alveolar overdistension, and lower plateau airway pressures are beneficial [1] . PEEP should be set to improve oxygenation without restricting liver outflow. Debate exists as to whether high PEEP impairs liver blood outflow [1] . Saner et al., however, showed that PEEP up to 15 cm H 2 O did not decrease hepatic vein outflow or portal blood flow [57] . Prolonged mechanical ventilatory support predisposes to ventilator-associated pneumonia, muscle deconditioning, and tracheal injury [30] . In the general ICU population, ventilator weaning strategies reduce cost and length of stay, improving 1-year survival [30] . These protocolized strategies should be applied to ventilated liver transplant recipients. Examples include spontaneous breathing periods and interruption of sedation [1] . Transition to noninvasive ventilation should be considered in patients who may not be immediately successful with extubation [55 • ]. The incidence of renal dysfunction following liver transplant ranges widely due to differences in criteria and definition. Presentation may be acute or chronic with acute renal failure being a common complication following liver transplant. Much has been written on defining acute kidney injury (AKI) with the Risk, Injury, Failure, Loss, and End-Stage Kidney Disease (RIFLE) criteria [58] . Etiologies for renal failure are complex and multi-factorial, contributed to by pre-existing renal dysfunction, hepatorenal syndrome, intraoperative course, graft dysfunction, infection, immunosuppressants, and prolonged use of vasoactive agents [59 • ]. Isolated liver transplant treats hepatorenal syndrome while combined kidney liver transplant may treat advanced irreversible disease [60] . A systematic approach assessing pre-renal, intrinsic, and post renal causes is useful when evaluating renal dysfunction. Serum creatinine-based estimates of renal function have proven inaccurate in the setting of end-stage liver disease, because creatinine elevations are often delayed [61] . The close monitoring of urine output, fluid balance, and hemodynamic parameters is critical in anticipating potential renal dysfunction in the ICU. Oliguria is an early warning of renal dysfunction; however, assessment is complex and must take into account multiple clinical and biochemical factors. Nephrotoxic drugs such as the CNIs must be used with appropriate dosing and therapeutic levels, with alternatives considered for high-risk patients. Refractory volume overload and electrolyte disturbances (refractory hyperkalemia, hyper uremia, and metabolic acidosis) are the most common indications for RRT [30] . Continuous lactate-free RRT is most often undertaken because it causes less fluid shifts and hemodynamic instability. RRT is predictive of worse outcome, with longer ICU stay and higher mortality rates [62, 63] . Neurological complications following liver transplantation occur at an incidence of *20 % [64] . An increased frequency is observed in deceased donor versus living donor transplants [65] . Presentation is usually early after surgery and often in the ICU. Encephalopathy is the most common CNS complication following liver transplantation [66] . With a spectrum from drowsiness and confusion, to delirium and coma, the etiology usually relates to excess ammonia. Improvement should be seen following transplantation. If mental status does not improve, investigation of graft function is warranted. Seizures are the second most common neurological complication after liver transplant. Usually tonic-clonic, they relate to encephalopathy, immunosuppressant therapy, infection, metabolic derangements, and hypoxic-ischemic injury [67] . Correction of the underlying cause is necessary. Drug treatment and prophylaxis must consider interactions with immunosuppressants given their cytochrome P450 metabolism. Leviteracetam should be considered first line with phenytoin as an alternative [67] . Immunosuppression-related neurotoxicity may occur through use of tacrolimus. Presentations include tremor, headache, seizures, paresthesias, polyneuropathy, and myopathy [65] . Posterior-reversible encephalopathy syndrome from CNI insult to the blood brain barrier has also been described [68] . Treatment involves dose reduction, brief cessation, or interchange with CNI-sparing regimens. Transplant recipients are at risk of CNS infections due to immunosuppression. This usually occurs late after liver transplant. Incidence is rare, but mortality is high. Common organisms include Listeria monocytogenes, Aspergillus fumigatus, and Cryptococcus neoformans [69] . Viral infections occur due to herpes simplex virus and cytomegalovirus, but the incidence has declined with the use of antiviral prophylaxis. A number of differences exist in the ICU management of living donor liver recipients as compared to deceased donor recipients. Right lobe grafts are most commonly used and involve a more complex, technically challenging surgery. Greater caution is required in IV fluid replacement as size differentials increase susceptibility to graft congestion, and ''small for size syndrome'' may occur. The incidence of biliary and hepatic artery complications is higher, carrying greater risk of reoperation. Vigilance on the part of the intensivist is therefore necessary for early detection and appropriate management. Liver transplant recipients with acute liver failure experience longer ICU lengths of stay with increased morbidity and mortality [70] . Postoperative ventilation is standard as patients may have high-grade encephalopathy and cerebral edema necessitating intracranial pressure monitoring, often with the added challenges of coagulopathy, portopulmonary hypertension, and hemodynamic instability. Patients also have greater risk of complications with a higher requirement for RRT and increased risk of infection and rejection [71] .@story_separate@The ICU course following liver transplantation remains a critical step following surgery. Despite the challenges of increasing disease severity, an older comorbid population and increased use of marginal donors, ICU lengths of stay, readmissions, and overall morbidity and mortality have greatly improved. The majority of admissions are indeed uneventful. While advances in surgical technique, perioperative management, and immunosuppression regimens are to be credited, so too should the role of the intensivist in adopting a thorough patient assessment, with anticipation and early management of complications. Paramount to this approach is involvement of a multidisciplinary team, utilizing a patient-focused approach and institution-specific protocols guiding management.","Patient survival following orthotopic liver transplantation has greatly increased following improvements in surgical technique, anesthetic care, and immunosuppression. The critical care of the liver transplant recipient has paralleled these improvements, largely thanks to input from multidisciplinary teams and institution-specific protocols guiding management and care. This article provides an overview of the approach to critical care of the postoperative adult liver transplant recipient outlining common issues faced by the intensivist. Approaches to extubation and hemodynamic assessment are described. The provision of appropriate immunosuppression, infection prophylaxis, and nutrition is addressed. To aid prompt diagnosis and treatment, intensivists must be aware of postoperative complications of bleeding, primary nonfunction, delayed graft function, vascular thromboses, biliary complications, rejection, and organ dysfunction."
"Our proposed model stems from the classical SEIR model, a deterministic mathematical model to simulate epidemiologic dynamics, as shown in Equations (1) through (4). The SEIR model is composed of four variables: S (susceptible population), E (exposed population), I (infectious population), and R (recovered population). It explicitly quantifies a four-stage cycle of the disease spreading among humans in terms of differential equations. Each stage is formulated as a derivate of the population (i.e., S, E, I, R) with respect to time (t), representing the change of the stage-specific population. In the equations, denotes the total population (N = S + E + I + R); β, σ, and γ are the daily transmission rate, daily incubation rate, and daily recovery rate, respectively. The basic reproduction rate can be derived as R0 = β/γ. This classic SEIR model, along with its many extensions, has been widely applied to epidemic modeling of COVID-19 , Kissler et al. 2020 , Lai et al. 2020 ).@story_separate@The meso-scale, generally known as a study area of 1-1000 kilometers, is of critical importance in the effective containment of the epidemic growth. This significance can be justified by the mechanism of the preventive strategies over the different phases of epidemic development. In the early development of COVID-19, large-scale preventive measures, such as border control and air travel restrictions, were implemented to slow international and domestic transmissions. When these measures were in effect, new cases of infection would be primarily induced by community spread, such as the human interaction within and between neighboring cities, towns, and communities. Existing macro-scale studies using classical epidemic models, notably the Susceptible, Exposed, Infectious, Recovered (SEIR) model are unable to accommodate the need for meso-scale modeling, because of three existing limitations in COVID-19 research. First, in the United States, the timing of the COVID-19 outbreak differs by state and so do their regulatory countermeasures, such as the enforcement of the stay-at-home order. It is relatively intractable to model COVID-19 at a macro-scale while considering the heterogeneity in the timing of local policies and the strength of their enforcement. Second, when long-distance travel (e.g., flights) are restricted, the transmission will be dictated by short-distance travel, such as daily commuting trips by public transit or private automobiles. In this context, individual mobility and the likelihood of travel is largely driven by the compliance of social distancing rules. Therefore, modeling COVID-19 at the mesoscale should articulate how social distancing affects people's travel activities or the willingness to travel as parameters to model the process of transmission. This gap has not been fulfilled by the status quo macro-scale models. Third, while COVID-19 data (e.g., infection, death, and recovery) on a daily basis has become largely available in the public sector, data with finer spatial granularities, such as across townships or census tracts, are extremely lacking. These three tiers of research gaps fuel the need to develop a meso-scale epidemic model that simulates past COVID-19 cases while predicting the local, community-level spread in preparing for a highly likely resurgence in the near future. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . In this paper, we propose a meso-scale epidemic model using town-level COVID-19 infection data in the state of Connecticut. Because the local infection is largely subject to effects of social distancing, the model development follows two evaluative metrics in social distancing: compliance, which represents the strength of the policy enforcement, and containment, which represents individual mobility. By incorporating these two metrics into the SEIR model, we have proposed a meso-scale SEIR model and have performed model fitting and sensitivity analysis under ten different social distancing scenarios. Using the developed model, we have evaluated how different social distancing strategies (i.e., minimal, moderate, and substantial) would shape the epi curve of COVID-19 for each town. This study, while among the first to simulate the COVID-19 development at the meso-scale, has the potential to inform both epidemiologists and stakeholders about the public health risks using different social distancing strategies. The paper is organized as follows. Following the background, Section 2 introduces the methodological development of the model based on the classical SEIR model and the guiding principle of social distancing. Section 3 applies the new model to a case study in Connecticut, performs the model fitting, and simulates epi curves and spatial patterns at the town level based on different social distancing scenarios. Section 4 discusses the major findings and insights shed by the modeling results. Lastly, Section 5 concludes the study with long-term impacts. Adapting the SEIR model to the meso-scale should emphasize the effectiveness of social distancing in communities. This evaluation follows the Centers for Disease Control and Prevention (CDC)'s social distancing guidelines for COVID-19 given in three aspects: operations of public facilities, restrictions on businesses, and restrictions on personal movement (Gostin and Wiley 2020). For the restrictions on personal movement, the guidelines impose limitations on people's travel and social behaviors in terms of prohibiting mass gatherings, requiring physical distancing in face-to-face interaction, and enforcing stay-at-home orders (Gostin and Wiley 2020). The CDC also calls for legal and community efforts to enhance compliance with these social distancing measures. Under this guiding principle, we propose a conceptual model in measuring the effectiveness of social distancing with an emphasis on travel activities as part of the personal movement. The model All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint comprises two metrics, compliance and containment, that evaluate the effectiveness of the policy enforcement, as shown in Figure 1 . Compliance evaluates the likelihood of the residents not following the social distancing rules. While there are various ways in which compliance can be articulated, one variable could be the percentage of residents engaging in travel activities as a surrogate for the metric. Containment evaluates the level of human mobility, and a variable for the evaluation could be the maximum distance that people are willing to travel under the social distancing regulation. These two metrics, resulting from the strengths of the policy enforcement, will likely affect the transmission risk of the epidemic. This conceptual model featuring the two evaluative metrics is integrated into the classical SEIR model to develop a meso-scale epidemic model for COVID-19.  We modify the SEIR structure with an emphasis on the impacts of travel activities at the mesoscale, where the study area is a state and the unit of analysis is a town (formally known as county subdivision in the United States). Recent epidemic models have employed various forms of mobility data, such as smart-phone heat maps (Lai et al. 2020 ) and air traffic flow (Gilbert et al. 2020), to All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint estimate mobility in the SEIR model. Because of the lack of mobility data at the town level, we employ the Huff-model (Huff 1963) to estimate the potential for travel. The huff-model is traditionally used for analyzing the business potential based on the probability of customers' visits to retail and service facilities. It has also been extended to forecasting the external trips between communities (Anderson 1999; Anderson 2005) . The classical Huff-model uses real-world survey data to calibrate the model parameters, including the attractiveness of facilities and the distance decay (Huff and McCallum 2008) . In this paper, we choose the linear form to estimate the probability of travel between two towns, as shown in Equation (5). This linear form is seen as a better form to forecast inter-city trips and has been corroborated with field data (Anderson 1999 ). In Equation (5), Tij is the probability that a person traveling from town i to town j; Dij is the distance between i and j; and Pi is the population of town i. We have further added to the Huff model two other parameters: a compliance parameter Ci, meaning the percentage of the population of town i engaging in inter-town trips, and a containment parameter D0, meaning the maximum distance people are willing to travel under influences of social distancing. These two parameters extend the Huff-model to estimate Mij, the total population traveling from town i to town j, as shown in Equation (6) (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint assumptions: (1) both the susceptible and exposed populations conform to the mobility rule in Equation (6); (2) the infectious and recovered populations are isolated so that they cannot travel to other towns; (3) the susceptible population traveling to other towns can be affected by the infectious population in both their origin town and destination town; (4) the total population and the daily travel population of a town are stable during the modeling period; (5) daily travelers return to their origin town by the end of the day; and (6) the transmission rate gradually decreases due to non-pharmaceutical interventions during the social distancing period (Lai et al. 2020) . Based on these assumptions, we have developed the meso-scale SEIR model (MSEIR), simulating the daily dynamics of susceptible (Si), exposed (Ei), infectious (Ii), and recovered populations (Ri) of the ith town, as shown in Equations (7) through (11). where Ei: exposed population of town i; Ii: infectious population of town i; Mij: population (susceptible or exposed) traveling from town i to town j. The parameter is derived from Equation (6). Ni: total population of town i (Ni = Si + Ei + Ii + Ri); Ri: recovered population of town i (including hospitalized, self-recovered, and death); Si: susceptible population of town i; All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint t: time (daily); a: daily change rate of the transmission rate (0 < a < 1); β: transmission rate (conversion from the susceptible population to exposed population); γ: recovery rate; σ: daily incubation rate (reciprocal of the incubation period); In the MSEIR model, Equations (7) through (10) are a series of differential equations indicating the daily variation of the susceptible, exposed, infectious, and recovered population at each transmission stage. Equation (11) is the daily change of the transmission rate. To implement the model, five state variables at the initial stage must be derived: (1) the initial transmission rate β0 (estimated from our case study, see below); (2) the initial exposed population Ei0 (estimated from our case study, see below); (3) the initial infectious population Ii0 , which equals to the cases of infection on March 23, 2020, the start date of the data. (4) the initial susceptible population i0 , which can be derived as Si0 = Ni -Ei0; and (5) the initial recovered population R0 = 0 under the assumption that no individuals are cured, hospitalized, or had died at the initial stage. σ and γ can be derived from historical data. σ is the daily incubation rate as the reciprocal of the incubation period. γ is the recovery rate, indicating the rate of reduction in the infectious population due to hospitalization, self-recovery, and death. This parameter assumes that once an infectious individual is hospitalized, self-recovered, or died, the person will be isolated from the transmission cycle. According to a recent study among the first 425 diagnosed patients , the mean incubation period of COVID-19 was 5.2 days (at a 95% confidence interval [CI], 4.1 to 7.0 days), and the mean time duration from the illness onset to hospital admission was 9.1 days (95% CI, 8.6 to 9.7 days). Thus, we All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint assumed that our study had a similar incubation period and duration from illness onset to the first medical visit. In our model, σ = 1/5.2 and γ = 1/9.1. For parameters β0 and a, we estimated their optimal values for each town using the daily cumulative cases of infection derived from the Connecticut Department of Public Health (CDPH, 2020). We assumed that β0 and a were constant throughout the study area and under different social distancing scenarios. The exposed population at the initial stage Ei0 was an unknown parameter that varied by town. Because of this uncertainty, we treated Ei0 as another parameter to be estimated. Thus, each town i had an independent Ei0 given the difference in the onset of the outbreak, population, and other factors dictating the early exposed population. The Nelder-Mead algorithm (Nelder and Mead 1965) was employed to estimate parameters by minimizing the negative normal log-likelihood between the simulated and the confirmed daily cumulative cases. Our study was implemented in the state of Connecticut with the unit of analysis being county subdivision or town. Located in the New England region, Connecticut is the third smallest state by area in the United States with 169 towns and a total population of 3.5 million (Figure 2a) . On March 8, the first COVID-19 case was reported in Wilton, a town neighboring New York (The New York Times, 2020). Because of the geographical proximity to New York City, the epicenter of the national outbreak, the state experienced an exponential rise of infections in the early outbreak. As of May 11, the total confirmed cases of infection were over 34,000, and the total deaths were over 3,000 (CDPH 2020). Figure 2b shows the COVID-19 infection rate per 10,000 people as of May 11, 2020 (Figure 2b ). All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint Modeling COVID-19 at the meso-scale is inseparable from state policy related to social distancing. In Connecticut, the first stage of the social distancing rules was implemented on March 23 by the governor's executive order ""Stay Safe, Stay Home,"" requiring the closure of non-essential businesses and some non-profit organizations (Ct.gov 2020a) . This policy was relieved by reopening certain nonessential businesses effective on May 20 (Ct.gov 2020b) . Based on this context, we retrieved the daily town-level COVID-19 infection data during this period, specifically the first 50 days since the first day of enforcing the state social distancing rules (i.e., March 23 through May 11, 2020). The dataset was solicited from the state government's daily publications (CDPH 2020). We have designed three compliance levels and three containment levels to estimate Mij in the MSEIR model, forming a total of nine models representing different degrees of social distancing policy enforcement, as shown in Table 1 . In this framework, Model 1 represents the substantial enforcement with only 10% of the population taking inter-town trips and a maximum travel distance of 20 miles; Model 9 represents the minimum enforcement with 50% of the population taking inter-town trips and a maximum travel distance of 140 miles. The 140-mile threshold is the road network distance between the two most remote towns in Connecticut (i.e., Thompson and Greenwich). All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . These social distancing scenarios were incorporated into Equation (6) We then employed the fitted models for predicting future trends. Using the town-level data, we implemented the MSERI model under all social distancing scenarios in Table 1 . In addition to the model fitting, we extended the epi curves of the cumulative cases of infection (IC) to the future development with an end date of July 12, 2020. We also established the baseline scenario in the SEIR model where there is no travel or interaction between towns (Ci = 0%, D0 = 0 miles). All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint For the sake of clarity, we selected four scenarios for comparison and discussion: the SEIR model for no interaction, Model 1 for substantial social distancing, Model 3 for moderate social distancing, and Model 9 for minimum social distancing. Figure 3 shows the COVID-19 epic curves of the entire state. As shown in the figure, the SEIR model has considerably underestimated the epi curve, with the value of Ic converging to 26,000. When the three social distancing scenarios are introduced, the epic curves start to align with the confirmed cases, with the minimum social distancing scenario (Model 9) yielding the steepest curve. The simulation predicts that the total cumulative cases of infection will be in the range of 45,752-48,105 (Model 5 and Model 9) as of July 12, which is a rise by 34.2%-41.1% with respect to the reported cases (Ic = 34,070) as of May 11. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint Figure 4 shows the COVID-19 epic curves for six selected towns. As shown in Figure Figure 5c ) and the minimum control scenarios (Model 9, Figure 5d ). We then scrutinized the results by deriving the rate of increase per 10,000 people for each town between May 11 and July 12 under each of the ten models. Then, we counted the frequency of the town appearing on the top 10 list. We found that the following towns appeared on the list at least five times: Westport (N = 10), Bethlehem (N = 10), Stafford (N = 6), New Canaan (N = 6), Darien (N = 6), Ridgefield (N = 6), Wilton (N = 5), and Weston (N = 5). These towns, as labeled in Figure 5 , have a higher likelihood of outbreak during May, June, and July. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint  To evaluate the performance of the MSEIR model, we derived two statistical metrics for each of the ten models: r 2 and root-mean-square error (RMSE). Specifically, we calculated r 2 and RMSE for each of the 169 towns by comparing the simulation results with the confirmed cumulative cases in the 50-day period. r 2 assesses whether the MSEIR model captures the trend of the historical data, while RMSE quantifies the absolute difference between the model output and the observation. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint First, we performed the evaluations across all 169 towns and derived the respective average of the 169 values of r 2 and RMSE. Then, the total number of towns with r 2 greater than 0.95 were counted, as shown in Table 2 . Overall, all models achieved satisfactory levels of fitting with the historical data in terms of trend monitoring (r 2 > 0.9). The differences in RMSE were more evident. We identified that Model 7 had a better performance than other models in terms of a relatively high r 2 and low RMSE. To further excavate the applicability of the MSEIR model, we further divided the towns into three categories based on the United States Census Bureau (USCB)'s urban-rural classification (USCB 2010): urbanized areas (UAs), urban clusters (UCs), and rural areas (RAs). Then, we evaluated the model fitting for towns under each category, as shown in Table 3 . We identified that while UAs and UCs achieved relatively satisfactory levels of model fitting (r 2 > 0.9), RAs or towns with a small population could not be fitted well (r 2 < 0.7). Thus, the MSEIR model is best suited for towns exceeding a certain size (i.e., urban clusters) and must be adjusted for applications for small towns. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https: //doi.org/10.1101 //doi.org/10. /2020 (2010) based on population: urbanized areas (UAs) of 50,000 or more people, urban clusters (UCs) between 2,500 and 50,000 people, and rural areas (RAs) of less than 2,500 people. It should be noted that USCB uses a different areal unit for urban-rural classification and is not based on the county subdivision (i.e., town). Thus, the category in this analysis does not suggest the actual urban-rural status of a town. The proposed MSEIR model applied to meso-scale COVID-19 simulation is among the first to evaluate the development of the pandemic using an administrative unit smaller than a county. By downscaling the analysis to the town level and realizing the model under different social distancing scenarios, the study sheds important insights into COVID-19 studies. First, meso-scale analysis is of critical importance for revealing the epidemic development after the initial wave of outbreak. When social distancing orders were placed for curbing the early infection, needs for domestic flights or interstate travel were largely suppressed (Gao et al. 2020) . New cases of infection would be primarily caused by local spread through short-distance travel. Thus, efforts and policies to contain the COVID-19 development would be most effective by curbing inter-or intra-town travel activities. Incorporating the interaction across townships and deriving their epi curves can help the municipality to leverage resources for preparing for rising contingencies, such as the resurgence of an outbreak in the future. The classical SEIR model and its many extensions, however, lack the capability of simulating the epidemic spread at the meso-scale. This increased spatial granularity to model COVID-19 is the major contribution of the work. Second, the proposed social distancing framework including the compliance and containment provides quantifiable metrics for COVID-19 studies that attempt to evaluate the effects of social distancing. Since the pandemic is growing at an alarming rate worldwide, existing studies have largely emphasized on the timing (Chinazzi et al. 2020) , economic impacts (Atkeson 2020) , and the ethical issues (Lewnard and Lo 2020) of social distancing, while the effects on human mobility at the community scale are not well scrutinized. This gap has likely resulted from the lack of detailed mobility data (especially the origin-destination trip data), coupled with the sensitivity of data collection due to the nature of the outbreak and the federal requirement (e.g., the Health Insurance Portability and Accountability Act) for privacy protection. The simulation of the travel activities using the Huff model All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint could help to estimate the regional human movement pattern; and further model calibration will increase the rigor of the estimation (Huff and McCallum 2008) . Lastly, we have found that there are discrepancies in the modeling results across different towns. While the SEIR model has underestimated the majority of the epi curves, it tends to align with towns with a sparse population or located in rural areas, such as Mansfield ( Figure 4c ) and Wilton ( Figure 4f ). This alignment is very likely due to the relatively low level of spatial interaction in terms of inter-town travel in these towns. The proposed MERI model works best for towns exceeding a certain size (Table 3 ) but does not well perform for towns with a complex mobility pattern, such as the city of Hartford (Figure 4b ). This result justifies that although towns in a state are subject to the same timing of social distancing orders, the actual policy effects on the residents' mobility pattern, and consequently, on curbing the epi curves of the pandemic are largely different. Due to this spatial heterogeneity in mobility pattern, which is internally driven by socioeconomic inequities (Bonaccorsi et al. 2020) , it is impossible to establish a one-size-fits-all model for COVID-19 analysis for every town in a state. Therefore, we have two recommendations for improving and better understanding the MSEIR model: first, a field survey to solicit people's daily travel activities (e.g., travel frequency, distance, mode, time, origin-destination) is a necessity to derive the actual mobility pattern between towns in lieu of the model estimation. To fulfill this goal, we have initiated a separate project to investigate people's actual travel activities during the period of the state easing the lockdown; second, we suggest that local stakeholders employing the modeling results should adopt and prepare for the worst-case scenario (e.g., Model 9) and target towns that may experience the most rapid epidemic growth under all scenarios (e.g., labeled towns in Figure 5 ). This elevated caution in preparedness can guide the leverage of public health resources towards the most severe situation and the most vulnerable areas. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint No potential conflict of interest was reported by the authors. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 2, 2020. . https://doi.org/10.1101/2020.06.01.20119073 doi: medRxiv preprint@story_separate@The COVID-19 pandemic has posed an unprecedented challenge to the global economy and the health-care system. While modeling COVID-19 by simulating the epic curve has become a growing practice across all disciplines, existing models have not been able to examine the issue at the mesoscale, using a small unit of analysis such as town or census tract, nor have quantified how social distancing may curb the transmission at this scale. The proposed MSEIR model introduces the effects of spatial interaction between towns on the epidemic development. The scenario-based analysis could help policy stakeholders to understand how the compliance with and the containment by social distancing rules regulate people's travel activities and can help predict how different degrees of policy enforcement would shape the epic curve over different phases of policy implementation. These modeling results have the potential to assist stakeholders with strategical decisions about the timing and expected outcomes of relieving social distancing rules. It should also be noted that with the rapidly evolving epidemic situation and many emerging local policies as countermeasures, the actual epi curves would be very different from what the model predicts. Albeit the tiers of uncertainties, we believe the developed MSEIR model will establish the foundation for community-level assessment and better preparedness for COVID-19.","In the early development of COVID-19, large-scale preventive measures, such as border control and air travel restrictions, were implemented to slow international and domestic transmissions. When these measures were in full effect, new cases of infection would be primarily induced by community spread, such as the human interaction within and between neighboring cities and towns, which is generally known as the meso-scale. Existing studies of COVID-19 using mathematical models are unable to accommodate the need for meso-scale modeling, because of the unavailability of COVID-19 data at this scale and the different timings of local intervention policies. In this respect, we propose a meso-scale mathematical model of COVID-19 using town-level infection data in the state of Connecticut. We consider the spatial interaction in terms of the inter-town travel in the model. Based on the developed model, we evaluated how different strengths of social distancing policy enforcement may impact future epidemic curves based on two evaluative metrics: compliance and containment. The developed model and the simulation results will establish the foundation for community-level assessment and better preparation for COVID-19."
"To understand the dynamics of infectious diseases it is crucial to understand the structure and interactions within the host population. Conversely, it is possible to learn something about host population structure by observing the pattern of pathogen spread within it. In either case, it is necessary to have a good model of the host population structure and interactions within it. Networks, where nodes of the network represent hosts and edges between nodes represent contacts across which pathogens may be transmitted, are now regularly used to model host interactions [1] [2] [3] . While many models have been proposed to describe the structure of these contact networks for different populations and different modes of transmission, it is not yet understood how different features of networks affect the spread of pathogens. One promising development in this field is the use of statistical techniques which aim to model a contact network based on data relating to the passage of a pathogen through a population. Such data includes infection times [4] [5] [6] and genetic sequences that are collected from an epidemic present in the population of interest [7] [8] [9] . These data have previously been shown to be useful for reconstructing transmission histories (the distinction between a contact network and a transmission history is that a contact network includes all edges between hosts across which disease may spread, whereas the transmission history is just the subset of edges across which transmission actually occurred). Infection times can be used to crudely reconstruct transmission histories by examining which individuals were infectious at the time that any particular individual was infected [10] . Genetic sequences from viruses are informative about who infected whom by comparing the similarity between sequences. Due to the random accumulation of mutations in the sequences, we expect sequences from an infector/infectee pair to be much closer to each other than sequences from a randomly selected pair in the population (see [11] for a review of modern approaches to analysing viral genetic data). The work of [4] [5] [6] seeks to extend the use of this data to reconstruct a model for the whole contact network rather than just the transmission history. In theory, these statistical methods could settle arguments about which features of the network are important in the transmission of the disease and which are simply artifacts of the physical system. In this article, we focus on clustering in networks and ask whether or not networks which differ only in their level of clustering could be distinguished if all we observed was transmission data from an epidemic outbreak. The answer to this question will determine whether these new statistical techniques can be extended to estimate the level of clustering in a network. Throughout, we consider a population with N individuals that interact through some contact process. This population and its interactions are fully described by a undirected random network, denoted Y , on N nodes. An simple example of a network is shown in Figure 1 with illustrations of some of the terms we use in this article. Y can be represented by the symmetric binary matrix [Y ij ] where Y ij = Y ji = 1 if an edge is present between nodes i and j, otherwise Y ij = 0. We stipulate that there no loops in the network, so Y ii = 0 for all i. The degree of the ith node, denoted d i is the number of edges connected to i, so d i = j:j>i Y ij . Clustering is one of the central features of observed social networks [12, 13] . Intuitively, clustering is the propensity for triangles or other small cycles to form, so that, for example, a friend of my friend is also likely to be my friend. Where there is a positive clustering effect, the existence of edges (i, j) and (i, k) increases the propensity for the edge (j, k) to exist, while a negative clustering effect implies that (j, k) is less likely to exist given the presence of (i, j) and (i, k). When there is no clustering effect, the presence or absence of (i, j) and (i, k) has no bearing on that of (j, k). Thus clustering is one of the most basic of the true network effects-when it is present, the relationship between two nodes depends not only on properties of the nodes themselves but the presence or absence of other relationships in the network. The effect of clustering on the dynamics of stochastic epidemics that run over networks remains largely unknown, though it has been studied in a few special cases. The difficulty with studying this effect in isolation is in trying to construct a network model where clustering can change but other properties of the network are held constant. In simulations we study here, we focus on holding the degree sequence of a network constant-that is, each node maintains the same number of contacts-while varying the level of clustering. Intuition suggests that clustering will have some effect on epidemic dynamics since, in a graph with no cycles, if an infection is introduced to a population at node i and there is a path leading to j then k, k can only become infected if j does first. However, where cycles are present, there may be multiple paths leading from i to k that do not include j, so giving a different probability that k becomes infected and a different expected time to infection for k. Figure 1 . An example of a network on 7 nodes. The nodes are the red dots, labelled 1 to 7 and represent individuals in the population. The edges are shown as black lines connecting the nodes and represent possible routes of transmission. The degree of each node is number of edges adjacent to it, so that node 5 has degree 3 and node 7 has degree 1. The degree sequence of the network is the count of nodes with a given degree and can be represented by the vector (0, 2, 0, 3, 1, 1) showing that there are 0 nodes of degree 0, 2 of degree 1, 0 of degree 2 and so on. A cycle in the network is a path starting at a node and following distinct edges to end up back at the same node. For example, the path from node 6 to node 1 to node 3 and back to node 6 is a cycle but there is no cycle that includes node 4. Clustering is a measure of propensity of cycles of length 3 (triangles) to form. Here, the edges (2,1) and (2,6) form a triangle with the edge (1,6), so work to increase clustering in the network. However, the edges (2,1) and (2,5) do not comprise part of a triangle as (1,5) does not exist, so work to decrease clustering. Previous work on the effect of clustering on epidemic dynamics has produced a variety of results which are largely specific to particular types of networks. Newman [14] and Britton et al. [15] show that for a class of networks known as random intersection graphs in which individuals belong to one or more overlapping groups and groups form fully connected cliques, an increase in clustering reduces the epidemic threshold, that is, major outbreaks may occur at lower levels of transmissibility in highly clustered networks. Newman [14] , using heuristic methods and simulations, suggests that for sufficiently high levels of transmissibility the expected size of an outbreak is smaller in a highly clustered network than it would be in a similar network with lower clustering. These articles show that graphs with different levels of clustering do, at least in some cases, have different outbreak probabilities and final size distributions for epidemic outbreaks. Kiss and Green [16] provide a succinct rebuttal to the suggestion that the effects found by [14] and [15] are solely due to clustering. They show that, while the mean degree of the network is preserved in the random intersection graph, the degree distribution varies greatly (in particular, there are many zero-degree nodes) and variance of this distribution increases with clustering. An increase in the variance of the degree distribution has previously been shown to lower the epidemic threshold. They demonstrate that a rewiring of random intersection graphs that preserves the degree sequence but decreases clustering produces networks with similarly lowered epidemic thresholds and even smaller mean outbreak sizes. Our experiments, reported below, are similar in spirit to those of [16] but look at networks with different degree distributions and study in detail how epidemic data from networks with varying levels of clustering might vary. Ball et al. [17] show, using analytical techniques, that clustering induced by household structure in a population (where individuals have many contacts with individuals in the same household and fewer global contacts with those outside of the household) has an effect on probability of an outbreak and the expected size of any outbreak. The probability of an outbreak, in some special cases, is shown to be monotonically decreasing with clustering coefficient and the expected outbreak size also decreases with clustering. There is no suggestion that these results will apply to clustered networks outside of this specific type of network or that they apply when degree distributions are held constant. Eames [18] also studies networks with two types of contacts: regular contacts (between people who live or work together, for example) and random contacts (sharing a train ride, for example). Using simulations of a stochastic epidemic model and deterministic approximations, it is shown that both outbreak final size and probability of an outbreak are reduced with increased clustering, particularly when regular contacts dominate. As the number of random contacts increases, the effect of clustering reduces to almost zero. Strong effects on the expected outbreak size in networks with no random contacts are observed for values of the clustering coefficient above about 0.4, however, no indication of the magnitude of the variance of these effects is given. Keeling [19] reports similar results, introducing clustering to a network using a spatial technique-nodes live in a two-dimensional space and two nodes are connected by an edge with a probability inversely proportional to their distance. The clustering comes about by randomly choosing positions in space to which nodes are attracted before connections are made. The results suggest that changes in clustering at lower levels has little effect on the probability of an outbreak, but as the clustering coefficient reaches about 0.45, the chance of an outbreak reduces significantly. As in [14] and [15] , while the mean degree of network nodes is held constant here, nothing is said about the degree distribution as clustering varies. Serrano and Boguñá [20] look specifically at infinite power-law networks and shows that the probability of an outbreak increases as clustering increases but the expected size of an outbreak decreases. Some more recent papers seek to distinguish the effects of clustering from confounding factors such as assortativity and degree sequence. Miller [21] develops analytic approximations to study the interplay of various effects such as clustering, heterogeneity in host infectiousness and susceptibility and the weighting of contacts on the spread of disease over a network. The impact of clustering on the probability and size of an outbreak is found to be small on ""reasonable"" networks so long as the average degree of the network is not too low. The rate at which the epidemic spreads, measured by the reproduction number, R 0 , is found to reduce with increased clustering in such networks. In networks with low mean degree, R 0 may be reduced to point of affecting the probability and size of an outbreak. Miller [22] points out that studies of the effects of clustering should take into account assortativity in the network, that is, the correlations in node degree between connected nodes. Assortativity has been shown to affect epidemic dynamics and changing the level of clustering in a network can change the level of assortativity. To distinguish between the effects of assortativity and clustering, a method of producing networks with arbitrary degree distributions and arbitrary levels of clustering with or without correlated degrees is presented and studied using percolation methods. The effect of increasing clustering in these models is to reduce the probability of outbreaks and reduce the expected size of an epidemic. Badham and Stocker [23] use simulated networks and epidemics to study the relationship between assortativity and clustering. Their results suggest that increased clustering diminished the final size of the epidemic, while the effect of clustering on probability of outbreak was not very clear. Like [23] , Moslonka-Lefebvre et al. [24] use simulations to try to distinguish the effects of clustering and assortativity but look at directed graphs. Here, they find that clustering has little effect on epidemic behaviour. Melnik et al. [25] propose that the theory developed for epidemics on unclustered (tree-like) networks applies with a high degree of accuracy to networks with clustering so long as the network has a small-world property [12] . That is, if the mean length of the shortest path between vertices of the clustered network is sufficiently small, quantities such as the probability of an outbreak on the network can be estimated using known results that require only the degree distribution and degree correlations. The theory is tested using simulations on various empirical networks from a wide range of domains and synthetic networks simulated from theoretical models. Taken together, these studies show that clustering can have significant effects on crucial properties of epidemics on networks such as the probability, size and speed of an outbreak. These results primarily relate to the final outcome and mean behaviour of epidemics. However, if we can obtain a transmission tree for an outbreak then we have information from the start to the finish of a particular epidemic including times of infection and who infected whom. Since epidemics are stochastic processes, data from a particular epidemic may differ considerably from the predicted mean. Whether or not such data contains information about clustering in the underlying network is the question we seek to address here. We simulate epidemics over networks with fixed degree distributions and varying levels of clustering and inspect various summary statistics of the resulting epidemic data, comparing the summaries for epidemics run over networks with the same degree distribution but different levels of clustering. The precise details of the simulations are described in Section 2. The results of the simulations, presented in Section 3, show that there is likely little to no signal of clustering in a contact network to be found in a single realisation of an epidemic process over that network. We conclude that it is unlikely that clustering parameters can be inferred solely from epidemiological data that relates to the transmission tree and suggest that further work in parameter estimation for contact networks would be best focused on other properties of contact networks such as degree distribution or broader notions of population structure.@story_separate@We simulate multiple networks from two network models: a Bernoulli model [26] and a power-law model [27] . Under the Bernoulli model (also called the Erdős-Rényi or binomial model), an edge between nodes i and j is present with some fixed probability 0 ≤ p ≤ 1 and absent with probability 1 − p, independently of all other edges. Due to their simplicity, Bernoulli networks are well-studied and commonly used in disease modeling but are not generally thought to be accurate models of social systems. A Bernoulli network is trivial to construct by sampling first the total number of edges in a the graph where N is the number of nodes in the network, and then sampling |Y | edges uniformly at random without replacement. We set N = 500 and p = 7/N = 0.014 in the simulations reported below. A power-law network is defined as having a power-law degree distribution, that is, for nodes i = 1, . . . , N , P (d i = k) ∝ k −α for some α > 0. Power-law networks are commonly used to model social interactions and various estimates of α in the range 1.5-2.5 have been claimed for observed social networks. In the model used here, we set α = 1.8. We simulate power-law using a Reed-Molloy type algorithm [28] . That is, the degree of each node, d i , i = 1, . . . , N , is sampled from the appropriate distribution. Node i is then assigned d i ""edge stubs"" and pairs of stubs are sampled uniformly without replacement to be joined and become edges. When all stubs have been paired, loops are removed and multiple edges between the same nodes are collapsed to single edges. This last step of removing loops and multiple edges causes the resulting graph to be only an approximation of a power law graph but the approximation is good for even moderately large N . We set N = 600 and consider only the largest connected component of the network in the simulation reported below. The size of the networks considered here is smaller than some considered in simulation studies though on a par with others (see, for example, [25] who looks a a wide range of network sizes). We choose these network sizes partly for convenience and partly because the current computational methods for statistical fitting of epidemic data to network models would struggle with networks much larger than a few hundred nodes [6] so our interest is in networks around this size. From each sampled network, Y , we generate two further networks, Y hi and Y lo that preserve the degrees of all nodes in Y but have, respectively, high and low levels of clustering. We achieve this using a Monte Carlo algorithm implemented in the ERGM package [29] in R [30] that randomly rewires the input network while preserving the degree distribution. A similar algorithm is implemented in Bansal et al. [31] . For details of the ERGM model and implementation of this algorithm, we refer the reader the package manual [32] and note that the two commands used to simulate our networks are y_hi = simulate(y˜gwesp(0.2,fixed=T), theta0 = 5,... constraints =˜degreedist, burnin=5e+5) and y_lo = simulate(y˜gwesp(0.2,fixed=T), theta0 = -5,... constraints =˜degreedist, burnin=5e+5) We measure clustering in the resulting networks using the clustering coefficient [12] , defined as follows. Let N i = {j|Y ij = 1} be the neighbourhood of vertex i and d i = |N i | be the degree of i. Let n i = j<k∈N i Y jk be the number of edges between neighbours of i. Then, if d i > 1, the local clustering coefficient is , which is the ratio of extant edges between neighbours of i to possible edges. For d i ∈ {0, 1}, let C i = 0. The (global) clustering coefficient is the mean of the local coefficients, 1} is somewhat arbitrary, though other possible choices, such as C i = 1 or excluding those statistics from the mean, give similar qualitative results in our experiments. Over each simulated network, we simulate a stochastic susceptible-exposed-infectious-removed (SEIR) epidemic. All nodes are initially susceptible to the infection. The outbreak starts when a single node is chosen uniformly at random and exposed to a disease. After a gamma-distributed waiting period with mean k E θ E and variance k E θ 2 E , the node becomes infectious. The infection may spread across the edges of the network, from infectious nodes to susceptible nodes according to a Poisson process with rate β. Infected nodes recover after an infectious period with a gamma distributed waiting time with mean k I θ I and variance k I θ 2 I . Once a node is recovered, it plays no further part in the spread of the infection. The process stops when there are no longer any exposed or infectious nodes. For each pair, Y hi and Y lo , we start the infection from the same node. We condition on the outbreak infecting at least 20 nodes. The parameter values are set at β = 0.1, k E = k I = 1 and θ E = θ I = 3 in the simulations reported below. A transmission tree encodes all information about the epidemic outbreak it describes. As such, it is a very complicated object. To compare sets of transmission trees and decide whether there are some systematic differences between them, we rely on various summary statistics derived from the trees and compare the distribution of the summaries over the ensembles in question. The summaries we use can be divided into two groups, those relating solely to the number of infected through time and those relating to topology of the tree. The first group of summaries can all be derived from the epidemic curves, that is, the number infected as a function of time. From this, we derive scalar summaries being the total number of individuals infected, the length of the epidemic (measured from the time of the first infection to the last recovery), the maximum of the epidemic curve and the time of that maximum. We label each individual in the population (equivalently, each node in the contact network) with labels 1, . . . , N . A transmission tree, a distinct graph from the contact network, has a time component and can be defined as follows; an example of a transmission tree and the notation is given in Figure 2 . There are three types of nodes in a transmission tree (not to be confused with nodes in the contact network): the root node corresponding to the initial infection, transmission or internal nodes corresponding to transmission events, and leaf or external nodes corresponding to recovery events. Leaf nodes are defined by the time and label pair (t i , u i ) where t ≥ 0 is the time of the recovery event and u i is the label of individual that recovered. The internal nodes are associated with the triple (t i , u i , v i ) being the time of the event, t i , the label u i of the exposed individual and v i that is the transmitter or ""parent"" of the infection. The root node is like an internal node but the infection parent is given as 0, so is denoted (t 0 , u 0 , 0). The branches of the tree are times between infection, transmission and recovery events for a particular vertex. For example, if the individual labelled u is infected at event (t 1 , u, v 1 ), is involved in transmission events (t k , v k , u), k = 2, . . . , m − 1, and recovers at (t m , u) where t i < t j for i < j and {v 1 , . . . , u m−1 } are other individuals in the population, there are m − 1 branches of the transmission tree at u defined by the intervals (t i , t i+1 ], for i = 1, . . . , m − 1. We summarise the transmission tree using the following statistics: the mean branch length between internal nodes (corresponding to the mean time between secondary infections for each individual); the mean branch length of those branches adjacent to a leaf node (which corresponds to the mean time from the last secondary infection to removal for each individual); the number of secondary infections caused by each infected individual (that is, for each infected individual v we count the number of internal nodes that have the form (t i , u i , v), for some i); and, the distribution of infective descendants for each individual, v, which is defined recursively as the sum of secondary infections caused by v and the secondary infections caused by the secondary infections of v and so on. An equivalent definition is to say that number of infective descendants of v is the number of leaves that have a node of the form (t, u i , v) as an ancestor. Finally, we consider the number of cherries in the tree [33] which is the number of pairs of leaves that are adjacent to a common internal node. This simple statistic is chosen as it is easy to compute and contains information about the topology or shape of the tree. To compare the number of cherries in outbreaks of different size, we look at the ratio of extant cherries to the maximum possible number of cherries for the given outbreak. The experimental pipeline can thus be summarised as: 1. Repeat for i = 1, . . . , 500: (a) Sample a graph Y i according to given degree distribution. (b) Simulate two further graphs Y hi i and Y lo i with high clustering and low clustering, respectively, using a Monte Carlo sampler that rewires Y i to alter the clustering level while preserving the degree of each node.  We report results here for SEIR epidemics run over Bernoulli and power-law networks. A number of smaller trials that we do not report were run: with different values chosen for the network and epidemic parameters; on networks with the same degree distributions as a random intersection graph; and, using an SIR epidemic rather than an SEIR. The results for those smaller trials were qualitatively similar to the results reported here. The distributions of the measured clustering coefficients is shown in Figure 3 and show that the simulated networks with high and low clustering for a given degree distribution are easily distinguished from one another. The Bernoulli networks with low clustering contain no triangles, so the clustering coefficient for each of these networks is zero, while for highly-clustered Bernoulli networks, clustering coefficients are in the range (0.28,0.33). For the power-law networks, the low clustered networks have clustering in the range (0.00,0.09) while the highly clustered networks have clustering in the range (0.24,0.38). Figures 4 and 5 show comparisons of summary statistics for networks with differing levels of clustering and Bernoulli degree distributions. The summaries show some differences between the outbreaks on the differently clustered networks. In particular, the outbreaks in the highly-clustered networks spread more slowly, on average, leading to marginally longer epidemics with fewer individuals infected at the peak of the outbreak, that occurs slightly later, than we see in outbreaks on the networks with low clustering. These mean effects are in line with the predictions of [22] . The variances of the measured statistics, however, are sufficiently large due to stochastic effects in the model that the ranges of the distributions overlap almost completely in most cases. Statistics derived from the transmission tree appear to add little information, with only the number of cherries differing in the mean. Figures 6 and 7 show the corresponding distributions for networks with power-law degree distributions. Again, differences in the means between the two sets of statistics are apparent with the mean length of epidemic, total number infected and number infected at peak all lower in the epidemics on networks with high-clustering. The largest difference is found in the total number infected, where in the low-clustered networks, the range of the statistic is (231, 445) while it is just (211, 361) in the high-clustered networks. The primary cause here is due to the change in size of the largest connected component of the network. If we adjust for this by looking instead at the proportion of the giant component infected, the distributions again overlap almost completely with the range for the proportion infected in the low-clustered networks being (0.39, 0.74) and (0.42, 0.74) for the high-clustered networks.  I thank David Hunter, Marcel Salathé, Mary Poss and an anonymous referee for useful comments and references that improved this paper. This work is supported by NIH grant R01-GM083603-01.@story_separate@The results presented above suggest that the behaviour of an epidemic on a random network with a given degree sequence is relatively unaffected by the level of clustering in the network. Some effect is seen, but it is small relative to the random variation we see between epidemics on similarly clustered networks. The results also suggest that the complete transmission tree from an epidemic provides little information about clustering that is not present in the epidemic curve. These results do not imply that clustering has little effect, rather they suggest as noted in [16] , the apparently strong effect of clustering observed by some is more likely to due to a change in the degree distribution-an effect we have nullified by holding the degree sequence constant. These broader effects are probably best analysed on a grosser level such as the household or subgroup level rather than at the individual level at which clustering is measured. Our simulation method, in which the degree sequence for each network is held constant while clustering levels are adjusted, places significant restrictions on the space of possible graphs and therefore clustering coefficients. The levels of clustering achieved in the simulations reported here (for example, having a clustering coefficient in the low-clustered Bernoulli case of 0 versus a mean of 0.30 for the high-clustered case) are not so high as those considered in the some of the simulations and theoretical work described in Section 1, and this may partly account for the limited effect on epidemic outcomes that we find here. There is little known about the levels of clustering found in real contact networks [31] (though one recent detailed study [34] find values for clustering in a social contact network in the region 0.15-0.5) and no evidence to suggest that very extreme values of clustering are achieved for a given degree sequence. It is plausible, however, that the degree sequence of a social network of interest could be found-for example, via ego-centric or full-network sampling [34] [35] [36] -and therefore reasonable to explore the achievable levels of clustering conditional on the degree sequence. In doing so, we separate the effects on epidemic dynamics of change in the degree sequence of the contact network from those of clustering. From a statistical point of view, these results indicate that even with full data from a particular epidemic outbreak, such as complete knowledge of the transmission tree, it is unlikely that the level of clustering in the underlying contact network could be accurately inferred independently of the degree distribution. This is primarily due to the large stochastic variation found from one epidemic to the next that masks the relatively modest effects of clustering on an outbreak. With this much stochastic noise, we suggest that it would require data from many outbreaks over the same network (that is, pathogens with a similar mode of transmission spreading in the same population) to infer the clustering level of that network with any accuracy. The results also suggest that attempting to estimate a clustering parameter without either estimating or fixing the degree sequence, as in Goudie [37] , may see the estimated clustering parameter acting chiefly a proxy for the degree sequence. It cannot be ruled out that a statistical method, which takes into account the complete data rather than the summaries we use here, or which takes data from parts of the parameter space that we have not touched on here, could find some signal of clustering from such data. In practise, however, it would be highly unusual to have access to anything approaching complete data. A more realistic data set might include times of onset and recovery from disease symptoms for some individuals in the population and sequences taken from viral genetic material. The noise that characterises such data sets already makes it difficult to accurately reconstruct the transmission tree; this extra uncertainty would likely make any inference of a clustering parameter, in the absence of other information, very difficult.","Networks are often used to model the contact processes that allow pathogens to spread between hosts but it remains unclear which models best describe these networks. One question is whether clustering in networks, roughly defined as the propensity for triangles to form, affects the dynamics of disease spread. We perform a simulation study to see if there is a signal in epidemic transmission trees of clustering. We simulate susceptible-exposed-infectious-removed (SEIR) epidemics (with no re-infection) over networks with fixed degree sequences but different levels of clustering and compare trees from networks with the same degree sequence and different clustering levels. We find that the variation of such trees simulated on networks with different levels of clustering is barely greater than those simulated on networks with the same level of clustering, suggesting that clustering can not be detected in transmission data when re-infection does not occur."
"Pseudomonas aeruginosa is a highly pathogenic Gramnegative bacterium that may be difficult to treat due to various intrinsic and acquired mechanisms of resistance. The predominant intrinsic mechanisms of resistance include poor outer membrane permeability due to various restrictive porins (e.g., OprD), expressed efflux pumps (e.g., MexAB-OprM, MexCD-OprJ, MexEF-OprN, and MexXY-OprM), and antibiotic-deactivating enzymes (e.g., AmpC betalactamases). Although P. aeruginosa has potential to produce beta-lactamases from all four Ambler classes, it does not commonly produce these enzymes with the exception of class C (e.g., AmpC) [1] . Resistance mechanisms may also be acquired through mobile genetic elements (e.g., plasmids, transposons, and integrons) that harbor resistance genes. Mobile genetic elements may be transferred from one bacterium to another via horizontal gene transfer (i.e., transformation, transduction, and conjugation). This may cause loss of porin channels, hyperproduction of efflux pumps, and/or production of antibiotic-deactivating enzymes in P. aeruginosa. These resistance mechanisms may prevent effective use of most anti-pseudomonal beta-lactams, including anti-pseudomonal carbapenems [2, 3] . Unfortunately, antimicrobials that can bypass all mechanisms of resistance do not currently exist. Ceftolozane/tazobactam, a novel oxyimino-aminothiazolyl cephalosporin, has the ability to bypass certain betalactamase (i.e., chromosomal AmpC), porin (i.e., OprD), efflux pump (i.e., MexXY-OprM, MexAB-OprM) mutations commonly identified in P. aeruginosa, due to its structural stability against these mechanisms, higher affinity towards P. aeruginosa penicillin binding proteins (i.e., 1b, 1c, 2, and 3), and the presence of tazobactam to inhibit certain Ambler class A and C beta-lactamases [2, [4] [5] [6] . Ceftolozane/tazobactam is a novel intravenous beta-lactam/beta-lactamase inhibitor combined with a traditional beta-lactamase inhibitor that was approved by the US Food and Drug Administration (FDA) as monotherapy for complicated urinary tract infections and for complicated intraabdominal infections when used concomitantly with metronidazole. For both indications, ceftolozane/tazobactam is dosed as 1.5 g intravenously (IV) every 8 h. It recently received FDA approval for hospital-acquired pneumonia (HAP) and ventilator-associated pneumonia (VAP), but it must be dosed at 3 g IV every 8 h [7]. Ceftolozane/tazobactam demonstrates higher concentrations in lung epithelial lining fluid (ELF) than piperacillin/tazobactam demonstrates, but doses of 1.5 g every 8 h did not produce adequate lung ELF concentrations to eradicate P. aeruginosa as plasma-to-ELF penetration ratio is approximately 50%. Dosing 1.5 g IV every 8 h produced a mean ceftolozane ELF concentration of 21.8 mg/L, which may not be sufficient in multidrug-resistant P. aeruginosa [8, 9] . Several studies and case reports demonstrate that doubling the dose to 3 g IV every 8 h may be sufficient to obtain adequate lung ELF concentrations over the dosing interval to achieve > 90% probability of target attainment and treat nosocomial pneumonia secondary to multidrug-resistant P. aeruginosa [9] [10] [11] [12] [13] [14] [15] . Ceftolozane/tazobactam failures have been observed when used off-label in pneumonia. Many of these patients are more severely ill compared to patients who experienced clinical success [15] . Currently, there are not any reported cases of ceftolozane/tazobactam-induced leukocytosis. Herein, we report the first published case of ceftolozane/tazobactaminduced leukocytosis and clinical failure when utilized for a patient being treated for VAP secondary to carbapenemresistant P. aeruginosa, and during re-challenge.@story_separate@We present the case of a 25-year-old Caucasian male with quadriplegia who was bedridden in a nursing home. He presented with fever and tachycardia and was diagnosed with sepsis. Blood and tracheostomy secretion samples were sent for culture and susceptibility testing in the nursing home. Symptom assessment was difficult due to medical history of a gunshot wound leading to quadriplegia and anoxic brain injury. A chest X-ray demonstrated right upper lobe pneumonia. He was empirically initiated on vancomycin 750 mg IV every 8 h, cefepime 1000 mg IV every 8 h, and metronidazole 500 mg IV every 8 h on day 1, and subsequently transferred to the intensive care unit (ICU). Fever (temperature 101.1°F), tachycardia (heart rate 137 beats per minute (bpm)), tachypnea (respiratory rate 29 breaths per minute (bpm)), and leukocytosis (white blood cell (WBC) count 21 × 10 9 /L) were documented on ICU presentation. Respiratory secretions grew pan-susceptible Pseudomonas aeruginosa and blood cultures grew methicillin-resistant Staphylococcus epidermidis; empiric antibiotics were continued with positive clinical response. Fever defervesced, blood cultures became negative on day three, and leukocytosis, tachycardia, and tachypnea were gradually resolving. A repeat chest X-ray demonstrated large right-sided hydropneumothorax and increased diffuse left-sided airspace opacities. A right-sided chest tube was subsequently placed. On day 10, vancomycin was discontinued, and linezolid was initiated for 12 additional days due to persistent signs and symptoms. A non-contrast chest computed tomography (CT) later demonstrated probable mucus plug and possible postobstructive pneumonia. On day 22, our patient was downgraded. A repeat respiratory culture then grew heavy Acinetobacter baumannii-calcoaceticus and moderate P. aeruginosa with many WBCs, so linezolid was discontinued. On day 24, the chest tube was removed and there was not any evidence of pneumothorax following removal. On day 25, both A. baumannii and P. aeruginosa were found to be resistant to cefepime and imipenem; cefepime was discontinued. Additional susceptibilities and molecular testing for carbapenemases were requested for both organisms. Meanwhile, our patient was initiated on dualcarbapenem therapy (ertapenem 1000 mg IV every 24 h and meropenem 500 mg IV every 6 h) to combat potential OXA-48 carbapenemases in A. baumannii, polymyxin B 800,000 units IV every 12 h, and colistin 150 mg inhaled every 8 h to synergistically combat potential porin and efflux pump mutations. Acinetobacter baumannii was found to be susceptible to tetracycline, so minocycline 200 mg orally every 12 h was initiated. On day 32, blood cultures grew yeast, so micafungin 150 mg IV every 24 h was initiated. The culture was later confirmed as Candida auris. Beyond day 32, surveillance blood cultures were negative. While on ertapenem, meropenem, polymyxin B, inhaled colistin, minocycline, and micafungin, our patient seemed to be improving. However, on day 35, our patient went into cardiac arrest. On day 38, our patient's WBC decreased to 14.3 × 10 9 /L, the lowest since initiating this regimen. A respiratory culture demonstrated light growth of P. aeruginosa with moderate WBCs. On day 38, both A. baumannii and P. aeruginosa were found to be susceptible to polymyxin B and colistin; P. aeruginosa was also susceptible to ceftolozane/tazobactam. Molecular testing was unable to be performed. Ertapenem, meropenem, polymyxin B, inhaled colistin, and oral minocycline were discontinued, and ceftolozane/tazobactam 3 g IV every 8 h, for carbapenem-resistant P. aeruginosa, and minocycline 100 mg IV every 12 h, for carbapenem-resistant A. baumannii, were initiated, and micafungin was continued. Our patient's WBCs progressively increased from 14.3 × 10 9 / L on day 38 to 26.2 × 10 9 /L on day 42. Our patient also became tachycardic to 129 bpm, tachypneic to 32 bpm, and febrile to 100.8°F, so intravenous polymyxin B and inhaled colistin were re-initiated A repeat respiratory culture persistently grew P. aeruginosa. On day 48, our patient's WBCs peaked at 36.9 × 10 9 /L. On day 50, all antimicrobials were discontinued, and WBC declined to 26.9 × 10 9 /L. A non-contrast chest CT demonstrated worsening left lower lobe pneumonia without abscess and severe bronchiectasis with mucus plugging, but our patient's WBC further improved to 11.5 × 10 9 /L on day 53 while off antimicrobials. Ceftolozane/tazobactam monotherapy was reinitiated due to radiographic findings. Immediately after re-challenging ceftolozane/tazobactam, our patient's WBCs increased from 11.5 × 10 9 to 17 × 10 9 /L on day 54, 18.7 × 10 9 /L on day 55, and 24.5 × 10 9 /L on day 56 (Fig. 1) . A repeat respiratory culture again grew P. aeruginosa. Ceftolozane/tazobactam was discontinued and our patient's WBC improved to 21.9 × 10 9 /L. Our patient was then transferred to an outside facility. Unfortunately, our patient's status could not be tracked beyond the transfer. Conflict of Interest The authors declare that they have no conflict of interest. Fig. 1 The trend in white blood cell count throughout duration of antimicrobial therapy, including when ceftolozane/tazobactam was started and stopped, demonstrating drug-induced leukocytosis. Figure created  Ethics Approval The Institutional Review Board waived the need for ethical approval for this case report given that identifiable health information was not disclosed. Informed Consent Consent to participate and publish this case report was obtained from the patient.@story_separate@To the best of our knowledge, this is the first reported case demonstrating ceftolozane/tazobactam-induced leukocytosis. Our patient initially appeared responsive to polymyxin-based therapy. When transitioned to ceftolozane/tazobactam, his WBCs began to worsen, though he remained clinically stable. We initially attributed this to clinical failure of ceftolozane/ tazobactam and added polymyxin B and colistin. Despite prolonged combination therapy with active antimicrobials, Pseudomonas aeruginosa microbiologic clearance was not achieved. Unfortunately, our patient's WBC continued to worsen. Upon discontinuation of all antimicrobials and monitoring for 3 days, our patient's WBCs improved. Upon reinitiation of ceftolozane/tazobactam monotherapy, our patient's WBCs rose again. Three days later, ceftolozane/ tazobactam was again discontinued and, once again, WBCs declined. According to the Naranjo algorithm, our patient experienced a probable drug-induced adverse drug reaction. Though it is unclear how ceftolozane/tazobactam may induce leukocytosis, clinical failure should be differentiated from an adverse drug reaction in patients with increasing leukocytosis but stable symptoms on ceftolozane/tazobactam. Acknowledgements The collaborative contributions from the following individuals have been greatly appreciated: (1) Bejoy Maniara, PharmD, BCPS and (2) Ian Wells, BS, PharmD. Author Contributions I (Dr. Bejoy Maniara) substantially contributed to the conception of this case report and acquisition, analysis, and interpretation of data. I drafted the article and critically revised it for important intellectual content. I have provided final approval of this version to be published. I agree to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. Dr. Ian Wells also substantially contributed to the conception of this case report and acquisition, analysis, and interpretation of data. He assisted in drafting the article, as a co-author, and assisted in critically revising it for important intellectual content. He has provided final approval of this version to be published. He agrees to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.","Ceftolozane/tazobactam is an intravenous beta-lactam/beta-lactamase inhibitor that utilizes a novel oxyimino-cephalosporin with a traditional beta-lactamase inhibitor. It is approved by the Food and Drug Administration to treat complicated intra-abdominal infections in combination with metronidazole, complicated urinary tract infections, and, most recently, hospital-acquired bacterial and ventilator-associated bacterial pneumonias. It is commonly utilized to treat infections caused by multidrug-resistant Pseudomonas aeruginosa. This case report delineates the first published case of ceftolozane/tazobactam-induced leukocytosis (up to 36.9 × 10(9) cells/L) and clinical failure when utilized in a high-dose regimen for a patient being treated for ventilator-associated pneumonia secondary to carbapenem-resistant P. aeruginosa. The reaction occurred during initial challenge, resolved after discontinuation, and recurred during re-challenge. In patients who are appropriately being treated with ceftolozane/tazobactam for susceptible infections, consider a drug-induced reaction as a potential cause of rising leukocytosis; this should be differentiated from clinical failure if the patient is clinically stable."
"Obesity, characterized by excessive fat storage in tissues, presents excessive risks to an individual's health, and is, therefore, considered a major risk factor for morbidity and mortality worldwide. Moreover, obesity is associated with diseases such as type 2 diabetes, hypercholesterolemia, hypertension, and hepatic steatosis, termed as the metabolic syndrome (MS), which is a crucial problem that needs to be resolved for improved quality of life [1] . Obesity occurs from a combination of less active lifestyle and a failure to reduce dietary energy intake in line with reduced total energy expenditure arising from reduced physical activity [2] . Recently, lockdown due to the coronavirus disease 2019 (COVID-19) pandemic have caused disruptions in daily lifestyles, thereby increasing the global prevalence of obesity [3] . Lactic acid bacteria (LAB) are lactic acid-producing gram-positive bacteria that have been exploited in association with various health benefits and are widespread in nature. The most common health-promoting LABs are classified as probiotics. Probiotics are live microorganisms that provide beneficial health effects to the host when administered in adequate amounts [4] . Numerous beneficial effects of probiotics, such as anticonstipation, antiosteoporotic, and antiobesity effects, are frequently suggested by many research studies [5] [6] [7] . The health benefits of probiotic bacteria are usually explained by the protective effects of the interaction of consumed probiotics with commensal gut microbiota in the host [8] . It is, therefore, essential for LABs to withstand low pH conditions in the stomach and the presence of secreted bile salts in the small intestine [9] . Moreover, all probiotics meant for consumption must undergo thorough safety checks, including the absence of harmful metabolite (such as urease and gelatinase) secretion [10] . Gut microbiota (GM) is defined as the community of bacteria inhabiting the gastrointestinal (GI) tract that has a complicated and mutually beneficial relationship with the host. Recently, the control on host gut microbiota exerted by probiotics has emerged as an important factor affecting health in the host, including obesity [11] . Dysbiosis, a form of microbial imbalance induced by a high-fat diet, is one of the most important factors in the development of obesity [12] . Colonization of intestinal microbes from obese mice to germ-free mice resulted in increased body weight gain and fat accumulation in the latter, thereby providing robust evidence of the association between obesity and GM [13] . Taken together, employing probiotic bacteria to target and alter high-fat diet-induced disturbance of gut microbiota might be an effective approach to treat obesity. The present work was conducted in order to screen novel potential probiotics by testing basic probiotic properties such as resistance to low pH and bile salts. We have previously prescreened 61 strains out of 151 probiotic candidates based on their survival rate in a low pH environment. Therefore, the objective of this study was to confirm the survivability of these prescreened strains and explore their adaptation to the bile salt environment. Moreover, their cholesterollowering and antioxidant activities were probed to identify strains capable of exerting antiadipogenic effects in 3T3-L1 adipocyte cells in vitro.@story_separate@The bacterial strains used in this study were obtained from the Probiotics Research Laboratory, CKDBio Research Institute (Ansan, South Korea) and the Department of Food Bioscience and Technology, Korea University (Seoul, Korea). Strains were individually grown in Man, Rogosa and Sharpe (MRS) broth (BD Co., Franklin Lakes, NJ, USA) for 18 h at 37 °C. The strains were sub-cultured thrice prior to each experiment. Tolerance to acid and bile conditions was assessed as reported previously [14] , with minor modifications. Activated bacterial strains were harvested by centrifugation (10,000×g, 5 min, 4 °C) and washed twice in phosphatebuffered saline (PBS) prior to inoculation in acidified and bile-supplemented MRS broth. To evaluate the ability of the strains to grow under acidic conditions, MRS broth was acidified to pH 2.5 and supplemented with 1000 U mL −1 of pepsin (Sigma-Aldrich, St. Louis, MO, USA). The washed bacterial cells were inoculated into the acidified broth and incubated for 3 h at 37 °C. Acid tolerance was evaluated by comparing the number of colonies at 0 h with that at 3 h after incubation. The ability of strains to grow in the presence of bile was evaluated using MRS broth containing 0.3% oxgall (Sigma-Aldrich, St. Louis, MO, USA). The broth was inoculated with the washed bacterial cells and incubated for 24 h at 37 °C. The viability of strains in the bile condition was assessed by comparing the number of colonies at 0 h with that at 24 h after incubation. A 100-μL aliquot of each sample was spread in triplicate onto MRS agar plates in order to count the number of viable bacterial colonies on the surface. Acid and bile tolerance rates were evaluated by calculating the survival rate after 3 and 24 h of incubation at 37 °C, respectively. To evaluate bacterial safety, urease and gelatin liquefaction activities of the strains were assessed. A gelatin medium containing 12% gelatin (Sigma-Aldrich, St. Louis, MO, USA) was inoculated with activated strains at a concentration of 1% and incubated for 48 h at 37 °C. Gelatin liquefaction of strains was assessed by storing medium in a refrigerator for 24 h and checking whether gelatin was hydrolyzed or not. Urease activity of the strains was assessed in urea agar media containing 2% urea (Sigma-Aldrich, St. Louis, MO, USA) and 0.0012% phenol red (Sigma-Aldrich, St. Louis, MO, USA). Each strain was streaked in urea agar media and incubated for 48 h at 37 °C. Media was kept under observation to check whether the color changed from yellow to pink. Change in media color to pink indicates that the strain has the ability to hydrolyze urea. A colorimetric assay to assess the cholesterol-lowering activity of strains was conducted [15] , with minor modifications. MRS-THIO broth was prepared by adding 0.2% sodium thioglycolate (Sigma Aldrich, St. Louis, MO, USA) and 0.3% oxgall (Sigma-Aldrich, St. Louis, MO, USA) to MRS broth. The broth was further supplemented with filtersterilized cholesterol micelles (1 mg mL −1 in 0.4 M sucrose solution) at a final concentration of 100 µg mL −1 . The broth was inoculated with 1% of the selected strains and incubated for 20 h at 37 °C. Uninoculated broth was used as a negative control. After incubation, cells were removed by centrifugation (10,000×g, 10 min, 4 °C) and total cholesterol content of the supernatant was measured using a colorimetric method [16] , with minor modifications. The supernatant (2 mL) was mixed with 3 mL of 97% ethanol (Sigma-Aldrich, St. Louis, MO, USA) and 2 mL of 50% potassium hydroxide (w/v), and then heated at 60 °C for 10 min. After cooling to room temperature, 5 mL of hexane was added and the resultant mixture was vortexed. Next, 4 mL of the hexane layer was transferred into a tube and dried using nitrogen gas. o-Phthalaldehyde (Sigma-Aldrich, St. Louis, MO, USA) (0.55 mg dissolved in 1 mL of acetic acid) was added to the tube and incubated for 10 min. Further, 2 mL of sulfuric acid was added and mixed for 1 min. Absorbance was measured spectrophotometrically at 550 nm using a VersaMax™ Tunable Microplate Reader (Molecular Devices, San Jose, CA, USA). To determine the concentration of cholesterol, the recorded A 550 values were compared with a standard curve. Results were expressed as micrograms of cholesterol per milliliter. The cholesterol-lowering activity was calculated using the following equation: To investigate the antioxidant activity of selected strains, live cells of activated strains were assessed by the DPPH method [17] , with minor modifications. An aliquot of bacterial live cell (800 μL) was added to 1 mL of a 0.2 mM methanolic solution of 2,2-diphenyl-1-picrylhydrazyl (DPPH) (Sigma-Aldrich, St. Louis, MO, USA) reagent. The suspension was mixed thoroughly and allowed to stand for 30 min at 37 °C in dark. After incubation, the supernatant from each sample was collected by centrifugation (10,000×g, 1 min, 4 °C). The absorbance of the supernatant was measured spectrophotometrically at 517 nm using a VersaMax™ tunable microplate reader (Molecular Device, San Jose, CA, USA). For comparison, PBS and 0.2 mM ascorbic acid (Sigma-Aldrich, USA) were used as negative and positive controls, respectively. The antioxidant activity was expressed as the percentage of DPPH radical scavenging activity using the following equation: For the cell experiments, Leuconoc mesenteroides 7 (99% identity: accession no. CP003101), Lactobacillus rhamnosus 86 (99% identity: accession no. NR_113332.1), Lactobacillus sakei 105 (99% identity: accession no. CR936503), Lactobacillus casei 911 (99% identity: accession no. KP326371.1), Lactobacillus johnsonii 3121 (99% identity: accession no. NR_117574.1), and Lactobacillus plantarum MA2 (99% identity: accession no. NR_113338.1) were selected based on their probiotic potentials. The mouse preadipocyte cell line 3T3-L1 was obtained from the American DPPH radical scavenging activity (%) = OD 517(control) − OD 517(sample) Type Culture Collection (ATCC, Rockville, MD, USA). Cells were grown in Dulbecco's modified Eagle's medium (DMEM) (GE Healthcare, Chicago, IL, USA) containing 10% (v/v) fetal bovine serum (FBS) (Gibco, Dublin, Ireland) and 1% (v/v) antibiotic solution (penicillin and streptomycin solution, 100 U mL −1 ) (GE Healthcare, Chicago, IL, USA). Cells were incubated at 37 °C and 5% CO 2 in a humidified atmosphere, and the culture medium was replaced with fresh DMEM every 2 days. Cells were transferred at 60% confluence using 1 mL of trypsin-EDTA (GE Healthcare, Chicago, IL, USA). Cell differentiation was performed in 6-well cell culture plates (Sigma-Aldrich, St. Louis, MO, USA). Cells were seeded at a density of 8 × 10 4 cells/well in maintenance medium (DMEM containing 10% FBS and 1% antibiotic solution) and grown to 100% confluence. At 100% confluence, the culture medium was replaced with fresh maintenance medium and incubated for 48 h to induce cell arrest. After 48 h, the maintenance medium was replaced with induction medium (  The cytotoxicity of the selected strains was assessed by MTT assay. The mouse pre-adipocyte 3T3-L1 cells were seeded into 96-well cell culture plates (Sigma-Aldrich, St. Louis, MO, USA) at a density of 1 × 10 4 cells/well and incubated at 37 °C and 5% CO 2 condition. After 24 h, the medium was replaced with maintenance medium containing each of the heat-killed strains at a concentration of 10 8 CFU mL −1 and incubated for 24 or 48 h. The medium was subsequently removed, and the remaining cells were used for the MTT assay. A 10-μL aliquot of a 12 mM stock solution of  IBM SPSS Statistics software version 25.0 (IBM Corp, Armonk, NY, USA) was used to analyze the data. One-way analysis of variance was used to compare sample means. Multiple comparisons of means were performed using Tukey's post hoc test. P < 0.05 was considered statistically significant. Probiotic functionality depends on the ability of the strain to confer health advantages on a host upon oral consumption of viable cells. Therefore, we studied the tolerance of bacterial strains to acidic conditions (artificial gastric juice) and the presence of bile salt (artificial intestinal stress). We set a cutoff value of 0.5 for the log CFU value at 3 h subtracted from that at 0 h, to indicate intolerance to low pH conditions. The same cutoff value was also considered for the bile salt condition. Previously, we have prescreened 61 strains out of 151 candidates that qualified for further investigation based on this cutoff value for resistance to acid and bile salts (data not shown). In order to increase the accuracy of identifying potential probiotics from the prescreened strains, we double-checked the acid and bile salt tolerance of the 61 prescreened strains (Figs. 1a-c  and 2a-c) . In the main screening process, the tolerance rates to acid and bile conditions were evaluated by calculating the survival rate after 3 h in acidic broth and 24 h in bile-supplemented broth. Twenty out of the 61 strains exhibited a high survival rate (more than 95%) after incubation in an acidic environment for 3 h (Fig. 1a) . Moreover, these 20 strains also showed adaptability to high bile conditions, as evident from the more than 120% survival rate (Fig. 2a) . Thereafter, the safety of the prescreened strains was verified using urease and gelatinase agar, and all 61 strains were evaluated to be safe ( Table 2 ). In order to confirm the functionality of the 61 strains, we assessed their cholesterol lowering activity in the presence of 0.3% oxgall (Fig. 3a-c) . All strains were capable of removing cholesterol from the MRS-THIO broth after 18 h of incubation. However, the extent of cholesterol reduction was strain-specific. The top 20 of the 61 strains exhibited over 27% reduction in cholesterol concentration (Fig. 3a) . Moreover, Lactobacillus plantarum MA2 and L. johnsonni 3121 were identified to exhibit the highest cholesterol-lowering activities (over 50%) in MRS-THIO broth. We further examined the functional properties of the 61 prescreened strains by measuring the radical scavenging activity of DPPH (Fig. 4a-c) . DPPH is a widely used chemical compound for evaluating the antioxidant activity of cell-free supernatant of bacteria. Leuconostoc mesenteroides 7, Lactobacillus casei 911, and Lactobacillus sakei 105 exhibited over 55% DPPH scavenging activities. Moreover, the top 20 strains were also characterized by over 30% DPPH scavenging capacity, which was taken as the minimum cutoff value for in vitro experiments (Fig. 4a) . Further investigations were continued by narrowing down the 61 strains to 6 probiotic candidates that qualified in the top 20 with respect to the parameters of functionality (acid tolerance, bile tolerance, cholesterol-lowering activity, and DPPH scavenging activity) explored in this study. Therefore, L. johnsonii 3121, L. rhamnosus 86, L. plantarum MA2, L. sakei 105, L. casei 911, and Leuc. mesenteroides 7 were selected for in vitro experiments using 3T3-L1 cells. The MTT assay was used to determine cytotoxic effect of the six heat-killed probiotic candidates on 3T3-L1 cell proliferation (Fig. 5) . Our results showed that none of the six heat-killed strains affected the viability of 3T3-L1 cells. Culturing cells with these six heat-killed strains did not result in significant differences, compared to the control group, at both 24 and 48 h of incubation (P > 0.05). These data indicate that the six probiotic candidates displayed negligible cytotoxicity and caused no damage to the cells. In order to evaluate the antiadipogenic effects of the heatkilled bacterial strains, the 3T3-L1 pre-adipocytes were treated with or without the heat-killed probiotic candidates for 8 days (Fig. 6a-c) . The differentiated 3T3-L1 cells were subsequently stained with oil red O for visualization of lipid droplets and treatment with L. rhamnosus 86 and L. johnsonii 3121 were found to significantly inhibit lipid accumulation (Fig. 6c) . The microscopybased imaging and examination of oil red O-stained lipid droplets were performed by eluting in isopropanol. These data showed that L. rhamnosus 86 and L. johnsonii 3121 significantly downregulated the intracellular lipid content compared to control 3T3-L1 cells (P < 0.05) (Fig. 6b) . Moreover, the decreased lipid accumulation activity was also supported by trends in the TG content in 3T3-L1 cells (Fig. 6a) . Both L. rhamnosus 86 and L. johnsonii 3121 were capable of significantly reducing the TG content compared to the control (Fig. 6a) . Taken together, these results suggest that treating 3T3-L1 cells with heatkilled L. rhamnosus 86 and L. johnsonii 3121 during differentiation could lead to inhibition of adipogenesis by suppressing lipid accumulation. enhancer-binding protein α (C/EBPα), and adipocyte protein 2 (aP2), were evaluated in 3T3-L1 preadipocytes treated with L. rhamnosus 86 and L. johnsonii 3121 (Fig. 7) . All three genes were significantly downregulated in pre-adipocytes, which confirms that the differentiation process was successfully induced in mature adipocytes. Interestingly, 3T3-L1 cells treated with L. rhamnosus 86 and L. johnsonii 3121 showed significantly downregulated gene expression levels of PPARγ, C/EBPα, and aP2 (P < 0.05), which represent the key adipogenic transcription factors related to adipocyte differentiation. These results indicate that L. rhamnosus 86 and L. johnsonii 3121 decrease the amount of intracellular lipid accumulation in 3T3-L1 adipocytes by downregulating the expression levels of genes related to adipogenesis. The present study was designed to identify novel probiotics with antiadipogenic capacity. Bacteria must be able to survive acidic conditions in the stomach and resist bile acids in order to exert their beneficial effect on the host and function as probiotics [9] . Therefore, in this study, artificial stress conditions of the human GI tract were mimicked. The first stress condition that probiotic bacteria face is the low pH environment in the stomach where gastric acid is secreted [22] . The average pH of secreted gastric acid is 2.5. This can damage the cell membrane of the bacteria and kill it before it reaches the gut and exerts its beneficial effects. Next, bacteria must resist the acidic bile conditions prevalent at the start of the small intestine; this is another crucial requirement for bacteria to act as probiotics. Bile is known to play an essential role in specific and nonspecific gut defense systems, and the intensity of its inhibitory effect is determined primarily by the bile salt concentration [23] . On the other hand, bile salts can disrupt bacterial cell membranes, which is toxic to living bacterial cells; therefore, bile tolerance is considered an important characteristic of probiotics, which enables bacterial survival, growth, and subsequent positive action in the GI tract [24] . We have previously identified 61 strains, out of 151 candidates, that exhibit high resistance to bile and low pH conditions. The present work was carried out with the objective of selecting the top 20 strains out of the 61 prescreened ones, which show the highest tolerance to both low pH and bile salt environments. Several studies have demonstrated that some LABs have high survivability in bile salt containing medium due to the presence of genes coding for bile salt hydrolases [25] . Moreover, safety evaluation is another important characteristic needed to be considered while screening for potential probiotics. The absence of urease and gelatinase activities represents one of the crucial factors that underscore the safety of probiotic consumption. Urease is an enzyme that catalyzes the hydrolysis of urea to ammonia and carbon dioxide, thereby playing a key role in urea-related diseases such as urolithiasis [26] . Gelatinase is a protease that is capable of hydrolyzing gelatin, which may lead to tissue necrosis and damage to the body [27] . In our study, all 61 prescreened strains showed negligible action with respect to both of these factors. In order to confirm the functional characteristics of these 61 strains, their antioxidant and cholesterol-lowering activities were evaluated. We anticipated that the most important functional ability needed for LABs to exert antiobesity effects could be cholesterol reducing activity. Kumar and colleagues have earlier suggested that cholesterol-lowering probiotics could be potential biotherapeutics for treating metabolic diseases [28] . Several LAB strains have been reported to possess the ability to assimilate and uptake cholesterol by adsorbing cholesterol into the cell wall, thereby assimilating it into the cell membrane [29] [30] [31] . Our study demonstrated that the top 20 strains exhibited over 27% reduction in cholesterol. Moreover, L. plantarum MA2 and L. johnsonni 3121 were capable of lowering cholesterol levels by more than 50%. For the second functionality, we evaluated the radical scavenging activity of the 61 strains. Since chronic oxidative stress is a major cause of metabolic diseases such as obesity, the antioxidant activity of LAB strains could be an ideal therapeutic method for treating obesity. Previous studies have shown that oxidative stress in accumulated fat mediates the development of obesity-associated MS via the dysregulation of adipocytokine production and increased ROS production [32] [33] [34] . 20 . Since the objective of this study was to screen for probiotics with antiobesity effects, the cytotoxicity and lipid accumulation levels were examined using 3T3-L1 mouse pre-adipocyte cells. The proliferation of 3T3-L1 cells was not affected by the six strains, indicating that none of these strains were cytotoxic to adipocytes. Further examination of the six strains was performed by confirming the decreased TG content and downregulated lipid accumulation in 3T3-L1 cells. Among the six strains, only L. johnsonii 3121 and L. rhamnosus 86 were capable of significantly decreasing the TG content and lipid accumulation in fully differentiated adipocytes. To confirm this antiadipogenic effect, the expression of adipogenesis-related genes was examined by qRT-PCR. Several studies have demonstrated the inhibition of adipogenesis in adipocytes on treatment with functional bacterial strains, which regulate adipogenic transcription factors [35, 36] . Similar findings were observed in our study. The qRT-PCR analysis revealed that both L. johnsonii 3121 and L. rhamnosus 86 significantly decreased the gene expression levels of PPARγ, C/EBPα, and aP2, which are known to control adipocyte differentiation [37] . The early stage of adipocyte differentiation is known to be regulated by PPARγ and C/EBPα, which are critical transcription factors in adipogenesis [38] . Moreover, PPARγ regulates expression of genes involved in lipid metabolism (such as aP2), thereby triggering intracellular fat accumulation [39] . Further, aP2 is a carrier protein of fatty acids which is expressed in mature adipocytes. Interestingly, mRNA expression and protein levels of aP2 are known to markedly increased on increased PPARγ gene expression, which highlights the role of PPARγ as an aP2 regulator [40] . Based on these results, our study clearly indicates that the inhibited adipogenesis and lipid accumulation effects exerted by heat-killed L. johnsonii 3121 and L. rhamnosus 86 in mouse preadipocyte cells are mediated by the suppression of key adipogenic transcription factors related to adipocyte differentiation. The datasets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request. Ethics Approval This article does not contain any studies with human or animal subjects.@story_separate@This study aimed to screen functional probiotic strains with antiobesity effects and identified L. johnsonii 3121 and L. rhamnosus 86 as potentially effective antiobesity probiotic strains. We established five steps to screen potential probiotic strains with antiobesity functions (Fig. 8) . Sixty-one novel strains were prescreened from 151 candidates for their ability to show resistance to acidic and bilecontaining environment. The functional aspects of these 61 strains were assessed in terms of their cholesterol-lowering and antioxidant activities. Based on the data regarding acid tolerance, bile tolerance, cholesterol reduction, and antioxidant activity, L. johnsonii 3121, L. rhamnosus 86, L. plantarum MA2, L. sakei 105, L. casei 911, and Leuc. mesenteroides 7 were selected for further studies, since these strains exhibited their probiotic potential by qualifying among the top 20 strains in all four parameters measured. Of the six strains, only L. johnsonii 3121 and L. rhamnosus 86 were found to be capable of lowering TG content and lipid accumulation in 3T3-L1 cells. Further, L. johnsonii 3121 and L. rhamnosus 86 could inhibit adipogenic differentiation in 3T3-L1 cells by downregulating the expression levels of adipogenic transcription factors PPARγ, C/EBPα, and aP2. Taken together, these results identify L. rhamnosus 86 and L. johnsonii 3121 as potential therapeutic agents possessing antiobesity effects. Moreover, in vivo trials are under progress in animal models of high-fat diet-induced obesity in order to further confirm their functionality as antiobesity probiotics. Funding This work was financially supported by grants funded by the Chong Kun Dang Bio and Korea University Grant.","Abnormal adipocyte growth, distinguished by an increase in cell numbers and cellular differentiation, is regarded as a major pathological characteristic of obesity. Thus, inhibition of adipogenic differentiation in adipocytes could prevent obesity. Recently, certain probiotic stains have been reported to regulate lipid metabolism in vitro and/or in vivo. In this backdrop, this study aimed to investigate basic probiotic properties and potential antiobesity characteristics of mouse 3T3-L1 preadipocytes. Six lactic acid bacteria (LAB) strains were prescreened for their cholesterol-lowering activity, antioxidant activity, and survival at low pH and in a solution containing bile salts. These six strains were investigated for antiadipogenic activity by employing 3T3-L1 mouse preadipocytes. 3T3-L1 cells were treated with selected strains during the differentiation process. Lactobacillus johnsonii 3121 and Lactobacillus rhamnosus 86 were found to be more capable of reducing triglyceride and lipid accumulation, as compared to control group, which are fully differentiated 3T3-L1 adipocytes. These strains also inhibited adipocyte differentiation by downregulating the adipogenic transcription factor in 3T3-L1 adipocytes. Taken together, these results indicate that L. johnsonni 3121 and L. rhamnosus 86 could potentially act as probiotic bacteria and prevent fat accumulation by regulating adipogenesis-related markers."
"Coronaviruses (CoVs) belong to RNA viruses and infect different vertebrates, such as mammalian and avian species (Durham et al., 1979; Law et al., 2005) . As an important member of CoVs, porcine epidemic diarrhea virus (PEDV) can cause an acute enteritis disease, which is characterized by vomiting, diarrhea and dehydration, leading to high mortality in newborn piglets (Song and Park, 2012) . The genome of PEDV is about 28 kb in size and composed of at least six open reading frames (ORFs) including ORF1a, ORF1b, spike (S), envelope (E), membrane (M), and nucleocapsid (N) (Wang et al., 2019) . Among them, S protein is one of the most important structural protein due to its involvement in multiple functions, such as virus attachment, receptor binding, virus-cell membrane fusion, and inducing the production of virus neutralizing antibodies in the host (Vaughn et al., 1995; Vennema et al., 1998; Vijgen et al., 2005; Hasoksuz et al., 2007; Lorusso et al., 2008) . Therefore, it is very necessary to continuously monitor the genetic alterations of PEDV S gene in the field (Park et al., 2014; Zhao et al., 2017) . Since its first appearance in Europe in 1971, PEDV has caused considerable economic losses, especially in Asia (Pensaert and de Bouck, 1978; Sun et al., 2016) . Since 2010, PEDV variant strain has emerged in Asia, which can infect the pigs of all ages but most severely in suckling pigs, reaching up to 95% mortality (Bi et al., 2012; Li et al., 2012; Pan et al., 2012) . In 2013, the first outbreak of PEDV in the United States (US) was reported, and then spread to Canada and Mexico (Stevenson et al., 2013; Chen et al., 2014; Pasick et al., 2014) . Phylogenetic analyses showed the emergent US PEDV strains are most closely related to a Chinese strain detected in 2012 (Huang et al., 2013) . From a broad perspective, phylogenetic analysis based on S gene can divide PEDVs into two major genotypes in the US: the original non-S-INDEL (S-INDEL standing for insertions/deletions in the S gene) and the variant S-INDEL (Vlasova et al., 2014; Lin et al., 2016) . PEDV strains which were first identified in the US in 2013 with high virulence are classified as the non-S INDEL strains (Stevenson et al., 2013) . The new variant strains which were reported in the US in 2014 with relatively milder virulence are termed as S-INDEL strains . In addition, PEDVs can be divided into genome 1 (G1) and genome 2 (G2) clades and further divided into four subgroups: G1a, G1b, G2a, and G2b . Despite they have relatively conserved neutralizing epitopes, commercial vaccines based on CV777 strains cannot provide complete protection in piglets against variant PEDV infections which are currently circulating in China and the US (Zhu et al., 2019) . Monitoring the genetic alterations in the S gene of PEDV could provide more clues for understanding the epidemic characteristics of PEDV and adjusting the immunization program of PED in pig farms. Henan province, located in the center of China, is the largest pig-producing province in China. Since 2010, severe diarrhea outbreaks caused by variant PEDV frequently occurs in this area. In our routine epidemiological investigation, 52 sequences of the full-length S genes and 9 complete genomes of PEDV have been determined, indicating the complexity of PEDV in Henan (Su et al., 2016) . In this study, a PEDV strain with novel insertion in its S gene (called HNAY) was successfully isolated from an intensive farm in Henan in 2016. We determined the genetic relationships, variant characteristics, potential recombination features, and the clinical characterization of HNAY. Our findings could provide valuable information for PED outbreaks in Central china and contribute to prevent and control of PED.@story_separate@Intestine and fecal samples were collected from pig farms in Henan, China during 2016-2018 and stored at -80 • C. These samples came from piglets with clinical signs including vomiting, and severe diarrhea. Total RNA was extracted from the small intestine samples using TaKaRa MiniBEST Viral RNA/DNA Extraction Kit Ver.5.0 (TaKaRa, Dalian, China). Viral cDNA was generated via reverse transcription using PrimeScript reverse transcriptase (TaKaRa, Dalian, China) according to the manufacturer's instructions. The samples were examined for PEDV by RT-PCR (Li et al., 2018) . Three samples tested PEDV positive were sequenced for complete genome as described in previous study (Wang et al., 2013) . Purified PCR products were cloned into PMD-19T vector and recombinant DNA clones were sequenced by the BigDye Terminator v3.1 Cycle Sequencing kit (Biotech Company, China). Complete genome sequence of PEDV and their S gene were aligned using ClustalW in DNASTAR7.1. Phylogenetic tree of PEDV was constructed using neighbor-joining (NJ) method with 1,000 bootstrap replicates in MEGA7. The sequences of reference strains are downloaded from GenBank database ( Table 1) . Potential recombination in the genome of PEDV HNAY were assessed by the Recombination Detection Program v4 (RDP4) which was supported by ≥6 programs. According to the crystal structure of S protein of PEDV USA/Colorado/2013 available in the PDB database (accession code 6VV5) as the input model, the three-dimensional structure of the S protein of HNAY was generated via SWISS-MODEL Homology Modeling server and figures were made with PymoL (Version 1.0 Schrödinger, LLC; Wrapp and McLellan, 2019) . Vero cells were used for viral isolation as previously described (Oka et al., 2014) . Cells were inoculated with sterile supernatants of prepared samples, maintained in Dulbecco's modified Eagle's medium (DMEM; HyClone) with 10 µg/mL trypsin (Life Technologies) and monitored daily for cytopathic effect (CPE). All the PEDV isolates were passed in Vero cells for 10 generations, and the 10th-generation of plaque purified viruses were chosen for the following experiments.Then, the cells were fixed with anhydrous ethanol when 70% of cells showed CPE. Finally, an immunofluorescence assay (IFA) was performed with a mouse anti-N protein monoclonal antibody diluted 1:1,000, and with a fluorescence isothiocyanate (FITC)-conjugated goat anti-mouse secondary antibody (1:200 dilution), 4' ,6-diamidino-2-phenylindole (DAPI) was used for nucleic acids staining. The plates were examined using a fluorescence microscope. To determine the growth curve of PEDV strains of HNAY, HB, and HNXX, viruses were inoculated onto cell monolayers at MOI of 0.1. After adsorption at 37 • C for 1 h, the cells were maintained with DMEM containing 10 µg/mL trypsin at 37 • C with 5% CO 2 . Cells were collected for virus titration every 12 h post infection. After centrifugation, the supernatants were collected and the median tissue culture infective dose per milliliter (TCID 50 /mL) was determined with a microtitration infection assay described by Reed and Muench (1938) . Virus titration at different time points was performed in triplicates. To determine the virulence of PEDV isolates, 42 two-day-old piglets, which were confirmed negative for PEDV and other common viral pathogens in pigs by PCR or RT-PCR, were chosen for challenge experiment. Then they were randomized into four groups by weight with 10 pigs in each group, and housed in separate rooms. The infection groups were orally challenged with 0.5 mL of the 10th passage of plaque purified PEDV HNAY, HB, and HNXX, respectively, at 10 5 TCID 50 /mL. The 10 piglets of control group were inoculated with equal volume of medium. All the animals were monitored daily for clinical signs. Rectal swabs were collected for scoring fecal denseness according to previous studies (Lin et al., 2015) . The fecal viral RNA loads were quantified by real-time RT-qPCR (Su et al., 2018) . The animal experiment was approved by Institutional Animal Care and Use Committee of Henan Academy of Agriculture Science (LLSC100085). Intestine and other major organs were collected and fixed for pathological examination. Samples of duodenum, jejunum, ileum, caecum, colon, rectum, and mesenteric lymph nodes were collected, and fixed in formalin. After 48 h, the jejunum was stained with haematoxylin and eosin (H&E) and the villous height-to-crypt depth (VH:CD) ratios were calculated according to previous study (Jung et al., 2014) . Serial sections of ileums were evaluated for viral antigen by immunohistochemistry (IHC) using a mouse anti-N protein monoclonal antibody and biotinylated goat anti-mouse antibody as the secondary antibody with 3,3 -diaminobenzidine (DAB) as the chromogen (Lin et al., 2011) . All data are expressed as means ± standard deviations (SD) and were analyzed with the GraphPad Prism software (GraphPad Software Inc.). Statistical analysis was performed using one-way ANOVA or two-way ANOVA followed by t-test. Differences were considered statistically significant at P < 0.05. To determine causative agent associated with diarrhea in piglets, total RNA of clinical samples were extracted and subjected to RT-PCR. PEDV positive samples were processed and used for virus isolation on Vero cell as described previously (Chen et al., 2014) . CPEs were observed on cells inoculated with PEDV positive samples, characterized by the rounding up, enlarging and detachment of cells as well as the formation of syncytia. In the end, three PEDV strains were successfully isolated, named HNAY, HNXX, and HB, respectively. The IFA results showed that PEDV specific fluorescence was observed in the inoculated cells, but not in the non-infected cells ( Figure 1A) . The viral titres of three PEDV isolates were determined in Vero cells. The titers of HNXX and HB reached the maximum (10 4.6 TCID 50 /mL and 10 5.3 TCID 50 /mL) at 24 hpi, whereas the peak virus titer of HNAY only reached 10 3.8 TCID 50 /mL at 36 hpi ( Figure 1B ). The genome of the isolates were sequenced and submitted to GenBank (accession numbers MT338517. (Table 4) . Interestingly, sequence analysis showed that HNAY strain had a novel 21-nt insertion in its S1 gene at 1,063-1,083 nt (Figure 2A) . Besides, the inserted sequence (AGAAGAACAAAUCCAGAGCCA) were the same as the sequence of its N gene at 785-805 nt ( Figure 2B) . Insertion of the deduced 7 aa was located at the 358-364 aa of PEDV S1 protein ( Figure 2C) . Besides, HNAY S protein structure was predicted by SWISS-MODEL according to the structure of PEDV USA/Colorado/2013 strain in PDB database (accession code 6VV5; Figure 3) . Structure prediction showed that the 7-aa insertion might be located at the flexible loop (Leu354 to Ala363) at the apex of the trimer of PEDV S1A domain (Wrapp and McLellan, 2019) . To date, three neutralizing epitopes of the PEDV S protein have been reported, including core neutralizing epitope (COE), SS2 and SS6 (Chiou et al., 2017) . Multiple alignments revealed that similar to other variant strains, compared to CV777 strain, HNAY S protein possessed nine aa substitutions (A517S, S523G, V527I, T549S, G594S, A605E, L612F, I635V, and Y766S) in the COE and one amino acid substitution (Y766S) in the SS6 (Figure 4) . Compared with CH/HNAY/2015 strain which was isolated in the same region as HNAY, two additional aa substitutions (D520G and H521Y) in the COE were observed in the HNAY strain. In addition to these shared mutations, HNAY strain have two unique mutations (T500A and H521Y) in the COE that were absent in other PEDV variant strains and CV777-based vaccine strains. The phylogenetic tree based on the sequences of 3 PEDV isolates along with 33 PEDV reference strains revealed that they can be clustered into two groups, classical G1 and variant G2 (Figure 5A ). G1 contains eight isolates: CV777, SM98, and DR13 isolated from Korea, and SD-M, LZC, CHM, and JS2008 from China. G2 includes many virulent strains from Japan, Korea, China, and the US. HNAY, HNXX, and HB were grouped FIGURE 3 | Structure prediction of S protein of PEDV HNAY in the prefusion conformation. The primary sequence of PEDV S protein can be divided into S1 and S2. The S1 region can be further divided into S10, S1A, S1B, and S1CD (in red, admiral blue, yellow, and arctic blue, respectively). The 7-aa insertion was shown in purple within S1A domain. Viewing the trimeric PEDV HNAY S protein from the membrane distal apex and a 90 • view based on the crystal structure of S protein of USA/Colorado/2013. S10, S1A, S1B, S1CD, and S2 were shown in red, admiral blue, yellow, and arctic blue, respectively, and the 7-AA insertion was in pink in the crystal structure model. in subgroup G2 as most of other isolates from China in the past 10 years. Furthermore, phylogenetic analysis of complete S genes delineated G2 group into 2a, 2b, and S-INDEL subgroups. HNXX and HB belongs to G2a and G2b, respectively, which was consistent with the phylogenetic analysis based on their complete genomes. Interestingly, HNAY strain belongs to a separate branch other than G2a and G2b ( Figure 5B) . To further analyze the association between PEDV HNAY and reference strains, a recombination analysis was performed by using RDP4 software (Martin et al., 2015) . As shown in Figure 6 , PEDV HNAY might arise by the recombination of HNZZ47 and GDS28 strains, which was supported by 6 programs (Figure 6) . The major parent strain of the recombination might be HNZZ47 isolated from Henan, May 2016; the minor parent strain was GDS28 which was isolated in Guangdong, December 2012. Furthermore, we also identified potential breakpoints for recombination in the ORF1b and S region (nt 17,205-21,832) . This suggests that HNAY might be derived from a natural recombination between two Chinese variant PEDV strains. To investigate the virulence of PEDV HNAY in piglets in comparison with that of HNXX and HB, suckling piglets were orally infected with the three PEDV strains. Clinical observation showed that piglets in challenge groups exhibited lethargy, loss of appetite, diarrhea, dehydration and vomiting at 12-20 hpi. The control pigs remained healthy. The challenged piglets began to die at 1 day post infection (dpi), and all piglets in the HNAY-, HB-and HNXX-challenged groups died within 2, 3, and 4 dpi, respectively ( Figure 7A) . From fecal score analysis, there was no significant difference between piglets in three groups ( Figure 7B ). Necropsy examinations were performed immediately after the death of the infected piglets. All the infected piglets displayed typical lesions of PED. The wall of the small intestine was thin and transparent. The small intestine and stomach were, respectively, distended and filled with curdled and undigested milk. By contrast, the intestinal organs of control piglets appeared grossly normal. Furthermore, viral RNA in fecal samples were tested positive for PEDV in challenged groups (2-6log 10 genomic equivalents/mL). HNXX and HB reached peak at 1 dpi, but HNAY reached peak at 2 dpi ( Figure 7C) . Microscopic examination of jejunum revealed moderate to severe, extensive, atrophic enteritis in three PEDV isolates infected piglets (Figure 7D) . The jejunum VH:CD ratios ranged from 1.14 to 2.49 in PEDVs infected piglets. The VH:CD ratios in the three PEDVs infected piglets were lower when compared with that of non-infected pigs, but there was no obvious difference between three PEDVs infected groups ( Figure 7E ). In addition, PEDV antigens were detected in the duodenum, jejunum, ileum, caecum, colon, rectum and MLNs of HNXX-, HB-, and HNAY-infected piglets. IHC results showed that PEDV antigens were mainly distributed in the villus epithelial cells. Specifically, viral antigen was expressed in the colon and cecum but mainly distributed in the mucosa and submucosa of the HNXX-infected piglets; viral antigen of HB-infected piglets was expressed in the mucosal epithelium of each segment of the intestine. While the tissues from the piglets in the HNAY-infected group showed remarkable levels of viral antigen in the intestinal glands and mucosal epithelium of the jejunum, and the mucosal layer of the colon and rectum (Figure 8) . The results of PEDV challenge test indicate that HNAY displayed higher pathogenicity compared with two other clinical isolates. PED is one of the most critical diarrheal diseases threatening the global pig industry. In 2010, a new variant PEDV (G2 genotype) first emerged in Central China and spread rapidly throughout the country, resulting in big economic losses (Li et al., 2012) . Subsequently, this type of virus spread to many countries in Asia, America and Europe (Peng et al., 2017) . In 2014, another FIGURE 5 | Phylogenetic analysis of PEDV complete genome and S genes. (A) Multiple sequence alignments were generated with Clustal X and complete genome phylogenetic tree was constructed using neighbor joining (NJ) method and supported with a bootstrap test of 1,000 replicates in MEGA7. ""•"" indicates the PEDV strains isolated in this study. (B) S gene phylogenetic tree was constructed by using the same method as above. ""•"" indicates the PEDV strains isolated in this study. Scale bars indicate nucleotide substitutions per site. FIGURE 6 | Recombination analysis of PEDV HNAY with indicated PEDV strains. The result was described using RDP method which was supported by ≥6 programs to further characterize the potential recombination events. The black arrow indicates the regions where recombination event may occur. genotype of PEDV, designated as S-INDEL, was first detected in the USA . Since then, more and more variant PEDV strains, such as those with a large deletion in the S gene and deletions in the ORF1a gene, have been discovered worldwide (Lin et al., 2016) . The S glycoprotein of coronaviruses contains two domains called S1 and S2. S1 domain contributes to receptor binding and S2 domain is thought to be associated with direct fusion between the viral and cellular membranes (Walls et al., 2016) . Similar to other coronavirus S proteins, the PEDV S protein plays a critical role in viral entry and production of Oka et al., 2014; Vlasova et al., 2014) . Interestingly, HNAY was identified as a novel PEDV strain with 7-aa insertion (358-364 aa) in S1A domain (233-501 aa), and the inserted sequence was identical with the sequence of 785-805 nt in N gene. Although HNAY had higher sequence identity with G2a and G2b strains, phylogenetic analysis revealed that HNAY belonged to a single branch instead of G1, G2 or S-INDEL. In addition, a recombination event was identified in the genome of HNAY at 27,105-28,059 nt, where PEDV HNZZ47 and GDS28 were major and minor parents, respectively. Currently, none of clinically isolated PEDV strain has been reported to have multiple amino acid insertions in the S1A region. The prevalence of this type of variants in pig farms needs further epidemiological investigation. Mutations in the S1 region of PEDV have been shown to be responsible for the alternation of viral tropism and pathogenicity in pigs (Gallagher and Buchmeier, 2001; Sato et al., 2011; Lee, 2015) . In this study, HNAY-infected Vero cells were obviously characterized by cell fusion and syncytial formation, but viral titre was lower compared to that of the other two PEDV strains. Animal experiments showed that pigs that infected by HNAY showed most severe disease compared to those infected by HNXX and HB, as all of HNAY-infected piglets died within 2 dpi. Moreover, a partial of the PEDV N antigen was also found in caecum muscularis of HNAY-infected pigs, but not in other virus strains infected groups. Considering the particularity of this insertion position, further studies are required to decipher its role in receptor binding and virulence in the PEDV strain. Recently, the atomic-resolution structure of prefusion PEDV spike protein has been resolved (Wrapp and McLellan, 2019) . Similar to other class I fusion proteins in the prefusion conformation, PEDV S1 subunit is made up of a series of β-sheets, whereas the S2 subunit is almost composed of a series of discontinuous α-helices (Wrapp and McLellan, 2019) . Interestingly, the 7-aa insertion happens to be in the flexible loop at the apex of the trimer (354-363 aa). However, this region was not clearly resolved in structure model of PEDV S protein (Wrapp and McLellan, 2019) . Therefore, we predicted that this region may be an ideal insertion site for foreign proteins or peptides, which could provide clues for constructing recombinant PEDV strains with molecular markers in S1 domain by reverse genetics technology. Whether the insertion in this region affects the infectious characteristics and pathogenicity of PEDV needs further study. The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found in the article/ supplementary material. The animal study was reviewed and approved by the Animal Experiment Committee of Henan Academy of Agricultural Sciences. DL, YL, and GZ wrote the manuscript and conceived and initiated the study. DL, YL, and YC devised the experimental methods. WJ and HF curated the data. JW and YZ performed animal experiments. DL prepared the original manuscript draft. YL and GZ reviewed the manuscript and edited it. All authors read and approved the final manuscript. @story_separate@In this study, a novel 7-aa insertion in the S1 and a recombination event were detected in PEDV HNAY strain.This insertion might affect the structure of S protein, thereby directly or indirectly altering viral tropism and pathogenicity, resulting in consistent infection in pigs. Therefore, further research is needed to determine the impact of this insertion on the pathogenicity of HNAY strain. In addition, how such PEDV variants emerged and evolved in the field needs further investigations, which would significantly contribute to the prevention and control of PED outbreaks worldwide.","Porcine epidemic diarrhea virus (PEDV) is the major pathogen that causes diarrhea and high mortality in newborn piglets with devastating impact to the pig industry. Recombination and mutation are the main driving forces of viral evolution and genetic diversity of PEDV. In 2016, an outbreak of diarrhea in piglets occurred in an intensive pig farm in Central China. A novel PEDV isolate (called HNAY) was successfully isolated from clinical samples. Sequence analysis and alignment showed that HNAY possessed 21-nucleotide (nt) insertion in its S1 gene, which has never been reported in other PEDV isolates. Moreover, the sequence of the insertion was identical with the sequence fragment in PEDV N gene. Notably, the HNAY strain exhibited two unique mutations (T500A and L521Y) in the neutralizing epitopes of the S1 protein that were different from those of other PEDV variant strains and CV777-based vaccine strains. Additionally, PEDV HNAY might be derived from a natural recombination between two Chinese variant PEDV strains. Animal experiments demonstrated that HNAY displayed higher pathogenicity compared with two other clinical isolates. This study lays the foundation for better understanding of the genetic evolution and molecular pathogenesis of PEDV."
"Several advances have been made in the eld of mathematical modeling in studying the behavior of certain dynamical systems whose state evolves with time [1, 10, 23, 38, 43, 44, 49, 51, 54, 56, 57] . Most of these dynamical processes in nature are far from equilibrium and so using stationary distribution to describe and analyze the evolution of such processes has a great limitation [8, 9, 30, 55] . Although studying the evolution of such random dynamical systems using time-dependent probability density function is challenging, signicant analysis and estimates about the process can be deduced from such study. The exact solutions in terms of probability density function of dynamical systems can only be obtained for a restricted class of dynamical systems [41, 12, 13, 21, 31] . Apart from Fokker-Planck equation (FPE), a partial dierential equation that describes the time evolution of probability density function, there are other methods such as the moment or cumulant equations approach [17] that can be used to analyze nonlinear systems under random perturbations. Because of the complexity of solving partial dierential equations, many approximate methods have been developed numerically to solve the FPE equation for situations far from equilibrium. A simple thermodynamically consistent matrix numerical method (MNM) is developed by Holubec et al. [26] for solving over-damped FPEs with time-dependent coecients. Paola at al. [17] proposed an approximate method called the Taylor moments for the probabilistic description of response of nonlinear system driven by a stochastic process. Other methods such as the stochastic linearization (SL) method [53] , the equivalent non-linear equations method (ENLE) [14] , the moment dierential equation method (MDE) Monte Carlo simulation using a non-Gaussian closure approximation [40] , the path integral approach, perturbation technique and Galerkin method [35, 32, 61] have been developed for approximating the time-dependent probability density of some general rst-order and second-order non-linear stochastic systems. In this work, we develop the time-dependent probability density function for the number of infections of certain diseases satisfying a particular stochastic SIS epidemic model. The state transition probability density function for the dynamic process is governed by the FPE equation [19, 59] . (2.2) The model (2.1) has been studied extensively by Brauer et al. [11] , Hethcote and Yorke [25] , Lajmanovich and Yorke [33] and Nold [45] . Many factors such as pneumonia seasonality, mobility, testing rates, mask use per capital weather [27] , social behavior, strain-specic factors [42] , and public health intervention [34] can act as external uctuations aecting the contact/transmission rate of the disease. For this reason, we assume the contact/transmission rate β of the disease is aected by environmental perturbations, such as stated above, changing the infection transmission rate β to the form where each infected individual makes βdt infectious contacts with each other in the interval [t, t+dt), W (t) is a standard Wiener process on a ltered probability space (Ω, F t , (F t ) t≥0 , P), the ltration function (F t ) t≥0 is right-continuous and each F t with t ≥ 0 contains all P-null sets in F t . By substituting (2.3) into (2.1), we reduce the deterministic epidemic model (2.1) to the Stratonovich stochastic where • denotes the Stratonovich integral [2] . We used the Stratonovich calculus instead of the Itô calculus following the arguments made in [7, 37] . We also assume the initial process (S 0 , I 0 ) is F t0 measurable and independent of W (t) − W (t 0 ). The solution of (2.4) with Itô calculus has been studied extensively by Gray [22] . In their work, Dalal et al. [16] showed that the introduction of stochastic noise can stabilize system that is unstable. In this work, we are interested in studying how the system behaves in the presence of noise in the transmission rate of the disease. This behavior is studied by analyzing the time-dependent probability density function of the process S(t) and I(t). The stochastic dierential equation has a unique positive solution [22, 39, 47, 60] in the feasible region for all t ≥ 0 with probability one. The model governing I in (2.4) reduces to the Itô form (2.6) (2.7) The number R 0 is referred to the reproduction number for (2.1). This is the average number of infection cases produced by an infectious individual when introduced into a completely susceptible population. The number R 0 is the stochastic version of R 0 for the model (2.6). It was shown in Méndez et al. [39] and Otunuga [48] that the boundaries I = 0 and I = N of (2.6) are unattainable at all times if R 0 > 1, regardless of the noise intensity. Following a similar Theorem in [22] , we show in Theorem 1 that the disease will die out on the long run in the presence of noise if R 0 < 1. Theorem 1. For any given initial condition I 0 ∈ (0, N ), the solution I(t) of the stochastic dierential equation (2.6) tends to zero exponentially almost surely if R 0 < 1. Proof. It follows from (2.6) that (N − I(s)) I(s)dW (s), (N − I(s)) I(s)dW (s), The result follows from the fact that lim sup using the large number theorem for martingales [24] . We see in Theorem 1 that replacing the condition R 0 < 1 with the condition R 0 < 1 for the disease to die out exponentially almost surely is also valid. We note here that epidemic advances can still grow initially, leading to transient A numerical result is derived later in Figure 3 of Section 4 to conrm Theorem 1 by showing that the stationary probability distribution of I concentrates entirely on zero if R 0 < 1 (which also implies R 0 < 1). Likewise, it can be shown that the stochastic dierential equation (3.2) has a unique stationary distribution if R 0 > 1. The proof of this is similar to the proof given in Theorem 6.2 of the work of Gray et al. [22] , so we omit the proof here. We give the closed form representation of the time-dependent and stationary probability density function for I in the next section and conrm that these distributions exist if It was shown in Otunuga [48] that the solution (S(t), I(t)) of the system (2.4) is obtained as (2.10) Let p I (I|t, I 0 ) be the probability density for the process I satisfying (2.6) at time t given initial point I 0 . In his work, Otunuga [48] derived the probability density function p I (I|t, I 0 ) for the specic case where the resulting Fokker Planck dierential equation for p I (I|t, I 0 ) has only discrete eigen-values r ≡ r n and λ satisfying is a non-negative integer. In this work, we extend the work of Otunuga [48] to include both discrete and continuous eigen-values,. we reduce (2.4) to the form (3.2) By setting S = 1 − I, the stochastic dierential equation governing I in (3.2) reduces to the Stratonovich stochastic dierential equation The Itô equivalent of (3.3) is given by (3.4) Using the change of state variable in (3.4) , we obtain the Itô stochastic dierential equation whereĀ andC are dened in (2.10). Let p X (x|t, x 0 ) be the probability density function for the process x satisfying (3.6) at time t given initial point x 0 , and let p s X (x) denotes the corresponding limiting or stationary distribution. We give the closed form expression for p s X (x) and p X (x|t, x 0 ) in the following theorem. Theorem 2. Assume x 0 > 0 andĀ + 1 > 0. Then the solution x(t) satisfying (3.6) has a unique stationary and time-dependent probability density function p s X (x) and p X (x|t, x 0 ), respectively, obtained as n!α n Γ(α n + n + 1) e −rnt (xx 0 ) −n L αn n (x 0 )L αn n (x) for n = 0, 1, 2, · · · M,Ā for n = 0, 1, 2, · · · M,Ā (a) b = a(a+1)(a+2) · · · (a+b) is the Pochhammer symbol [5] , and WhittakerW k,θ (x) is the Whittaker function [46] . Proof. It follows from (3.6) and the Fokker Planck equation that p X (x|t, with boundary condition We assume a solution of the form where r ≥ 0 is a constant. The stationary density function p s X (x) corresponding to (3.7) is obtained as provided thatĀ We convert (3.7)-(3.8) to Sturm-Liouville equation by substituting ψ(x|x 0 ) = h(x)p s X (x). By substituting (3.10) into (3.12), we see that the dierential equation in (3.12) reduces to (3.13) Using the transformation (3.14) we further reduce (3.13) into a dierential equation of the form (3.16) The dierential equation (3.15 ) is the well known Whittaker dierential equation (see Section 13.14 of [46] ) with solution where B 1 , B 2 are constants and WhittakerM θ,v (x); WhittakerW θ,v (x) are the Whittaker functions [46, 5] . It now follows from (3.14) that the function h(x) satisfying (3.12) is obtained as Using relations 6.9.2 and 6.9.4 in Bateman [5] , the Sturm-Liousville equation (3.12) has M + 1 eigenvalues for n = 0, 1, 2, · · · M,Ā with corresponding eigenfunction where α n =Ā + 1 − 2n > 0, (3.21) L αn n (x) is the Laguerre polynomial of degree n, and C n is a normalizing factor obtained as C n = n!α n Γ(Ā + 1) Γ(α n + n + 1) . Several advances have been made in the field of mathematical modeling in studying the behavior of certain dynamical systems whose state evolves with time [1, 10, 23, 38, 43, 44, 49, 51, 54, 56, 57] . Most of these dynamical processes in nature are far from equilibrium and so using stationary distribution to describe and analyze the evolution of such processes has a great limitation [8, 9, 30, 55] . Although studying the evolution of such random dynamical systems using time-dependent probability density function is challenging, significant analysis and estimates about the process can be deduced from such study. The exact solutions in terms of probability density function of dynamical systems can only be obtained for a restricted class of dynamical systems [12, 13, 21, 31, 41] . Apart from Fokker-Planck equation (FPE), a partial differential equation that describes the time evolution of probability density function, there are other methods such as the moment or cumulant equations approach [17] that can be used to analyze the distribution of nonlinear systems under random perturbations. Because of the complexity of solving partial differential equations, many approximate methods have been developed numerically to solve the FPE equation for situations far from equilibrium. A simple thermodynamically consistent matrix numerical method (MNM) is E-mail address: otunuga@marshall.edu developed by Holubec et al. [26] for solving over-damped FPEs with time-dependent coefficients. Paola at al. [17] proposed an approximate method called the Taylor moments for the probabilistic description of response of nonlinear system driven by a stochastic process. Other methods such as the stochastic linearization (SL) method [53] , the equivalent non-linear equations method (ENLE) [14] , the moment differential equation method (MDE) Monte Carlo simulation using a non-Gaussian closure approximation [40] , the path integral approach, perturbation technique and Galerkin method [32, 35, 60] have been developed for approximating the time-dependent probability density of some general first-order and second-order non-linear stochastic systems. In this work, we develop the time-dependent probability density function for the number of infections of certain diseases satisfying a particular stochastic SIS epidemic model. The state transition probability density function for the dynamic process is governed by the FPE equation [19, 58] . The result obtained is used to analyze the distribution of the aggregate daily infection count of COVID-19 cases for the United States collected from the Center of Disease Control and Prevention (CDC) for the period: 01/22/2020-03/23/2021. The organization of the paper is as follows. In Section 2 , we formulate a stochastic differential equation ( SDE is also discussed. The threshold under which the disease dies out using the SDE model is obtained and analyzed. In Section 3 , we derive the closed form time-dependent probability density function for the number of infection at a given time t for the stochastic SIS model. Properties of the distribution, namely, mean, variance, skewness, kurtosis functions are also derived in Section 3 . Special cases of the distribution are also discussed in this section. Numerical results are carried out in Section 4 to verify our claim. Discussion and summary of the work done are presented in Section 5 .@story_separate@The Sturm-Liouville equation also has continuous range of eigenvalue where U(a, b; x) is the Kummer function [46] , i is the imaginary unit, and G(η) is a constant derived using the orthogonal condition where δ(.) is the Dirac delta function. According to Szmytkowski [52] , the functions W κ,iθ (z) ≡ WhittakerW κ, iθ (z) and W κ,iθ (z) ≡ WhittakerW κ, iθ (z), with θ , θ > 0, are orthogonal on the positive real semi-axis with the weight It follows immediately from (3.25) and (3.26) that The principal solution p X (x|t, x 0 ) is obtained as (3.27) Remark 1. We note here that the distribution p s X (x) is the Gamma distribution with shape parameterĀ. Since r 0 = 0 and r(η) > 0, it follows from (3.27) that Using the fact that the distribution p s X (x) is the Gamma distribution, it follows immediately that the limiting mean, mode, variance, skewness, kurtosis function respectively. Using the following integrals regarding Laguerre polynomial (these follows from the Chu-Vandermonde identities (see [46] Section 16.1.1)), where (a) n is the Pochhammer's symbol, it can be shown that p X (x|t, x 0 ) > 0 is the Hypergeometric regularized function [46] . Remark 2. In order to conrm the validity of the solution (3.27), we show that the solution p X (x|t, x 0 ) corresponds to an initial value δ(x − x 0 ). That is, for We use (3.29) and equation (44) in Becker [6]  Let p I (I|t, I 0 ) and p S (S|t, S 0 ) be the time-dependent probability density function for the number of infected and susceptible individuals at time t given initial points I 0 and S 0 , respectively. Also, let and p s I (I) be the corresponding stationary density function. We give the closed form expression for p I (I|t, I 0 ), p S (S|t, S 0 ), and p s I (I) in the following theorem. Then the solution (I(t), S(t)) given in (2.8) and satisfying (2.4) has a unique stationary and timedependent probability density function p s I (I), (p I (I|t, I 0 ), p S (S|t, S 0 )), respectively, obtained as Proof. Using the transformation in (3.5), we obtain the probability stationary function p s I (I) and the density function p I (I|t, I 0 ) of the number of infection I at a given time time t with initial condition I 0 as and follows that the density probability function p S (S|t, S 0 ) of the number of susceptible individuals at time t 0 with initial condition S 0 can be obtained as (3.34) The cummulative density function, P s (I) for the distribution p s I (I) in (3.30) is obtained as where γ(a, z) = z 0 t a−1 e −t dt is the lower incomplete gamma distribution. The mean and variance, denoted µ s and σ 2 s , respectively, of the distribution is the upper incomplete gamma function and U(a; b; z) is the Kummer/conuent hypergeometric function [46] . We see later in (3.40 ) that these results correspond to the limiting mean and variance of the distribution p I (I|t, I 0 ). It follows from (3.35) that the median is the numberm that satises the equation The following theorem shows interval where the stationary density function is decreasing and increasing. Theorem 4. Dene Proof. We note that dp s > 0 on (s − , s + ) and dp s The condition R 0 = 1 is equivalent toĀ = 0. For this case, p s I (I) reduces to If {I 1 , I 2 , · · · , I M } are samples of M independent identically distributed random variables, the maximum likelihood estimateĈ ofC iŝ The j-th moment, denoted µ (j) using identities (13.14.5), (13.6.19) and (13.16.6) in [46] . The mean µ (1) variance σ 2 , skewness sk I (t) = E I − µ (1)  where α 0 is dened in (3.21) and U (a; b; z) is the Kummer/Congruent Hypergeometric function [46] . It follows immediately from (3.39) that lim t→∞ µ (1) where Γ(a, z) = ∞ z t a−1 e −t dt is the incomplete gamma function. The values obtained in (3.40) are the mean, variance, skewness, and kurtosis, respectively, of the stationary density function p s I (I) in (3.30) . This is conrmed numerically in Figure 9 . In this section, we briey discuss few interesting cases of the expression for p I (I|t, I 0 ) given in (3.30) involving particular values for the parameters µ, γ, β, and σ. 3.3.1. Case for small µ + γ,C ≈ 0 IfC ≈ 0, then p I (I|t, I 0 ) is approximately with p s The constant E = µ + γ is called the harvesting eort of the system (2.4). It follows from (3.11) that 0 < µ + γ < β − σ 2 /2. For large E = µ + γ so that µ + γ → β − σ 2 /2, it follows from (2.8) that I(t) → 0. That is, large value of µ + γ leads the infected population to extinct. Also, this condition is equivalent toĀ → 0 so that p s N −I and the probability density function p I (I|t, I 0 ) reduces to that in (3.30) .This is veried numerically in Figure 4 . As the noise intensity in the transmission rate of disease increases (that is, as σ → ∞), we see thatĀ → −1,C → 0 and the probability distribution P (I|t, I 0 ) converges to ∞ as I → 0 + and I → N − . This eect is shown numerically in  We apply the distribution using published and assumed parameters. According to recent survey conducted by CDC 1 on people with mild COVID-19 cases, one-third did not return to normal health within two to three weeks of testing positive, and recovery takes six weeks or more for those with severe cases. For this reason, we set γ to be in the range [  We note from (3.1) that the time-dependent probability density function p I (I|t, I 0 ) reduces to p I (I|t, I 0 ) if the population size is converted to fractions, that is, if N = 1. For the rest of the numerical analysis in this subsection, we set N = 1. In order to verify the correctness of the density function p I (I|t, I 0 ) and the stationary density function p s I (I) obtained in (3.30), we rst discretize the stochastic model (3.4) using the Milstein scheme [20] as follows: , are independent standard normal variable, t j = j∆t, ∆t = 1/10, j = 1, 2, · · · , N, for sample size N , l = 1, 2, · · · , L for L simulations. Also, we observe that as β increases, the stationary density function shifts concentration to the right. The concentration moves closer to I * = N = 1 as β grows larger. This is because as the transmission rate increases, we expect the number of infection to increase until everyone in the population becomes infected. This can be conrmed analytically using (3.30). Figure 3 : Stationary density function p I (I, ) for the case where R 0 → 1 + and R 0 → 1 + , respectively. As shown in Theorem 1, the disease will die out on the long run if R 0 < 1 (implying R 0 < 1 also). Figure 3(a) and (b) show the behavior of the distribution as disease dies out in the population using parameters µ = 1 80.3×365 ,γ = 1/7, σ = 0.1 and varying β so that R 0 → 1 + in 3(a) and R 0 → 1 + in 3(b). The result shows that on the long run, the density function of I converges to the Dirac delta function δ(I) as R 0 → 1 + . It follows from condition (3.11) that 0 < γ < β − µ. Figure 4 (a) , and σ = 0.3 in Figure 4 (b) , respectively. We see here that as γ increases to β −µ from the left, the distribution shifts concentration to the left until it concentrates entirely on 0. This shows that the disease dies out as γ → β − µ. We also see the eect of large noise in the system as γ increases. We see that the distribution becomes taller and narrower in the presence of small noise, and atter and wider in the presence of large noise. In Figure 4 (c), we see that the stationary distribution p s I (I) concentrates more on the nal size of the epidemic as the recovery rate decreases to zero. This analysis shows that the disease dies out as the recovery rate γ reaches the threshold β − µ. The number of infected reaches maximum as the number of those who recovered declines to zero. Table 1 with β = 0.5, σ = 0.65. We see here that as I → 1 − , the stationary distribution p s I (I) → ∞. This follows directly from (3.30). 4.1.6. Distribution for the case where µ + γ ≈ 0.  of the deterministic equivalent of (3.4) where σ = 0 converges to The number I * = 1 − 1 R0 N is the endemic equilibrium of the deterministic equivalent of (3.4) where σ = 0. Endemic persists in the deterministic system if R 0 > 1. This is conrmed in Figure 7(a) . The graph shows that p s I (I) → δ (I − I * ), the Dirac delta function as σ → 0 + . This is not the case for large σ. In fact, as σ → ∞, the stationary density function Table 1 with µ = Figure 8(a) shows that if the transmission rate is β = 0.2 and the temporary recovery rate is as low as γ = 1/7, the average number of infection cases will rise to 28% on the long run if proper care and prevention is not taken. The variance function converges to 0.0064 on the long run. This shows that the data tends to be very close to the mean. The skewness function is a positive function, suggesting that the distribution of the data is skewed right. Table 1 with µ = 1 80.3×365 , β = 0.8, γ = 1/7 and σ = 0.65. The dashed line is as described in Figure 8 . Figure 9 (a) shows that if the transmission rate is β = 0.8 and the temporary recovery rate is as low as γ = 1/7, the average number of infection cases will rise to 77.9% on the long run if proper care and prevention is not taken. The variance function converges to 0.012 on the long run. The skewness function is a negative function, suggesting that the distribution is left skewed. Table 1 with µ = 1 80.3×365 , β = 1, γ = 1/7 and σ = 0.65. The dashed line is as described in Figure 8 . Figure 10(a) shows that if the transmission rate is β = 1 and the temporary recovery rate is as low as γ = 1/7, the average number of infection cases will rise to 82.8% on the long run if proper care and prevention is not taken. The variance function converges to 0.0064 on the long run. The skewness function is a negative function. By comparing the results derived in Figures 9 and 10 , it follows that the average number of cases increases and the variance decreases as the transmission rate increases. Several epidemiological models [1, 10, 51, 38, 23, 43, 44, 49, 57] [27] , social behavior, strain-specic factors [42] , and public health intervention [34] . Also, in the presence of this noise, the harvesting function is not constant as widely assumed, but non-linear. Least Squares estimation scheme [15, 36] . We also estimated the initial point Here, we study the eect of small disturbances in the system by setting Table 3 . We conrm the result derived in Figure 7 (a), that is, the probability density function p I (I|t = T,Î 0 ) of the aggregate count of COVID-19 for March 23, 2021 concentrates entirely on the number N = 1 − 1 R0 N for small σ. This result is shown in Figure 14 . The analysis shows that the aggregate count of COVID-19 for the states analyzed converges to N asymptotically on the day March 23, 2021. This number is estimated and reported in Table 3 . We verify this by plotting, for large t, say, t = 100, 000, the distribution p I (I|t,Î 0 ) together with p s I (I). The verication plot is shown in Figure 15 . For this reason, we analyze the distribution of the nal size of the aggregate infection count using the stationary probability density function p s I (I). Figure 15 shows the comparison of the stationary density function p s I (I) (in red color) and the limiting distribution lim t→∞ p I (I|t, I 0 ) (in blue color). As evidenced in Figure 2 (d), we see that the stationary probability density function p s I (I) concentrates more on the nal size of the epidemic N as the infection growth rate β increases. We also see a similar behavior in Figures 4 (c) and 7 (b) as the aggregate harvesting eort µ + γ reduces and as the noise intensity σ increases, respectively. For this reason, we study the eect of high infection growth rate β, low recovery rate (low aggregate harvesting eort µ+γ), and eect of large noise on the distribution of the aggregate COVID-19 counts in the United States in the following subsections. This is done by plotting the stationary probability density function p s I (I) of the nal size of the aggregate infection count for large, small and large β, γ and σ, respectively. We see that the graph of p s I (I) concentrates on the estimate N (obtained in Table 2 ), which is the aggregate carrying capacity of the COVID-19 count in the United States as public health intervention reduced. Table 2 with large noise intensity σ = 0.2 and varying infection growth rates β = 0.06 (blue curve), β = 0.15 (black curve), and β = 0.3 (red curve) for each states analyzed. The gure shows that if proper intervention is not taken (resulting in increase in infection growth rate β and constant recovery rate γ), the aggregate count of COVID-19 infection will rise to the estimated aggregate carrying capacity value N in Table 2 for each respective states and territories. The analysis was done for the 48 states and territories mentioned in Table 2 and similar results obtained for each states and territories. For this reason and in order to minimize space, we only report the plots for the state of AK, ID, KY, ND, SD, WI, WV, WY. Table 2 with large noise intensity σ = 0.2 and varying recovery rate γ = 0.02 (blue curve), γ = 0.015 (black curve), and γ = 0.01 (red curve) for each states analyzed. The gure shows that if proper intervention is not taken (resulting in decline in recovery rate γ and constant aggregate growth rate β), the aggregate count of COVID-19 infection will rise to the estimated aggregate carrying capacity value N in Table 2 for each respective states and territories. The analysis was done for the 48 states and territories mentioned in Table 2 and similar results obtained for each states and territories. We only report the plots for the state of AK, ID, KY, ND, SD, WI, WV, WY here. The author declares that there is no known competing nancial interests or personal relationships that could have appeared to inuence the work reported in this paper. 8 . Funding Our main focus in this work is on the derivation of timedependent probability density function for the number of infected individuals following the general stochastic SIS model. To do this, we first study the SIS deterministic epidemic model where I and S represent the population of infected and susceptible individuals, respectively, S 0 > 0 , I 0 ≥ 0 , and > 0 is the recruitment rate, β is the transmission rate, μ is the natural death rate and γ is the temporary recovery rate. To maintain a constant population, we assume = μ. With this, the population size N remains constant over time so that S + I = N . This reduces the model governing I in (2.1) to the form The model (2.1) has been studied extensively by Brauer et al. [11] , Hethcote and Yorke [25] , Lajmanovich and Yorke [33] and Nold [45] . Many factors such as pneumonia seasonality, mobility, testing rates, mask use per capital weather [27] , social behavior, strainspecific factors [42] , and public health intervention [34] can act as external fluctuations affecting the contact/transmission rate of the disease. For this reason, we assume the contact/transmission rate β of the disease is affected by environmental perturbations, such as stated above, changing the infection transmission rate β to the form βd t = βd t + σ d W (t) , (2.3) where each infected individual makes βdt infectious contacts with each other in the interval [ t , t + dt ) , W (t ) is a standard Wiener process on a filtered probability space ( , F t , (F t ) t≥0 , P ), the filtration function (F t ) t≥0 is right-continuous and each F t with t ≥ 0 contains all P -null sets in F t . By substituting (2.3) into (2.1) , we reduce the deterministic epidemic model (2.1) to the Stratonovich stochastic model where • denotes the Stratonovich integral [2] . We used the Stratonovich calculus instead of the Itô calculus following the arguments made in [7, 37] . We also assume the initial process ( S 0 , I 0 ) is F t 0 measurable and independent of W (t) − W (t 0 ) . The solution of (2.4) with Itô calculus has been studied extensively by Gray [22] . In their work, Dalal et al. [16] showed that the introduction of stochastic noise can stabilize system that is unstable. In this work, we are interested in studying how the system behaves in the presence of noise in the transmission rate of the disease. This behavior is studied by analyzing the time-dependent probability density function of the process S(t ) and I(t ) . The stochastic differential equation has a unique positive solution [22, 39, 47, 59] in the feasible region for all t ≥ 0 with probability one. The model governing I in (2.4) reduces to the Itô form (2.7) The number R 0 is referred to the reproduction number for (2.1) . This is the average number of infection cases produced by an infectious individual when introduced into a completely susceptible population. The number R 0 is the stochastic version of R 0 for the model (2.6) . It was shown in Méndez et al. [39] and Otunuga [48] that the boundaries I = 0 and I = N of (2.6) are unattainable at all times if R 0 > 1 , regardless of the noise intensity. Following a similar Theorem in [22] , we show in Theorem 1 that the disease will die out exponentially almost surely on the long run in the presence of noise if R 0 ≤ 1 .  The result follows from the fact that lim sup using the large number theorem for martingales [24] . We see in Theorem 1 that replacing the condition R 0 < 1 with the condition R 0 < 1 for the disease to die out exponentially almost surely is also valid. We note here that epidemic advances can still grow initially, leading to transient epidemic advance if 1 − σ 2 2(μ + γ ) A numerical result is derived later in Section 4 to confirm Theorem 1 by showing that the stationary probability distribution of I concentrates entirely on zero if R 0 ≤ 1 (which also implies R 0 ≤ 1 ). Likewise, it can be shown that the stochastic differential Eq. (3.2) has a unique stationary distribution if R 0 > 1 . The proof of this is similar to the proof given in Theorem 6.2 of the work of Gray et al. [22] , so we omit the proof here. We give the closed form representation of the time-dependent and stationary probability density function for I in the next section and confirm that these distributions exist if R 0 > 1 . It was shown in Otunuga [48] that the solution (S(t) , I(t )) of the system (2.4) is obtained as  (2.10) Let p I (I| t, I 0 ) be the probability density for the process I satisfying (2.6) at time t given initial point I 0 . In his work, Otunuga [48] derived the probability density function p I (I| t, I 0 ) for the specific case where the resulting Fokker Planck differential equation for p I (I| t, I 0 ) has only discrete eigen-values r ≡ r n and λ sat- is a non-negative integer. In this work, we extend the work of Otunuga [48] to include both discrete and continuous eigen-values. Using the transformation S = S N ,  (3.2) By setting S = 1 − I, the stochastic differential equation governing I in (3.2) reduces to the Stratonovich stochastic differential equation (3. 3) The Itô equivalent of (3.3) is given by (3.4) Using the change of state variable in (3.4) , we obtain the Itô stochastic differential equation where Ā and C are defined in (2.10) . Let p X (x | t, x 0 ) be the probability density function for the process x satisfying (3.6) at time t given initial point x 0 , and let p s denotes the corresponding limiting or stationary distribution. We give the closed form expression for p s X (x ) and p X (x | t, x 0 ) in the following theorem. Theorem 2. Assume x 0 > 0 and Ā + 1 > 0 . Then the solution x (t) satisfying (3.6) has a unique stationary and time-dependent probability density function p s X (x ) and p X (x | t, x 0 ) , respectively, obtained as p s is the Laguerre polynomial [46] L αn is the Pochhammer symbol [5] , and WhittakerW k,θ (x ) is the Whittaker function [46] . Proof. It follows from (3.6) and the Fokker Planck equation that We assume a solution of the form where r ≥ 0 is a constant. The stationary density function p s provided that Ā + 1 > 0 , or equivalently R 0 > 1 . (3.11) We convert (3.7) -(3.8) to Sturm-Liouville equation . By substituting (3.10) into (3.12) , we see that the differential equation in (3.12) reduces to Using the transformation (3.14) we further reduce (3.13) into a differential equation of the form (3.16) The differential Eq. (3.15) is the well known Whittaker differential equation (see Section 13.14 of [46] ) with solution where B 1 , B 2 are constants and WhittakerM θ , v (x ) ; WhittakerW θ , v (x ) are the Whittaker functions [5, 46] . It now follows from (3.14) that the function h (x ) satisfying (3.12) is obtained as n Ā + 1 − n , for n = 0 , 1 , 2 , · · · M, with corresponding eigenfunction h n (x ) = C n x −n L αn n (x ) , (3.20) where L αn n (x ) is the Laguerre polynomial of degree n, and C n is a normalizing factor obtained as . The Sturm-Liouville equation also has continuous range of eigenvalue where U (a, b; x ) is the Kummer function [46] , i is the imaginary unit, and G (η) is a constant derived using the orthogonal condi- (3.25) where δ(. ) is the Dirac delta function. According to Szmytkowski [52] , the functions  (3.27) Remark 1. We note here that the distribution p s X (x ) is the Gamma distribution with shape parameter Ā . Since r 0 = 0 and r(η) > 0 , it follows from (3.27) that Using the fact that the distribution p s X (x ) is the Gamma distribution, it follows immediately that the limiting mean, mode, variance, skewness, kurtosis function of x (t) are obtained as respectively. Using the following integrals regarding Laguerre polynomial (these follows from the Chu-Vandermonde identities (see [46] Section 16.1.1)), where (a ) n is the Pochhammer's symbol, it can be shown that p X (x | t, x 0 ) > 0 and is the Hypergeometric regularized function [46] . In order to confirm the validity of the solution (3.27) , we show that the solution To do this, we show that for We use (3.29) and equation (44) in Becker [6] to show that Let p I (I| t, I 0 ) and p S (S| t, S 0 ) be the time-dependent probability density function for the number of infected and susceptible individuals at time t given initial points I 0 and S 0 , respectively. Also, let and p s I (I) be the corresponding stationary density function. We give the closed form expression for p I (I| t, I 0 ) , p S (S| t, S 0 ) , and p s I (I) in the following theorem. and time-dependent probability density function p s Proof. Using the transformation , we obtain the probability stationary function p s I (I) and the density function p I (I| t, I 0 ) of the number of infection I at a given time time t with initial condition I 0 as p s follows that the density probability function p S (S| t, S 0 ) of the number of susceptible individuals at time t 0 with initial condition S 0 can be obtained as Eq. (3.30) follows using the transformation (3.1) Remark 3. The condition Ā + 1 > 0 given in (3.10) is equivalent to R 0 > 1 . It follows that the probability distribution p s Following similar approach in Remark 1 , it can be shown that One can easily check that lim t→∞ p I (I| t, I 0 ) = p s I (I) . (3.34) The cummulative density function, P s (I) for the distribution p s I (I) in (3.30) is obtained as P s The mean and variance, denoted μ s and σ 2 s , respectively, of the distribution p s is the upper incomplete gamma function and U (a ; b; z) is the Kummer/confluent hypergeometric function [46] . We see later in (3.40) that these results correspond to the limiting mean and variance of the distribution p I (I| t, I 0 ) . It follows from (3.35 ) that the median is the number ˆ m that satisfies the equation The following theorem shows interval where the stationary density function is decreasing and increasing. In this case, p s Proof. We note that dp s > 0 on (s − , s + ) and dp s The condition R 0 = 1 is equivalent to Ā = 0 . For this case, p s The jth moment, denoted μ ( j) using identities (13.14.5), (13.6.19) and (13.16.6) in [46] . The mean μ (1)  where α 0 is defined in (3.21) and U ( a ; b; z ) is the Kummer/Congruent Hypergeometric function [46] . It follows immediately from where (a, z) = ∞ z t a −1 e −t dt is the incomplete gamma function. The values obtained in (3.40) are the mean, variance, skewness, and kurtosis, respectively, of the stationary density function p s . This is confirmed numerically in Section 4. In this section, we briefly discuss few interesting cases of the expression for p I (I| t, I 0 ) given in (3.30) involving particular values for the parameters μ, γ , β, and σ . with p s The constant E = μ + γ is called the harvesting effort of the system (2.4) . It follows from (3.11) that 0 < μ + γ < β − σ 2 / 2 . For large E = μ + γ so that μ + γ → β − σ 2 / 2 , it follows from (2.8) that I(t ) → 0 . That is, large value of μ + γ leads the infected population to extinct. Also, this condition is equivalent to Ā → 0 so that p s N −I and the probability density function p I (I| t, I 0 ) reduces to that in (3.30) . This is verified numerically in Section 4. As the noise intensity in the transmission rate of disease increases (that is, as σ → ∞ ), we see that Ā → −1 , C → 0 and the probability distribution P (I| t, I 0 ) converges to ∞ as I → 0 + and I → N − . This effect is shown numerically in Section 4. In this section, numerical simulation is carried out to verify our claim. First, we use published and assumed COVID-19 epidemiological parameters in Subsection 4.1 to confirm our results. The properties of the distribution are investigated numerically in Subsection 4.2 . In Subsection 4.3 , the obtained time-dependent and stationary probability density function are used to analyze the distribution of aggregate number of COVID-19 infection cases in the United States. We apply the distribution using published and assumed parameters. According to recent survey conducted by CDC 1 on people with mild COVID-19 cases, one-third did not return to normal health within two to three weeks of testing positive, and recovery takes six weeks or more for those with severe cases. For 1 https://www.health.harvard.edu/diseases-and-conditions/ if-youve-been-exposed-to-the-coronavirus . 03. 28 Therefore, we set μ to be in the range 83 3650 0 0 0 , 1 80 . 3 ×365 . The parameters used are associated with COVID-19 data and are given in Table 1 below. A MATHEMATICA program that evaluates the Whittaker and Laguarre functions and performs the integration in (3.32) is available from the author upon request. We note from (3.1) that the time-dependent probability density function p I (I| t, I 0 ) reduces to p I (I| t, I 0 ) if the population size is converted to fractions, that is, if N = 1 . For the rest of the numerical analysis in this subsection, we set N = 1 . In order to verify the correctness of the density function p I (I| t, I 0 ) and the stationary density function p s I (I) obtained in (3.30) , we first discretize the stochastic model (3.4) using the Milstein scheme [20] as follows:  In this section, we analyze numerically the behavior of the time-dependent distribution p I (I| t, I 0 = 0 . 05) and p s I (I) as the transmission rate β increases. We see here that the distributions for the three cases skewed left. This is evident in Figs. 9 (b) and 10 (b) as we can see there that the skewness plot is negative. We see from Fig. 2 (d) that p I (I| t, I 0 = 0 . 05) → p s I (I) as t → ∞ . Also, we observe that as β increases, the stationary density function shifts concentration to the right. The concentration moves closer to I * = N = 1 as β grows larger. This is because as the transmission rate increases, we expect the number of infection to increase until everyone in the population becomes infected. This can be confirmed analytically using (3.30) . As shown in Theorem 1 , the disease will die out on the long run if R 0 ≤ 1 (implying R 0 ≤ 1 also). Fig. 3 (a) and (b) show the behavior of the distribution as disease dies out in the population using parameters μ = 1 80 . 3 ×365 , γ = 1 / 7 , σ = 0 . 1 and varying β so that R 0 → 1 + in 3 (a) and R 0 → 1 + in 3 (b). The result shows that on the long run, the density function of I converges to the Dirac delta function δ(I) as R 0 → 1 + . It follows from condition (3.11) that 0 < γ < β − μ. Fig. 4 (a) and (b) shows the effect of increase in the parameter γ on the stationary density function p s I (I) using parameters Fig. 4 (a) , and σ = 0 . 3 in Fig. 4 (b) , respectively. We see here that as γ increases to β − μ from the left, the distribution shifts concentration to the left until it concentrates entirely on 0. This shows that the disease dies out as γ → β − μ. We also see the effect of large noise in the system as γ increases. We see that the distribution becomes taller and narrower in the presence of small noise, and flatter and wider in the presence of large noise. In Fig. 4 (c) , we see that the stationary distribution p s I (I) concentrates more on the final size of the epidemic as the recovery rate decreases to zero. This analysis shows that the disease dies out as the recovery rate γ reaches the threshold β − μ. The number of infected reaches maximum as the number of those who recovered declines to zero. Fig. 5 (a) and (b) show the probability and stationary density functions p I (I| t, I 0 = 0 . 05) and p I (I) , respectively, for the case where β − (μ + γ ) − σ 2 / 2 ≈ 0 , or equivalently, Ā ≈ 0 using parameters in Table 1 with β = 0 . 5 , σ = 0 . 65 . We see here that as 4.1.6. Distribution for the case where μ + γ ≈ 0 . Fig. 6 shows the probability density function p I (I| t, I 0 = 0 . 05) for the case where E = μ + γ = 0 using parameters in Table 1 with β = 0 . 5 , σ = 0 . 7 . The analysis also shows that if the number of Fig. 7 (a) shows the distribution as σ → 0 while Fig. 7 (b) shows the distribution as σ → ∞ . We see from Fig. 7 (a) that the stationary density function concentrates entirely on the number  N as σ → 0 . This is because the solution of the deterministic equivalent of (3.4) where σ = 0 converges to N is the endemic equilibrium of the deterministic equivalent of (3.4) where σ = 0 . Endemic persists in the deterministic system if R 0 > 1 . This is confirmed in Fig. 7 (a) . The graph shows that p s I (I) → δ( I − I * ) , the Dirac delta function, as σ → 0 + . This is not the case for large σ . In fact, as σ → ∞ , the stationary density function p s I (I) → ∞ as I → 0 + and as I → 1 − . Fig. 8 (a), (b) , (c) and (d) is the graph of the mean, variance, skewness, and kurtosis, respectively, of the distribution p I (I| t, I 0 = 0 . 04) at time t using parameters in Table 1 with μ = Fig. 8 (a) shows that if the transmission rate is β = 0 . 2 and the temporary recovery rate is as low as γ = 1 / 7 , the average number of infection cases will rise to 28% on the long run if proper care and prevention is not taken. The variance function converges to 0.0039 on the long run. This shows the magnitude of the spread of the data away from the mean is small. The skewness function is a positive function, suggesting that the distribution of the data is skewed right. Fig. 9 (a), (b) , (c) and (d) is the graph of the mean, variance, skewness, and kurtosis, respectively, of the distribution p I (I| t, I 0 = 0 . 05) at time t using parameters in Table 1 with μ = 1 80 . 3 ×365 , β = 0 . 8 , γ = 1 / 7 and σ = 0 . 65 . The dashed line is as described in Fig. 8 . Fig. 9 (a) shows that if the transmission rate is β = 0 . 8 and the temporary recovery rate is as low as γ = 1 / 7 , the average number of infection cases will rise to 77 . 9% on the long run if proper care and prevention is not taken. The variance function converges to 0.012 on the long run. The skewness function is a negative function, suggesting that the distribution is left skewed. Fig. 10 (a), (b) , (c) and (d) is the graph of the mean, variance, skewness, and kurtosis, respectively, of the distribution p I (I| t, I 0 = 0 . 05) at time t using parameters in Table 1 with μ = scribed in Fig. 8 . Fig. 10 (a) shows that if the transmission rate is β = 1 and the temporary recovery rate is as low as γ = 1 / 7 , the average number of infection cases will rise to 82 . 8% on the long run if proper care and prevention is not taken. The variance function converges to 0.0064 on the long run. The skewness function is a negative function. By comparing the results derived in Figs. 9 and 10 , it follows that the average number of cases increases and the variance decreases on the long run as the transmission rate increases. Several epidemiological models [1, 10, 23, 38, 43, 44, 49, 51, 57] have been developed to study the transmission of the COVID-19 virus. As it is well known, the generalized logistic equation is widely used in interpreting the aggregate number of COVID-19 infection trajectories in several countries [49, 50, 57] . We see in our work that model (2.2) is a logistic differential equation. In the case of modeling the aggregate number of infected cases, β is referred to as the aggregate infection growth rate, N is the aggregate infection carrying capacity, and (μ + γ ) serves as the aggregate infection harvesting effort. In this section, we study the trajectory and the distribution of the aggregate counts of COVID-19 cases reported by the Centers for Disease Control and Prevention (CDC) 5 for some states in the United States using model (2.6) and the time-dependent density function (3.30) , respectively. We assume the aggregate number of infection follows the model (2.6) , where I(t ) in this case represents the aggregate infection cases at time t. The advantage of using model (2.6) over most models available in literature is that it considers presence of external perturbations/disturbances in the contact rate of the disease that can be caused by many factors such as pneumonia seasonality, mobility, testing rates, mask use per capital weather [27] , social behavior, strain-specific factors [42] , and public health intervention [34] . Also, in the presence of this noise, the harvesting function is not constant as widely assumed, but non-linear. [15, 36] . We also estimated the initial point I 0 for better fit. The parameter estimates N , ˆ β, ˆ γ , and ˆ I 0 of the aggregate infection carrying capacity N , the infection growth rate β, the infection recovery rate γ , and the initial population size I 0 are estimated along with the root mean square error (RMSE) of the estimation and reported in Table 2 . T is the number of non-zero aggregate infection days from January 22, 2020 to March 23, 2021. The trajectory of the aggregate infection counts, together with the estimated trajectory for each of the 48 states and territories studied are reported in Figs. 11, 12 , and 13 . The red and blue curves are the trajectory for the real and simulated COVID-19 aggregate count data, respectively. The estimated parameter N here represents the carrying capacity of the aggregate infection count for each states. We show in later section that as the aggregate harvesting effort μ + γ reduces, or as the aggregate infection growth rate increases due to no proper public health intervention, the aggregate COVID-19 count estimate converges to N . Here, we study the effect of small disturbances in the system by Table 3 . We confirm the result derived in Table 3 . In this section, we study and analyze the distribution of the final size of the aggregate infection count in the United States by studying how the distribution p I (I| t, ˆ I 0 ) behaves as t → ∞ . According to (3.34) , we know that We verify this by plotting, for large t, say, t = 10 0 , 0 0 0 , the distribution p I (I| t, ˆ I 0 ) together with p s I (I) . The verification plot is shown in Fig. 15 . For this reason, we analyze the distribution of the final size of the aggregate infection count using the stationary probability density function p s As evidenced in Fig. 2 (d) , we see that the stationary probability density function p s I (I) concentrates more on the final size of the epidemic N as the infection growth rate β increases. We also see a similar behavior in Figs. 4 (c) and 7 (b) as the aggregate harvesting effort μ + γ reduces and as the noise intensity σ increases, respectively. For this reason, we study the effect of high infection growth rate β, low recovery rate (low aggregate harvesting effort μ + γ ), and effect of large noise on the distribution of the aggregate COVID-19 counts in the United States in the following subsections. This is done by plotting the stationary probability density function p s I (I) of the final size of the aggregate infection count for large, small, and large β, γ , and σ, respectively. We see that the graph of p s I (I) concentrates on the estimate N (obtained in Table 2 ), which is the aggregate carrying capacity of the COVID-19 count in the United States as public health intervention reduced. Fig. 16 shows the distribution of the final size of the aggregate infection count as the infection growth rate β increases using the estimated parameters in Table 2 with large noise intensity σ = 0 . 2 and varying infection growth rates β = 0 . 06 (blue curve), β = 0 . 15 (black curve), and β = 0 . 3 (red curve) for each states analyzed. The figure shows that if proper intervention is not taken (resulting in increase in infection growth rate β and constant recovery rate γ ), the aggregate count of COVID-19 infection will rise to the estimated aggregate carrying capacity value N in Table 2 for each respective states and territories. The analysis was done for the 48 states and territories mentioned in Table 2 and similar results obtained for each states and territories. For this reason and in order to minimize space, we only report the plots for the state of AK, ID, KY, ND, SD, WI, WV, WY. Fig. 17 shows the distribution of the final size of the aggregate infection count as the aggregate harvesting effort decreases using the estimated parameters in Table 2 with large noise intensity σ = 0 . 2 and varying recovery rate γ = 0 . 02 (blue curve), γ = 0 . 015 (black curve), and γ = 0 . 01 (red curve) for each states analyzed. The figure shows that if proper intervention is not taken (resulting in decline in recovery rate γ and constant aggregate growth rate β), the aggregate count of COVID-19 infection will rise to the estimated aggregate carrying capacity value N in Table 2 for each respective states and territories. The analysis was done for the 48 states and territories mentioned in Table 2 and similar results obtained for each states and territories. We only report the plots for the state of AK, ID, KY, ND, SD, WI, WV, WY here. The data used in the analysis can be found on the CDC 5 website. This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors. The author declares that there is no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Supplementary material associated with this article can be found, in the online version, at doi: 10.1016/j.chaos.2021.110983 . Olusegun Michael Otunuga: Conceptualization, Data curation, Formal analysis, Software, Writing -original draft, Writing -review & editing.@story_separate@By assuming the contact rate β of certain diseases is aected by environmental perturbations, we convert the general deterministic SIS epidemic model with vital dynamics and constant population to a stochastic SIS model and used this model to study the dynamics of infectious diseases. The study in this work involves analyzing the distribution of numbers of infections whose dynamic follows the SIS stochastic model (2.6). To do this, we derive the closed-form time-dependent probability density function p I (I|t, I 0 ) of the number of infection I at time t given the initial point I 0 . The stationary probability density function p s I (I) of the process is also derived and analyzed and our studies show that p I (I|t, I 0 ) converges to p s I (I) on the long run. We showed that these distibutions exist if the average number, R 0 , of individuals infected by an infectious individual in a completely susceptible population is more than one. Also, we showed that the disease will die out if R 0 < 1. Using the Milstein scheme, the stochastic model (2.6) is discretized for N sample size and L simulations and the correctness of the obtained probability density functions p I (I|t = 2, I 0 ) and p s I (I) are veried in Section 4.1.1 by comparing them to the probability density function derived from the histogram of the discretized processes I l 20 and I l N (for large N ), respectively, in (4.1), for 1 ≤ j ≤ N , 1 ≤ l ≤ L, and ∆t = 1/10 using published epidemiological data. The eect of changes in the transmission rate and temporary recovery rate on the distribution p I (I|t, I 0 ) and p s I (I) is studied. It was shown that as R 0 approaches 1 (from above), the distribution p s I (I) approaches the Dirac delta function δ(I) and concentrates entirely on zero. That is, on the long run, the number of infection declines and the disease eventually dies out as the reproduction number R 0 approaches 1 (from above). Also, as the recovery rate decreases to zero, the distribution of the number of infection shifts concentration to the right until it concentrates entirely on the infection carrying capacity N . That is, the infected population converges to the infection carrying capacity N (estimated as N in Table 2 ) as the recovery rate reduces signicantly. A similar analysis done on the transmission rate β shows that the infected population converges to the infection carrying capacity N as β increases. The eect of noise on the system is also analyzed. It was shown that on the long run, the probability density function p I (I|t, I 0 ) shifts concentration on the disease endemic equilibrium point 1 − 1 R0 N as the noise intensity σ approaches zero. This is because (2.2) has an endemic equilibrium 1 − 1 R0 N that is globally stable if R 0 > 1. Some properties of the time-dependent probability density function namely the mean, variance, skewness, and Kurtosis functions are derived and analyzed as a function of time. with the histogram of the distribution of the random variable I l T , l = 1, 2, · · · , L, for L = 10, 000 simulations, where T is the number of non-zero days from January 1, 2020 to March 23, 2021. We also show numerically using the real COVID-19 aggregate counts for AK, ID, KY, ND, SD, WI, WV, WY that on the long run, the time-dependent density function p I (I|t, I 0 ) converges to the stationary density function p s I (I). We use the distribution to conrm the estimate of the aggregate count for the month of March 23, 2021 in Table 3 and compare the result with the real data. By studying the distribution of the nal size of the aggregate infection counts, our analysis shows that on the long run, if proper intervention is not taken such that the harvesting eort decreases signicantly to 0.01 (or less), the aggregate counts of COVID-19 cases for each states may increase to the value N reported in Table 2 . A similar analysis shows that the aggregate counts of COVID-19 cases for each states may increase to the value N if the infection growth rate increase to 0.3 (or more). These studies are conrmed by showing that the distribution p s I (I) shifts concentration on the value N as the harvesting eort decreases or the infection growth rate increases. More studies are still ongoing on the distribution of the aggregate count of infection as data are being updated daily. Further extension of the result obtained in this work using fractional order cases as discussed in Jajarmi et al. [28, 29] is under investigation. For more readings on fractional derivatives, we direct readers to the papers [51, 56, 3, 4] . 6 . Availability of data and materials The data used in the analysis can be found on the CDC 5 website. By assuming the contact rate β of certain diseases is affected by environmental perturbations, we convert the general deterministic SIS epidemic model with vital dynamics and constant population to a stochastic SIS model and used this model to study the dynamics of some infectious diseases. The study in this work involves analyzing the distribution of numbers of infections whose dynamic follows the SIS stochastic model (2.6) . To do this, we derive the closed-form time-dependent probability density function fected by an infectious individual in a completely susceptible population is more than one. Also, we showed that the disease will die out if R 0 ≤ 1 . Using the Milstein scheme, the stochastic model (2.6) is discretized for N sample size and L simulations and the correctness of the obtained probability density functions p I (I| t = 2 , I 0 ) and p s I (I) are verified in Section 4.1.1 by comparing them to the probability density function derived from the histogram of the discretized processes I l 20 and I l N (for large N), respectively, in (4.1) , for 1 ≤ j ≤ N, 1 ≤ l ≤ L, and t = 1 / 10 using published epidemiological data. The effect of changes in the transmission rate and temporary recovery rate on the distribution p I (I| t, I 0 ) and p s I (I) is studied. It was shown that as R 0 approaches 1 (from above), the distribution p s I (I) approaches the Dirac delta function δ(I) and concentrates entirely on zero. That is, on the long run, the number of infection declines and the disease eventually dies out as the reproduction number R 0 approaches 1 (from above). Also, as the recovery rate decreases to zero, the distribution of the number of infection shifts concentration to the right until it concentrates entirely on the infection carrying capacity N . That is, the infected population converges to the infection carrying capacity N as the recovery rate reduces significantly. A similar analysis done on the transmission rate β shows that the infected population converges to the infection carrying capacity N as β increases. The effect of noise on the system is also analyzed. It was shown that on the long run, the probability density function p I (I| t, I 0 ) shifts concentration on the disease endemic equilibrium point 1 − 1 R 0 N as the noise intensity σ approaches zero. This is because (2.2) has an Some properties of the time-dependent probability density function, namely the mean, variance, skewness, and Kurtosis functions are derived and analyzed as a function of time. Similar analysis described above is done using the real aggregate counts of COVID-19 cases reported by the Centers for Disease We use the distribution to confirm the estimate of the aggregate count for the month of March 23, 2021 in Table 3 and compare the result with the real data. By studying the distribution of the final size of the aggregate infection counts, our analysis shows that on the long run, if proper intervention is not taken such that the harvesting effort decreases significantly to 0.01 (or less), the aggregate counts of COVID-19 cases for each states may increase to the value N reported in Table 2 . A similar analysis shows that the aggregate counts of COVID-19 cases for each states may increase to the value N if the infection growth rate increases to 0.3 (or more). These studies are confirmed by showing that the distribution p s I (I) shifts concentration on the value N as the harvesting effort decreases or the infection growth rate increases. More studies are still ongoing on the distribution of the aggregate count of infection as data are being updated daily. Further extension of the result obtained in this work using fractional order cases as discussed in Jajarmi et al. [28, 29] is under investigation. For more readings on fractional derivatives, we direct readers to the papers [3, 4, 51, 56] .","We derive the time-dependent probability distribution for the number of infected individuals at a given time in a stochastic Susceptible-Infected-Susceptible (SIS) epidemic model. The mean, variance, skewness, and kurtosis of the distribution are obtained as a function of time. We study the effect of noise intensity on the distribution and later derive and analyze the effect of changes in the transmission and recovery rates of the disease. Our analysis reveals that the time-dependent probability density function exists if the basic reproduction number is greater than one. It converges to the Dirac delta function on the long run (entirely concentrated on zero) as the basic reproduction number tends to one from above. The result is applied using published COVID-19 parameters and also applied to analyze the probability distribution of the aggregate number of COVID-19 cases in the United States for the period: January 22, 2020-March 23, 2021. Findings show that the distribution shifts concentration to the right until it concentrates entirely on the carrying infection capacity as the infection growth rate increases or the recovery rate reduces. The disease eradication and disease persistence thresholds are calculated."
"Concerns over global warming and its detrimental consequences continue to rise, making carbon emissions reduction an increasingly critical matter. It is a global consensus that carbon emissions stand out as the prime cause leading to climate change and global warming (IPCC, 2014) . The recent surge in carbon emissions and its negative impact is mainly attributed to the fast-paced industrial growth and the associated intensive energy consumption. The amount of carbon footprint generated evidently varies across different sectors of the economy, where the potential reduction of such emissions in the industrial, construction, and agricultural sectors was discussed by Huisingh et al. (2015) . The authors stated that carbon emissions due to logistics operations in specific constitute a small percentage to possibly more than 10 percent of the global emissions depending on the characteristics of goods as well as the transportation mode adopted. As a matter of fact, in the year 2017, it is reported that 29% and 28% of greenhouse gas emissions in the United States were generated from transportation and electricity, respectively 1 . On the notion of goods characteristics, cold supply chain has unique dynamics and peculiarities that sets it apart from other supply chains. Cold, or temperature-sensitive, products are typically of perishable nature and encompass a wide range of products such as fresh produce, poultry and dairy products, fishery items, pharmaceuticals, vaccines, among many others. Efficiently managing the logistics operations for such products has recently received an ever growing interest from both industrial practitioners and academic researchers alike, which may partially be attributed to two main reasons. First, the expanded market reach of these products and the unprecedented surge in their sales figures due to the advancement in the enabling cooling technologies coupled with the increase in the number of third party logistics service providers specialized in handling this type of products. For instance, it has been estimated that global cold chain market was valued at $189.92 Billion in 2017 and it is projected to reach $293.27 Billion by 2023 2 . In the year 2018, the overall global capacity of cold storage reached around 616 million cubic meters 3 . These numbers clearly illustrate the great potential that exists towards optimizing the movement and storage of such products along each step across the supply chain. Secondly, since cold products are typically chilled ( ) or frozen ( ), special temperature-controlled 0 ℃ -20 ℃ transport and storage facilities are needed to handle them making this industry highly energy intensive. In fact, Kayfeci et al. (2013) pointed out that energy consumption in cold chains amounts to 30% of the total world energy consumption. Furthermore, this extensive use of energy triggers elevated levels of carbon emissions, where it has been reported by James and James (2010) that the cold chain is held accountable for almost 1% of the world's greenhouse gas emissions. The intensive energy usage, and accordingly the cost, of cold products logistics operations coupled with their negative environmental impact renders the development of efficient and sustainable replenishment policies of such products an inevitable necessity. A bad selection for the number and capacity of temperature-controlled trucks, the lot size to order, and the number and size of freezer units at the retailing outlets, among other factors, could have a devastating impact on the cost, quality, environment and customer service level. Therefore, supply chain practitioners dealing with cold products ought to explicitly account for sustainability aspects as an integral part of their operational decision-making process. Muriana, 2016) . However, the dynamic or stochastic demand patterns are more practical as they better capture real-life dynamics of the demand for many products such as the ones under study here. More specifically, cold or perishable products in general, typically exhibit time varying demand stressing the need for dynamic lot sizing modeling approach to optimize inventory and transportation related decisions on a periodic basis, and accordingly control costs and carbon emissions. For instance, dairy products, fishery items and fresh food exhibit daily or weekly varying demand patterns. In case of daily demand, this demand is much higher during the weekend than during weekdays as most consumers, living in the vicinity of the retail stores, frequently tend to purchase their needs of such items on weekends. The remaining consumers prefer to go to the retail store when the need arises during the weekdays. Similarly, the demand varies from week-to-week, where the demand in the first week of the month is especially higher as consumers do more of their purchases during this week after receiving their paychecks. This paper addresses the logistics operations of a cold product exhibiting a discrete time varying demand over a finite planning horizon. As modular temperature-controlled units are used to store and transport such products, the carbon footprint generated due to these activities is taken into account through the carbon cap regulatory policy. The cap is firstly set on the total emissions throughout the planning horizon and then a stricter version is considered with the cap being imposed on each period's emissions. For each of the two cases, a mixed integer linear programming (MILP) model is developed along with a solution algorithm that yields the optimal ordering policy. To the authors' best knowledge, this work is the first to tackle this problem in the context of cold products using temperature-controlled transportation trucks and warehousing facilities while accounting for the products limited shelf life aspect. The remainder of this paper is organized as follows. Section 2 presents a review of the state-of-the-art literature pertaining to the problem at hand, and highlights the contributions of this work. Section 3 provides the mathematical models along with the proposed solution algorithms. The impact of the carbon cap (both total and periodic) as well as other key problem parameters on the lot sizing policy, the operational cost and the carbon footprint generated is assessed in Section 4 through sensitivity analysis. Concluding remarks in addition to suggestions for future research avenues are presented in Section 5. Lastly, the detailed derivation of the economic and environmental objective functions coefficients along with illustrative examples for the total and periodic cap cases are shown in the appendices. illustrated the economic and emissions reduction benefits realized when two buyers cooperate to share transportation paths and handling units. @story_separate@Perishability is an important aspect characterizing a wide range of products. Due to their widespread applicability, an increasing body of literature has been devoted to modeling the logistical operations of these products while explicitly accounting for their perishable nature. As  For perishable products in general, accounting for shelf life aspect is of practical relevance as it directly affects the replenishment strategy and the associated carbon emissions as well as the potential waste generated and ultimately a firm's profitability. Despite its paramount importance, it is noted in the review paper of Pahl and Voß (2014) that little research has been done in the modeling of lifetime restrictions to prevent wastage and disposal of perishable products, especially in a dynamic planning context. As cold products are usually of a perishable nature, this work contributes to such deficiency through addressing the lot-sizing policy of a cold product facing time varying demand while explicitly considering environmental and limited lifetime aspects. Stated more formally, we next highlight the three main contributions of this paper. 2) It is known that Lagrangian relaxation approach provides lower bounds to complex minimization problems. As such, this approach is typically used to generate approximate (nearoptimal) solutions. However, as shown in this paper, the novelty in the proposed hybrid Lagrangian relaxation and Bisection based solution procedure is that it generates the optimal solution to the optimization problem when a carbon cap is imposed on the total carbon emitted over the planning horizon. In addition, based on the optimal value of the Lagrangian multiplier,  Consider a cold product facing known time-varying demand over a discrete planning horizon of length T periods. Due to its perishable nature, the cold product has a pre-determined shelf life and requires refrigerated trucks for its transportation and modular temperature-controlled Following are the assumptions underlying the mathematical models developed in this paper: 1) Orders are delivered only at the beginning of the periods. 2) Ideal transportation and storage conditions are always maintained which prohibits the deterioration of the cold product during those activities. 3) The cold product is perishable in the sense that it loses its value/utility all at once upon exceeding the fixed shelf life (see Pahl and Voß (2014) for a more detailed discussion). Accordingly, a quantity delivered at the beginning of period t can only be held in stock for a limited number of periods equal to its shelf life, SL. Demand fulfillment follows a first-in first-out (FIFO) stock outflow pattern. In this case, ending inventory left from an order delivered at the beginning of period t, is g periods old at the end of period (t + g -1), where g is less or equal to SL. The lead time associated with shipment delivery from the supplier is negligible. 6) Demand backordering is not permitted, and holding cost is charged against inventory at the end of each period. The operational status of a freezer unit does not change during the period, and a freezer is switched off only when it is completely emptied. 8) There is no restriction on the number of reefers and freezers available to transport and store the cold product, respectively. 9) The adopted carbon regulatory policy is carbon cap, which sets a limit on the amount of carbon footprint generated from the transportation and storage activities. 10) Without loss of generality, the initial (ending) inventory at the beginning (end) of the planning horizon is set equal to zero. The following main notations are adopted in the development of the mathematical models. More notations will be introduced as needed. Problem parameters: h: Unit storage cost of the cold product for one period, excluding energy consumption cost Binary variable, equals to one when an order is placed and received at the beginning of period t and zero otherwise Towards curbing carbon emissions, the carbon cap regulation has proven to be an effective regulatory policy that is gaining wider acceptance nowadays. Following such policy, a cap is set on the maximum carbon footprint generated by an organization where this cap may span the entire planning horizon (e.g., a year) or could simply be imposed on a shorter-range periodic amounts of carbon emissions (e.g., a month), with the latter being obviously a more strict version of the former. In this paper, we address both cases where the following subsection presents the mathematical formulation and the solution algorithm for the case of a cap being defined for the entire planning horizon whilst the next subsection tackles the shorter interval caps. For a better organization of the paper, the derivation details of the mathematical expressions of the coefficients for the total operational cost function and total carbon footprint constraints are delegated to Appendix A. Furthermore, illustrative examples on the two optimization problems, with total and periodic caps, are shown in Appendices B and C, respectively. Using the expressions for the costs associated with the reefers and freezers operations derived in Appendix A, the operational cost incurred during period t is where the first two terms are the ordering and holding costs incurred during period t, respectively. The sum of next two terms represents the transportation cost and the last term is the freezers' operational cost. Accordingly, the total operational cost over the planning horizon ( ) is given by: The total carbon footprint over the entire planning horizon ( ) is directly attainable from Equation (A7) and it is given by: Therefore, the constraint stipulating that the allowable carbon cap over the planning horizon is not exceeded would be given by: In the following, an ordering policy is defined by the vector in the = ( 1 , 2 , …, ) sense that once is determined then the remaining decision variables can be found using: Hence, the operational cost optimization problem with carbon emission constraint is given by: (CAP T ): Subject to: ≥ 0 = 1, 2, …, , Equations (3) represent the classical inventory balance constraints, while constraints (4) establish the number of trucks needed to transport the lot size of that period. The number of operational freezers in a particular period is dictated by the beginning inventory as seen in constraint set (5) . Constraints (6) ensure that the lot size is zero in case no order is placed in period . Assuming a FIFO consumption pattern, constraints (7) are the shelf life constraints, which mandate that the inventory at the beginning of a period does not exceed the demand for periods including that own period's demand. The remaining constraints represent the non-negativity, binary and integrality restrictions on the respective decision variables. We next provide some insights leading to the development of an optimal solution algorithm to problem (CAP T ). Feasibility assumption: The carbon cap should satisfy the condition ≤ ≤ . The lower bound carbon cap, is the minimum carbon footprint over the entire planning horizon obtained by solving the following carbon cap-unconstrained environmental optimization problem, since its objective function is to minimize the total carbon emitted over the planning horizon: Cap min,T : Min TCF(Q) subject to constraints (3) to (11) The upper bound, , is the total carbon emissions of the optimal lot sizing policy of the following carbon cap-unconstrained operational cost optimization problem. Cap max,T : Min TOC(Q) subject to constraints (3) to (11) In order to solve the optimization problem (CAP T ), the carbon cap constraint (2)  The objective function of (D) is, therefore, a piecewise linear concave function of . The dual function is shown in Figure 1 using the data of the illustrative example presented in Appendix B. Note that the function Z() has a finite number of breakpoints where it is not differentiable, and between each two consecutive breakpoints the functions TOC(Q) and TCF(Q) remain constant. We show in the following Lemma that TOC(Q) and TCF(Q) are non-decreasing and nonincreasing functions of , respectively. (i) (ii) Let Q(0) be the optimal ordering policy for the unconstrained carbon cap problem (Cap max,T ). Clearly, this unconstrained ordering policy has the least total operational cost, TOC(Q(0)) and the largest total carbon footprint, TCF(Q(0)). Therefore, for a given positive , the total operational costs, TOC(Q()), of the optimal ordering policy Q( to the Lagrangian relaxation problem (CAP T () cannot be smaller that TOC (Q(0) ). Similarly, it can be seen that TCF(Q()) ≤ TCF(Q(0)). Next, consider the optimal solution Q(' to the Lagrangian relaxation problem (CAP T (') , with ' =  +  ≥ . In its expanded form, the objective function of (CAP T (') is: ] -} which can be rewritten as: For = 0 and setting the objective function's coefficients for the reefers and freezers' Δ operational costs to and , respectively, the optimal solution to the + , + + relaxed problem is Q( with the smallest total operational costs and largest total carbon footprint with these coefficients. Consequently, TOC(Q(+ )) ≥ TOC(Q( )) and TCF(Q( )) ≤ TCF(Q( Δ Δ )) for a given Δ > 0. It can be observed from Figure 1 that for a carbon cap of 1.7 tons, the range of values for the Lagrangian multiplier between the two dotted vertical lines will result in the optimal ordering policy for the primal problem (CAP T (   Therefore, the smallest  value with the total carbon footprint smaller than the carbon cap can be used to determine the optimal solution. Using this observation and assuming that , we develop the following Bisection based ≤ ≤ algorithm to generate the optimal ordering policy. Obviously, in case , the optimization < problem (CAP T ) has no feasible solution. On the other hand, if , then the optimal ordering > policy for the optimization problem (Cap max,T ) is also optimal for (CAP T ). Optimal solution procedure to solve the optimization problem (CAP T (). Step 0. Set   0,  L =  and solve CAP T (0) Step Step 2.3. If TCF( < C set  U =  and go to step 3 Step 2.4. If TCF( = C set  U =  and go to step 5 Step 3. If  U - L > 0.01, go to step 4.1, otherwise go to step 5 Step 4.1. Set  = ( U +  L )/2 and Solve P( using Shamayleh et al. (2019) DP algorithm Step 4.2. If TCF( > C set  L =  and go to step 3 Step 4.3. If TCF( < C set  U =  and go to step 3 Step 4.4. If TCF( = C set  U =  and go to step 5 Step 5.  * =  U , Q * = Q( * ), TOC * = TOC( * ), and TCF * = TCF( * ) The value of the Lagrangian multiplier,    is vital towards assessing the cost and carbon emission performance of the carbon cap regulatory policy when compared to the carbon tax policy. The following lemma shows the relationship between these two commonly used carbon regulatory policies. Let be the tax rate charged for each ton of carbon emitted. , then < * ( > * ) a-Total carbon emitted under carbon tax policy is larger (smaller) than the one generated by the carbon cap policy. b-The total operational cost of the carbon tax policy is smaller (larger) than the one of the carbon cap policy. The proof is straightforward by referring to Figure 1 . In case the cap is imposed on the amount of carbon emitted over each period of the planning horizon, the carbon cap constraints (2) of the optimization problem (CAP T ) are replaced by: where are given in equations (A9) and (A11). , and The optimization problem to be solved is then: Subject to: Constraints (3) to (11) and (15) Feasibility assumption: The carbon cap per period, CP, should satisfy the condition: . The periodic upper carbon cap is the maximum carbon emitted per period over the entire planning horizon when following the optimal lot sizing policy of the unconstrained carbon cap optimization problem, i.e., CP max = max{CF t , t =1, 2, …, T}. On the other hand, the periodic lower carbon cap, CP min , is the optimal objective function value of the following Min-Max optimization problem: Cap min,t : Min X Subject to In order to solve the optimization problem (Cap min,t ), we propose the following dynamic programing based algorithm. We first rewrite the carbon footprint during period t as: (16) = ⌈ ⌉ + ⌈ -1 + ⌉ + for = 1, 2, …, Next, note that the ordering quantity in a period t depends only on the beginning inventory in the same period. For example, when t = T, the ordering quantity is equal to since --1 the ending inventory at period T must be zero. For other periods, the beginning inventory, E t-1 + Q t , must satisfy: Therefore, we define E t-1 as the state variable at period t. We also let F t (E t-1 ) be the minimum of the maximum carbon footprint generated during periods t through T when the beginning inventory at period t is E t-1 . The periodic lower carbon cap is then F 1 (0). For period T, we have (18)  On the other hand, for any period t < T, the beginning inventory at period t should satisfy Equation (17) . Note the right-hand-side inequality is due to the product shelf-life constraint. Under these two inequality constraints, the following recursive equation can be used to solve the T-period problem for Cap min,t : and (20) In order to solve the optimization problem (CAP t ), we can use Lagrangian relaxation method by relaxing the set of constraints in (15) . For given Lagrangian multipliers associated with constraints (15) However, the Bisection method cannot be used to solve the dual problem to (CAP t ( ) as we are dealing with more than one Lagrangian multiplier. Instead, other solution : = 1, 2, …, ) procedures, such as the sub-gradient method, have to be used which may not guarantee the attainment of an optimal lot sizing policy. In the following, we propose a DP based algorithm similar to the one used to solve (Cap min,t ) with the same state variable E t-1 to solve the optimization problem (CAP t ). Let K t (E t-1 ) be the minimum total operational costs satisfying the demands and carbon footprint limit during periods t through T when the state variable is E t-1 at the beginning of period t. The minimum total operational costs over the planning horizon is then K 1 (0). For a given E T-1 , the operational costs during period T is: Next, for any period t < T, the beginning inventory should satisfy Equation (19) and . ⌈ ⌉ + ⌈ -1 + ⌉ + ≤ Then, the recursive equation to be used is: where y t = 1 if Q t > 0 and 0 otherwise. In this section, we analyze the impact of the main problem parameters, such as the imposed carbon cap, inventory related cost (ordering and holding costs), as well as cooling infrastructure related parameters (driver's wage, trucks capacity, fuel price and electricity price) on the resulting lot sizing policy for the two optimization problems (CAP T ) and (CAP t ). Being a key model parameter, we assess in this section the performance of the two mathematical models under various values of the imposed carbon cap (both total and periodic). The purpose is to draw analytic managerial insights pertaining to the impact of the carbon caps on the resulting lot sizing strategy and the associated operational cost and carbon emissions. The importance of conducting such analysis is that it aids the policymakers in setting appropriate values for these caps to effectively reduce the carbon emissions rather than doing so in a complete ad-hoc manner. From the individual corporations' perspective, it greatly helps them capitalize on and maneuver within the caps imposed by the legislative entities through adopting the most-cost effective lot sizing and shipping policy that is in accordance with the allowed caps limits. It shall be noted that the analysis carried hereafter is based on the illustrative example presented in the appendix, wherein the chosen values for the carbon cap respect the established limits. Table 4 and Figure 3 , respectively. price. As such, as the total cap is relaxed (i.e., assumes a higher value), this resource becomes more abundant and each additional ton of the emissions cap becomes less worthy. That is, it can be seen from Table 3 that as the total cap is increased, the optimal value decreases until reaching the * upper limit of the feasibility range, or the unconstrained carbon cap policy, at which point the optimal dual price value . Besides the important role of the Lagrange multiplier in assessing * = 0 the performance of the carbon tax and the carbon cap policy (as seen in Lemma 2), it also provides the policymaker with valuable information on the value of each additional ton of emissions cap helping ultimately with the setting of appropriate values for those caps. Insight 2: As the total emission cap becomes less tight, more frequent shipments take place and/or more trucks are utilized in conjunction with fewer number of freezer units turned on (see Table 3 ). This pattern is justified as the model takes advantage of the increased permits on the cap and thus strives to minimize the operational cost, through minimizing the holding and freezers operational costs, at the expense of an increase in the ordering and transportation costs, where the savings in the former two cost components outweigh the increase in the latter two. As can be seen from Figure   2 , a stepwise decrease (increase) in the operational cost (total emissions) is realized for higher values of the emissions cap. Explicitly accounting for the limited trucks and freezers capacities induce such stepwise behavior where the Lagrange multiplier, and accordingly the lot sizing policy, remains the same for a range of the emission cap values. Insight 3: Through making operational adjustments to the lot sizing strategy, it might be possible to substantially reduce carbon emissions without significantly compromising the operational cost. As can be seen from Table 3 Table B2 . We did not present the results for the second case (periodic cap) as we observed almost the same effect for most of the parameters, with few exceptions, where the justification behind such exceptions is provided at the end of the previous section. Surprisingly, the increase in the holding cost did not affect the total number of orders placed over the planning horizon. Typically, as the holding cost increases, one would expect the lot size to decrease at the expense of an increase in the number of orders. However, it should be noted here that the total cost represents a tradeoff between the holding and ordering cost on one end, and the trucks and freezers cost on the other end. For smaller lot sizes, there will be a need for more trucks due to more orders and, consequently, larger trucks related costs. Accordingly, in order to minimize the overall cost function, it is more economical to maintain the same number of orders for larger holding cost rates. Additionally, the increase in the holding cost did not have any impact on the total carbon emissions or the number of trucks and freezers used over the planning horizon. This can be explained by the same rational provided above. As can be noted from Figure 4 , increasing the holding cost resulted in an increase in the optimal Lagrangian multiplier value, which implies that the carbon tax policy will result in smaller (larger) total operational cost (carbon footprint) than the carbon cap policy over a wider range of tax values. Such implication is justifiable using the results of Lemma 2. Holding cost (h) Lagrange multiplier (λ) Figure 4 . Impact of the holding cost on the Lagrange multiplier value ( ) Turning to the ordering cost, as anticipated, the obtained results indicate that an increase in this cost would lead to a decrease in the number of orders with an accompanying increase in the number of operational freezers (see Figure 5 ). Furthermore, increasing the ordering cost triggers a decrease in the optimal value of the Lagrangian multiplier, and an increase in the amount of carbon footprint generated (as seen in Figure 6 ). As opposed to the holding cost, while the ordering cost is increased, it prevails over the rest of the cost components (trucks and freezers costs) leading the model to prefer a reduction in the number of orders while naturally utilizing more freezers due to the increase in the lot sizes. The heightened levels of carbon footprint is attributed to better utilization of the trucks capacities through FTL shipments, where the CO 2 emissions are related to the load as explained in Appendix A. Lastly, the induced reduction in the Lagrangian multiplier results in a smaller range for the tax values for which the carbon tax policy outperforms that of the carbon cap in terms of the operational cost while yielding larger carbon footprint. As for the driver's wage, it turns out that increasing this fixed component of the transportation cost leads to smaller values (see Figure 7) , while the number of orders, trucks * and freezers utilized as well as the associated carbon footprint remain unchanged. This is caused by the fact that the variable fuel based transportation cost outweighs the fixed transportation cost since the former is a key component that contributes to the carbon footprint, which has to be maintained within the imposed cap. Accordingly, all carbon related variables ( , and ) ( ) remain unchanged. For the obtained reduction in the value, the same rationale provided above * for the ordering cost holds true. sizes can be shipped and, therefore, less total number of orders are placed and fewer total number of trucks will be used. As can be noted from Table 5 , the medium size truck ( units) = 1125 yields the lowest operational cost and CO 2 emissions, and shall thus be selected. Upon increasing the fuel price (pg), the observed outcome is a decrease in the total carbon footprint as well as the number of trucks and the number of orders whereas the number of freezers increased (see Table 6 ). Clearly, the reduction in CO 2 emissions is attributed to the use of fewer trucks where this reduction outweighs the additional emissions as a result of using more freezers. In order to minimize the fuel consumption related cost associated with larger values of the fuel price, the number of trucks (and orders) have to be decreased, which is what we observed. Obviously, decreasing the number of orders implies an increase in the lot size and the initial inventory in each period and consequently the number of freezers needed to accommodate them. Finally, it is noted that varying the electricity price (EP) had no apparent impact on the lot sizing policy as it only affects the freezer related cost where this cost is overshadowed by the other cost components. In principle, as the electricity price increases, one may expect the number of freezers to decrease and accordingly smaller initial inventory and lot sizes are realized. However, such a decrease would imply an increase in the number of trucks and the number of orders, and consequently the trucks and ordering related costs. In order for this not to happen, the number of freezers, trucks, and orders remains the same.@story_separate@In adherence to external pressures from legislative entities and conscientious customers with regard to carbon emissions, companies are constantly facing the challenge to adopt environmentally friendly practices that aim at reducing their generated carbon footprint. To that end, this paper tackles the lot sizing problem of a temperature-sensitive product having a limited shelf life while accounting for environmental constraints via the carbon cap regulatory policy. We present mathematical models to address the two scenarios where the carbon cap is imposed on the emissions generated throughout the planning horizon or those generated per period. For each case, solution algorithms that yield the optimal ordering strategy are developed. For the first case, a hybrid Lagrangian relaxation and Bisection based solution approach is developed to obtain the optimal ordering policy, after establishing the upper and lower bounds on the total emissions. Through the use of the Lagrangian multiplier, we compare the performance of the carbon tax and the carbon cap policies from both environmental and economic perspectives, which ultimately aids the policymakers in choosing the most effective policy. For the second case, a dynamic programming based solution algorithm is devised which also guarantees the convergence to the optimal lot sizing policy. Furthermore, a one-way sensitivity analysis is conducted on the key model parameters to assess their impact on the lot sizing policy, and the resulting operational cost and carbon emissions. The results indicate that operational adjustments to the lot sizing strategy may pose as a viable and a more affordable alternative towards reducing carbon emissions as compared to making substantial investments in costly energy-efficient technology. Also, it turned out that making operational adjustments, through modifying the order quantities and accordingly the number of trucks and freezers used, may significantly reduce the carbon footprint generated at the expense of a minor increase in the operational cost. Furthermore, it is noted from the computational analysis that the operational cost (carbon emission) is decreasing (increasing) with higher values of the carbon cap, where the later increase could possibly take place on an intermittent basis for the periodic carbon cap case. The work presented in this paper provides the policymakers or legislative entities with a decision making tool to aid them in setting appropriate values for the carbon caps towards effectively reducing the carbon emissions rather than doing so in a complete ad-hoc manner. From the corporate decision making perspective, once those caps have been set, individual corporations may make use of this work to establish the most cost-effective lot sizing and shipping policy that adheres to the imposed cap limits whilst attaining operational efficiency goals. The work presented in this paper may be extended in several directions. One may opt to analyze similar problem settings to the one presented herein but for a more involved supply chain structure encompassing multi stages with one or more firm at each stage. Similarly, this work tackled a single cold product situation while an interesting extension would be to explore the multi cold product case which further complicates the analysis and renders a more challenging problem to solve. The consideration of other regulatory policies, such as cap-and-trade, or situations wherein the demand is stochastic, rather than deterministic, pose as other promising future research avenues. Finally, our work could be extended to situations of unforeseen disruptions such as the recent COVID-19 outbreak through devising contingency plans that seek to prioritize logistics needs in terms of required storage and transportation capacity against the uncertainties pertaining to the availability and delivery of the items (see Ivanov and Dolgui, 2020) . In such times of rising uncertainties, considering the resilience profiles of involved firms as well as the pre-booking of logistics capacity to minimize cost becomes the imperative rather than a choice. To that end, deploying simulation based approaches is of particular significance towards assessing the negative effects of such disruption and developing effective risk mitigation strategies (see Aldrighetti The freezers at the retailer's facility are held accountable for high levels of energy consumption and increased amount of CO 2 emissions. In particular, the carbon footprint generated per period due to cold storage activities is a function of the number of freezers operational during that period ( ), the energy consumption by one freezer operated for one period, and the carbon footprint of one kWh energy. It is thus given by: * * , or * , where (A11) = * Using equations (A8) and (A10), the carbon footprint generated due to transportation and storage activities during period t is:","Amid the ever growing interest in operational supply chain models that incorporate environmental aspects as an integral part of the decision making process, this paper addresses the dynamic lot sizing problem of a cold product while accounting for carbon emissions generated during temperature-controlled storage and transportation activities. We present two mixed integer programming models to tackle the two cases where the carbon cap is imposed over the whole planning horizon versus the more stringent version of a cap per period. For the first model, a Lagrangian relaxation approach is proposed which provides a mean for comparing the operational cost and carbon footprint performance of the carbon tax and the carbon cap policies. Subsequently, a Bisection based algorithm is developed to solve the relaxed model and generate the optimal ordering policy. The second model, however, is solved via a dynamic programming based algorithm while respecting two established lower and upper bounds on the periodic carbon cap. The results of the computational experiments for the first model display a stepwise increase (decrease) in the total carbon emissions (operational cost) as the preset cap value is increased. A similar behavior is also observed for the second model with the exception that paradoxical increases in the total emissions are sometimes realized with slightly tighter values of the periodic cap."
"The social and economic costs associated with medical errors are staggering. 1 Reducing accidents and errors is a major focus of hospital quality programs and an international policy imperative. 2 Engaging patients is increasingly recognized to be an important component of safety initiatives [3] [4] [5] and a logical extension of efforts to involve patients in the health care process. 6 Patients are present at the point of care where errors may occur, able to detect medically relevant incidents, 7 concerned about their safety, [8] [9] [10] and correspondence: charles e cunningham ron Joyce children's health centre, child and Youth Mental health Program, 237 Barton street east, hamilton, On l8l 2X2, canada Tel +1 905 521 2100 ext 77307 Fax +1 905 577 8453 email cunnic@hhsc.ca motivated to improve the quality of the care they receive. 11 Patients have been encouraged to reduce hospital-acquired infections by cleaning their hands and reminding service providers to observe hand hygiene protocols. 12 They have been asked to contribute to the prevention of diagnostic errors, 13 check medications, 14, 15 join safety committees, 6, 16 voice their safety concerns, 17 and notify health care workers if errors are detected. 18 The likelihood of engaging patients in safety partnerships varies as a function of the demographics of both patients and their service providers. Younger patients with higher levels of education, greater health literacy, and more accurate information about potential risks prefer a more active role in the delivery of safe care. 8 Engagement in safety initiatives also varies with the professional background of the health service providers with whom patients must partner. Patients, for example, are much more likely to direct questions regarding hand hygiene to nursing staff than to physicians. 12 Davis et al 12 reported that, across three studies, 90%-100% of participants questioned nurses about hand hygiene, whereas only 32%-40% asked physicians. Participation in safety partnerships is also linked to the experiences and attitudes of patients. Although many patients believe that they can contribute to safer hospital care, 19 their willingness to participate in safety initiatives varies as a function of their risk perceptions, 3 exposure to medical errors, 3 and beliefs regarding their role in safety. 12, 20 Cognitive models, such as the Theory of Planned Behavior, predict that the intent to participate would reflect expectations regarding the effectiveness of risk reduction strategies, encouragement by significant individuals, and confidence in one's ability to contribute to prevention. 11, 12 The type of safety partnership patients are asked to participate in exerts a strong influence on their engagement. 11, 19 Discharged inpatients would be more comfortable questioning nurses and doctors about medications than asking whether they had cleaned their hands. 6 Indeed, while 75.2% reported that they had inquired about medications, only 4.6% asked whether staff had cleaned their hands. 6 Patients are reluctant to make comments that might be perceived to challenge the authority or competence of service providers. 8, 21 They are concerned that health service providers may respond negatively, 11 patients may be labeled as difficult, 3 their relationship with service providers may be compromised, and the quality of the care they receive may be affected. 17 Studies of the attitudes of professionals provide some support for these concerns. 22 Efforts to engage patients in safety initiatives have included badges encouraging patients to ask whether health care providers cleaned their hands, 12 posters depicting the correct administration of key health care strategies, 23 or personal requests from health care professionals. 12 In one study, patients felt that they would be more than twice as likely to ask whether nurses or physicians had cleaned their hands if health care workers provided an invitation. 24 Although the best strategy seems to be a personal invitation from health care providers, 12 relative preference for, and effectiveness of, different engagement strategies is not well understood. This issue is one focus of the current study. Although the mechanisms via which patients might contribute to a reduction in medical errors seem clear, Berger et al concluded that ""while patient engagement in safety is appealing, there is insufficient high quality evidence informing real-world implementation."" 25 Systematic reviews suggest that there is a need for research regarding the effectiveness of efforts to engage patients, the contribution of patients to a reduction in errors, improvements in health outcomes, or the potential risks of engaging patients in safety partnerships. 11, 12, 16, 25 Ultimately, an effective engagement strategy is a prerequisite to a successful patient safety partnership. To engage patients, the design of safety partnerships needs to be informed by the preferences of potential participants. 11, 26 Although studies have asked patients for feedback on safety initiatives, few have included patients in the design and development process. 12 Davis et al 12 reported that only two of 23 studies included in a systematic review indicated that patients had been engaged in the design process.@story_separate@We extend research in this area by using a discrete choice conjoint experiment (DCE) to engage a large sample of patients, or those acting on their behalf, in the design of an approach to hospital safety partnerships. 27 Although DCEs have been applied to the design of other risk reduction strategies, 28 this is, to our knowledge, the first application of these methods to the study of hospital safety partnerships. DCEs make a methodological contribution to safety research by engaging the multistage decision strategies likely to influence the intent to participate in real-world safety initiatives, 29 reducing the influence of social desirability biases, 30 and improving the estimates of the relative value of the individual components of complex safety initiatives. 31 We explored four general research questions (RQs) and examined six more specific hypotheses (HYPs). 12 we examined relative preferences for partnerships that might include medication and identity double checks or membership on hospital safety committees. Previous studies suggest that, while patients respond positively to safety partnerships focusing on strategies to ensure the accuracy of medication administration, 6 they are uncomfortable in addressing staff compliance with hand hygiene protocols. 6 We predicted, therefore, that: HYP 1. Patients would show a stronger preference for partnerships involving medication double checks than for those asking staff to clean their hands. Although patients recognize the value of hand hygiene, 24 they are hesitant to participate in safety partnerships that involve questioning staff. 8, 21 We predicted that: HYP 2. Participants would prefer partnerships focusing on hand hygiene for patients rather than an approach encouraging patients to remind staff to clean their hands. Although previous studies do not provide a basis for specific HYPs, we extend research in this area by exploring a set of partnership features that might influence the decision to participate. These included the way in which risk information is communicated to patients, sources of evidence regarding the benefits of safety partnerships, the process via which patients are engaged in safety partnerships, strategies for providing the training needed to participate, processes for reporting errors, and organizational responses to safety concerns. RQ 2: Are there segments preferring different safety partnerships? Patients hold different attitudes regarding their role in their health 32 and safety. 6, 20, 33, 34 A patient-centered approach to safety partnerships needs to reflect these differences. Using latent class analysis, 35  This study was approved by the Hamilton Integrated Research Ethics Board. Data were collected in a regional service, which included a pediatric hospital and five affiliated hospitals serving a population of 2.2 million Canadians. In outpatient waiting areas and inpatient rooms, a hospital staff member asked patients or those acting on their behalf (eg, parents of children, partners, or friends) if they would consider participating. If they agreed, a research team member explained the study, obtained electronic consent, and administered the survey on a laptop computer. Of 1,883 approached, 1,609 (85.4%) agreed to consider participation. A member of the research team presented the study to 1,567 potential participants (42 of 1,609 were called for an appointment before the study was presented). Although 1,475 agreed to participate, 380 were called for service before completing the survey, eight equipment failures occurred, and nine declined to participate. Overall, 1,084 completed the DCE. Our sample size is consistent with the recommendation of 200 participants per segment. 31 Demographics are summarized in Table 1 . We developed safety partnership attributes in several steps. 41 Focus groups or individual interviews were conducted with patients (n=18), family members or support persons (n=6), a Family Advisory Council (n=6), staff (n=18), and physicians (n=1). The Family Advisory Council consisted of parents, family members, and community representatives who collaborate with health professionals and leaders to promote family-centered care. Staff participating in focus groups or interviews included registered nurses, physiotherapists, occupational therapists, imaging technologists, clinical managers, and environmental aides. Recordings were transcribed and summarized thematically. Next, we identified widely disseminated safety partnerships and attributes of the implementation process that might influence patient decisions (eg, safety partnership decision making or training). Using a consensual process, we narrowed this information to 15 safety partnership attributes. Attributes ranged from the point of care (eg, medication and identity double checks) to policy and governance (safety committee membership). 26 Each attribute included four levels 42 selected to combine logically with the levels of other attributes. 31, 41 We included a level depicting the absence of most attributes. 31 experimental design and procedure Each participant completed 17 choice sets. Each set presented three safety partnership profiles or options ( Figure 1 ). Participants were instructed that ""Below are three ways to make health care safer. Click below the option you would prefer."" We used a partial profile design to simplify choices and improve the performance of participants. 43, 44 Each profile included the levels of two attributes. Sawtooth Software's experimental design algorithm created the attribute combinations appearing in each choice set. 44 Given a main effects design, the attribute levels in each profile did not overlap. The survey defined the term ""staff"" as doctors, nurses, health care providers, and administrative personnel. The term ""patients"" was defined as patients or their family members. 41 Participants completed one warm-up task, 17 choice sets, the Safety Partnership Attitudes Questionnaire described in Figure S1 , and demographic questions (a median completion time of 13.4 minutes).  To explore attitudes that might influence safety partnership preferences, we developed a Safety Partnership Attitudes Questionnaire reflecting the components of the Theory of Planned Behavior, a model linked to participation in safety initiatives. 45 We composed 33 Likert-type scale questions (strongly disagree to strongly agree) reflecting the Theory of Planned Behavior's five subscales. Attitudes measured the anticipated benefits of patient safety behaviors. Subjective norms measured contextual and social factors encouraging participation in safety partnerships. Perceived behavioral control: self-efficacy reflected confidence in one's ability to contribute to safety partnerships. Perceived behavioral control: barriers reflected factors that might prevent participation in safety partnerships and intent reflected the stated willingness to participate in different safety partnership activities. Questions from the Safety Partnership Attitudes Questionnaire and internal consistency scores from this study appear in the Supplementary material. As described elsewhere, 46 we used a latent class program (Latent Gold Choice 4.5) to group participants with similar safety partnership preferences into classes. Utility coefficients, reflecting preference for the levels of each safety partnership attribute, were estimated for each class. 47 Three covariates were included in the latent class model: 35, 47 intent to participate in safety partnerships (from the Safety Partnership Questionnaire), education (high school or less versus some college or higher), and status as a patient versus parent or person acting on behalf of a patient. A maximum likelihood solution with 1, 2, 3, 4, and 5 classes was estimated. To avoid an unrepresentative model, each solution was computed ten times from different starting points. 35, 47 Using Latent Gold's individual utility coefficients, importance scores were derived by converting the range of the utility coefficients of each attribute to a percentage of the total range across attributes. 47 Importance scores reflect the relative influence of variation in the levels of each safety partnership attribute on choices. As described elsewhere, 46 HYPs 5 and 6 were examined by entering Latent Gold Choice 4.5's individual utility coefficients into Sawtooth Software's Randomized First Choice simulator. 48, 49 Simulations predict each participant's response to hypothetical safety partnerships created by combining the levels of several attributes. Across 200,000 iterations estimating two sources of error, the simulator assumes that participants would choose a safety partnership with a combination of attribute levels yielding the greatest utility. 48, 50 reliability and validity We included identical ""hold-out"" choice sets at positions 7 and 13 in the 17 set sequences. 31, 41 These choices were not used to compute utility coefficients. 31 Reliability analysis showed that 96% of participants made identical choices to the two hold-out sets. Simulations based on the remaining choice data predicted the percentage of participants choosing each option. For both hold-out sets, the difference between predicted and recorded choices was 1.4%. This measure, mean absolute error, shows high predictive validity. 31 Based on modeling studies, our goal was to identify a latent class model that minimized Bayesian Information Criterion values and yielded an interpretable solution with administratively manageable sample sizes. 51 A two-class model yielded the lowest Bayesian Information Criterion, the lowest Consistent Akaike Information Criterion, and the highest (Table 3 ). Both segments preferred that patients and staff double check patient's identity and medication accuracy. Consistent with HYP 2, an initiative encouraging patients to clean their hands was more important than asking patients to remind staff to clean their hands. Both segments preferred signs (versus staff or volunteers) reminding patients to wash their hands and to ask staff if they had washed their hands (Table 3) . communicating risk and safety information to patients Disclosure of risks exerted an important influence on choices ( Table 2 ). Both segments preferred that all patients were informed of risks and that staff encourage patients to ask about safety (Table 3) . The safety reporting process and the hospital's response to safety questions exerted a moderate influence on choices ( Table 2 ). Both segments preferred that patients report safety concerns directly to staff and that those reporting concerns were thanked and informed about the hospital's response ( decide whether to give their names when reporting safety concerns (Table 3) , variations in the anonymity afforded patients reporting concerns exerted little influence on choices ( Table 2) . Although utility values suggest that a collaborative approach to safety partnership decisions was preferred (Table 3) , variations in the levels of this attribute exerted a limited influence on choices (Table 2 ). rQ 2: Are there segments preferring different safety partnerships? Actively engaged and passively engaged segments of the two-segment latent class solution were consistent with HYP 3's predictions. We consider differences in these segments subsequently. Covariate analysis suggests that membership in the actively engaged segment was linked to higher education, P,0.001, and a greater intent to participate in safety partnerships, P,0.01. The status of informants as patients versus those acting on behalf of patients was not associated with segment membership, P=0.09. The actively engaged segment was likely to be younger, outpatients, born in Canada (Table 1) . Scores from the Safety Partnership Attitudes scale (Table 4) address HYP 4. As predicted, actively engaged participants anticipated greater benefits to partnerships, reported more confidence in their ability to contribute, and expressed a stronger intent to participate. This segment preferred that staff present the research supporting safety partnerships (Table 3) . Although they preferred simply reading how to make care safer, they also responded positively to a multicomponent approach, including readings, videos, and checklists. The actively engaged segment preferred that staff, rather than signs, encourage patients to report safety concerns and that staff disclose all mistakes. Membership in the passively engaged segment was associated with lower education and a lower intent to participate in safety partnerships. Participants who were immigrants were more likely to reside in this segment ( was less confident in their ability to contribute ( Table 4 ). The utility values show that they preferred staff to decide whether patients were informed of mistakes (Table 3 ). Importance scores show that the safety partnership decision-making process was among the attributes exerting the least influence on choices. In contrast to the evidence-informed approach preferred by the actively engaged segment, passively engaged participants preferred that staff explain why they (rather than research) felt patients should participate in safety partnerships. Patient representation on hospital safety committees was more important to the passively engaged segment than to the actively engaged segment; they preferred that patients were represented on all safety committees. rQ 3: To what extent do patients prefer a collaborative approach to safety? To explore this question, we simulated each participant's response to three approaches to safety. While utility coefficients examine relative preference for the individual levels of each attribute, simulations capture the complexity of multicomponent, real-world safety initiatives. 12 We manipulated the levels of three attributes while holding 12 constant. According to the safety partnership model, patients received safety training that 1) included readings, videos, and checklists. Both patients and staff double checked that 2) staff helped the right patient and 3) medications were correct. According to the staff safety model: 1) patients did not learn to make care safer. Staff double checked that 2) they were helping the right patient and 3) medications were correct. In the control condition, 1) patients did not learn to make care safer, and no one double checked that 2) staff were helping the right patient, and 3) medications were correct. Consistent with HYP 5 simulations predicted that both actively (100%) and passively engaged (91%) participants would prefer partnerships with staff rather than a model delegating safety to staff alone (Table 5 ). rQ 4: What type of engagement strategy do patients prefer? We used Randomized First Choice simulations to address this question and to examine HYP 6's prediction that patients would prefer that staff personally engage them in safety partnerships. We manipulated the levels of four attributes while holding eleven constant. According to the personal engagement model, staff encouraged patients to 1) ask about safety, 2) report concerns, 3) clean their hands, and 4) remind staff to wash their hands. According to the visual engagement model, signs encouraged patients to 1) ask about safety, 2) report concerns, 3) clean their hands, and 4) remind staff to clean their hands. In the control condition, patients were not  This study modeled the safety partnership preferences of health service users. Although DCEs represent a standard approach to the assessment of health service preferences, 27 we believe this is their first application to the study of safety partnerships. Our findings contribute to research on this topic by estimating the relative value of the different features of multicomponent approaches to safety, demonstrating important individual differences in preferences, and simulating the response of participants to different engagement strategies. rQ 1: What features of safety partnerships are most important to each segment? As predicted, participants preferred point of care initiatives such as medication and identity double checks that might contribute to an immediate reduction in personal risk. The administration of medications, for example, represents a significant source of error. 52 Double-checking medications exerted a stronger influence on choices than any other attribute. This is consistent with studies suggesting that patients rate double checks, and related approaches to the prevention of medication errors, very positively. 19, 21 Hand hygiene campaigns, in contrast, exerted a limited influence on safety partnership choices. Consistent with HYP 2, participants were more likely to choose partnerships prompting patients to wash their hands than those encouraging patients to remind staff to wash their hands. This finding is consistent with research suggesting that patients consider asking staff whether they have cleaned their hands to be less effective than other strategies and themselves to be less likely to participate in these programs than in other risk reduction initiatives. 21, 53 Waterman et al 19 reported that only 5% of 2,078 post-discharge inpatients asked nurses or doctors whether they had cleaned their hands. This is consistent with evidence that patients are reluctant to engage in partnerships that might be perceived to challenge the competence of service providers. 8 rQ 2: Are there segments with different safety partnership preferences? Consistent with HYP 3, latent class analysis revealed two segments that might be expected to respond to different safety partnerships. Younger outpatients with higher education were more likely to be members of an actively engaged segment that valued scientific evidence that patients could improve safety. As HYP 4 postulated, they anticipated more benefits to safety partnerships and expressed more confidence in their ability to contribute. As the Theory of Planned Behavior predicts, they were more intent on participating. 11 They showed a stronger interest in multifaceted approaches to safety education, preferred personal reminders, and advocated complete disclosure of errors. In previous studies, patients with higher activation scores engage in more preventive activities, are more likely to follow treatment protocols, evidence better health outcomes, incur fewer costs, and evaluate care experiences more positively. 32 Passively engaged participants anticipated fewer benefits to safety partnerships, were less confident in their ability to contribute, and less intent on participating. They preferred that staff give a rationale for safety partnerships and decide whether patients were informed of errors. In comparison to the actively engaged segment, patient representation on safety committees was more important to the passively engaged segment. Passively engaged participants, who may be less comfortable expressing their concerns, may value patient representatives who can speak on their behalf. Participants with immigrant backgrounds, less education, and receiving services as inpatients were more likely to be members of the passively engaged segment. These findings are consistent with studies linking limited education and lower levels of health literacy 54 to a preference for a less active role in health 32,36 and safety. 3, 8, 19, 55 The Theory of Planned Behavior predicts that enhancing self-efficacy should increase the intent to participate. 11 Although utility values showed that actively engaged participants preferred to read how to make care safer, they also responded positively to a more comprehensive multimodal approach to safety education utilizing readings, videos, and checklists. Passively engaged participants, in contrast, preferred to simply read about safety strategies. However, when the medication and identity double-checks participants valued were included in a multicomponent (readings, videos, and checklists) educational strategy, simulations predicted that 91% of the passively engaged segment would choose an approach including this active learning option. The results of simulations reveal attitudinal processes via which highly valued attributes Consistent with HYP 5, simulations predicted that, rather than delegating responsibility for safety to hospital staff, 97.6% of our study participants would prefer partnerships between staff and patients. The strength of this finding is consistent with a study reporting that 91% of a sample of discharged inpatients agreed that patients could contribute to the prevention of health service errors. 19 rQ 4: What type of engagement strategy do patients prefer? HYP 6 postulated that patients would prefer a personal engagement strategy rather than visual safety prompts. Simulations predicted that 57.5% of the study participants would prefer a personal strategy in which staff engaged patients in safety partnerships. This is consistent with evidence that encouragement by doctors and nurses may increase participation. 12 In contrast, 42.4% would prefer an approach with signage reminding patients to ask about safety, report safety concerns, and wash their hands. Preference for a visual communication strategy was strongest in the passively engaged segment. We were surprised by the number of participants predicted to choose a visual strategy. There may be several explanations for this finding. Patients, for example, may perceive signs to be less of a burden to staff than a personal discussion. 3 In a sample of 277 health care workers, 26% felt there was insufficient time to encourage patients to ask about hand washing. 22 Signs may also put less pressure on those who find safety partnerships inconsistent with their perception of the patient's role. In addition to their alignment with the preferences of a significant number of participants, the signage and visual prompts included in a range of health, safety, and infection control initiatives 56, 57 can simultaneously inform patients, family members, staff, and the administrators who are critical to the success of large-scale safety initiatives. 39, 58 Signs can be prepared in multiple languages, use an array of interactive strategies, allow patients to review safety recommendations, and facilitate the positioning of reminders at key points along the health service pathway. 59 Despite these advantages, effective signage requires careful attention to visual appeal, content, health literacy, and culture; 39,60,61 evidence regarding its unique contribution to hospital safety is lacking. 39 Although decision-making processes exerted less influence than many other partnership design attributes, both segments preferred an approach to safety based on shared decisions. Neither segment chose to delegate safety decisions to staff, nor to make these decisions independently. Systematic reviews show that patients are more likely to adhere to health services that are consistent with their preferences. 62, 63 Collaborative decisions, therefore, are more likely to promote the engagement that enhances the patient experience and improves outcome. 32 Informed decisions require an awareness of the risks safety partnerships might reduce. Risk information exerted an important influence on partnership choices. Both segments preferred that all patients were informed about risks to safety. Awareness of risks is associated with greater confidence in one's ability to prevent medical errors. 21 Confidence in one's ability to prevent medical errors (self-efficacy), in turn, predicts the intent to act preventively. 21 Both segments preferred that patients report safety concerns directly to staff and that those conveying safety concerns were thanked and told how the hospital will respond. Although both segments preferred that patients decide whether to give their names when reporting safety concerns, variations in the anonymity afforded those reporting safety concerns exerted relatively little influence on choices. limitations This study was conducted in Ontario, Canada, a province in which local media coverage of issues such as SARS (severe acute respiratory syndrome) and Avian flu might have altered public perceptions of the risks of hospital-acquired infection and the importance of participation in infection control strategies. 64, 65 Results require replication. We defined the term staff as doctors, nurses, health care providers, and administrative personnel. The finding that patients are more likely to engage in safety partnerships that may challenge nurses rather than doctors 66 suggests that future studies should examine preferences for partnerships with different health service providers. Although the waiting areas in which most surveys were completed may have increased the survey's contextual validity, return rates were reduced: 26% of those prepared to consider participation were called for appointments before completing the survey. Because this sample loss was related to organizational factors beyond patient control, it did not, in all probability, represent a systematic enrollment bias. @story_separate@Participants preferred point of contact safety partnerships that might afford an immediate reduction in risk. They valued collaborative decisions supported by information regarding risks, errors, and the benefits of safety partnerships. Health service providers need to ask patients about their goals and preferences, ensure the safety partnerships available reflect the views of different segments, teach the skills needed to participate, enhance self efficacy, and ensure a receptive response when patients participate or raise safety concerns. Respecting individual differences in safety partnership preferences should enhance engagement, improve health outcomes, and contribute to a more positive patient experience. 32","BACKGROUND: Patients and their families play an important role in efforts to improve health service safety. OBJECTIVE: The objective of this study is to understand the safety partnership preferences of patients and their families. METHOD: We used a discrete choice conjoint experiment to model the safety partnership preferences of 1,084 patients or those such as parents acting on their behalf. Participants made choices between hypothetical safety partnerships composed by experimentally varying 15 four-level partnership design attributes. RESULTS: Participants preferred an approach to safety based on partnerships between patients and staff rather than a model delegating responsibility for safety to hospital staff. They valued the opportunity to participate in point of service safety partnerships, such as identity and medication double checks, that might afford an immediate risk reduction. Latent class analysis yielded two segments. Actively engaged participants (73.3%) comprised outpatients with higher education, who anticipated more benefits to safety partnerships, were more confident in their ability to contribute, and were more intent on participating. They were more likely to prefer a personal engagement strategy, valued scientific evidence, preferred a more active approach to safety education, and advocated disclosure of errors. The passively engaged segment (26.7%) anticipated fewer benefits, were less confident in their ability to contribute, and were less intent on participating. They were more likely to prefer an engagement strategy based on signage. They preferred that staff explain why they thought patients should help make care safer and decide whether errors were disclosed. Inpatients, those with immigrant backgrounds, and those with less education were more likely to be in this segment. CONCLUSION: Health services need to communicate information regarding risks, ask about partnership preferences, create opportunities respecting individual differences, and ensure a positive response when patients raise safety concerns."
"The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) originated in Wuhan, China (1), in December 2019, and it has engulfed the world in an unprecedented global pandemic. The coronavirus disease 2019 (COVID-19) associated with this virus has caused more than 16.8 million new cases and 662,000 deaths as of July 30, 2020 (2) , generating a high burden of disease that has exceeded the assistance capacities of several healthcare systems around the world. The clinical characteristics of patients with COVID-19 are similar to those observed during the outbreak of SARS-CoV-1, which emerged in 2002-2003, causing more than 8,000 confirmed cases and ∼800 deaths (3) . As such, the human infection with SARS-CoV-2 mainly affects the lower respiratory tract, causing mild to moderate respiratory symptoms in about 85% of patients with COVID-19 (4) (5) (6) , including fever, headache, fatigue, myalgia, dry cough, and diarrhea. Most symptomatic individuals are men in their fifth and sixth decades of life that attend medical centers after an incubation period of about 4 to 5 days (4) (5) (6) (7) . Another 15% of patients present moderately severe forms of the disease manifested as pneumonia of atypical features in radiological studies of the lung, such as bilateral multi-lobe consolidations and ground-glass opacities (8) . Finally, in 5 to 30% of COVID-19 patients, the virus causes severe acute respiratory syndrome (SARS), which is characterized by profound respiratory distress that obligates the establishment of intensive life support interventions, such as intubation and mechanical ventilation (4) (5) (6) . Initial reports estimated mortality rates of about 2 to 4%. However, new analyses indicate a higher lethality of COVID-19 (9) , especially among individuals older than 65 years, and patients with comorbidities (4) (5) (6) . Unfortunately, the risk of a fatal outcome is disproportionally higher among patients requiring mechanical ventilation, with a mortality rate close to 80% (7) . The rapid transmission of SARS-CoV-2 and the increasing number of positive cases reported around the world have overcome the resources of the healthcare systems in different regions. This has significantly impacted all areas of medicine, especially those directly related to the management of severe respiratory infections, such as pneumology and critical care medicine. Nonetheless, SARS-CoV-2 has the potential to spread to different extrapulmonary tissues, and, in some of the most severe cases, the infection can progress to multiorgan failure (5) . Therefore, all healthcare providers from any area of medicine must acquire adequate knowledge of the principal characteristics of COVID-19. Currently, there is increasing preoccupation about the potential capacity of SARS-CoV-2 to invade the central nervous system (CNS) and the peripheral nervous system (PNS). These concerns are based on recent observations in individuals infected with SARS-CoV-2 that present neurological findings (10) . A better understanding of the mechanisms underlying the neurologic sequela of patients with COVID-19 is urgent to discover novel targets for therapeutics development. In the current review article, we therefore provide an overview of the spectrum of neurological manifestations of COVID-19. Additionally, we analyze host-and pathogen-specific factors that determine the tissue tropism of SARS-CoV-2 and discuss the possible routes employed by the virus to invade the nervous system. Furthermore, we propose possible therapeutics for the neurologic complications of COVID-19.@story_separate@Virology SARS-CoV-2 is a novel member of the group of human coronaviruses (HCoVs), which is constituted of HCoV-229E, HCoV-NL63, HCoV-HKU1, HCoV-OC43, SARS-CoV, and MERS-CoV (11) . These are RNA single-stranded viruses belonging to the Coronaviridae family. Some of these pathogens have caused a variety of respiratory diseases in the past. For instance, SARS-CoV-1 infected more than 8,000 individuals around the world (3) . Also, the human coronavirus related to the respiratory syndrome of the Middle East (MERS-CoV), which emerged in Saudi Arabia in 2012 and caused high mortality rates among infected people (12, 13) . Based on sequence comparisons of viral genomes, HCoVs are grouped into four genera: alpha, beta, gamma, and delta coronaviruses. SARS-CoV-2 is a beta coronavirus genetically related to another bat coronavirus named BatCoV RaTG13 as well as SARS-CoV-1 (14, 15) . Furthermore, SARS-CoV-2 also shares its genetic identity with coronaviruses isolated from pangolins (16, 17) . Hence, it is believed that COVID-19 is a zoonotic disease that originated from bats or pangolins. The genome of SARS-CoV-2 consists of a single RNA strand of 29.903 bp that codifies for the replicase-transcriptase, as well as for the structural proteins spike (S), envelope (E), membrane (M), and nucleocapsid (N) (15) . The initial step of SARS-CoV-2 infection is the recognition of its receptors on the surface of host cells. This step is mediated by the viral spike (S) protein, which recognizes the human receptor angiotensin I-converting enzyme 2 (ACE2), the same receptor for the S protein of SARS-CoV-1 (18) (19) (20) . This protein owns two functional domains: the S1 domain contains the receptorbinding domain (RBD), which attaches to ACE2, whereas the S2 domain mediates the fusion of the viral and host cell membranes (20) . Therefore, the organ distribution of the ACE2 receptor is a crucial determinant of the virus infectivity and tropism. A second step determinant in the infection process of SARS-CoV-2 is the activation of the S protein. This process is mediated by different host proteases, which execute the cleavage of the molecule at the S1/S2 and S'2 sites. This protein processing allows the complete activity of the S2 domain and the fusion of the viral and cellular membranes. For this purpose, and as in the case of SARS-CoV-1, SARS-CoV-2 uses the transmembrane serine protease 2 (TMPRSS2) (19, 21, 22) . Interestingly, the proteases TMPRSS4 and cathepsin L also promote SARS-CoV-2 infection of human small intestinal enterocytes and 293/hACE2 cells (23, 24) . Hence, the tissue patterns of expression of TMPRSS2, TMPRSS4, and cathepsin L is another decisive factor that determines the tropism of the virus, and, indeed, some drugs that inhibit the activity of these proteases are now proposed as potential therapeutic agents to prevent and treat COVID-19 (19, 23) . Other factors implicated in the process of SARS-CoV-2 infection include the phosphatidylinositol 3-phosphate 5kinase (PIKfyve) (23) . This enzyme mediates the production of phosphatidylinositol-3,5-bisphosphate [PI (3, 5) P2], a phosphoinositide that participates in the maturation process of endosomes. Treatment with apilimod, a potent inhibitor for PIKfyve, reduced the infectivity of SARS-CoV-2 and could be a novel candidate for therapeutic applications. After the entry into host cells, viral replication begins with the translation of the replicase-polymerase gene and the assembly of the replication-transcription complex. This complex subsequently transcribes the genomic regions that codify for structural proteins. New virions are assembled in the endoplasmic reticulum and Golgi apparatus to finally egress from the cell (11) . A particular feature of SARS-CoV-2 is that it possesses a polybasic furin cleavage sequence (PRRA) in the S1/S2 site, which is absent in other close related coronaviruses (14, 20) . This inserted furin cleavage sequence is processed at the Golgi apparatus during the biosynthesis of the S protein of novel virions inside the host infected cells (20) . The novel virions of SARS-CoV-2 may thus contain an S protein primed and ready to infect any other cells expressing the ACE2 receptor, with no further requirement of TMPRSS2 activity. As virtually all cells express furin under normal conditions, the inserted furin cleavage sequence may expand the transmissibility and tissue tropism of SARS-CoV-2. Figure 1 illustrates the process of SARS-CoV-2 infection. The Immune Response Against SARS-CoV-2 SARS-CoV-2 elicits an exuberant immune response characterized by a dysregulated production of soluble immune mediators. This phenomenon has been called a ""cytokine storm"" and is responsible for mediating tissue damage in patients with COVID-19 that progress to severe illness (25) (26) (27) (28) . The immune receptors that recognize the viral infection and initiate the immune responses against SARS-CoV-2 are unknown. As this virus is genetically related to SARS-CoV-1, it is presumed that both viruses share mechanisms of infection. In this sense, SARS-CoV-1 is recognized by the toll-like receptors (TLR) TLR3 and TLR4, which induce an immune reaction via MyD88 and TRIF pathways (29, 30) . Furthermore, SARS-CoV-1 triggers the production of IL-1β through the activation of the inflammasome (31) . In this regard, the activation of the inflammasome is also possible to occur during SARS-CoV-2 infection, as high levels of IL-1β have been observed in COVID-19 patients (32) . Other immune mediators that are exaggeratedly produced in response to SARS-CoV-2 include IL2, IL-6, IL7, IL10, G-SCF, CXCL10, MCP-1, MIP-1A, and TNFα (5, 28, 33) . From these, IL-1β, IL-6, CXCL10, and TNFα are the cytokines with a higher capacity to generate tissue damage in several organs, including the CNS, due to their pro-inflammatory properties. For instance, IL-1β and IL-6 have been implicated in neurotoxicity associated with chimeric antigen receptor (CAR) T cell therapy in patients with hematological malignancies (34, 35) . These cytokines possess detrimental effects on endothelial function at several vascular niches, which may be implicated in the pathophysiology of the neurological complications of COVID-19, as discussed later. Notably, despite the dysregulated production of immune mediators, an ample range of immune cell subtypes are depleted from the circulation of patients with severe SARS-CoV-2 infection. These cells include monocytes, dendritic cells, CD4+ and CD8+ T cells, and NK cells (36) . Furthermore, the few adaptive lymphocytes that remain in the blood express markers of functional exhaustion (37) . These data suggest that severe COVID-19 is a state of immunosuppression similar to the known sepsis-induced immunosuppression (38) . However, it is also possible that the robust recruitment of functional immune cells to the sites of SARS-CoV-2 infection may explain the leukopenia observed during COVID-19. Several HCoVs, including SARS-CoV-1, have the potential to infect different human tissues and organs (39, 40) . Similarly, SARS-CoV-2 may also spread to several extrapulmonary tissues, including the CNS. Although recent analyses of autopsy specimens from patients with COVID-19 have not explored the presence of this virus in the brain (41), the neurological manifestations observed among individuals with COVID-19 (10) and the isolation of other human coronaviruses from neurological specimens support the notion of a possible neurotropism of SARS-CoV-2 (42) (43) (44) (45) (46) (47) . The neurotropism of other HCoVs has been extensively revised elsewhere (48) . As mentioned before, the patterns of expression of ACE2, TMPRSS2, TMPRSS4, furin, cathepsin L, and other entry factors used by SARS-CoV-2 for infection determine the tropism of the virus. The ACE2 receptor is highly expressed in cells of the alveolar epithelium (49, 50) , which explains the vulnerability of the lungs to infection. The expression of ACE2 has also been found in other tissues, including the oral mucosa, endothelium, heart, kidney, lymphoid organs, testis, gut, and urinary tract (49) (50) (51) (52) . Nonetheless, distribution of TMPRSS2 has been assessed in a limited variety of human tissues, showing high expression in prostate cells, respiratory epithelial cells, salivary gland, kidney, liver, stomach, small intestine, and colon (53) (54) (55) . TMPRSS2 is regulated by androgens (53) , which may explain the higher susceptibility of men to suffer from severe forms of COVID-19. Few studies have analyzed the expression of TMPRSS4 and cathepsin L in healthy human organs. According to the Human Protein Atlas (https://www.proteinatlas.org/) dataset, TMPRSS4 is present in the cerebral cortex, hippocampus, caudate, thyroid gland, adrenal gland, nasopharynx, bronchi, lung, stomach, duodenum, colon, rectum, gallbladder, pancreas, and genitourinary tract. Meanwhile, cathepsin L shows medium expression in lung and liver, and low expression at bronchi, salivary gland, liver, kidney, pancreas, and genitourinary tract. The expression in the human body of the known genes mediating the entry of SARS-CoV-2 into human cells coincides with the multiorgan pattern of COVID-19 manifestations. Nonetheless, the presence of such factors is low in the CNS under normal conditions. This may be in part because previous studies have only analyzed the bulk organ gene expression patterns of ACE2 and TMPRSS2. More recently, a comprehensive analysis of several single-cell RNA-seq databases showed that there are dual-positive ACE2+TMPRSS2+ cells in tissues beyond the respiratory system, including oligodendrocytes in the brain, and inhibitory enteric neurons (56) . Furthermore, ACE2+CTSL+ cells were enriched in the olfactory epithelium. These data support some of the possible routes of SARS-CoV-2 entry into the CNS discussed below. The mechanisms employed by SARS-CoV-2 to infect the nervous system are unknown. Currently, the hypotheses about the routes of viral entry into the CNS rely on previous observations made in experimental studies of SARS-CoV-1 infection. One hypothesis proposes that SARS-CoV-2 invades the brain by breaching the blood-brain barrier (BBB). Evidence in favor of this infection mechanism includes the high expression of the ACE2 receptor in endothelial cells of blood vessels (49, 50) . The virus may therefore infect endothelial cells of the brain vasculature in the first term, and it may then spread to the surrounding ACE2+TMPRSS2+ oligodendrocytes and, finally, to the neurons. This would explain why SARS-CoV-1 has been observed inside neurons even when they have a mild expression of ACE2 under normal conditions (39, 40, 57) . Despite this, SARS-CoV-1 has not been isolated from or observed inside endothelial cells (58) . Conversely, the high concentrations of pro-inflammatory cytokines in the systemic circulation of patients with severe forms of COVID-19 might induce structural and functional alterations of the BBB (5, 28, 59) . In this sense, it is well-known that different inflammatory mediators have detrimental effects on BBB integrity, increasing its permeability to neurotoxic molecules and immune cells (60) . SARS-CoV-2 could thus gain access to the CNS directly through a paracellular route or within the immune cells, a mechanism that has been called a ""trojan horse"" (61) . It might be feasible for this mechanism to occur during SARS-CoV-2 infection since the previous SARS-CoV-1 has also been observed inside different leukocyte subsets (40) . Secondly, the virus could enter the CNS through the olfactory epithelium, crossing the cribriform plate of the ethmoid bone and reaching the olfactory bulb from which it could spread to different areas of the brain (62) . This route was demonstrated in mice intranasally inoculated with SARS-CoV-1, among which a rapid viral spread from the olfactory bulb to the brain stem was observed. This exposure to the virus caused high lethality among infected animals due to the occurrence of neuronal death in the respiratory centers of the brain stem (63) . Similar results were observed in another animal model of CNS infection with the HCoV-OC43 coronavirus (64) . In humans, some studies demonstrated olfactory neuropathy in patients with SARS-CoV-1 infection (65) . Likewise, recent investigations have shown that the olfactory epithelium is enriched with ACE2+CTSL+ cells (56) . Moreover, hyposmia and anosmia are frequent manifestations of COVID-19 (10, 66) , suggesting that SARS-CoV-2 might also infect the olfactory bulb in COVID-19 patients. In light of these findings, some researchers have proposed that the neuroinvasive potential of SARS-CoV-2 could contribute to the respiratory failure observed in patients with severe COVID-19 (67) . Finally, as in the case of other respiratory viruses with neurotropic potential, including the influenza A virus (68), SARS-CoV-2 could gain access to the CNS through the vagus nerve. The terminals of this nerve are located along the respiratory and gastrointestinal tracts, sites with high expression of ACE2 (49, 50) and enriched with ACE2+TMPRSS2+ enteric neurons (56) . From these organs, the virus could gain access to the brain stem, taking advantage of the polarization of neurons and the machinery responsible for retrograde neuronal communication, or through endocytosis and clathrin-mediated exocytosis, as observed in the case of the transsynaptic transmission of the porcine coronavirus HEV 67N (69). The possible CNS invasion routes used by SARS-CoV-2 are illustrated in Figure 2 . Some of the initial descriptions of the clinical phenotype of patients infected with SARS-CoV-2 showed that up to 10% of individuals with COVID-19 manifested non-specific neurological symptoms such as headache and dizziness (5, 6, 70) . In a more recent report by Mao et al., a third of patients with COVID-19 presented non-specific neurological manifestations, including dizziness (16.8%), headache (13.1%), loss of consciousness (7.5%), and seizures (0.5%) (10) . Two recent systematic reviews and meta-analyses showed that headache and dizziness are among the most frequent neurological symptoms affecting COVID-19 patients (71, 72) . Interestingly, headache can occur even in the absence of fever and can be manifested as a migraine, tension-type, or cluster headache (73) . These non-specific neurological symptoms may reflect the neurotoxic effect of hypoxemia and the cytokine storm observed in patients with severe COVID-19. However, some of these manifestations must be differentiated from delirium, and other secondary causes, such as metabolic, gastrointestinal, renal, and hematological complications, must be ruled out, particularly in aged patients with underlying comorbidities. Interestingly, non-specific neurological manifestations are more frequent in patients who progress to respiratory failure, which supports the hypothesis about a possible contribution of the CNS infection to the respiratory failure caused by SARS-CoV-2 (67) . Furthermore, patients with unspecific neurological symptoms have shown higher degrees of leukopenia, thrombocytopenia, and elevated blood urea nitrogen levels (BUN) (10) . These data suggest that some of these findings might have certain prognostic value to predict the occurrence of more severe neurological complications. However, the predictive potential of non-specific neurological symptoms needs to be further evaluated in prospective studies. This would be of great help for the timely detection of patients at risk of neurologic sequela. Acute meningitis and encephalitis are dramatic complications of various viral infections that often result in high morbidity and mortality rates due to their severity. Coronaviruses have also been associated with these neurological complications in humans. For instance, the HCoV-OC43 coronavirus was isolated from the brain of a patient who died of viral encephalitis (74) . Likewise, both SARS-CoV-1 (46) and MERS-CoV have been reported to cause encephalitis (75) . In this context, SARS-CoV-2 can also cause viral meningitis and encephalitis, as demonstrated by a recent report of a 64-yearold patient with laboratory-confirmed COVID-19 who presented neurologic manifestations during the infection, including lethargy, clonus, and pyramidal signs in the lower limbs as well as stiff neck and Brudzinski sign (76) . The cerebrospinal fluid (CSF) study revealed high protein levels and hypoglycorrhachia, although the virus could not be isolated from CSF in this case. The patient received antiviral drugs and symptomatic measures, progressing favorably without neurological complications. Similarly, in another report, a 24-year-old man with a 3-day history of headache developed fever, loss of consciousness, and seizures (77) . Upon hospital admission, he presented signs of meningeal irritation and a low Glasgow Coma Scale (GCS) score, requiring mechanical ventilation. During his medical follow-up, he continued presenting seizures resistant to pharmacological treatment. His laboratory studies revealed high protein levels and pleocytosis in the CSF, and the MRI showed hyperintensities in the mesial temporal lobe. The patient tested negative for COVID-19 when his nasopharyngeal swab specimen was analyzed. Nonetheless, the result of the test was positive in the CSF sample. This finding was the first demonstration of the presence of SARS-CoV-2 in the CNS. The occurrence of encephalitis as the initial and even only manifestation of COVID-19 has latter been reported in three additional cases from China and the United States (78) (79) (80) . Finally, another case report showed that SARS-CoV-2 infection could cause acute necrotizing encephalopathy (81) . This entity is a severe neurological complication resulting from the disruption of the BBB associated with the cytokine storm observed in individuals with a critical illness. Together, these cases illustrate the development of severe acute neurological complications in patients with COVID-19, confirming the neurotropism of SARS-CoV-2. These findings justify the intentional search for SARS-CoV-2 infection in patients attending with acute neurological manifestations and  The antecedent of a recent respiratory infection, such as influenza, or influenza-like illness, has been related to acute cardiovascular complications, including acute myocardial infarction and stroke (82) . Among infectious causes of vascular events, the infection with the varicella-zoster virus (VSV) is the most frequent viral cause of stroke (83) . The study by Mao et al. revealed that 3% of patients with COVID-19 also present stroke as their only neurological manifestation of the infection. From these, the majority were affected by ischemic strokes (six ischemic vs. one hemorrhagic from a total of 214 patients included in the study) (10) . Stroke in individuals with COVID-19 occurs late during the disease and is more frequently observed among patients with severe respiratory failure. Interestingly, some COVID-19 patients were admitted to medical centers with hemiplegia and no history of respiratory symptoms (10) . Other studies have also reported stroke in patients with severe COVID-19, even among young individuals (84, 85) . This might indicate that stroke could be a result of vascular alterations directly driven by the virus, although the presence of cardiovascular risk factors can increase the incidence of this complication. A recent meta-analysis found that stroke, apart from being a frequent complication of COVID-19, has a considerable prognostic value to predict the risk of mortality. As such, patients with stroke have a 3-fold increase in the risk of death due to COVID-19 (86) . The association between stroke and COVID-19 might result from the critical condition and the pro-inflammatory state that prevails in most severely ill patients. The increased levels of pro-inflammatory cytokines in these individuals could alter the normal function of the cerebral vessels. These factors, along with the high prevalence of cardiovascular risk factors among patients with COVID-19, can trigger cerebrovascular complications. The endothelial infection of the cerebral vasculature due to its high expression of the ACE2 receptor might further contribute to these complications (49) . In fact, the incidence of stroke in patients with VSV infection is a consequence of the invasion of the cerebral arteries by the virus (83) . Other mechanisms by which SARS-CoV-2 could cause stroke include coagulation disorders. The abnormalities in the coagulation of severe COVID-19 patients have unique characteristics that partially resemble disseminated intravascular coagulation (DIC) or thrombotic microangiopathy. These alterations increase the risk of thrombotic complications and death due to COVID-19 (87) . Acute myocarditis has been reported in patients with SARS-CoV-2 infection (88, 89) . This cardiac complication could trigger events of brain embolization and stroke, which might explain the incidence of cerebral infarctions in young patients with COVID-19 in the absence of cardiovascular risk factors. During the outbreak caused by SARS-CoV-1, some studies described the occurrence of peripheral motor neuropathy and myopathy among infected individuals, mostly as part of the spectrum of manifestations of the critical illness polyneuropathy and myopathy disorders (90) . Similarly, 2.3% of patients with COVID-19 have presented neuropathic pain, probably associated with peripheral neuropathy, whereas 10.7% of the cases showed data of skeletal muscle injury with elevated serum levels of creatine phosphokinase (CPK) (10) . As in the case of other neurological manifestations, neuropathic pain and myopathy have been more frequently observed in patients with severe forms of COVID-19. Notably, these symptoms occur earlier during the disease in individuals with SARS-CoV-2 infection as compared to patients affected by SARS-CoV-1 (10) . This suggests that the neuropathy and myopathy of COVID-19 are directly associated with the injury of peripheral nerves and striated muscles driven by the virus. COVID-19 patients with neuropathy and myopathy, however, exhibit higher levels of neutrophils and acute phase reactants than individuals without neurological manifestations (10) . The nerve and muscle disorders observed during SARS-CoV-2 infection might thus be associated with a critical illness polyneuropathy of rapid development due to the more deteriorated clinical condition of patients with COVID-19 as compared to cases of SARS-CoV-1 infection. Vascular, thrombotic, ischemic, and direct nerve and muscle alterations driven by SARS-CoV-2 can contribute to neuropathy and myopathy of COVID-19 patients. A wide range of infectious diseases can cause complicate within cranial neuropathies like facial palsy and ophthalmoplegia. Among the pathogens that cause these manifestations with more frequency are HIV and VSV (91) . Cranial nerves might also be susceptible to a direct or indirect injury caused by SARS-CoV-2. In fact, according to a recent study, about 85% and 88% of patients with COVID-19 develop olfactory and gustatory dysfunction (66) . Similarly, in another investigation conducted in Italy, about 33% of patients with COVID-19 reported taste and/or olfactory disorders (92) . These findings might be specific for SARS-CoV-2 infection and could predict the causative pathogen in patients with acute respiratory illness. Indeed, smell and/or taste disorders were more frequently observed among COVID-19 patients as compared to individuals with laboratory-confirmed influenza infection in a case-control study conducted in Spain (93) . These observations might be of particular relevance for the upcoming flu season, which is predicted to be historically unique due to the convergence of influenza and COVID-19. During such an envisioned scenario, the differentiation of these diseases by clinical manifestations could be complicated. Nonetheless, the correct identification of the causative pathogen have therapeutic implications, such as the selection of adequate antiviral treatment. The presence of smell and taste dysfunction could thus be useful to distinguish COVID-19 from influenza. Furthermore, these symptoms can precede the onset of respiratory symptoms (94, 95) , and their presence may predict a milder clinical course of the disease (96) . Notably, COVID-19-related olfactory dysfunction has not been associated with rhinorrhea or nasal congestion, and more than half of the affected patients did not recover the function of the olfactory nerve (66) . This suggests direct damage to the olfactory epithelium, which further reaffirms the possibility of an entry route of SARS-CoV-2 through the cribriform plate, reaching the olfactory bulb from where it spreads to other parts of the CNS (62). Guillain-Barré Syndrome The association between viral infections and Guillain-Barré syndrome has been largely described in the past (97) . Infection with Campylobacter jejuni, cytomegalovirus, or Mycoplasma pneumoniae precedes Guillain-Barré syndrome in up to twothirds of affected individuals (98) . More recently, several viral emerging diseases have shown this syndrome as one of its more common and severe complications, as is the case of the infection with the Zika virus (99) . Although this association was not described in patients infected with SARS-CoV-1, cases of Guillain-Barré syndrome were observed during the outbreak of MERS-CoV (100) . In this context, the infection with SARS-CoV-2 could also complicate with or manifests as Guillain-Barré syndrome. In a recent report, Zhao et al. described the case of a woman that developed asymmetric and progressive muscle weakness in the lower limbs, associated with leukopenia and high protein levels in the CSF without pleocytosis, accompanied by data of demyelinating neuropathy in studies of nerve conduction (101) . The patient had a history of a recent trip to the city of Wuhan, and she showed no evidence of respiratory system involvement at the time of symptom onset. A total of 8days later, the appearance of fever, respiratory symptoms, and radiological data compatible with pneumonia was documented, confirming the SARS-CoV-2 infection by laboratory testing in a nasopharyngeal swab sample. The patient received intravenous immunoglobulin treatment recovering the neurological function without sequel. Similarly, in another case from Italy, a 71-yearold male also developed Guillain-Barré syndrome before the onset of any respiratory symptom (102) . These reports suggest that Guillain-Barré syndrome may be the first manifestation of COVID-19, presenting as a parainfectious phenomenon. This is due to the parallel occurrence of neurological and respiratory symptoms, instead of the postinfectious pattern observed in other infections, including the MERS-CoV (100). Nonetheless, two new case reports of six COVID-19 patients demonstrated that Guillain-Barré syndrome could occur a few days after the onset of respiratory symptoms (103, 104) . Collectively, these findings obligate physicians to continuously monitor the neurological condition of patients with suspected or confirmed SARS-CoV-2 infection to identify any sign of demyelinating neuropathy. Furthermore, the occurrence of Guillain-Barré syndrome associated with COVID-19 must be carefully distinguished from the myopathy and neuropathy disorders of the critically ill patient. Miller Fisher syndrome is a rare neurological disease that is considered a variant of the Guillain-Barré syndrome. This disorder is characterized by the triad of abnormal muscle coordination, paralysis of the eye muscles, and the absence of tendon reflexes. Miller Fisher syndrome can be associated with a history of recent viral illness; however, no evidence exists of its association with human coronavirus infections. Interestingly, a recent paper has reported the occurrence of the triad of ataxia, areflexia, and ophthalmoplegia in a 50-yearold man that presented cough, fever, anosmia, and hypogeusia some days before the onset of the neurological symptoms. The infection with the SARS-CoV-2 infection was confirmed in an oropharyngeal swab sample, and blood tests showed lymphopenia, elevated C-reactive protein levels, and anti-GD1b-IgG antibodies. He received treatment with intravenous immunoglobulin, which caused significant improvement in his neurological functions. Collectively, the literature summarized here indicates that neurological syndromes caused by aberrant immune responses, such as Guillain-Barré and Miller Fisher syndromes, can occur as part of the clinical spectrum of SARS-CoV-2 infection. Despite this, the immune mechanisms implicated in these phenomena, and the possibility of a direct neuropathic effect driven by the virus are unknown. Molecular mimicry has been proposed as the primary immune alteration underlying the development of Guillain-Barré syndrome during infections (105) . This phenomenon is related to the presence of carbohydrates in infectious agents of similar structural characteristics as compared to carbohydrates expressed on neuronal membrane ganglioside and galactocerebrosides. For instance, the lipopolysaccharides of Campylobacter jejuni share ganglioside-like epitopes with peripheral nerves (106), whereas galactocerebroside-like structures are present in glycolipids of Mycoplasma pneumoniae (107). These molecular similarities trigger the production of anti-glycolipid antibodies, which mediate autoimmune damage to peripheral nerves. Gangliosideor galactocerebroside-like epitopes have not been described in SARS-CoV-2. However, the S protein of this virus possesses 22 Nlinked glycan sequons per promoter (20) , that could potentially share certain similitude with carbohydrates localized on the surface of the host nerve cells. Future studies are required to evaluate the serologic features of anti-glycolipid antibodies in patients with COVID-19 to elucidate possible mechanisms underlying the association between SARS-CoV-2 infection and Guillain-Barré syndrome. Several viruses affecting humans have been implicated in the development of psychiatric symptoms due to their neurotropism. The immediate antecedent for the global transmission of a respiratory pathogen was the 2009 pandemic associated with the emergence of a novel influenza A (H1N1) virus. Several neuropsychiatric manifestations during the outbreak of influenza were observed among infected patients, including fear and behavioral changes (108) . Similarly, during the SARS-CoV-1, a range of psychiatric disorders was identified, including anxiety, depression, suicidal ideation, and hallucinations (109, 110) . A recent systematic review found a high incidence of confusion, depression, anxiety, memory impairment, insomnia, and steroidinduced psychosis among patients with SARS-CoV-1 or MERS-CoV infection (111) . The mechanisms underlying psychiatric disorders in patients with viral infections are not precise, but they might be related to the structural and functional disruption of the BBB mediated by circulating inflammatory cytokines produced in response to viruses. These mediators might also alter neuronal networks implicated in cognitive functions. Indeed, several psychiatric illnesses, including schizophrenia, have been proposed to result from immune-mediated pathogenic mechanisms (112) . In this sense, it is clear that the current pandemic can cause indirect effects on the mental health of infected and non-infected people due to quarantine and social distancing measures, which constitute sources of distress additional to the daily life problems (113) . At this moment, however, there is little literature about neuropsychiatric disorders directly associated with the infection with SARS-CoV-2. In a case series of three patients with laboratory-confirmed COVID-19 and no evidence of respiratory symptoms, it was found that such individuals presented anxiety, agitation, paranoid behavior, disorganized thinking, and auditory hallucinations (114) . Other authors have also reported that delirium can be present in a high percentage of COVID-19 patients (111) . Thus, as mentioned before, delirium must also be considered in the differential diagnosis of individuals with acute neuropsychiatric manifestations associated with SARS-CoV-2 infection. Finally, the virus could lead to long-term neuropsychiatric and cognitive sequels. In fact, survivors of SARS-CoV-1 and MERS-CoV have been found to present depression, anxiety, and posttraumatic distress syndrome several months after the diagnosis (111) . Therefore, it is essential to conduct long prospective observational studies to estimate the incidence of psychiatric disorders in the post-illness stage of COVID-19. Future studies must address possible links between the antecedent of SARS-CoV-2 infection and the incidence of chronic neurodegenerative disorders. The studies about the spectrum of neurological and psychiatric manifestations of COVID-19 are summarized in Table 1 . Supportive measures, along with strict control and prevention of fever, high blood pressure, elevated glucose, and seizures, may ameliorate the neurotoxic potential of SARS-CoV-2 infection. Currently, there are no mechanism-based therapeutics specific for neurological complications of COVID-19. The evidence curated in this review suggests possible pathologic processes underlying the involvement of the CNS/PNS during SARS-CoV-2 infection. A better understanding of these mechanisms may reveal targets for therapeutic interventions. Direct effects driven by the virus, such as the infection of brain blood vessels and nerve cells, are proposed to play a role in neurologic manifestations of COVID-19. Although studies addressing the Other neurological manifestations reported in COVID-19 patients include ataxia, acute hemorrhagic necrotizing encephalopathy, polyneuritis cranialis, and neuralgia (10, 81) . relationship between viral loads in the CNS and the severity of such manifestations are required, reducing the number of copies of SARS-CoV-2 in the circulation and tissues might be a useful strategy. Remdesivir is the only antiviral drug with demonstrated capacity to blocking SARS-CoV-2 replication in pre-clinical trials approved for usage in humans. This antiviral drug reduces the time of clinical recovery in patients with COVID-19 (116) . The benefits of remdesivir for patients with neurological complications have not been evaluated. Other candidate agents that antagonize the activity of the host proteases implicated in the infection process of SARS-CoV-2 may be useful to limit the infective capacity of this virus. These include the camostat mesylate and nafamostat mesylate, two compounds that block the activity of TMPRSS2 (19, 117) . The effects of these drugs on the severity and recovery of neurologic sequela associated with COVID-19 must be evaluated in future clinical trials. Passive immunization by transfer of convalescent human plasma may also contribute to reduce the viral loads and prevent or reverse the development of neurological symptoms. This assumption is supported by recent systematic reviews that found that convalescent plasma therapy improves symptoms, reduce viral loads, and diminishes mortality in COVID-19 patients (118) . The time at which these proposed interventions would be more useful to counteract neurologic sequela of COVID-19 is unknown. Immune-mediated neurotoxicity is an obvious therapeutic target for individuals with SARS-CoV-2 infection (59). The immune profile of patients with severe COVID-19 resembles the cytokine release syndrome (CRS) observed after CAR-Tcell therapy (34, 35) . As aforementioned, individuals receiving CAR-T cells who develop CRS are at risk of injury to the nervous system. Therefore, lessons from the treatment of patients with CAR-T-cell-therapy-associated neurotoxicity might be applicable to COVID-19 patients. Tocilizumab, an anti-IL-6 monoclonal antibody, is the primary treatment for CRS (119) , and is currently being used to ameliorate inflammatory manifestations caused by SARS-CoV-2 infection (120). In patients with severe COVID-19, tocilizumab declined cytokine production and reduced the risk of intubation requirement (120) . However, the utility of tocilizumab for management of CRSassociated neurotoxicity is controversial (121) . Interestingly, mouse models have revealed that the antagonist of the receptor of IL-1β anakinra might be a better option than tocilizumab for the treatment of CRS and neurotoxicity after CAR-T-cell therapy (122) . As a strong induction of IL-1β has been observed in severely ill COVID-19 patients (32), the potential use of anakinra deserves further investigation. Monocytes and macrophages also contribute to the development of CRS and neurotoxicity after CAR-T-cell therapy. As such, inhibition of GM-CSF with monoclonal antibodies has shown to reduce neuroinflammation in Phase I studies of patients receiving CAR-T-cell therapy (123) . Interestingly, in a recent study conducted in patients with COVID-19, the GM-CSF blockade with mavrilimumab improved clinical symptoms, survival, and reduced intubation requirement (124) . Inhibition of GM-CSF is thus a potential therapeutic for patients with COVID-19 that develop neurological complications. Short courses of steroids are safe and provide some benefits for the treatment of immune-mediated neurotoxicity. Specifically, dexamethasone may constitute a good candidate due to its excellent CNS penetration and beneficial effect on the integrity of the BBB. Dexamethasone has been safely used in patients with acute respiratory distress syndrome, reducing the requirement of mechanical ventilation and mortality (125) . These data may support the use of dexamethasone for the management of neurological manifestations of SARS-CoV-2 infection, although possible consequences of the dexamethasoneinduced immunosuppression need to be evaluated. The breaching of the BBB is an important event for the development of neurotoxicity in COVID-19 patients and individuals under CAR-T-cell therapy. Pharmacological agents targeting the BBB may thus be useful to treat severe neurological manifestations of COVID-19. The sonic hedgehog (SHH) signaling pathway is essential for the maintenance of integrity and immune homeostasis of the BBB (126) . Agonists of SHH, such as purmorphamine, a compound that activates the SHH by promoting smoothened protein (127) , reduce BBB damage in animal models of infection and ischemic stroke (128) (129) (130) . Although little evidence exists of the safety of purmorphamine in humans, this agent warrants further exploration for the management of neurotoxicity associated with severe infections, including COVID-19. The magnitude of the current pandemic has generated concerns among professionals from various areas of medicine. The evidence summarized in this review shows that neurology is an active area of medicine at the frontline of the current pandemic. Actually, due to the increasing number of confirmed cases around the world and the neurotropic potential of SARS-CoV-2, it is highly likely that neurologists would have to provide medical care to patients with COVID-19, some of which might present neurological manifestations. The first and most important precautionary measure that must be taken by neurological centers around the world is to improve the knowledge of the disease among health care professionals. Obviously, measures of personal protection and social distancing should be extreme in neurology and neurosurgery clinics since it is possible that some COVID-19 patients attending with neurological symptoms with a not yet confirmed SARS-CoV-2 infection may constitute potential foci of inadvertent contagion for doctors, especially if they do not manifest respiratory symptoms initially. To prevent contagions, it is important to investigate previous contact with people with laboratoryconfirmed COVID-19 in patients attending to neurological centers. Similarly, it is crucial to maintain a high degree of clinical suspicion about possible SARS-CoV-2 infection in patients presenting an acute neurological condition. Furthermore, the continuous surveillance and intentional search for neurological complications in patients with confirmed SARS-CoV-2 infection are necessary and even mandatory because these measures could allow the timely establishment of therapeutic strategies for limiting neurologic sequelae. Finally, the current pandemic may obligate some changes in normal care to patients with neurologic disorders at medical centers receiving many COVID-19 cases. Of particular importance is the possible impact of this pandemic in the triage and management of patients with stroke and other acute neurological emergencies due to resource re-allocation. Also, the interruption of activities at many neurology outpatient clinics may affect the management of chronic neurological conditions, requiring increased usage of tools such as telemedicine and e-care. PG-O, JC-P, and CS-M drafted the manuscript. FP-S, AR-N, and GG-Q are medical students from the Centro Especializado en Neurocirugía y Neurociencias México (CENNM) and the Escuela Nacional de Medicina y Homeopatía, Instituto Politécnico Nacional in Mexico City. They participated in the search for scientific literature and revised the paper for intellectual content. All authors read and approved the final version of the manuscript.@story_separate@The clinical phenotype of COVID-19 encompasses a spectrum of neurological manifestations of varying severity that, besides respiratory symptoms, can cause high morbidity and mortality rates in individuals with SARS-CoV-2 infection. The current review constitutes a useful reference to improve our understanding of the pathophysiological mechanisms of SARS-CoV-2 infection and should motivate further studies about novel strategies to mitigate the impact of the current pandemic on the field of neurology.","The human infection of the novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a public health emergency of international concern that has caused more than 16.8 million new cases and 662,000 deaths as of July 30, 2020. Although coronavirus disease 2019 (COVID-19), which is associated with this virus, mainly affects the lungs, recent evidence from clinical and pathological studies indicates that this pathogen has a broad infective ability to spread to extrapulmonary tissues, causing multiorgan failure in severely ill patients. In this regard, there is increasing preoccupation with the neuroinvasive potential of SARS-CoV-2 due to the observation of neurological manifestations in COVID-19 patients. This concern is also supported by the neurotropism previously documented in other human coronaviruses, including the 2002–2003 SARS-CoV-1 outbreak. Hence, in the current review article, we aimed to summarize the spectrum of neurological findings associated with COVID-19, which include signs of peripheral neuropathy, myopathy, olfactory dysfunction, meningoencephalitis, Guillain-Barré syndrome, and neuropsychiatric disorders. Furthermore, we analyze the mechanisms underlying such neurological sequela and discuss possible therapeutics for patients with neurological findings associated with COVID-19. Finally, we describe the host- and pathogen-specific factors that determine the tissue tropism of SARS-CoV-2 and possible routes employed by the virus to invade the nervous system from a pathophysiological and molecular perspective. In this manner, the current manuscript contributes to increasing the current understanding of the neurological aspects of COVID-19 and the impact of the current pandemic on the neurology field."
"The first case of infection attributed to Middle East respiratory syndrome coronavirus (MERS-CoV) was detected in Saudi Arabia in June 2012 [1] . MERS-CoV then spread to several neighboring countries, mainly Jordan and Qatar (see Fig. 2 ), and imported cases of the disease were reported throughout the world in Asia, Africa, Europe and the Americas [2] . By the 16th of October 2018, 2260 con- @story_separate@The first two coronaviruses demonstrated to cause respiratory infections in humans, the coronaviruses 229E and OC43, were identified in the 1960s. They were held responsible for respiratory infections of moderate severity in humans. Despite these viruses being identified in several reports as causing lower respiratory tract infections, it was generally accepted that coronaviruses were of low pathogenicity until the emergence of SARS-CoV (Severe Acute Respiratory Syndrome Coronavirus) in 2002, a virus with a fatality rate estimated at 10%. The SARS outbreak that resulted in more than 8400 cases was finally contained two years later, in 2004, and the virus has not been detected again since [4] . There was renewed interest in coronavirus research following the SARS epidemic, and two novel endemic human coronaviruses were identified, NL63 and HKU1 respectively in 2004 and 2005, but could not be replicated in cell culture. Both of these new viruses were responsible for respira-tory infections of moderate seriousness like the coronaviruses 229E and OC43. Great effort has been made to identify coronaviruses in animal populations, both before and after the SARS outbreak, in order to better understand and control the risk of animal-to-human transmission. This resulted in the discovery of coronaviruses in numerous animal species, with a few exceptions such as sheep and goats, fish and non-human primates [5] . The first case of MERS-CoV infection was reported in Jeddah, Saudi Arabia, in June 2012 [1] . The patient, a 60-year-old man, died from lung and kidney failure 11 days after being admitted to hospital. Very shortly afterwards, in September 2012, a second patient was admitted to hospital in the United Kingdom for severe respiratory infection related to a novel coronavirus following travel to the Middle East. The new virus was found to replicate in a tissue culture model and was rapidly isolated and identified for both cases [6, 7] . Retrospectively, other cases of the disease were found to have occurred before the 2 aforementioned cases: in April 2012, an outbreak at Zarqa hospital in Jordan affected the staff of the intensive care unit, with two fatal cases. The respiratory samples collected were later confirmed to be positive for MERS-CoV [8] . These initial cases were rapidly followed by a series of outbreaks in all Saudi Arabian provinces that were characterized by the infection of health professionals in direct contact with the patients. Other similar outbreaks were observed in several neighboring countries: Qatar, Bahrain, Kuwait, Jordan and Tunisia. Health authorities reacted quickly to the reports of these epidemics and the strong resemblance with observed clinical features of SARS-CoV infections. Indeed, although a few patients developed mild infections, the fatality rate for patients infected with MERS-CoV was over 30% [2] . Following the identification of MERS-CoV, great effort was put into finding which animal species it originated from in order to stop the further spread of the disease to humans. MERS-CoV was very rapidly determined to be genotypically closely related to the betacoronavirus lineage C viruses identified in bats [9] . Based on these findings, and the major role of bats in the genetic diversity and spread of coronaviruses, much of the initial work aiming at finding the natural reservoir of MERS-CoV focused on bats. However, no conclusive evidence demonstrating that bats were the natural reservoir of MERS-CoV in the Arabian peninsula were found, despite the identification of closely related viruses in bats in Sub-Saharan Africa [10] , far from the existing outbreaks. Very strong epidemiological links were identified between the human cases and camels and resulted in the isolation in camels of viruses that were directly related to MERS-CoV and that could replicate in cultured human cells [11] . The investigation of dromedary camel serum collections, some of which collected as early as 1983, demonstrated that the virus was already widespread (seropositivity rate > 80%) in the East African countries (Somalia, Sudan and Egypt). These countries export dromedary camels to Arabian countries, but also in Kenya, Nigeria, Tunisia, Ethiopia, Burkina Faso and Morocco [12] [13] [14] . Phylogenetic analysis revealed 5 distinct coronavirus lineages in dromedary camels, including one recombinant lineage that led to the MERS-CoV epidemic in humans [15] . MERS-CoV is a betacoronavirus belonging to lineage C. It is an enveloped virus with a positive-sense single-stranded RNA genome of about 30 kb. Under electron microscopy, virions are generally spherical with surface projections (spikes) formed by the surface protein S creating an image reminiscent of a crown or solar corona. The positive-sense single-stranded RNA genome acts as messenger RNA (mRNA) with a 5 cap and a 3 polyadenylated tail. It plays three roles during the host cell cycle: (i) it acts as the initial RNA molecule for the infection cycle; (ii) it is the template for replication and transcription; (iii) it is the substrate that is packaged into the newly assembled viral particles [16] . The MERS-CoV genome is organized in the same way as other coronavirus species. The first two thirds of the MERS-CoV genome contain two overlapping reading frames (ORF1a and ORF1b) that translate into the replication-transcription complex including 16 non-structural proteins. The remaining third of the genome encodes the four structural proteins, the spike (S), envelop (E), membrane (M) and nucleocapsid (N) proteins, as well as five accessory proteins (ORF3, ORF4a, ORF4b, ORF5 and ORF8b) that are not required for genome replication but are probably involved in virulence. The flanking sequences, on both ends of the genome, contain untranslated 5 and 3 regions (UTR) (Fig. 3 ) [17] . The viral particle can enter the cell in two ways, which probably contribute to the broad tissue tropism of this virus that replicates mainly in respiratory epithelial cells but can also infect many other cell types. Via the endosomal pathway, the S1 domain of the MERS-CoV spike protein (S) binds its receptor, dipeptidyl peptidase 4 (DPP4) [18] , induces endocytosis of the viral particle and a change in the conformation of the S2 subunit of the S protein that then mediates virus-host membrane fusion and uncoating of virus RNA. MERS-CoV can also enter host cells via a non-endosomal mechanism by direct fusion of the virus with the plasma membrane following S protein cleavage by human proteases [19] . Following entry into the cytoplasm and uncoating of the virus nucleocapsid, the viral genomic RNA is translated to produce two polypeptides, pp1a and pp1b, that form the replicase-transcriptase complex. This initial replicase-transcriptase complex uses the genomic RNA to produce 16 non-structural proteins that assemble into the replication complex. The replication complex then replicates the genomic RNA and produces other subgenomic RNAs that ensure the translation of the structural proteins. Virions are assembled at the endoplasmic reticulum membrane as viral proteins and genomic RNA are grouped together and then bud into the lumen of the endoplasmic reticulum. The virions are then exported via the secretory pathway of the endoplasmic reticulum into the Golgi intermediate compartment and then into the extracellular environment. The M protein drives the packaging process by selecting and organizing the viral envelop components at the assembly sites and interacting with the nucleocapsid to allow budding [20] . Several large serology studies suggest that cases of asymptomatic or mild MERS-CoV infection occur regularly, although infrequently. The importance of such cases is difficult to assess [10] . It is therefore difficult to determine whether these cases are due to or take part in human-to-human transmission. Several studies suggest that less than 50% of infected patients transmit the virus to individuals they come into contact with, even at the beginning of an outbreak [10] . The disease therefore seems to spread due to frequent animal-to-human transmission, from camels to humans, with limited subsequent human-to-human transmissions [21] . There are unfortunately exceptions to this observation and local outbreaks caused by human-to-human transmission have been observed on a regular basis, mostly in hospitals. To date, the most poignant example is the outbreak that occurred in South Korea in which the index case caused 185 secondary cases, among whom 30 were care providers, leading to 24 fatalities [3] . This outbreak was characterized by the key role of a few ""super spreaders"", delayed diagnosis, high doctor shopping behavior and the importance of confined spaces (waiting room, hospital room, ambulance). In this example, the resemblance with SARS-CoV's spreading mechanisms is striking, despite lower degrees of transmission to care providers for MERS-CoV [22] . These regular cases of imported-MERS, the most recent was reported in England in August 2018 [23] , represent a real threat of local epidemics outside Saudi Arabia and special screening and isolation procedures need to be implemented in units likely to receive patients suspected of MERS-CoV infections. When possible, the first measure to be taken is to delay departure, in particular for individuals over 65 or with chronic disease, and for pregnant women or children. Such measures are nevertheless challenging to maintain today as that the virus is still present 6 years after its apparition. All other preventive measures aim at preventing both animalto-human transmission and human-to-human transmission. It is therefore recommended to avoid any contact with domestic animals (firstly dromedary camels), their secretions, raw milk and insufficiently cooked meat. It is also advised to avoid eating fruit and vegetables that might have been in contact with animal secretions if not washed and peeled by oneself. To avoid human-to-human transmission, the usual recommendations for preventing the spread of any respiratory virus should be applied: hand washing with soapy water or an alcohol-based solution, covering one's nose and mouth when sneezing, refraining from shaking hands and touching one's mouth and nose with one's hands, avoiding contact with people with respiratory symptoms. Finally, a last series of recommendations focus on how to behave in case of suspicious symptoms: (i) consult a doctor as soon as symptoms occur during travel and delay the return until symptoms disappear; (ii) if symptoms occur with 14 days of returning home, consult a doctor and tell him/her about the recent travel [24] . PCR-based detection methods are currently the preferred option for detecting the virus in respiratory samples and making a diagnosis of MERS-CoV infection. Serology tests can also be performed and are often used for second-line diagnostic investigation in patients with a high suspicion of MERS-CoV but negative results by direct PCR testing. Various respiratory matrices can be used: nasopharyngeal swabs, nasopharyngeal or tracheal aspirates, bronchoalveolar lavage (BAL), and even in some cases, induced sputum. The deepest samples, tracheal aspirates and BALs, show the greatest sensitivity and significantly higher viral loads [25] . The genome amplification and detection methods used (PCR) were initially mostly developed in situ and performed in biosafety level 3 (BSL-3) reference facilities. The time to results is generally relatively long, 24-48 h, due to the usual time required for conventional PCR testing to which must be added the additional preparation and sample neutralization time needed to protect the laboratory staff against this virus. The PCR methods used are generally semi-quantitative and some studies suggest a correlation between the amount of virus detected and the severity of the symptoms [26] . Nevertheless, no consensus has been reached yet regarding a threshold level that could actually predicts clinical severity. Targeting the envelop gene upE is recommended with confirmatory testing for ORF 1A or 1B or the N gene. If results diverge, sequencing is sometimes required to obtain conclusive results [27] . Today, an increasing number of commercial tests are becoming available (Altona Diagnostics, Fast Track Diagnostics, Primerdesing Ltd.) some even with a time to results of less than 1 hour (BioFire-bioMérieux). Some of these tests are point-of-care, or can be performed in BSL3 facilities or a standard laboratory following sample neutralization in a BSL3 facility. These commercial tests must always be validated before use to check their sensitivity and compare their performance with reference methods. As with any other acute viral infection, antibodies can only generally be detected about 10 days after the onset of symptoms. In some patients, especially those with severe infections, the time interval to antibody detection may be even longer [28] . Serological testing is therefore of little help for the initial diagnosis of symptomatic patients, but can be useful for epidemiological investigations. The highly immunogenic S and N viral proteins are widely used targets for serological tests and are found on all coronaviruses. Various approaches have been developed: serum neutralization assays [29] , microarrays [30] , or more recently ELISA confirmed by a microneutralization test [31] . All methods are technically complex and require a high level of expertise that restrict their use to a few highly specialized facilities. The first cases of infection with MERS-CoV were reported in 2012 [1] . Hospital-acquired MERS-CoV infections have been described worldwide and represented a third of all cases reported in Saudi Arabia in the early stages of the epidemic [1, 32, 33] . Clustered hospital-acquired infections were frequently observed during the first outbreaks and probably contributed to spreading the disease from the primary site of virus infection to the whole Arabian peninsula, the most striking example of hospital-acquired outbreak being the Korean outbreak in 2015 [34] . Care providers are often affected and represent 15-22% of cases [33] [34] [35] [36] [37] [38] [39] . Most of the cases are described in Middle East countries, in particular Saudi Arabia (73%), with a predominance of male patients (66-69% in various studies) and a mean patient age ranging from 40 to 55 years [34, 38, 40] . Comorbidities are found in 46-68.6% of patients, in particular diabetes and high blood pressure, followed by other heart conditions and finally obesity [34, 37, 38, 41] . The mean incubation time is 5 to 6.5 days. The generation interval (time between the onset of symptoms of the first case and those of the second case) is 7.6 days, which is identical to that of the respiratory syncytial virus (RSV) but threefold more than the influenza virus [36, [42] [43] [44] . The main challenge of MERS-CoV infection is the absence of specific clinical features for differential diagnosis with other viral respiratory diseases [37, 45] . This difficulty, combined with precautionary action taken to avoid potential secondary contamination with MERS-CoV [46] , can result in medical confusion and inappropriate patient management due to prolonged, difficult isolation that makes it impossible to perform the necessary complementary tests while waiting for PCR results [47] . The clinical features of MERS-CoV infection are extremely variable, ranging from an absence of symptoms (14-80% of cases) to a flu-like syndrome, pneumonia and acute respiratory distress syndrome (ARDS) [37, 48] . The three most frequent symptoms are: fever (77% [IQR: 59-82]), cough (90% [52] [53] [54] [55] [56] [57] [58] [59] [60] [61] [62] [63] [64] [65] [66] [67] [68] [69] ), and dyspnea (68% ). Many other secondary symptoms have been reported, such as sputum production (40%), odynophagia (39%), digestive system signs (20%), hemoptysis (4.3%), myalgia (43%) and headache (20%) [34, 37, 41, 42] . Diarrhea is significantly more frequent in patients infected with MERS-CoV than in patients with another acute, febrile respiratory conditions [45] . Severe MERS is characterized predominantly by ARDS, acute kidney failure, and in the most severe cases, by multiple organ failure that can be fatal [49, 50] . One third of patients develop pneumonia and 20% develop ARDS [51] . The median time to respiratory failure is 12 days after the onset of symptoms. Depending on studies, 53 to 89% of hospitalized patients are admitted to an intensive care unit (ICU) [43, 52] . Since the first MERS outbreak, WHO had documented, in October 2018, 2260 cases of MERS-CoV infection confirmed by laboratory testing and 803 related deaths in 27 different countries. The retrospective fatality rate varies between outbreaks, ranging from 36.5 to 60% [33, 35, 37, 38, 42] . The mortality rate of 20.4% observed for the Korean outbreak is probably the most reliable epidemiologically due to the comprehensive investigations carried out [34] . The death rate is highest among patients admitted to an ICU, ranging from 58% to 90% [49, 53] . In the only cohort study performed in Saudi Arabia, the fatality rate for MERS-CoV patients was of only 10% (8/80). However, the patients of this cohort were younger, had less symptoms, showed less radiological features and only 17% were admitted to an ICU [37] . The findings of the latter study diverge therefore with the situations observed in other hospitals, but are perhaps a better reflection of the infection profile in the general population in which younger subjects are less symptomatic and therefore less frequently admitted to hospital. The time interval between the onset of symptoms and death ranges from 11.5 to 27 days [34, 44, 54] . Finally, co-infection with other respiratory viruses, in particular influenza, has been described although the impact of such combined infections have not been evaluated [44, 55] . Co-infections with bacteria have also been reported in the patients developing the most severe disease [49, 51] . There are no specific laboratory findings related to MERS-CoV infection. Nevertheless in patients with acute respiratory infection in MERS-endemic areas, MERS-CoV infections have been associated with normal leukocyte and/or polymorphonuclear neutrophil counts but elevated transaminases [37, 45] . Moreover, hyperleukocytosis, lymphocytopenia, thrombocytopenia, hypoalbuminemia, elevated serum creatinine, LDH and CRP levels, and hypoxemia (PaO2/FiO2 < 300) have been repeated reported in MERS-CoV infected patients and are associated with severity and death [34, 45] . Imaging (chest X-ray and sometimes chest CT) has revealed infection-related features in 51-75% of cases. The lesions observed are uni-or multi-focal ground glass opacifications, of subpleural and lower lobe predominance, with sometimes bilateral bi-basal involvement or features of organizing pneumonia [34, 37, 42, 45] . Mortality is highest in elderly, male patients with comorbidities, especially diabetes [38, 45, 56] . Patients from Saudi Arabia and the Middle East have an increased mortality rate compared with patients from Korea or other countries [38, 40] . In contrast, being a medical professional significantly reduces the risk of mortality [38, 45] . Other factors associated with a higher mortality risk have been described in various studies: digestive symptoms, prolonged delay between the onset of symptoms and admission to hospital, smoking, low blood pressure, impaired gas exchange, leukopenia, anemia, disturbance of liver or kidney function, use of mechanical ventilation and prolonged stay in the ICU [42, 57] . For the Korean outbreak in 2015, the independent risk factors for mortality were: age > 55 years, dyspnea, diabetes, chronic lung disease, systolic blood pressure at admission < 90 mmHg, hyperleukocytosis at admission (> 10,000/mm 3 ) and the use of mechanical ventilation [34] . Positive PCR results for MERS-CoV in blood at diagnosis are associated with an increased risk of requiring mechanical ventilation, extracorporeal membrane oxygenation (ECMO) or to lead to death [58, 59] . The lack or delayed detection of MERS antibodies (ELISA IgG and IgA, or PRNT) in the blood or airways is a poor prognostic factor [54, 60] . It should however be noted that no seroconversion is observed in asymptomatic MERS-infected patients [54] . Finally, the MERS-CoV viral loads in distal lung samples were higher among deceased patients [60] . In a study including 45 patients in a tertiary referral hospital in South Korea: • the predictive factors for pneumonia in MERS-CoV patients were: age > 45 years, body temperature > 37.5 • C on day 3, platelet counts < 150,000/mm 3 , lymphocytopenia (< 1000/mm 3 ), CRP ≥ 20 mg/L and high viral loads (Ct value < 28.5); • the predictive factors for respiratory failure were male sex, high blood pressure, thrombocytopenia, lymphocytopenia, hypoalbuminemia < 35 g/L and CRP ≥ 40 mg/L. The patients with at least two, one and none of the predictive pneumonia factors developed pneumonia in 100%, 50% and 0% of cases, respectively [61] . Several therapeutic options targeting various viral elements are currently available or under development (Fig. 4) [62] . The different classes of available treatment are (i) immunotherapy with specific anti-MERS-CoV antibodies, (ii) molecules with antiviral activity, (iii) symptomatic treatment. Few molecules have shown real curative action and the reports in the literature generally describe isolated cases or small series of cases. More studies have focused on associated treatment and supportive care. At this time, preventive therapies are still in preclinical stages. The efficacy and safety of plasma from convalescent patients have not been assessed. Three separate reports concluded that such therapeutic approaches were inappropriate [63] . One trial is listed on www.clinicaltrials.gov. Two cases of therapy with intravenous polyclonal IgGs have been reported. In one of them, the IgGs originated from donors in regions negative for MERS specific antibodies. Several monoclonal antibodies were tested and seemed to show anti-MERS-CoV activity in vitro [64] . No clinical trials are currently underway. Recently, a phase I placebo-controlled, dose escalation study evaluated the efficacy of polyclonal IgGs produced by transchromosomal cattle with human immunoglobulin genes immunized with the MERS-CoV spike (S) protein [65] . The primary outcome of tolerance to a single dose was reached. The secondary pharmacodynamic endpoint (serum neutralization activity) showed efficacy with a dose of 50 mg/kg. No phase II trials are currently underway. A phase I study has been registered to assess the immunogenicity and tolerance of a combination of two monoclonal anti-MERS-CoV antibodies. The study has not yet started recruiting patients. Infection with MERS-CoV reduces the host's interferon response. MERS-CoV is 100 times more sensitive to IFN-␣. Treatment with IFN-␣ has been reported for many clinical cases and several retrospective cohort studies have been performed, in combination with ribavirin, lopinavir or mycophenolate mofetil (MMF). None of these studies have demonstrated increased overall survival. One study reported increased survival at D14 but not at D30 for critically ill intubated and ventilated patients [66] . A IFN/MMF combination trial is currently underway (see below). High doses of ribavirin have shown anti-MERS-CoV activity in vitro. Ribavirin has been used to treat patients in Saudi Arabia as well as in France for the most severe cases managed in ICUs [67] . No significant effects were demonstrated either on the mortality rate or the time spent in the ICU. Ritonavir-boosted lopinavir has shown efficacy against MERS-CoV in vitro. As a result, the FDA has extended the indications of lopinavir to patients infected with MERS-CoV. Two case reports (in Greece and Korea) have described improvement in patients treated with lopinavir, type 1 interferon and ribavirin [68] . A phase II-III clinical trial is registered on clinicaltrials.gov. The aim of this study is to evaluate the feasibility, efficacy and safety of the combination lopinavir/ritonavir/recombinant IFN␤-1b vs. a placebo in patients with confirmed MERS receiving optimal symptomatic care. Chloroquine is among the molecules approved by the FDA following in vitro studies. No clinical data or studies support its use in vivo at the present time. In vitro, anti-MERS-CoV activity has been demonstrated for doses of nitazoxamide that could be reached with two daily oral doses. No clinical data or studies support its use in vivo at the present time [69] . In vitro, anti-MERS-CoV activity has been demonstrated for doses of MMF that are acceptable for use in humans. MMF seems to show a synergistic effect with IFN-␤1b in vitro [70] . But in a non human primate common marmosets model, animals treated with MMF developed more severe lesions and showed a higher case fatality rate compared with untreated animals [70] . In contrast with animal model, the combination IFN-␤1b/MMF was administered to 8 patients in Saudi Arabia. All the patients survived but had lower APACHE II scores that other patient groups [71] . Alisporivir has been shown to provide additive in vitro anti-MERS-CoV activity when used in combination with ribavirin. No clinical data or studies support its use in vivo at the present time [72] . Silvestrol is a molecule of the flavagline family found in plants. It binds to eIF4A and enhances the affinity of eIF4A for mRNA. This blocks helicase activity and inhibits protein translation. A recent in vitro study demonstrated that silvestrol has anti-MERS-CoV activity [73] . No clinical data or studies support its use in vivo at the present time. Corticosteroid therapy is currently the most widely studied therapeutic option. In a retrospective study, Arabi et al. [67] compared the outcome of 309 patients with confirmed MERS-CoV infection managed in an ICU setting and treated with (151) or without (159) corticosteroid therapy. The overall fatality rate was 67%. Univariate analysis showed that mortality in the ICU, during the hospital stay or at 90 days was higher in the corticosteroid group. Then, following adjustment using a marginal structural model for causal inference, corticosteroid therapy was shown not to be associated with mortality, but delayed virus clearance. These findings, together with the absence of any description of the adverse effects caused by corticosteroid treatment, argue against the use of corticosteroids. A retrospective study was recently carried out in Saudi Arabia in MERS-CoV patients with refractory respiratory failure [74] . The patients were included in the study from 2014 to 2015 in five ICUs. The study consisted of two patient groups: ECMO versus conventional treatment. The primary endpoint was inhospital mortality. Secondary endpoints included the length of stay in the ICU and in hospital. Thirty-five patients were included: 17 were treated with ECMO and 18 received conventional care. Both groups had similar baseline characteristics. Inhospital mortality was lower in the ECMO group (65 vs. 100%; P = 0.02) although they stayed longer in the ICU (median stay of 25 days vs. 8 days; P < 0.01). The overall time in hospital was similar in both groups (median stay of 41 vs. 31 days; P = 0.421). In addition, patients in the ECMO group showed improved PaO2/FiO2 values at 7 and 14 days after admission into the ICU (124 vs. 63, and 138 vs. 36, respectively; P < 0.05), and lower levels of vasoactive amines at D1 and D14 (29 vs. 80%, and 36 vs. 93%, respectively; P < 0.05). The results of this study support the use of ECMO as salvage treatment for MERS patients with respiratory failure, as is the case for other respiratory infections. Two trials with candidate vaccines are currently registered at https://clinicaltrials.gov/ct2/home. A phase-I clinical trial on healthy volunteers was set up to evaluate the safety and immunogenicity of a plasmid DNA vaccine (GLS-5300) that expresses the S protein of MERS-CoV. This trial was planned to last one year and started in 2016. No results are available yet. A second phase-I trial was started by Oxford University in January 2018. It uses a chimpanzee adenovirus vector containing the MERS-CoV S protein gene [75] . Patient inclusion is currently underway. Many other candidate vaccines using various different technologies are at a less advanced stage of development. The authors declare that they have no competing interest.@story_separate@The MERS epidemic started in 2012. In contrast with SARS-CoV that disappeared 2 years after it first appeared, MERS-CoV continues to persist in the Middle East 6 years later. Although the disease has not become pandemic, outbreaks have occurred worldwide. Today, it is impossible to predict with certainty whether MERS-CoV will disappear or continue to remain a threat for human populations. Efficient vaccine development for host ani-mals and humans could play a key role in tilting the balance from potentially-pandemic to MERS-CoV elimination. Furthermore, the epidemiological and viral determinants of the emergence of MERS-CoV in the Middle East are difficult to comprehend, due to the high seropositivity rate of African dromedary camels but no similar disease in local human populations. The constant increase of transcontinental travel, in particular towards the main focal points of MERS outbreaks with religious pilgrimages and mass tourism, raises the problem of the management of patients suspected of MERS-CoV infection and the absence of efficient treatment options to this date. The main problem in non-epidemic countries is to detect a MERS-CoV case among a great number of non-MERS patients. In France, with the exception of the first 2 cases, no further cases have been detected. The current strategy is to isolate any suspicious cases as rapidly as possible to contain the infection and prevent local outbreaks as seen in South Korea. The ability to rapidly test patients suspected to have MERS-CoV infection is the cornerstone of this strategy. The experience gained over the last few years by the health community will also help deal with any respiratory infections that will emerge in the future.","Since the first case of human infection by the Middle East respiratory syndrome coronavirus (MERS-CoV) in Saudi Arabia in June 2012, more than 2260 cases of confirmed MERS-CoV infection and 803 related deaths have been reported since the 16th of October 2018. The vast majority of these cases (71%) were reported in Saudi Arabia but the epidemic has now spread to 27 countries and has not ceased 6 years later, unlike SARS-CoV that disappeared a little less than 2 years after emerging. Due to the high fatality rate observed in MERS-CoV infected patients (36%), much effort has been put into understanding the origin and pathophysiology of this novel coronavirus to prevent it from becoming endemic in humans. This review focuses in particular on the origin, epidemiology and clinical manifestations of MERS-CoV, as well as the diagnosis and treatment of infected patients. The experience gained over recent years on how to manage the different risks related to this kind of epidemic will be key to being prepared for future outbreaks of communicable disease."
"The current global SARS-CoV-2 pandemic (COVID- 19) represents a health crisis with few precedents in history; at the time of writing this article, SARS-CoV-2 caused about 6.42 million infected and about 383,000 deaths [1] . SARS-CoV-2 infection, in the most severe cases, can cause tissue hyperinflammation, fibrosis and scarring, lung collapse, multi-organ dysfunction, and patient death. [2] To date, no effective or antiviral vaccines against SARS-CoV-2 are available, so it is very important to decrease the aggressiveness of the viral infection, avoiding serious complications and patient death. The excessive inflammatory state, associated with the presence of fibrotic tissue induced by SARS-CoV-2, has been shown to play a key role in clinical cases considered more critical. [3] In the more severe stages of viral infection, excessive release of pro-inflammatory mediators, such as cytokines, leads to lung damage with extensive fibrosis and rapid onset of respiratory distress syndrome. [4, 5] The use of agents to prevent or reduce fibrotic status, such A preliminary version of this report was made publicly available as a socalled preprint at a nonprofit repository (Authorea) with DOI number: https://doi.org/10.22541/au.158802198.88770371 as pirfenidone, may be therapeutically effective in preventing serious or fatal complications. Pirfenidone is the drug of choice in the treatment of idiopathic pulmonary fibrosis (IPF) [6] and with a pleiotropic mechanism of action reduces the fibrotic and inflammatory state of lung tissue. Its therapeutic efficacy could also benefit healed patients with consequences on lung tissue with a state of fibrosis. In addition, a combination therapy of anti-inflammatories and antifibrotics such as pirfenidone could lead to additional clinical benefits, using low dosages and decreasing the risk of toxicity. The clinical aspects of the three phases of SARS-CoV-2 infection and similarities with IPF The first cases of SARS-CoV-2 infection were recorded in November 2019 in China; then, rapidly, they spread to all countries around the world causing thousands of deaths. SARS-CoV-2 infection in the most severe stages can rapidly cause respiratory distress syndrome. According to observational studies conducted, the majority of patients considered severe cases present bilateral interstitial pneumonia and a hyperactive inflammatory state that is not only localized in lung tissue but in all tissues of the body causing multi-organ dysfunction [7, 8] . SARS-CoV-2 infection has, according to scientific advice, been divided into three stages, the first as asymptomatic or slightly symptomatic with symptoms such as mild sore throat and abdominal pain and the second and third more severe stages presenting a generalized inflammatory state and respiratory distress syndrome. Studies have shown that bilateral interstitial pneumonia, so called because it attacks the tissue covering the pulmonary alveoli, is associated with the presence of fibrotic tissue caused by excess collagen ( f i b r o s i s ) i n t h e p u l m o n a r y i n t e r s t i t i u m w i t h hyperinflammation present [9] . Phases two and three are the most severe, and the presence of inflammation in the lungs and fibrotic tissue requires timely immunomodulatory and anti-inflammatory treatment. However, based on descriptions of symptomatology and diagnostic investigations of early observational studies, one might think that the use of a drug currently indicated for pulmonary fibrosis such as pirfenidone could bring great additional benefits both during viral infection and in the post-healing phase with residual pulmonary fibrotic damage [10] . The rationale for using antifibrotic therapy is based on the characteristics of pulmonary fibrosis observed in COVID-19, ranging from fibrosis associated with organic pneumonia to severe acute lung injury, where a rapid evolution towards widespread fibrotic change is observed [11] . In the most severe and fatal cases, pulmonary fibrosis is generally present [12] and also severe fibrotic organic pneumonia. The presence of pulmonary fibrosis is probably a consequence of the cytokine storm. Some of these biological and pathological features are shared with idiopathic pulmonary fibrosis (IPF) such as chronic inflammatory fibrotic lung disease caused by the synthesis and release of proinflammatory cytokines, including tumor necrosis factor alpha (TNF-α) and interleukin-1-beta (IL-1β). Antifibrotic therapy with pirfenidone, a drug indicated for the treatment of IPF, could therefore play a key role in preventing serious or fatal lung complications. However, antifibrotic therapy could play an even more important role in combined regimens, once identified, with effective anti-inflammatory treatments. Combination therapy could act on the main antiinflammatory and antifibrotic pathways in a synergistic way, mitigating the consequences of pulmonary fibrosis.@story_separate@Pirfenidone, for the treatment of IPF, is administered orally, 3 times a day, 2 or 3 tablets each time, for a minimum of 4 weeks. The mechanism of action of pirfenidone has not yet been fully determined and clarified. However, existing data indicate that pirfenidone has both antifibrotic and antiinflammatory properties, which have been tested in a variety of in vitro systems and animal models of pulmonary fibrosis (bleomycin-induced fibrosis and transplant fibrosis). Pirfenidone has been shown to reduce the accumulation of inflammatory cells in response to various stimuli [13] . Pirfenidone is able to mitigate the proliferation of fibroblasts, the production of proteins, and cytokines associated with fibrosis; it also mitigates the increase in biosynthesis and the accumulation of extracellular matrix in response to cytokine growth factors such as transformative growth factor beta (TGF-β) and platelet-derived growth factor (PDGF) [14] . There are currently no standardized therapeutic protocols to manage phases two and three of COVID-19 infection. Several clinical trials are underway to define the most appropriate drugs and doses to be used in the different stages of infection. However, it is certain that COVID-19 lung lesions are caused by a cytokinic storm leading to a hyperinflammatory and fibrotic state; therefore, control of this phase is essential to avoid serious complications and patient death. To date, the therapeutic efficacy of pirfenidone in pulmonary fibrosis induced by SARS-CoV-2 is still being demonstrated in clinical trials. Nevertheless, some evidence has already demonstrated the efficacy of antifibrotics in patients with pathogenic profibrotic pathways caused by immune/ inflammatory dysregulation, which may have similarities with those caused by SARS-CoV-2 infection [15, 16] . In addition, available studies potentially suggest that antifibrotic therapy, if used at the onset of SARS-CoV-2 infection, could be very effective in reducing and preventing fibrotic damage caused by inflammatory/immune dysregulation [17, 18] . A key aspect to consider is the timing of the onset of the antifibrotic action and the therapeutic efficacy of pirfenidone. In some severe cases of SARS-CoV-2, the evolution of the infection may be very rapid, and pirfenidone may not act with rapid efficacy. Again, evidence shows that pirfenidone has pleiotropic effects [19] in reducing inflammation and antioxidant action associated with a reduction in the fibrotic state (Fig. 1) . These pleiotropic effects could add value to the therapeutic p o t e n t i a l a g a i n s t C O V I D -1 9 [ 1 3 ] . I n a d d i t i o n , immunomodulants such as IL-1 and IL-6 inhibitors, or antiinflammatory, could be combined with pirfenidone to have an impact therapy that acts early on inflammation and fibrotic state. Finally, studies have shown that some patients cured of COVID-19 had pulmonary fibrotic tissue residues; also in this category of patients, the use of pirfenidone as therapeutic treatment after infection could be effective. For a possible relevance to the pulmonary outcomes of COVID-19, it should be noted that, recently, for pirfenidone, the revolutionary therapy status (which accelerates the drug approval process) for fibrous interstitial lung disease has been recognized by the FDA. However, some issues remain to be clarified. First, what is the effect of antifibrotic molecules such as pirfenidone on internalization and viral replication COVID-19? The authors declare that they have no conflict of interest. Ethical approval There are no sensitive data, and no patients were recruited for this study. The authors accept the full TRANSFER OF COPYRIGHT to the journal. @story_separate@The global COVID-19 pandemic is a health and economic emergency. Many features of biological processes leading to acute respiratory distress syndrome caused by SARS-CoV-2 infection are partly shared with IPF. Antifibrotic drugs such as pirfenidone may have therapeutic potential to prevent or reduce fibrotic lung lesions of the ongoing COVID-19 infection, or in patients already healed but with fibrotic consequences. In conclusion, we hope that the observations highlighted will induce the scientific world to work on well-designed studies of antifibrotic therapies for severe COVID-19 pneumonia. Authors' contributions I, the undersigned, Francesco Ferrara, and any other author declare that the manuscript was written entirely by the authors. All authors made an equal contribution in the development of the paper. Compliance with ethical standards The document does not conflict with ethical legislation.","AIM: SARS-CoV-2 infection has been divided by scientific opinion into three phases: the first as asymptomatic or slightly symptomatic and the second and the third with greater severity, characterized by a hyperinflammatory and fibrotic state, responsible for lung lesions, in some cases fatal. The development of antiviral drugs directed against SARS-CoV-2 and effective vaccines is progressing; meanwhile, the best pharmacological objective is related to the management of all the complications caused by this viral infection, mainly controlling the inflammatory and fibrotic state and preventing the infection from moving into the most serious phases. SUBJECT AND METHOD: Describe the scientific rationale related to the use of an antifibrotic therapy with pirfenidone, as monotherapy and/or in combination with anti-inflammatory drugs to manage and control complications of SARS-CoV-2 infection. RESULTS: Based on the scientific literature and epidemiological results and considering the pathophysiological, biological, and molecular characteristics of SARS-CoV-2, an antifibrotic drug such as pirfenidone as monotherapy or in combination with anti-inflammatory drugs can be (acting early, at the right doses and at the right time) therapeutically effective to avoid serious complications during viral infection. The same approach can also be effective as postinfection therapy in patients with residual pulmonary fibrotic damage. Management of inflammation and fibrotic status with a combination therapy of pirfenidone and IL-6 or IL-1 inhibitors could represent a pharmacological synergy with added value. CONCLUSION: In this article, we consider the role of antifibrotic therapy with pirfenidone in patients with SARS-CoV-2 infection on going or in the stage of postinfection with pulmonary fibrotic consequences. The scientific rationale for its use is also described."
"The severe acute respiratory virus coronavirus-2 (SARS-CoV-2) pandemic caused major changes also in health care support for patients with cancer worldwide (Maringe et al. 2020; Shah et al. 2019; Sud et al. 2020; van de Haar et al. Jun Ma and Xiaojun Huang have contributed equally to this work.@story_separate@The online version of this article (https ://doi.org/10.1007/s0043 2-020-03426 -0) contains supplementary material, which is available to authorized users. 2020). Recommendations from many professional societies suggest an individualized decision-making (Al-Shamsi et al. 2020; Di Ciaccio et al. 2020; ESMO 2020; Ismael et al. 2020) . The general thrust is to reduce therapy intensity in patients with cancer with concerns that cancer and treatment may lead to a higher risk of infections and worse coronavirus infectious disease-2019 (COVID-19) outcomes. We selected lymphoma as a frequent type of cancer and sought to investigate how the pandemic and typical interventions might impact on levels of anxiety among patients and their caregivers as well as how they affected patients' healthrelated quality-of-life (HRQoL). Therefore, we did an online survey using the platform of the Chinese lymphoma patient organization (House086). Patients and caregivers completed a questionnaire and standardized evaluation instruments to quantify levels of anxiety and HRQoL. The questionnaire and anxiety instrument were also completed by normals using the WeChat, a messaging and social media mobile app platform frequently used in China. We found that the prevalence of anxiety in lymphoma patient and caregiver respondents during the SARS-CoV-2 pandemic was significantly higher compared with normal. Unexpectedly, patient HRQoL during the pandemic was better compared with a propensity score matched pre-pandemic cohort. Better caregiver support was associated with less anxiety and better HRQoL. Access to an Internet-based lymphoma patient support platform and an education programme improved HRQoL. Several of these co-variates are actionable and may help to alleviate patients' concerns caused by SARS-CoV-2. We conducted a cross-sectional survey of lymphoma patients and their caregivers regarding the level of anxiety and patients' HRQoL between 17 and 19th April, 2020, using House086 as the distribution platform (Supplement 1). Controls for the anxiety instrument were persons with no association with lymphoma patients or hospitals invited to participate in an online WeChat survey. Data from a HRQoL nationwide cross-sectional survey of lymphoma patients in 2019 were used to find matching cases as a pre-pandemic control cohort. The 2019 lymphoma survey included 4068 Chinese with all sub-types of lymphoma from which 1106 patients matched on sex, age, education level, and sub-type of lymphoma and therapy type were extracted. Sample size was calculated as n = (z) 2 p (1 − p)/d 2 , in which z = 1.96 for a level (α) of confidence of 95%. Tolerated margin of error was 0.05. The prevalence of clinically important anxiety in the Chinese population is reported as 29-35% (Huang and Zhao 2020; Wang et al. 2020) . Minimum number of the qualified questionnaires was estimated as 350. An online questionnaire collected data on: (1) demographics; (2) lymphoma-related data; (3) impact of the pandemic on health care-related activities; (4) hours of mobile phone use; (5) online patient-assistance resources; (6) quality of caregiver support (10-point scale); and (7) quality of the CSCO online education programme (10-point scale). To quantify anxiety of lymphoma patients, caregivers, and normals, we used the Zung Self-Rating Anxiety Scale (SAS) (Chinese version) (Liu et al. 1997; Zung 1971; ZY 1984) . We used the EORTC QLQ-C30 (v.3; Chinese version) to quantify lymphoma patients' HRQoL (Aaronson et al. 1993; Zhao and Kanda 2000) . The study was approved by the Ethics Committees of Peking University Peoples' Hospital according to tenets of the Declaration of Helsinki (Register number 2020PHB173). Electronic informed consent was obtained from all respondents who could withdraw at any time during the survey without prejudice. Descriptive statistics were used for the demographic, social, and lymphoma-related co-variates. Anxiety index (AI) was calculated according to the Zung SAS, a rating instrument for anxiety disorders. Based on extensive validated data, an AI < 50 is defined as normal, 50-59, minimal/moderate, 60-69, marked/severe, and ≥ 70, extreme anxiety in the Chinese population with an internal consistency reliability of 0.66-0.80 and the Cronbach α of 0.87 (Minglu et al. 2020; Shao et al. 2020) . Scores of five functioning scales (physical, role, emotional, cognitive, and social functioning), eight symptom scales (fatigue, nausea/vomiting, pain, dyspnea, sleep disturbances, appetite loss, constipation, and diarrhea), fiscal impact, and overall HRQoL were calculated using the EORTC QLQ-C30 instrument (Aaronson et al. 1993) . Lymphoma respondents from this study were matched with respondents to the 2019 pre-pandemic study on covariates including age, education level, lymphoma sub-type, and therapy by the nearest neighbor matching method with R packages ""MatchIt"" at a 1:1 ratio. Standardized mean difference was calculated for each of the co-variates between the cohorts before and after matching to assess matching quality. An absolute standardized difference of > 20% denotes meaningful co-variate imbalance (Supplement 2). We used the Independent-Samples t test to compare groups of continuous variables and one-way analysis of variance (ANOVA) and LSD to analyze differences among cohorts and each paired cohort. Chi-square test was used to analyze categorical co-variates. We used a multi-variable analysis with binary logistic regression to identify risk factors of anxiety. The Kendall tau-b correlation was used to evaluate risk factors of HRQoL. Tests were two-sided and P ≤ 0.05 was considered significant. Statistical analyses were performed with SPSS 12.0 (IBM SPSS Statistics, New York, US). We received 2745 responses from subjects in 32 Chinese provinces, autonomous regions, centrally administered municipalities, and special administrative regions identified by internet protocol (IP) addresses. 166 questionnaires, incomplete or completed in < 1 min or > 60 min, were excluded from further analyses. 94 percent of questionnaires were evaluable. 1106 (43%) of the 2578 respondents were lymphoma patients, 948 (37%), caregivers and 524 (20%), normals (Table 1) . 1031 respondents (40%) were male and 2313 (90%), 20-60 years. 495 (45%) patient respondents were 20-39 years, 477 (43%) were 40-59 years, and 110 (10%) were ≥ 60 years. There was a discordance between patients' age reported by patients and caregivers (Table 2) . 1912 (74%) respondents were college graduates or received other higher education. 88 (3%) lived in Hubei province with Wuhan as the capital city known to be the first area on lockdown from 23rd January to 8th April in China. 275 (11%) were living outside their usual residence. 15 reported that they were infected with SARS-CoV-2 and another 19, their friends or relatives were infected with SARS-CoV-2. Distribution of lymphoma types reported by patient and caregiver respondents was similar to lymphoma distribution data from China (Cao et al. 2018; Sun et al. 2012; Yang et al. 2011) . 654 (59%) patient and 700 (74%) caregiver respondents reported an aggressive lymphoma (P < 0.001; Table 2 ). 966 (47%) patient respondents were on-therapy, parenteral in 707 (34%) and oral in 259 (13%). 1088 (53%) patient respondents were under medical supervision with no current therapy. 819 (47%) receive in-hospital (40%) or outpatient (7%) therapy. 1155 (56%) patients changed the hospital they had been visiting for routine monitoring and/or therapy during the SARS-CoV-2 pandemic. 192 (9%) changed to a therapy of lower intensity. 89 (4%) switched to oral anti-lymphoma drugs, 259 (13%) delayed scheduled parenteral therapy, and 761 (37%) delayed or postponed scheduled hospital visits. 482 (24%) experienced reduced therapy intensity including fewer drugs, reduced drug doses, a switch from parenteral to oral drugs, and/or therapy delay or discontinuation. 1059 (52%) reported no change of their medical activities including physician visits, exams, and/or therapy. The most frequent concerns of patient respondents were their lymphoma (N = 603; 55%), SARS-CoV-2-infection (N = 547; 50%), and the inability to attend outpatient clinics (N = 429; 39%). The most frequent concerns for caregiver respondents related to the patient they were caring for were lymphoma (N = 595; 63%), therapy disruption (N = 397; 42%), and SARS-CoV-2-infection (N = 392; 41%). The most frequent concerns of normal respondents were SARS-CoV-2-infection risk to their family (N = 347; 66%), themselves (N = 308; 59%), and income loss (N = 198; 38%). Respondents with any level of anxiety (i.e., Zung score > 50) were 33% (95% confidence interval [CI] 30, 36%) for lymphoma patients, 31% (28, 34%) for caregivers, and 21% (17, 24%; three-cohort comparison: P < 0.001) for normal individuals. Pair-wise comparisons showed incidence of anxiety was similar in patients and caregiver respondents (P = 0.29) but higher compared with normals (both P < 0.001). Severity of anxiety was similar in the three cohorts. Among persons with anxiety, minimal/moderate severity levels (score > 49) were 77%, 70%, and 72%, marked/severe anxiety (score > 59, 19%, 23%, and 22% and extreme anxiety (score > 69), 4%, 7%, and 6% (P = 0.22). We evaluated co-variates associated with anxiety in respondents (Table 3) Patient respondents not hospitalized during the pandemic but before the survey had less anxiety of any severity compared with hospitalized respondents (HR = 0.62 [0.48, 0.81]; P = 0.004). Frequency of marked/severe or extreme severity was also increased in hospitalized versus not hospitalized patient respondents (HR = 0.62 [0.40, 0.98]; P = 0.042). Among patient respondents not hospitalized during the pandemic but before the survey, persons with a higher family support score had lower incidence of anxiety (HR = 0.90 [0.85, 0.96]; P = 0.002). Among patient respondents hospitalized during the pandemic, but before the survey, there was no correlation between incidence of anxiety and caregiver support score (HR = 0.97 [0.86, 1.08]; P = 0.54). In multi-variable analyses, we found more patients receiving therapy (HR = 1.43 [1.08, 1.89]; P = 0.012), those with reduced therapy intensity (HR = 1.59 [1.14, 2.21]; P = 0.006)  Caregiver respondents were knowledgeable of patients' diagnoses, stage and therapy, were aware of difficulties patients faced, and were enthusiastic to receive information about lymphoma-related medical aspects (Table 1) . Patient respondents gave their caregivers a mean support score of 8.84 ± 2.16 (SD). There was a large increase in mobile phone use during the SARS-CoV-2 pandemic in China. 12% (10, 14%) of patient respondents, 10% (8, 12%) of caregivers, and 18% (15, 22%; P < 0.001) of normals used their mobile phones (the main source of Internet access in China) for ≥ 8 h per day versus 6% (5, 8%; P < 0.001), 5% (4, 6%; P < 0.001), and 8% (6, 11%; P < 0.001) before the pandemic. 40% (37, 43%), 50% (46, 53%), and 52% (47, 56%) reported an increase in mobile phone use by > 2 h daily during the pandemic. 86% (83, 88%), 87% (84, 89%), and 90% (87, 92%, P = 0.052) of patient, caregiver, and normal respondents accessed pandemic news on their mobile phones. 42% (39, 45%), 29% (26, 32%), and 53% (48, 57%; P < 0.001) of patient, caregiver, and normal respondents reported to use their mobile phone for entertainment including reading novels, movies or TV. 75% (72, 78%), and 84% (81, 86%; P < 0.001) of patients and caregiver respondents reported reading news about lymphoma or participated in the CSCO lymphoma education programme.  We used the EORTC QLQ-C30 instrument to compare lymphoma patient respondents' HRQoL at the time of our study with that of Chinese lymphoma patients in a survey in 2019 after matching for sex, age, education level, lymphoma type, and therapy in a propensity score analysis (Supplement 2). Patient respondents had better HRQoL scores compared with controls. Physical, role, emotional, cognitive, social functioning, and general HRQoL were significantly better (all P values < 0.05). Nausea and vomiting, dyspnea, insomnia, constipation, and financial difficulties were milder (all P values < 0.05) compared with pre-pandemic controls (Table 4 ). Next, we analyzed co-variates correlated with HRQoL. Increased daily mobile phone use and participation in the education programme were not correlated with HRQoL. In contrast, reduced therapy intensity was significantly associated with a worse general HRQoL and five worse functions, eight symptoms, and financial difficulties. Patient respondents who scored caregiver support high had a better general HRQoL, emotional function, cognitive function, and fewer or less severe insomnia and diarrhea. Patient respondents who scored the education programme high had better HRQoL including all five functions and fewer symptoms of nausea and vomiting, dyspnea, insomnia, and diarrhea (Supplement 3). The SAR-CoV-2 pandemic in China reduced lymphoma patients' access to medical care including out-and inpatient clinic and hospital visits and direct contact with medical personnel including doctors and nurses. It also decreased potential interactions with other lymphoma patients they might encounter in clinic or hospital settings. Because of travel restrictions, some patients had to switch their pointof-contact for medical care, for example, to a nearby clinic or hospital. Decreased blood testing and pharmacy access led to therapy modifications such as switching to oral drugs. These impacts of the pandemic occurred globally (Chen-See 2020; Triggle 2020). Because these co-variates are important determinants of anxiety and HRQoL in lymphoma patients, we sought to quantify these and to determine the impact, if any, of alternative support resources such as caregivers, patient support organizations, and an online education programme. There are few studies about anxiety or HRQoL in patients with cancer during the SARS-CoV-2 pandemic. A small study of 77 outpatients with lymphoma in one hospital reported an anxiety incidence of 36% (Romito et al. 2020) . We found that the incidence of anxiety in lymphoma patients and caregivers was about 30% and 50% higher than in normals in our survey. In our cross-sectional study, more than 70% of respondents had minimal/moderate anxiety. Covariates associated with low incidence of anxiety included no SARS-CoV-2 infection, not being a lymphoma patient or caregiver, physical exercise, higher education level, a > 2 h increase in daily mobile phone use, and a higher family support score. Among patient respondents, physical exercise and better caregiver support were associated with less anxiety, whereas female sex, receiving therapy, and reduced therapy intensity were associated with more anxiety. Previous cancer patient-caregiver dyads studies reported caregivers experienced similar or higher anxiety levels compared with patients (Li et al. 2018; Nipp et al. 2016; Sklenarova et al. 2015) . We found a similarly increased incidence of anxiety in lymphoma patients and caregiver respondents. In China, caregivers, typically young family members, are deeply involved in patients' medical care and related activities based on the concept of filial piety often assuming responsibility for patients' financial, physical, and mental support. There were some discordances between patient co-varieties reported by patients and by their caregivers possibly reflecting some degree of technical change posed by electronic reporting by older persons. A higher proportion of patients with aggressive lymphoma reported by the caregiver compared with patient respondents is consistent with caregivers' concern for patients. Many studies report that caregivers' well-being is an important aspect for patients' mental health (Castillo et al. 2019) . Consequently, we were not surprised to find patients scoring their caregiver support high had a lower incidence of anxiety compared with patients giving low scores. We were surprised to find that HRQoL of lymphoma patients during the pandemic was better than a propensity score matched cohort before the pandemic. When we analyzed unbalanced co-variates between the two cohorts correlating with HRQoL, we found no impact of increased daily mobile phone use. A reduction in therapy intensity, however, was significantly associated with worse HRQoL. Patient respondents who scored caregiver support high had a better general HRQoL, physical and emotional function, cognitive function, and fewer or less severe symptoms of insomnia and diarrhea. The lower diarrhea score is presumably related to the perception of severity rather than incidence, frequency, or severity. Social support resources for lymphoma patients besides caregivers included online patient support/discussion groups such as House086 and the CSCO professional education programme. We found that subjects who rated the quality of these online tools high had a better HRQoL. Reducing cancer therapy intensity during the pandemic is not an evidence-based recommendation (Al-Shamsi et al. 2020; Di Ciaccio et al. 2020; ESMO 2020; Ismael et al. 2020 ). However, decreased therapy intensity was reported by 24% of patients and caregiver respondents in our survey, and was associated with a higher incidence of anxiety and worse HRQoL. Our questionnaire did not allow us to determine why therapy intensity was reduced, but limited access to medical care at times when significant resources were used to cope with the challenges of the pandemic is the most likely reason. There are several limitations of our study. Our survey was online with potential selection biases. For example, our patient respondents were younger than most lymphoma patients, perhaps because of increased Internet familiarity and/or access. Not surprisingly, our normals cohort had a much younger age than patient and caregiver respondents. Because our survey was cross-sectional, it was not possible to compare anxiety and HRQoL in the same respondent before and during the pandemic. In our comparison of HRQoL with a pre-pandemic cohort, we lacked data on lymphoma stage, so we cannot know if the better HRQoL which we observed during the pandemic might result from patients with less advanced lymphoma (Stewart et al. 2016 ).@story_separate@During the SARS-CoV-2 pandemic, lymphoma patients and their caregivers had a significantly higher incidence of anxiety compared with normals. Incidence was increased in persons stopping or reducing therapy intensity. Paradoxically, lymphoma respondents had a better HRQoL compared with pre-pandemic lymphoma controls. Good social services including caregiver support and an online lymphoma education programme were associated with less anxiety and better HRQoL. Reduced therapy intensity was also associated with worse HRQoL. Reduced therapy intensity in cancer patients during the SARS-CoV-2 pandemic may have negative impact on patient anxiety and HRQoL.","INTRODUCTION: The severe acute respiratory syndrome-2 (SARS-CoV-2) pandemic disrupted medical care for persons with cancer including those with lymphoma. Many professional societies recommend postponing, decreasing, or stopping anti-cancer therapy in selected persons during the pandemic. Although seemingly sensible, these recommendations are not evidence-based and their impact on anxiety and health-related quality-of-life (HRQoL) is unknown. METHODS: We surveyed 2532 subjects including 1060 persons with lymphoma, 948 caregivers, and 524 normals using a purposed-designed questionnaire on a patient organization website. Respondents also completed the Zung Self-Rating Anxiety and patient respondents, the EORTC QLQ-C30 instruments to quantify anxiety, and HRQoL. We also evaluated caregiver support and an online education programme of the Chinese Society of Clinical Oncology (CSCO). Data of HRQoL from a 2019 pre-pandemic online survey of 1106 persons with lymphoma were a control. RESULTS: 33% (95% confidence interval [CI] 30, 36%) of lymphoma patients and 31% (28, 34%) of caregivers but only 21% (17, 24%) of normals had any level of anxiety (both pair-wise P < 0.001). Among lymphoma respondents, physical exercise and better caregiver support were associated with less anxiety, whereas female sex, receiving therapy, and reduced therapy intensity were associated with more anxiety. Paradoxically, lymphoma respondents during the pandemic had better HRQoL than pre-pandemic controls. Reduced therapy intensity was associated with worse HRQoL, whereas respondents who scored caregiver support and the online patient education programme high had better HRQoL. CONCLUSION: During the SARS-CoV-2 pandemic, lymphoma patients and their caregivers had significantly higher incidences of anxiety compared with normals. Lymphoma respondents reported better HRQoL compared with pre-pandemic controls. Reduced therapy intensity in persons with cancer may have unanticipated adverse effects on anxiety and HRQoL. Regular and intense support by caregivers and online education programmes alleviate anxiety and improve HRQoL. ELECTRONIC SUPPLEMENTARY MATERIAL: The online version of this article (10.1007/s00432-020-03426-0) contains supplementary material, which is available to authorized users."
"During the early months of 2020, it became evident that the SARS-CoV-2 virus was spreading through the global population at an alarming rate. As the pandemic devastated global economies and supply chains, it was obvious that the strategies in place were not sufficient to handle a crisis at this scale. Some of the obvious challenges presented by this crisis were the distribution of personal protective equipment, testing kits, and vaccine distribution under extreme shortages, as well as testing accuracy. At the time of this writing, the world is waiting for a vaccine to suppress the virus in the population and distributing it will present a new series of logistical issues. This problem is extremely rich with potential to improve distribution processes using This work is supported by the Air Force Office of Scientific Research (Award Number FA9550-19-1-0203). quantitative strategies; this work will choose a subset of these problems and utilize reinforcement learning and approximate dynamic programming strategies to improve them. In this paper, it is assumed that a country/region is in the midst of a pandemic and a decision-maker is tasked with allocating a limited supply of vaccines and testing kits to various local zones in order to try to mitigate the spread of the disease. These zones could be states, counties, or some other partition of the region. A key challenge in this setting is the uncertain number of infected individuals, which can only be learned by making observations through testing. The data collected through testing would then be used to create a probabilistic belief about the true underlying state, which gives vaccine distributors useful information about where to send vaccines to slow the spread. The combination of making resource allocation decisions under uncertainty, while also performing information collection decisions to improve through active learning, represents a unique modeling and algorithmic challenge. The heterogeneous characteristics of population densities, health characteristics and behavior will influence transmission rates and virus mobility within local regions; hence, intelligently allocated vaccines will impact the number of infections. The testing decisions are critical to making the best allocation decisions because the controller needs to have knowledge about the state of the pandemic. The observations made through testing will reflect biases in the samples caused by factors such as asymptomatic carriers, refusal to get tested, and false positives/negative errors. It is important to consider the risks caused by the biases because skewed testing data could eventually lead to poor allocation decisions. The best decisions can be made when each of these characteristics are properly modeled. This paper makes the following contributions: • It provides the first formal model for a high dimensional pandemic resource allocation problem that captures passive information processes, and active learning.. This model is able to capture the uncertainty in the knowledge about the elements of the SIR model through the belief state, make vaccine allocation decisions under uncertainty, and perform active learning to improve the quality of the belief state. • It proposes a vaccine allocation policy which combines a direct lookahead model with a parameterized approximation of the cost function in order to adjust for risk. The tunable lookahead policy in conjunction with an active learning policy is capable of outperforming a population-based myopic policy. We demonstrate this through multiple pandemics simulations on toy networks and simulation models of states in the USA. • We propose an observation function model in order to capture the biases introduced from asymptomatic carriers, refusal to get tested, and false positives/negatives. The risk-adjusted stochastic lookahead implementation policy proposed in section 5.1.2 can be tuned to reduce the risks posed by biased sampling. • We present a robust modeling framework which is capable of working with environment models of increasing complexity. As the epidemiological models used to create a simulator improve, the modeling framework has the flexibility to adapt to the new data. The paper is organized as follows. Section 2 summarizes the literature about vaccine distribution, POMDP modeling, and the unified framework. Section 3 describes the mathematical model for the environment agent using the unified framework. Section 4 describes the mathematical model for the controlling agent using the five components of the unified framework. Section 5 describes implementation policies selected from the two general strategies for designing policies: policy search and lookahead approximations. Section 5 describes the active learning policy chosen for allocating testing kits. Section 6 describes the results of the model implemented on an epidemic toy problem and the simulated SARS-CoV-2 pandemic model in the United States. Section 7 summarizes conclusions from the research.@story_separate@In section 2.1, we give a brief overview of the literature about vaccine distribution strategies during an epidemic. In section 2.2, we give a brief review of partially observable Markov decision processes (POMDP's) and their limitations. In section 2.3, we give an overview about modeling frameworks and their relationship to the unified framework in this paper. Planning during an epidemic requires making decisions in many different areas such as enacting social distancing measures, contact tracing, vaccine distribution, personal protective equipment distribution, and the allocation of various other essential resources. Making these decisions can be modeled as sequential decision problems with the common goal of limiting the number of infected individuals. The literature is rich with policies and algorithms across various different fields to make these decisions intelligently. The resource distribution problem is multi-faceted. The supply chain to deliver resources from the manufacturing facilities to the recipient has many different steps. For example, some of the decisions which need to be made are where to send resources, who recieves the resources (i.e. who gets vaccinated at a clinic), and how to transport the resources to these locations. The implementation decisions in this paper are concerned with where to send vaccines to have the greatest reduction in cases. Any sequential decision problem requires a dynamic model of the problem and a policy for making the decisions using the model. One of the most common ways to model a pandemic is to use compartmental models, and these are especially useful because they can be formulated as Markov chains. In 1927, Kermack and McKendrick (1927) created the SIR model which is the most basic compartmental model consisting of three groups within a population: those susceptible (S) to the disease, those infected (I) with the disease, and those removed (R) from the population (from death, recovery, or immunity). Since then, the compartmental model literature has expanded past the SIR model to include many different extensions. Some extensions of the SIR model include: the SEIR (Susceptible-Exposed-Infected-Removed) model, SIRS (Suscepible-Infected-Removed-Susceptible) model, stochastic SIR model, and a spatial SIR model. The SEIR model is used for diseases with an incubation period before an individual becomes infected. The SIRS model is used for diseases that do not have permanent immunity. The stochastic SIR model is used for diseases which have stochastic transmission rates over time. The spatial SIR formulation is used to model a disease across spatially distributed subpopulations which may interact with one another. In this paper, we focus on the SIR model with stochastic and spatial extensions; however, there could always be additional extensions which could make it marginally more realistic. Most models for planning during epidemics include compartmental models in their logic. Brandeau et al. (2003) utilizes an SI compartmental model in conjunction with optimization techniques to mitigate the spread of an infectious disease by allocating resources which suppress transmission rates. Martin et al. (1993) uses a spatial SEIR model in conjunction with multiple vaccine allocation strategies to mitigate a measles outbreak amongst dorms on a college campus. Ding et al. (2007) , Asano et al. (2008) ), Neilan and Lenhart (2011), and Zakary et al. (2017) use deterministic spatial SIR models and extensions to derive policies from optimal control theory using variations of the Hamilton-Jacobi-Bellman equations to decide where to allocate vaccines. Zhang and Prakash (2014) formulates a graphical model of a pandemic with uncertainty in the transmission rates reflected through the edges in the graph. They propose and compare algorithms to allocate a limited number of vaccines across the network to minimize the resulting footprint. Another decision is who receives a set of allocated resources. Patel et al. (2005) uses a stochastic influenza model along with a genetic algorithm to decide which age groups should receive a limited supply of vaccines. Medlock and Galvani (2009) uses models of past flu pandemics to compare policies for administering a limited supply of vaccines among various age groups. Ekici et al. (2008) uses a complex spatial SEIR model in conjunction with an age-based component to decide who to feed during a flu pandemic in Georgia by setting up food distribution centers. There are various other decisions studied among the literature to optimize a vaccine supply chain. For example, Lin et al. (2020) models a problem to decide whether a distributor will transport vaccines through a cold chain or a non-cold chain to ensure that they are still viable at administration. Dai et al. (2016) models an influenza supply chain in the U.S. consisting of healthcare providers, manufacturers, and distributors to ensure on-time delivery to each provider. This paper will assume that the true pandemic has a compartmental model; however, we assume that the controller does not have access to this model and must make decisions about where to test to learn about the true state of the pandemic (active learning). If the true state is only partially observable, then the controller must model the uncertainty to make decisions. There are various modeling strategies to handle decisions under uncertainty. The next section discusses the modeling framework for partially observable Markov decision processes (POMDP), and its limitations in this problem. A partially-observable Markov Decision Process (POMDP) is a system which includes a controlling agent making decisions in an environment where the underlying state transitions are Markov; however, the true underlying state of the environment can only be observed partially by the controlling agent. The finite horizon POMDP problem is modeled using the tuple (S, X , P, R, W, P obs , T ). • S -the state space of the environment (e.g. number of infected people in the population). • X -the decision space (e.g. number of vaccines sent to each zone). • P(s |s, x) -the probability transition matrix for the next environment state given a state-action pair. • R(s, x) -the reward function for a given state-action pair. • W -the observation space (e.g. number of new infections measured through testing). • P obs (w|s, x) -the probability of observing w ∈ W given a state action pair. • T -the time horizon. For the POMDP model, let s t be the state variable for the environment agent. The goal of a POMDP is the same goal as an MDP: to find a policy, X π , which maximizes (or minimizes) the expected sum of cumulative rewards, max π E π T t=0 R(s t , X π t (s t ))|s 0 . The expectation over π suggests that the stochastic processes in the problem are impacted by the decisions made by the policy. In a POMDP, the true state variable, s t , is unknown to the controlling agent at time t, hence the value of the state cannot be computed. If the true state variable is unknown then the state transitions are non-Markovian (from the controlling agents perspective); hence, the entire history of observations and actions would be required to make decisions. If the entire history of observations had to be stored this would grow extremely quickly. The rapid growth of the history of actions and observations is known as the curse of history. To circumvent the curse of history, the controlling agent stores a belief state variable, b t (s) ∀s ∈ S. b t (s) is a probability distribution over the (presumably discrete) state space, hence s∈S b t (s) = 1. Astrom (1965) shows that the belief state is a sufficient statistic for the history and describes a distribution over the possible states of the environment at time t derived from the previous observations, actions, and states. It is defined by, b t (s) = P(s t |W t , s t−1 , x t−1 , W t−1 , ..., s 0 , x 0 ) = P(s t |W t , b t−1 (s)). When new observations arrive the agent must perform a Bayesian update to compute this new belief state using only the new observations and the previous belief state. Using the terms in the tuple, we can compute In equation (2), the state space must be summed over; if it is a vector then |S| grows exponentially. Additionally, computing the transition matrix P(s |s, x) and observation matrix, P(w|s , x), when the observations and decisions are vectors will also be intractable. Powell (2011) discusses the reasons for the intractability of equation (2) known as the three curses of dimensionality. In theory, the solution to the belief MDP can then be used to solve for the optimal policy using Bellman's Equation Ross et al. (2008)  then Bellman's optimality equation for a POMDP is given by, It is important to note that b t+1 (s ) must be calculated using equation (2). For finite horizon problems the exact solution is only tractable when the state space, action space, and observation space are small. The belief state is an uncountable continuous set, therefore trying to find a mapping for each element of this set using backward dynamic programming is not possible. However, it is a well known result from the POMDP literature that the value function for belief states is still piecewise linear and convex (e.g. Pineau et al. (2006) ), which implies that an optimal solution exists. The ability to find the exact optimal solution is almost never possible for real world problems, in fact, the finite horizon POMDP is PSPACE-complete (e.g. Pineau et al. (2006) ). Pineau et al. (2006) gives a set of solutions using a point-based value iteration approach and compares it to other POMDP solvers. Ross et al. (2008) derives online planning algorithms for the POMDP problem. Hoey and Poupart (2005) formulates strategies for solving POMDPs with continuous and multi-dimensional observations spaces. Roy et al. (2005) attempts to circumvent the curse of dimensionality by finding a low dimensional belief space embedded in the high dimensional belief state to project into. There have been many algorithms developed for solving POMDPs to make the solutions tractable, but the computational complexities suggest that they would only work for problems with small state, action, and observation spaces compared to the size of the problem discussed in this paper. The POMDP modeling approach is widely used for problems with unobservable parameters or quantities, but it suffers from severe computational limitations (it probably cannot be applied to a problem in this paper with more than 3 or 4 zones). Often overlooked, however, are subtle modeling assumptions that would not apply for our COVID setting. In particular, the policy in equation (3) uses the one-step transition matrix P(s |s, x) which, aside from being computationally intractable, implicitly assumes that the transition function is known to the controller. This means that the controller actually knows the dynamics of how the disease is communicated, which is not the case with COVID-19. The traditional POMDP formulation is not only computationally intractable for all but toy problems, it does not properly model the fact that the people making decisions about testing and vaccine distribution do not even know the dynamics of the problem. The POMDP model is a more generalized version of the Markov Decision Process (MDP) framework which forms the roots for much of the reinforcement learning literature. It is not the only way to model a sequential decision problem in the literature. Powell (2019b) compares and contrasts reinforcement learning in the MDP framework with the modeling framework in the stochastic optimal control literature. The discussion by Powell (2019b) leads to formulation of the unified framework which ties together the various styles of modeling a sequential decision problem into a consolidated framework which can easily be translated into software. This framework leads to an optimization problem to search over policies, which discriminates it from other modeling frameworks. The unified framework consists of five core components: the state variable, the decision variable, the exogenous information process, the transition function, and the objective function. After the five components are modeled, a policy can be chosen from four classes of policies which are listed below: • Policy function approximation (PFA) -analytical functions directly mapping states to actions, e.g. lookup tables, parametric function, • Cost function approximation (CFA) -an optimization problem involving a parameterized approximation of the cost function, e.g. upper confidence bounding, and Powell (2020) utilize the unified framework for problems in application spaces such as energy storage, transportation, and dynamic pricing, respectively. This paper will view the controller and environment as two separate agents and model each of them with the unified framework. The interactions between the agents are then modeled as appendages to their respective exogenous information processes. From the perspective of the controlling agent, the environment agent is a black box which can be queried for observations and impacted by decisions. The real world will almost always be more complex than any simulator, and a controlling agent would have to approximate the real world to the best of its ability. Therefore, the environment model was designed to be sufficiently complex to include factors the controlling agent cannot anticipate. The point is to create a robust model that allows the controlling agent to make effective decisions with an imperfect model. The model presented in section 4 would function with any increasingly complex environment model. The simulator designed in this section is to make the environment model as realistic as possible by including more stochasticity and complexity than the controlling agent model; hence, we recognize that the simulator constructed for the environment model can be more complex. is the lack of symptoms in some portion of the positive cases, also known as an asymptomatic carrier. The presence of symptoms will cause issues with testing because it decreases the likelihood of a person going to get a test. To make the testing model as realistic as possible, these factors are included in the sampling oracle. The errors within the tests will also be a major concern because they are not always accurate. There are two types of errors that are possible: false positives and false negatives. Each type of error will have a probability of occurring given that a test was administered. Due to limited testing capacity, the number of tests available may exceed the number of people that try to get access to tests. The model will assume that as the number of tests available increases within a zone, then the likelihood of going to get a test will also increase. In summary, the environment agent model used to construct the simulator in this paper includes many factors such as spatial correlations between infected populations, biases in testing procedures, stochastically evolving transition rates, and vaccine success rates. Some of these factors would be extremely difficult to evaluate online as the controlling agent makes decisions, but they impact the results of the simulator. Hence, we claim that the simulator presented in this section is sufficiently complex to measure the performance of the policies designed in section 5 and the quality of the modeling in section 4. The state variables for the environment agent base model include the variables needed to model the system from time t and onward. The importance of modeling the simulator and the controller as separate entities is to capture the fact that the controller is not always able to observe the state of the environment perfectly. Hence, the dynamic state variable for the simulator is given by, where, Additionally, the initial environment state variable consists of all variables which do not change dynamically, hence it is given by S env In this model of the environment agent, we reiterate that this simulator does not include dynamically changing mean transmission rates, recovery rates, or vaccine success rates. In the real world, these factors are likely changing dynamically as local laws change and better drugs are developed. The exogenous information for the environment agent model refer to streams of information that occur exogenously, which we model as stochastic processes. These variables include: where, x vac t = vector of number of vaccines allocated to each zone, M t+1 = random matrix of inter-zone mobility, ε β t+1 = additive noise for transmission rate evolution, α t+1 = mobility rate at time t + 1, n vac t+1 = number of vaccines available at time t + 1. The simulator transition function describes how each simulator state variable evolves between time t and t+1. The spatial SIR model can be modified to allow vaccines (which are managed by the controller) to impact the environment agent. At time t, the x vac t vaccines pass through the environment transition functions and can impact the true state. The function of the vaccine is to directly move people from the susceptible group into the recovered/immune group. The dynamics are captured through the following transition equations, where ξ is the success rate of the vaccine, r t = β t+1,z Itz Nz , andM t+1 is the mobility probability matrix. The mobility rate and number of vaccines available are assumed to be totally exogenous based on the current laws and vaccine manufacturing process, respectively. The equation for the transition rate at t + 1 is given by, Since there are no decisions made within the environment there is no objective function. Another important component of the simulator is to model the impact of testing within each zone. To make the testing procedure as realistic as possible, the sampling oracle was designed to contain implicit biases. The following definitions are used to outline the important parts of the observation function. The complement of each of the outcomes listed are E neg , E asymp , E not , E tneg , respectively. Definition 3.2. The probability that a person drawn from the population is truly positive with the disease at time t is given by When the controlling agent attempts to query a sample from a zone, then the sampled positive cases may not reflect the true percentage in the population, on average. The controlling agent may not be able to see this bias; however, the environment agent will have access to the information causing the skew in the data. Definition 3.4. If a person is not showing symptoms while positive with the disease, then they have a lower chance of going to wait in the test queue between time t and t + 1. Assume that as the testing capacity of a zone is increased, then the likelihood of getting tested increases through the following equations, where c 0 and d 0 are the initial probability of attempting to get a test while there are none allocated to zone z. The simulator is able to access each probability, but the controller would not be able to observe this information directly. It is easier to think about the probabilities a, b, c and d as follows: a is the probability of being symptomatic while carrying the disease, b is the probability of being symptomatic without carrying the disease, c is the probability of trying to get tested while showing symptoms, and d is the probability of trying to get tested without showing symptoms. The probabilities c and d are functions of how many tests are available, while c 0 and d 0 are the base probabilities of trying to get tested given that there are no tests available. From the controllers perspective, these values cannot be seen however they are reflected in the sample created after administering the test. Lemma 3.1. Let f p and f n be the probability of false positive and false negative, respectively. a, b, c(x test tz ), d(x test tz ) are from definitions 3.3 and 3.4. p test tz represents the probability of testing positive if the person gets tested given by, where, The variables c and d are functions of the number of tests allocated to a zone. Proof. See Appendix. The adjusted probability allows the factors affecting the observation distribution to be reflected in the probability of testing positive. Therefore, the number of positive test results after administering the limited number of tests, x test tz , is given by the random variable,Î t+1,z . The random variableÎ t+1,z has a binomial distribution with parameters (n, p) = (x test tz , p test tz ). Lemma 3.1 implies the parameter of the binomial distribution for the observation function does not reflect the true percentage of infected individuals in the population on average, but a shifted distribution with a bias unknown to the controller. This section proposes a model for the controlling agent using the five components of the unified framework. The controller does not have access to the environment agent's state variable, S env t , or the transition functions describing how they evolve, S M,env (S env t , W env t+1 ). Due to the lack of this necessary information, the controller must make assumptions about the components of the environment agent's model. We are going to start by outlining the belief model, before giving the five elements of the controller model. In a sequential decision problem with imperfectly known states and state transitions, the controller must Definition 4.1. The SIR model assumes that the total population remains constant. Therefore, the belief about the true percentage of each subpopulation in a zone has the following property, p susc tz +p inf tz +p rec tz = 1. The property implies that the belief about the subpopulation of each zone has a multinomial distribution with parameters (S tz , I tz , R tz ) ∼ M ult(N z ,p susc tz ,p inf tz ,p rec tz ). Therefore, the belief state will contain the dynamically changing parameters of the multinomial distribution for each zone. The controlling agent assumes a functional form for the transition functions in the environment model. The transition functions in the environment model are used to update the state variable known perfectly to the environment agent. Therefore, the functions in this section would describe the set of equations to update the state variables if there was no uncertainty in the state at time t. Let (S t , I t , R t ) be vectors containing the number of susceptible, infected and removed individuals in each zone z, respectively. The vectors are the physical state variables for the environment agent. If the controlling agent had access to the true physical state variables and made the decision x vac t , then it believes the environment will transition to the next state according to the following set of equations: Equations (14 -16) describe the belief about how each environment state variable evolves. Since the true state variable is not fully observable each element of (S t , I t , R t ) are random variables; hence, the function cannot be evaluated by the controlling agent because it only has a belief state describing the random variables. However, the equations are important because they must be used to derive the updating equations for the belief state variables. The controlling agent will decide to allocate x test tz testing kits to zone z at time t. Between time t and t + 1 the testing kits are administered and produce a random response,Î t+1,z , which represents the total number of positive cases measured in zone z between t and t + 1. Assume the random variableÎ t+1,z has a binomial distribution with parameters (n, p) = (x test tz , p test tz ). The response would be analogous to the output of the observation function defined in the POMDP model and the specifics are outlined in section 3.4. The probability, p test tz , is the probability of randomly selecting an infected individual out of the population of individuals who received a test at time t in zone z. This probability is affected by factors such as the likelihood of going to get a test while showing symptoms, the likelihood of showing symptoms while positive and the probability of false positives and false negatives. The exact impact those factors will have on p test tz is not known to the controller, but the policies we discuss later will try to make decisions which can mitigate the risks imposed by the sampling biases. The belief state updating equations take the observations,Î t+1,z , queried from the testing centers and use them to estimate the new belief state at t + 1. Each of the three parametersp susc t+1,z ,p inf t+1,z , andp rec t+1,z in each zone z will need an updating equation. Note that the infected population is being observed directly withÎ t+1 , but the susceptible and removed populations are not.  The observations are assumed to be drawn from a binomial distribution with parameters (x test tz , p test tz ). p test tz is unknown to the controller, but a sample was just observed from its distributionÎ t+1,z . The beta prior is a conjugate prior to the binomial distribution, and through Bayes' theorem the updated distribution will be beta-binomial. The resulting distribution can be thought of as the binomial parameter p test tz being drawn from the beta distribution with parameters α prior tz and β prior tz . Lemma 4.1. Let α prior tz and β prior tz be parameters of a beta distribution andÎ t+1,z be a sample drawn from a binomial distribution with x test tz trials. The compound distribution produced by Bayes' Theorem is a betabinomial distribution. The estimator for the probability of an infection,p inf t+1,z is given by, Proof. See Appendix. After Definition 4.2. Let Π ∆z be the projection operator for the set defined by, ∆ z = (p susc t+1,z ,p rec t+1,z ) ∈ [0, 1] 2 :p susc t+1,z +p rec t+1,z = 1 −p inf t+1,z . The expected susceptible and removed subpopulations of each zone is computed by taking the expectation of equation (14) and (16), respectively. If the terms are not in the set ∆ z in definition 4.2, then they must be projected back to the nearest point. This set of equations is given by, In summary, the controlling agent updates the parameters in the belief state through the following process: 1) Make observationsÎ t+1,z for all z ∈ Z, 2) Compute the estimator ofp inf t+1,z in equation (19), 3) Use equations (20 -22) to updatep susc t+1,z andp rec t+1,z . It is important to emphasize the beliefsp susc t+1,z andp rec t+1,z would not be possible to update through observations ofÎ t+1 without the belief about the transition equations presented in section 4.1.2. The belief about the transition equations may not match the true model (as we demonstrate in this paper) because it is usually an approximation of the real world, which is usually not possible to know perfectly. After the belief model is fully defined, then the five components of the unified framework naturally follow. The state variables include the information which is needed to compute the transition functions, objective function, and policy for making decisions at time t. Any information which is not changing dynamically remains a latent variable defined in the initial state. The state variable for the base model is defined as, Let the state space be denoted by S cont . The initial state contains the variables which are not changing dynamically. The initial state for this model is given by, where,  There are two sets of decisions at each time step: the information collection decision of how many tests to allocate and the implementation decision of how many vaccinations to allocate to each zone. The decision to allocate vaccines to each zone is given by, x vac tz , which is constrained by the total number of vaccines available, n vac t . The decision to allocate testing kits to each zone is given by, x test tz , which is constrained by the total number of tests available, n test t . Hence, the vaccine decision variable is constrained by, The testing decision variable is constrained by, The set of decisions can be characterized by . The exogenous information, W cont t+1 , represents all the infromation that arrives between time t and t + 1. It is given by, where, I t+1,z = number of positive tests sampled, n vac t+1 = the number of vaccines available at t + 1, n test t+1 = the number of tests available at t + 1. The number of tests and vaccines available at t+1 is a process evolving completely exogenously from the model. These values could be determined by the bottlenecks in the manufacturing processes from the distributors. It is assumed that at the beginning of each time step this number is revealed to the system; however, it does not attempt to model the stochastics behind it. The transition function is the set of equations which describe how each of the state variables evolve between time t and t + 1. The state variable is given in Equation (23). A simple belief about the transition function would assume the basic SIR model where each zone is evolving independently. Equations (14 -16) from section 4.1.2 are defined as,  where,S tz = N zp susc tz , σ susc tz = N zp susc tz (1 −p susc tz ), and Φ is the standard normal cdf and φ is the standard normal pdf. Proof. See Appendix. If α prior tz =Ī t+1,z and β prior tz = N z −Ī t+1,z , then Lemma 4.1 gives the updating procedure forp inf t+1,z . The other belief state variables,p rec t+1,z andp susc t+1,z , are computed using equations (20 -22) and the result of Lemma 4.2. Hence, The objective function measures the performance of the system. It will measure how well the vaccine and testing allocation decisions impact the state of the epidemic. The goal of the problem is to come up with a decision making strategy, or policy, to minimize the total number of infected people in the population throughout the entire time horizon. Therefore, the cumulative reward objective can be posed as the following optimization problem, The functionC(S cont t , X π (S cont t ), W t+1 ) is a one period cost function describing the metric which is evaluated by the controller at each time period. The goal of mitigating the spread of disease is to minimize the number of infected people, but it is not possible to perfectly observe the true number of infected people at t + 1. If the controller had access to the true state and transition equations, then the goal would be to minimize the true one-step cost given by, Equation (37) is not observable, hence the controller will minimize the expected number of individuals infected with the disease, given the current belief state. The belief state contains the parameters of the probability distribution over the environment state variables, hence the controllers cost function is given by, To evaluate this cost function, the belief about the transition function for the infected number of individuals must be used to predict what the impact of the decision will be, hence equation (33) must be used to evaluate the right hand side of equation (38). The policy is a mapping from the state space to the decision space. At time t there are implementation decisions (the number of vaccines to allocate to each zone) and learning decisions (the number of testing kits to allocate to each zone). In section 5.1, we illustrate two types of implementation policies: one from the PFA class and one from the DLA class. In section 5.2, we present a CFA learning policy for deciding the zones with the most valuable information to collect through testing. The implementation decision in this problem setting is to choose how many vaccines to send to each zone in the nation, x vac tz . The decision space for the next set of policies is given by, The optimal policy for making a decision is given by Bellman's equation defined in equation (3), where V * t+1 (·) is the optimal value function at t+1 if we knew the true state of the environment. The dimension of the state variable defined in section 4.2 is 3|Z| + 2, therefore as |Z| grows it becomes computationally intractable to solve for the optimal policy due to the dimensionality of the state variable. When the optimal policy is not possible to achieve, then the goal of the problem becomes finding the best approximation to it. When designing the approximation, there are four possible classes of policies to choose from, which are defined in section 2.3. The PFA class of policies is an analytical function which maps states to actions, and usually includes tunable parameters. These policies can be used to characterize a simple rule-based method, which is why these are most commonly used in practice. Some examples of very simple PFA policies could be to allocate the set of vaccines evenly among the zones, proportionally by population, or proportionally by the belief of the number of infected individuals. In this paper, the PFA we chose to analyze consists of a sigmoid function, which is a function ofp susc tz , with tunable parameters θ P F A = (θ P F A 0 , θ P F A 1 ). The sigmoid function for each zone is given by, Then, to proportionally allocate each set of responses and ensure that the solution remains in the decision set, the policy becomes: This policy operates quickly online, but it requires a time consuming offline grid search to find the best set of hyperparameters. The policy will proportionally allocate the vaccines based on the magnitude of the response caused by the belief about the percentage of the population that is susceptible to the disease. In a direct lookahead approximation, an approximate model of the future is created to make the best decisions at t by looking at the impact of decisions in the future. The lookahead model will approximate the base model by choosing the θ risk -percentile of the distribution represented by the distribution of the belief state, and using this value as the lookahead state variable. The lookahead model will simulate the future by using the belief about the transition functions in equations (27 -30) . This is a reasonable approximation of the base model; however, it omits performing active learning. To create a proper lookahead model the five components of a sequential decision model defined by the unified framework in section (2.3) must be defined. A lookahead variable will have a tilde and two time indices, where the first is the time within the base model and the second index is the time within the lookahead model. Lookahead State Variable. The distribution of each subpopulation of each county is approximated by a normal distribution defined in Lemma 4.2; hence the θ risk -percentile of the susceptible distribution is given byS θ tt = S tz − z θ σ susc tz . The number of infected individuals will be approximated by the mean of the distributioñ I ttz =Ī tz , and the number of removed individuals will beR θ ttz = N z −S θ ttz −Ĩ ttz . The model at time t does not have access to a forecast of the number of vaccines available in the future, hence the lookahead model will assume that the number of vaccines available at each t in the future, where t ≥ t, will be the same. Hence, the lookahead state for t in the future is given by, Lookahead Decisions. The lookahead model will not attempt to learn in the future, hence the testing decision will not be modeled. Therefore, the only lookahead decision is the decision about where to allocate vaccines, x tt . Each of these decision vectors is constrained by 1 Tx tt ≤ n vac t . Lookahead Objective Function. The lookahead objective function is given bỹ The optimization problem for a two-step lookahead approximation is given by, The optimization problem in equation (43) reduces to a problem with a nonconvex quadratic objective function with linear constraints. For problems where |Z| is not too large the policy can be solved with bilinear solvers. The details describing the solution to equation (43) can be found in the Appendix. The second type of decision is to select how many samples to observe from each zone through testing. At time t the controlling agent must decide which zones to send the n test t kits after the implementation policy has already been made. The learning decision will impact the distribution of the random variable for positive tests,Î t+1 , and consequently affect the future decisions about where to send vaccines. It is important to have estimates of each environment state variable, and this decision will change those estimates. The testing policy we propose consists of a tradeoff between proportionally allocating a percentage of the testing kits, and trying to minimize the variance in the belief state at t + 1. The logic behind this design is get close to an estimate with respect to mean-squared error globally in the region, but also ensure that each zone is being sampled. Equation (19) updates the belief about p inf t+1 by assuming the posterior has a beta-binomial distribution. If the estimator in equation (19) has a beta-binomial distribution, then its variance is given by, Let the sum of variances in equation (44) become the objective function. The testing policy is induced by the optimization problem when the sum of variances is the objective function, given by subject to 1 T x test ≤ n test t . Lemma 5.1. Let equation (45) be the optimization problem used to produce the learning decisions. The optimization problem reduces to a quadratic program with linear constraints given by, where, This is an integer quadratic program with linear constraints. The problem with the policy induced by equation (46) is it will greedily choose which zones to send kits to and ignore some zones with lower variance for too long. We can circumvent this problem by ensuring that a certain portion of the testing kits, ρ test , are distributed proportionally to the population of each zone, and the remaining 1 − ρ test testing kits are chosen greedily. This policy falls into the CFA class of policies because it has an embedded optimization problem, and the parameter ρ test must be tuned to find the best proportion on average. The greedy policy and the proportional policy are given by and, respectively. Hence, the resulting testing policy becomes, The best ρ test in this function class can be tuned through policy evaluation using the simulator defined in section 3. The environment agent model from section 3 was used to construct a simulator in python. There were two simulators constructed: one for a toy problem with 25 randomly generated zones in a region discussed in section 6.1, and one for a simulation of the states in the United States discussed in section 6.2. Considering a vaccine would not be developed until a country is in the midst of a pandemic, the initial state of the infected population is randomly generated from a uniform distribution between 5% and 15% at t = 0. The testing and vaccine manufacturing process is assumed to be increasing (on average) to simulate the reality that there will not be a large number of doses at the onset of its distribution into the population. The toy problem simulator was constructed by randomly generating 25 sample locations, which would be considered nodes of a graph, and then weighting the mobility transition matrix,M t+1,zz , by the distance between the locations. Hence, individuals from nearby zones will have a higher probability of interacting with one another. Each zone has its own transmission rate and the removal rate for the disease remains constant for each zone. The graph of the simulated region is shown in Figure 1 . The weights of the edges of the graph represent the probability of individuals from each zone interacting with one another. Each of the policies in section 5 were implemented and the results of the cumulative total of infected individuals in each zone can be seen in figure 1 . The null policy shows the amount of infected individuals It is clear that each of the policies offers a significant improvement over the 140,000 people who would be infected if there was no vaccine being distributed in this region. The tuned PFA offers a 62.2% reduction in cases over the null policy and the DLA offers a 69% reduction in cases over the null policy. In the model of the United States, the zones in the country are partitioned at the state level. The population data for each state was provided by the US Census Bureau. Each state in the country has a known population, N z . The probability matrix,M t+1,zz , for each state was weighted by the distance between each state because neighboring states are more likely to infect each other. The beta values in each state are created by taking the logarithm of the population density and rescaling it between a fixed range of (β min , β max ). The policies discussed in section 5 were implemented with |Z| = 51 zones (including Washington, DC). The initial infection rate was generated by the record day of daily new infection data in each state to demonstrate that this strategy could work at the peak of a pandemic. In the USA simulator, we assume that the vaccines are being manufactured and the initial vaccine total is about 1% of the population. As the manufacturing capabilities increase, the total vaccines available for distribution will increase stochastically. Under the null policy with the assumed β z values, the simulator predicts about 18 million people would be infected with the disease. The PFA policy improves on the null policy by 45% and the DLA improves on the null policy by 54%. The DLA policy will also prevent about 1.8 million more infections than to the PFA policy over the given time horizon. When the problem is scaled up to 51 zones and the populations grow to be on the order of millions of people, then the number of infected individuals has the potential to grow significantly larger. The number of susceptible people determines the rate at which the infected group will grow, so it is important to allocate vaccines strategically in areas with large populations of susceptible individuals. In the plot in figure 4, we show a breakdown of the country as the pandemic spreads with three very different scenarios. In the first row, there are no vaccines so the infection can spread uncontrollably. In the second row, the PFA strategy is more likely to spread the vaccine evenly among states if there is a high percentage of susceptible individuals; hence the states with lower populations and transmission rates are targeted with more vaccines. The third row shows the DLA policy which is much more aggressive towards states with higher population density. It is obvious that states like New York, California, and Illinois, which have large cities, will spread the virus within their own state at a higher rate than states like Wyoming or Montana. Furthermore, many individuals travel within those high population states, so when the DLA targets those states with vaccines it will have higher order effects. Hence, the DLA is capable of mitigating those effects. It is intuitive that early action will always produce the fewest number of infections in the population, which is also why an aggressive DLA has better results. If we assume that the death rate due to the disease is fixed throughout the time horizon, then it is just a linear function of the number of infected individuals. Therefore, every infection prevented will be proportional to the number of deaths prevented from the disease. The risk-adjusted DLA policy prevented 1.8 million more infections than the PFA policy. Hypothetically, if a 1% death rate is assumed, then the DLA policy would save about 180,000 more lives than the myopic PFA. Lemma 3.1. Proof. This proof uses definitions 3.1-3.4. Since each of the probabilities are impacted by the number tests allocated there is an implicit assumption that x test tz is fixed. Hence, the probability of getting a test given that the person is positive to be written as, . These terms can be rearranged to arrive at, Let f p and f n be the probability of false positive and false negative, respectively. The following equation computes the probability of testing positive given that the person goes to get tested, Lemma 4.1. Let α and β be parameters of a beta distribution. Assume a sampleÎ from a binomial distribution after n trials and each trail has probability p. The pdf of the prior beta distribution is given by, π(x|α, β) = 1 B(α, β) x where, B(α, β) = Γ(α)Γ(β) Γ(α + β) . The likelihood of observingÎ t+1 is given by, Therefore, the Bayesian update is given by, P[p|α, β] = L(p = x|k)π(x|α, β) 1 0 L(p = x|k)π(x|α, β)dx The integral in the denominator is given by, 1 0 x k+α−1 (1 − x) n+β−k−1 dx = B(α + k, n + β − k). Hence, x k+α−1 (1 − x) n+β−k−1 B(α + k, n + β − k) , If we assume that the size of the population is fairly large, then through the central limit theorem we claim that each of the random variables S tz , I tz , and R tz can be approximated by independent normal distributions with parameters (S tz , σ susc tz ), (Ī tz , σ inf tz ) and (R tz , σ rec tz ), respectively. Assume S tz ∼ N S tz , (σ susc tz ) 2 , I tz ∼ N Ī tz , (σ inf tz ) 2 , and independence, then Through the identity in Zhan and Xing (2020) , the term in the previous equation is given by, The sum of the terms in equation (50) can be rewritten as, z∈ZĨ t,t+1,z = 1 T v + u Tx tt . The objective function can then be rewritten as, where we also assume the constrain z + w x tt >x t,t+1 . The terms that do not depend onx t,t+1 orx tt can be removed from the objective function; hence, = (2 − γ)(u Tx tt ) + (b (v + u x tt )) T (z + w x tt ) − (b (v + u x tt )) T (x t,t+1 ), @story_separate@This work presented a formal model for managing vaccines and testing kits during a pandemic using the unified framework. During a pandemic, the controller would not know the true state of the number of susceptible, infected and removed individuals; hence, the belief modeling in this paper captures the belief states and belief transitions. The multiagent modeling strategy in this paper is used to distinctly separate the modeling of the environment from the modeling of the controller. The strategy allows the environment to be considered a blackbox and the controller can only query observations and make decisions which impact it, which is why we focus on a tunable policy which can be optimized to mitigate the risks of an uncertain environment. Hence, if a more advanced environment model is applied to the problem, then the controller would still be able to robustly be applied. There were two types of decisions in this paper: the implementation decision and the learning decisions. This paper compared two implementation policies in the PFA class and the DLA class while using a CFA active learning policy for the testing decisions. The results demonstrate that the DLA class with a tuned risk adjustment parameter will perform the best in the toy problem and the US states problem. There are many more complex policies which could be applied to this problem, but we selected two that would illustrate the concepts most clearly. The PFA policy is intended to illustrate a very basic policy which is more likely to be used in practice than the DLA. The DLA policy is obviously more complex because it uses lookahead modeling and optimization, while the PFA is an analytical function. Therefore, we demonstrate that a well designed DLA policy can significantly outperform the basic policies most likely to be used in practice by myopic decision-makers. 8. Bibliography","The pandemic caused by the SARS-CoV-2 virus has exposed many flaws in the decision-making strategies used to distribute resources to combat global health crises. In this paper, we leverage reinforcement learning and optimization to improve upon the allocation strategies for various resources. In particular, we consider a problem where a central controller must decide where to send testing kits to learn about the uncertain states of the world (active learning); then, use the new information to construct beliefs about the states and decide where to allocate resources. We propose a general model coupled with a tunable lookahead policy for making vaccine allocation decisions without perfect knowledge about the state of the world. The lookahead policy is compared to a population-based myopic policy which is more likely to be similar to the present strategies in practice. Each vaccine allocation policy works in conjunction with a testing kit allocation policy to perform active learning. Our simulation results demonstrate that an optimization-based lookahead decision making strategy will outperform the presented myopic policy."
"Today's scholarly communication behaviour and logistics is still defined by centuries of printed document culture. Although there is progress by transforming journals into digital article repositories that, in principle, provide access to the content at all times and irrespective of a researcher's location, the nature of an article itself has not changed: The investigated hypothesis, the used methodology, the experiment, and the outcome are written in prosaic form; the final document is usually published for no other purposes than reading, seemingly optimised for human cognition. The Open Research Knowledge Graph (ORKG) [8] questions the ""paradigm of document-centric scholarly information communication"" [2] . It aims at transforming research literature into structured, machine-actionable data in order to represent and express information through semantically rich, interlinked knowledge graphs. Similarly to DBpedia, a prosaic knowledge source is transformed according to Linked Open Data standards [1] . Users are enabled to compare papers, discover patterns across methods or disciplines, or get a structured overview in a chosen context. The main use cases of the ORKG's beta version 1 are article search, a machineactionable, semantic representation, and especially paper comparison as introduced in [10] . To date, it indexes about 400 research articles. More than half are assigned to the subject cluster Physical Sciences & Mathematics.@story_separate@The structural science mathematics provides particularly suitable content for the ORKG: Its published prose is clear and dense from a linguistic point of view. However, as [4] have shown the high degree of abstraction in mathematics makes a conceptualisation consisting of the categories process, method, material, and data, which have been adapted to empirical sciences, inexpedient. The ORKG is not limited to this model but its feature, the abstract annotator, has been shown to be out of its depth with regard to mathematics. The applied mathematical science of operational research (OR) combines the rather abstract fields of combinatorics and numerical analysis with mundane research questions from economics. In favour of this study, we narrowed the topic down to the optimisation problem of Assembly Line Balancing. Its name derives from mass production where the intricate logistics for paced manufacturing assembly lines have to be organised efficiently, i.e. optimally. The Assembly Line Balancing Problem (ALBP) and its variations are not only well-covered in scholarly literature but also provide an abundance of structured overviews of exact and heuristic algorithms or benchmarks thereof. Thus, the research literature about ALBPs is an appropriate use case for the ORKG. In a first step, we choose literature reviews and articles that suggest minor optimisations to existing methods, which are compared to each other. Then, we suggest a semantic description that covers the content of the collection. It will serve as a prospective template for the ORKG. Furthermore, we will look for elements and patterns in the papers that are suited for automatic extraction in the future. Third, we ingest those literature reviews or articles that are published under an eligible licence, i.e. a CC-BY, CC-BY-SA, or arXiv's Non-exclusive licence to distribute into the ORKG. During this intellectual step, we will test and refine the proposed data model. Finally, we consider the representations and comparisons of the scholarly contributions in the ORKG and discuss its added value for researchers. Scholarly research of the ALBP can be traced back to the 1960s when it was shown to be a NP-hard combinatorial optimisation problem [7] . Since then scientists work on the sophistication of the mathematical model, exact algorithms for defined special cases or heuristic algorithms in order to find optimal solutions in adequate time. Recently, several reviews have been published to benchmark the stated mathematical model, exemplary data scenarios [5] or performances of the selected methods. We chose to set a focus on these reviews at first, but most publications were not openly accessible or free to be reused in the ORKG according to their respective licences. Eventually, articles introducing a new model statement for the ALBP or a heuristic to solve it were also considered. The collection comprised 28 topically relevant papers of which eight provide openly accessible preprints on arXiv 2 . These were manually ingested into the ORKG with varying degrees of thoroughness (cf. Sect. 2.2): From the single statement of the research problem to detailed descriptions of the algorithms and data sets that were applied 3 . The collection of research articles was organised in the open source reference management system Zotero 4 , also including documented experiences of the whole process. The ORKG's performance depends on a data model that is well-tuned to the content it is supposed to represent. That means expert knowledge in both the considered field and data modelling is required. Authors who possess the domain knowledge may not be able to squeeze it into the RDF scheme of the ORKG because there is no or little expertise in knowledge engineering. Data curators on the other hand may struggle with the proper in-depth indexing of the latest research knowledge. The ORKG's flexibility is an advantage because it allows almost limitless adaptions to describing papers by reusing existing concepts (mostly entries by former contributors) and relations but also by introducing new ones. The default schema stems from the comprehension of empirical sciences: A method is applied to a defined research question. This application causes a process that involves material to be observed or changed. Meanwhile observational data is collected and eventually evaluated in order to prove or disprove a hypothesis constructed prior to the experiment. In operational research in general and with respect to the ALBP in particular, there is also a rather standardised development that can be represented by a data model: The practical problem is formulated as a mathematical model or programme. Depending on the choice of the model, there is a toolbox of direct or heuristic algorithms to yield an exact (or approximate) solution to the model. Usually, in scholarly literature either a new variant of the ALBP is stated and the derived model is traced back to established methods or a new or rather slightly modified method is tested against known methods to solve the same problem. Thus, we conclude that most research papers about the ALBP are comprised of the elements listed in Table 1 . Has Performance contains the results that depend on the method that is applied, the graph the algorithm is applied on, and the specification of the implementation and system. Thus, it is semantically interlinked with other elements. If the suggested structure in Table 1 proves valid, it can be cast into a topicspecific template on its own in order to facilitate highly consistent knowledge graphs of further relevant papers independent of the curator. After careful study and annotation of the eight papers from arXiv, we entered the data into the ORKG. In the first of three steps of the procedure, the formal metadata can be automatically ingested via DOI 5 or a BibTeX entry. There is an additional fallback option to enter the formal metadata manually. Since the preprint repository arXiv does not provide a DOI for its documents, we chose BibTeX entries for the import. In the second step, the document is classified by subject. The ORKG's specified, hierarchical classification does currently not allow for several attributions. Hence, when assigning a single subject, a multidisciplinary field such as operational research is prone to inconsistencies with respect to its main focus in the respective paper or the curator. We chose to consistently assign the collection to Applied Mathematics → Numerical Analysis & Computation, although several other closely related fields would have been adequate as well, for example Engineering → Operations Research (and more). However, OR being predominantly a multidisciplinary subject involving mathematics, computer science, and economics, engineering seemed too misleading for a semantically sound assignment. The curator may choose between several templates; the template called Research Problem is closest to the data model as suggested in Sect. 2.1. The template provides the field Has research where keywords can be chosen from the suggested list or entered manually. Each entry is added to a bag-of-words and, thus, will be provided for autocompletion further on. This unrestricted freedom leads to a number of challenges. We struggled with typos (e.g. 'optimsation') as it was not immediately obvious how to correct these. Moreover, the same word was included in its American and British form, respectively, i.e. 'optimization' and 'optimisation'. We plan to add some functionality to ORKG to semi-automatically interlink such surface forms as they are describing the same concept. An underlying controlled vocabulary with an additional feature to enter free text would avoid wreaking havoc in the bag-of-words. A user entering 'optimisation problem' may thus be faced with four versions of which one contains a typo and two are identical. Further predefined fields are Has evaluation, Has approach, Has method, Has implementation, Has result, Has value, and Has metric. Not all of these semantic relations make sense for describing a mathematical paper, or rather, they lack distinctive accuracy, e.g. when does an approach become a method; or do we mean the outcome of the algorithm or its performance when stating the result? Yet, the relevant semantic units of an OR paper can be transferred and amended easily. Each field contains further fields in turn that may be annotated and indexed. And as a last resort, new relations can be introduced on every hierarchical level. The OR terms introduced in Table 1 were mapped by employing existing relations and introducing new ones (marked by an asterisk in the table). After leaving the hierarchical top level which is edited in the main browser window, every edit thereafter is conducted in a small overlay window. So while modelling, there is no visual aid where the description process is hierarchically taking place at the moment. However, we made it a habit to describe the top level first, save the description, such that the visualisation of the graph is available. From there, refinement is more accessible. The eight papers are not consistently described in this fashion because each paper gave reason to a refinement iteration of previous graphs. Thus, after each paper, there are (or should be) well-documented, retroactive modifications to each graph representing a paper. Again, this inevitably leads to inconsistencies even among papers that are ingested by the same curator. Another critical observation is our choice of terms: General denominations such as Has model, Has instance, or Has performance could mean completely different things in another context. Even between OR researchers these terms might not be semantically tight enough to guarantee frictionless communication. Hence, the relations are prone to cross-contextual use that might make the otherwise carefully created model fuzzy. In theory, a paper can be thoroughly represented by modelling each sentence as Linked Data, at arbitrary granularity. Again, in agreement with another field expert from biochemistry, we concluded: when to finish the indexing procedure is at the margin of discretion. Of course, the ORKG's crowd-sourcing philosophy allows and even demands for further refinement by others or at a later stage. Thus, a knowledge graph is never truly complete, especially if dynamic data such as citations will be taken into account in the future. An exemplary paper description is shown in Fig. 1.   Fig. 1 . Visualisation of a paper's knowledge graph.@story_separate@OR is a suitable test case for the ORKG, because the topic itself and the appropriate publication habits are highly structured and can easily be mapped to the default data schema already provided by the ORKG. However, on the basis of this study we tackle several general and subject-specific further improvements in the future: -Creating checklists and guidelines to define both minimum requirements and a gold standard for a paper's knowledge graph. -Underlying a general, and for templates a subject-specific, vocabulary with moderated editing workflows. Also, the resources should be displayed alphabetically or by assigned relevance instead of a last-in-first-out fashion in the tabular view. -Linear user guidance for generating a skeleton data set and visual support for the refinement. -Similarly described papers with identical or semantically close descriptions should yield similarity. -The selected papers met our expectations of being highly structured and easy to parse for the defined information patterns. They are well suited for a pilot study of automated extraction for information framing a basic knowledge graph. Automated indexing where scientific literature is indexed with terms of well-maintained thesauri like the German Authority File or automatically classified with the Mathematics Subject Classification (MSC) 6 may provide a first draft to be ingested into the ORKG [9] . -The aforementioned MSC would provide the obvious classification backbone for contributions from the mathematical sphere. The extremely confined example of the ALBP suggests that this would not only call for 63 template schemas for each top level class but at least 5.000 refinements accounting for MSC's subclasses. However, with this first experiment we cannot estimate the structural synergies between classes. We rather expect, given a wisely chosen sample that future work might result in a manageable number of mathematical templates with few extensions for the subclass topics. An example are the MSC classes 44 and 45 covering ordinary and partial differential equations, respectively. Even if they turn out to differ minutely in their ORKG template, these differences will be provided for in other templates, e.g. (numerical) analysis. -Since the ORKG follows a crowdsourcing philosophy, seeking support from and collaborate with further projects in the field of mathematical knowledge engineering guarantees high quality and integrity of the data and its community-curated modelling. Critical exchange with the researchers of MathDataHub is established [3] , but projects like swMATH, a database for mathematical software, should be considered more closely [6] .","The Open Research Knowledge Graph (ORKG) provides machine-actionable access to scholarly literature that habitually is written in prose. Following the FAIR principles, the ORKG makes traditional, human-coded knowledge findable, accessible, interoperable, and reusable in a structured manner in accordance with the Linked Open Data paradigm. At the moment, in ORKG papers are described manually, but in the long run the semantic depth of the literature at scale needs automation. Operational Research is a suitable test case for this vision because the mathematical field and, hence, its publication habits are highly structured: A mundane problem is formulated as a mathematical model, solved or approximated numerically, and evaluated systematically. We study the existing literature with respect to the Assembly Line Balancing Problem and derive a semantic description in accordance with the ORKG. Eventually, selected papers are ingested to test the semantic description and refine it further."
"The resistance to antimicrobials is currently one of the biggest health problems in the world. Several factors contribute to the rise of cases of infections caused by multidrug resistant microorganisms: the increase in patients with suppressed immune systems due to diabetes, cancer and AIDS; the higher number of patients who need invasive treatments such as hemodialysis, venous catheters, transplants and mechanical ventilation; and the higher prevalence of treatment with steroids, hyperglycemia, use of broad-spectrum antibiotics and antifungals in subinhibitory concentrations [1] [2] [3] [4] [5] . After the development of antibiotics, with the discovery of penicillin in the first half of the 20th century, the interest in fungal infections increased. Infections caused by opportunistic yeast species, such as the Candida genus, are among the most recurrent ones and may present as topical infections in the oral cavity, genitourinary tract, or skin. The Candida genus also appears to cause systemic infections, which can spread through the blood reaching different organs [2] [3] [4] [5] [6] [7] . In some cases, infections caused by the Candida genus could become long-lasting and easily progress to severe cases that can increase healthcare costs and extended hospital stays. Besides that, it is important to emphasize that prolonged hospital treatment results in the use of second-or third-line drugs which have higher chances of treatment failure [7] . The use of antimicrobial agents has been exponential since its development. In the period 2000-2010, BRICS countries (Brazil, Russia, India, China, and South Africa) were responsible for three-quarters of the global increase in antibiotic consumption [8, 9] . activity. Among such strategies are the synthesis of Hst5 fragments and the development of metal complexes formed with the peptide, which could increase the activity against C. albicans [36] [37] [38] [39] [40] [41] [42] . Thus, the aim of this work is to review concepts about the morphology, pathogenicity, and virulence factors of C. albicans as well as the human body's immune response against these microorganisms. In addition, this review proposes to highlight existing antifungal treatments, their mode of action and the mechanisms of resistance already reported, to thus present the characteristics and mechanisms of antifungal action of Hst5. Finally, we report here the works that were carried out in order to increase the action of Hst5 through an association between peptides and metallic ions. This strategy could generate new molecules derived from Hst5, with greater antifungal potential, making them a possible treatment against fungal infections caused by C. albicans and other species.@story_separate@The Candida genus includes more than 200 species of single-celled eukaryotic organisms. These organisms have a cell wall composed of sterols outside the plasma membrane and have an ideal growth temperature around 37 • C. Furthermore, they are able to metabolize glucose in both aerobic and anaerobic conditions [1, 26] . Several species such as Candida albicans, Candida dubliniensis, Candida glabrata, Candida guilliermondii, Candida kefyr, Candida krusei, Candida parapsilosis, Candida tropicalis and Candida viswanathii can be found naturally in the oral, gastrointestinal and genitourinary tracts of 40-60% of the population. C. albicans is the most recurrent and it appears in the commensal form of yeast, being harmless. The interaction between the fungal cells and the host immune systems is what maintains it is in the commensal form [43] . However, sometimes, the environmental conditions can allow the growth of filaments in the fungal cell, enabling the morphological transition to the hyphae form, which is the virulent morphology of C. albicans [2, 3, 33, 44] . During infection, yeast cells are primarily responsible for the spread of the fungus, while hyphal cells are predominant in the mechanisms of invasion and acquisition of nutrients. The morphological transitions that allow the hyphae growth in C. albicans cells are induced after initial contact with the host cell and by the expression of different proteins. Some of these proteins are: Hwp1, Als3, secreted aspartic proteases Sap4, Sap5, Sap6, hypha-associated proteins Ece1, Hyr1 and contribute to adhesion and invasion mechanisms [3, 26, 33, 45, 46] . The genes from Sap1 to Sap7 were already found in drug-resistant C. albicans isolates. While Saps 1 to 3 act directly on tissue damage on superficial invasion, Saps 4 to 6 tend to act in deeper tissues during penetration and interact with the cellular defense [47] . C. albicans has developed several adaptation mechanisms in order to survive in the host organism, even in situations of pH changes and low nutrient availability [33, 44, 45, 48] . Its high genomic plasticity allows genetic variants to better adapt to the microorganism in the environment. These mutations can affect the polymorphism, variation in chromosome copy number, recombination and total or partial loss of chromosomes under stress conditions [33] . Thus, it is possible to modulate the fungus behavior and control growth rate, morphology, and adaptation to nutrient availability. It also allows the fungus to deal with the stress induced by antifungal agents, contributing to the acquisition of resistance to drugs used in the treatment [2, 33, 49] . One example of this modulation is that the pH of the environment can be regulated by the fungus by excreting nitrogen, in ammonia form, promoting the growth of hyphae. Molecules such as farnesol, tyrosol and dodecanol, which act in microbial communication mechanisms, can also regulate morphogenesis by indicating cell density. When this amount is less than 10 7 cells mL −1 , the transition to the virulent form of hyphae occurs, being the ideal host for colonization. Contact between the fungal cell and biotic or abiotic surfaces also triggers the growth of hyphae, and on certain substrates, hyphae have the ability to invade [26, 45, 50] . Adhesion to epithelial cell surfaces is the first major virulence factor of C. albicans, being induced and controlled by a cascade of signals between the fungus and the host environment. Adhesion is favored by several components of the fungal cell wall, including mannose, mannoproteins and saccharins. In addition, factors such as the formation of germ tubes, the presence of mycelia and endotoxins also help with the fungus' adhesion. On biotic surfaces, hyphae cells are capable of secreting adhesins, which allow adhesion to the epithelial cell by binding to amino acids and sugars from other surfaces, facilitating invasion [3, 26, 50] . The adhesion to abiotic surfaces is also facilitated through the formation of biofilms. Biofilm formation is an important pathogenic factor that favors cell growth and proliferation. Biofilms also offer protection from external influences, including drug treatment, because it is generally polymicrobial in nature, and the production of the extracellular matrix increases the resistance to antimicrobial therapy by preventing drug diffusion [51] . Thus, fungal biofilms are highly resistant to antifungal therapies, representing a clinical challenge, which demonstrates the importance of research aimed at its prevention and control [5] . Biofilm formation is responsible, directly or indirectly, for more than 80% of microbial infections. Besides that, the highly resistant form of biofilms is capable of facilitating the spread of the fungus in the bloodstream, leading to invasive infections in tissues and in several internal organs [1, 3, 44, 52, 53] . Two predominant mechanisms of invasion are performed by C. albicans cells: active penetration and induced endocytosis. In the active penetration mechanism, entry into cells is facilitated by the secretion of hydrolases capable of digesting epithelial cell surface components. These hydrolases are necessary for the disruption of host membranes and damage to the human epithelium [26, [50] [51] [52] [53] [54] . Aspartic proteinase isoenzymes (Saps) are of great importance for the functionality of C. albicans cells, acting in adhesion processes (Saps 1-6), digestion of the epithelial cell wall, favoring invasion (Saps 2 and 9), as well as preserving the integrity of yeast cells (Saps 9 and 10). The directional growth of hyphae, called thigmotropism, helps the entry of fungal cells to host tissues by directing invasion to gaps present in epithelial cells surfaces [33, 45] . In the mechanism of induced endocytosis, C. albicans induces the epithelial cell to promote the formation of structures similar to pseudopods, enabling the entry of the fungus by the host itself [26, [50] [51] [52] [53] [54] . This induction is performed through the release of different adhesins and invasins, such as Als3 and E-cadherin. With access to epithelial cells or submucosal layers, C. albicans ends its pathogenicity with the induction of damage in two different ways. The fungal cell is capable of inducing apoptosis in healthy cells, through the inactivation of anti-apoptotic proteins Bcl-2 and Bcl-xL [26] . The other form of damage induction is necrosis, caused by secreted agents or associated with the hyphae of C. albicans. These mechanisms lead to mitochondrial edema and increase the permeability of the plasma membrane of the host cell, favoring its disruption [53, 54] . Another important factor that needs to be highlighted here is the fact that C. albicans uses some metals to maintain and modulate its metabolism. Metals such as cobalt, iron, zinc, manganese, molybdenum, and copper are essential for biological processes and for structural and catalytic functions. These metals are also involved in the glycosylation and phosphorylation reactions as well as in electron transfer and oxygen transport [55, 56] . Iron is one of the most relevant micronutrients during the growth and spread of C. albicans. Being necessary for cellular processes such as DNA replication, mitochondrial respiration and chromatin remodeling. In addition, it acts in enzymatic functions, detoxifying reactive oxygen species and in the formation of biofilms [57, 58] . Besides that, iron also allows the fungus to survive in the human gastrointestinal tract as a commensal. Due to the great importance of iron for fungal metabolism, C. albicans has developed several metabolic mechanisms for the acquisition of the metal, being able to compete with the host for this micronutrient [58] . The presence of copper is also extremely important for fungal biological systems, as it offers protection against oxidative stress. In addition, copper acts as an essential cofactor in several enzymes, including energy metabolism, carbon assimilation and metabolic gene expression [55, 59, 60] . Zinc is essential for the functions of microbial metabolism, being the catalytic and structural center of several enzymes, and a necessary factor for fungal growth. Besides that, this metal has relevant roles in virulence factors, participating in the endothelial colonization and cells invasion of the host's immune system by C. albicans. Zinc also acts in the detoxification of ROS generated by the host [61, 62] . Although essential for fungal metabolism, metals have the ability to change their oxidation state, which can result in reactive oxygen species (from the Fenton reaction, for example) that can oxidize lipids, proteins and DNA [55] . Thus, in some situations, the accumulation of these metals can be toxic to the fungus. For this reason, the host organism can manipulate the availability of metals, decreasing or increasing them. This modulation can cause nutritional hunger or poisoning due to metal overload. C. albicans, on the other hand, has specific mechanisms to deal with this induced stress [60] . However, it is interesting to note that the use of these metals, associated or not with antifungals drugs, could increase their antifungal action. The association between conventional or news drugs could cause the imbalance of these metals inside the C. albicans cells, causing their death. The virulence mechanisms for adhesion and colonization used by C. albicans activate some host immunological mechanisms, necessary for successful control of the infection [51] . The presence of hyphae, essential to the pathogenic mechanisms of C. albicans, is the main indication of infection for the host's immune system [26] . Epithelial cells are responsible for the initial recognition of the infection, through the detection of candidalysin. This 31-amino acid peptide presents an α-helix conformation and acts as a cytolytic toxin generated by the fungus from the Ece1 protein. Candidalysin is secreted by the hyphal portion of the fungal cell and has a cell lysis function through intercalation and permeabilization of epithelial membranes [51, 52] . The detection of the toxin by the epithelial cell occurs at lower levels than the ones necessary for candidalysin inducing damage. Thus, a danger response is readily activated, leading to the initiation of innate and adaptive immunity. The recognition of candidalysin is extremely important, as it prevents benign commensal yeast cells from being unnecessarily attacked, preventing an excessive immune response that could be harmful to the host [52] . The detection of candidalysin leads to the recruitment, differentiation and activation of several immune cells. The first line of defense consists of phagocytic cells, which try to kill the fungal cell through changes in pH, potassium fluxes and activation of proteases. Besides that, the neutrophils are the main effector cells at the beginning of systemic infection and are capable of capturing and killing the fungus through extracellular traps, such as chromatin fiber networks. On the other hand, neutrophils are also able to phagocytose fungal cells, inhibiting growth and morphological transition. In addition, they can produce reactive oxygen species, and also induce the release of antimicrobial substances in the body. Macrophages are also present in the first line of defense of the immune system. They are less efficient against C. albicans once the phagocytosed fungal cell is able to break up the macrophage avoiding the mechanisms of death [45, 63] . The adaptive arm of the anti-C. albicans involves the recruitment of dendritic cells at the target of infection. Besides killing fungal cells by phagocytosis, dendritic cells are responsible for recognizing pathogen cells and for processing an antifungal antigen, which is used by T cells to develop resistance to reinfection [63] . The release of inflammatory and chemotactic cytokines, activated by macrophages, dendritic cells and neutrophils through C. albicans recognition, also helps in the infection resolution [51] . As can be seen, innate immunity is extremely important to fight infections because it is the first reaction against the pathogen, preventing fungal cells from proliferating and spreading in the host organism [63] . Deficiencies in immune cells make the organism more susceptible to pathogens and have been associated mainly with topical skin infections. For systemic infections, the deficiency is associated with the number or action of neutrophils [5] . C. albicans cells also have mechanisms to neutralize the host's immune response. Some of these strategies include secretion of hydrolytic enzymes, β-glucan protection, hyphal growth, phenotypic exchange, modulation of host T cell response and inactivation of the complement system. C. albicans also can induce or inhibit apoptosis, which ensures preservation, dissemination and survival of the fungal cells in the body [26, 44] . To help the immune system to fight the infection or when the immune response alone is not enough, it is necessary to use drugs treatment. The similarity between the human epithelial cell and one of C. albicans cells makes it difficult to develop drugs that are not harmful to the human body [2, 64] . Some classes are available for treatment and many of them have been improved over the last decades, especially in order to reduce the toxicity [3, 4, 64] . The ergosterol, a sterol similar to cholesterol, is specific to the fungal cell and is the main target for antifungal drugs. The class of azoles, which includes popular drugs such as miconazole, clotrimazole, itraconazole and fluconazole, are the most common treatments. They have fungistatic properties and can lead to the accumulation of toxic compounds in the intracellular compartment of fungal cells. Azoles act inhibiting the enzymatic activity necessary for ergosterol biosynthesis. The action occurs in the endoplasmic reticulum of the cell, causing interference in the enzyme lanosterol 14-α-desmethylase, responsible for the transformation of lanosterol into ergosterol. The low concentration of ergosterol is harmful to the structural integrity of the cell and the accumulation of 14-α-methyl-3,6-diol leads to a toxic effect for the microorganism [2, 4, 65, 66] . The specificity of ergosterol prevents the human cell from being attacked. Although well tolerated by the human body, azole agents can present hepatotoxicity and are capable of inhibiting the action of different human enzymes [2, 4] . Polyenes are another class of drugs widely used in antifungal therapy, such as amphotericin B and nystatin. These drugs break the fungal cell membrane by binding to ergosterol, causing the formation of aqueous pores along the membrane. The pores formation causes the destabilization of the cell structure and allows the leakage of intracellular content, leading to cell death [2, 4, 67] . Amphotericin B is one of the oldest treatments for antifungal infections, having been approved in 1957. Currently, has less toxicity than the original formulation, but it still presents some nephrotoxicity, besides the high-cost production, which makes their use less common. On the other hand, even with a slightly narrower activity spectrum than amphotericin B, nystatin is widely used, although it has some side effects and its use is not recommended for diabetic patients, due to the high level of sucrose [1, 2, 4, 5, 47] . Echinocandins are the more recently discovered class with antifungal action, being the only novel antifungal drug class to enter medical practice in decades [68] . It is composed by drugs such as anidulafungin, mycofungin and caspofungin. They are lipopeptides whose action depends on the concentration of C. albicans [2, 65] . Echinocandins are able to damage the structural integrity of the cell wall through the non-competitive blocking of β-D-glucan synthase. Without the presence of glucan, the cell wall becomes more vulnerable to osmotic lysis [4, 65, 67] . Because they act on the fungal cell wall, echinocandins have a lower risk of side effects or toxicity on epithelial cells than other classes of antifungal agents [2] . As it presents a great safety profile, echinocandins were often chosen as the primary treatment of invasive candidiasis, replacing other drugs, such as fluconazole [5] . Other drugs, less common but still widely used, are flucytosine, allylamine, thiocarbamate and griseofulvin. Flucytosine, analogous to pyrimidine, is transported into fungal cells through cytosine-permease, where it acts by interfering with DNA synthesis. Flucytosine mode of action includes the inhibition of thymidylate synthase, or it can bond with RNA, interfering in translation and in protein synthesis. As a small molecule highly soluble in water, flucytosine is able to diffuse rapidly in the body when administered orally. It is a treatment rarely used as monotherapy, due to its toxic effects in high concentrations, and is generally associated with other drugs, such as amphotericin B and fluconazole [2, 4, 5, 65] . Allylamine and thiocarbamate, on the other hand, also act by interfering with the ergosterol synthesis and affecting the integrity of the fungal cell membrane [2, 65] . The increase in the occurrence of fungal infections, as well as the development of less toxic formulations of drugs, has considerably expanded the use of antifungal agents [64] . As a consequence, an increasing antifungal resistance was observed due to the adaptability shown by Candida species. The antifungal resistance led to an increasing in the cost and time of treatment and limits the drugs that can be used [64, 69] . Microbiological resistance can occur naturally in the pathogenic fungus, without prior exposure to the antifungal agent or it can be acquired after frequent contact with the drug in question [69] . The most common mechanisms of resistance include permeability barriers (biofilms) and decreased cellular concentration of the antifungal agent. The resistance to the drug occurs when the microorganism is trying to circumvent the effects caused by the drug. The microorganism can change the molecule target or increase the transporters that remove the agent from inside the cell. Another possibility of fungus' resistance is the adaptation to induced stress for minimizing the drug's toxicity [2, 4, 67] . In the case of fluconazole, there is an up-regulation for efflux pumps capable of decreasing the intracellular concentration of the drug. Positive regulation mechanisms of the gene encoding lanosterol 14-demethylase can also occur, leading to an increase in intracellular concentration or inhibition of ergosterol formation. The replacement of the sterol by a similar molecule is another possibility for present azoles to have some effect [2, 64, 69, 70] . Additionally, the use of fluconazole in resistant C. albicans can enhance the production of Saps, according to recent studies [47] . For echinocandins, resistance involves the acquisition of mutations in genes encoding catalytic glucan synthase subunits [64] . The mutations can be punctual, but they give the fungus resistance to the whole class of echinocandins. On the other hand, resistance to polyenes occurs mainly through the replacement of ergosterol by another sterol in the fungal cell membrane. These resistance mechanisms are caused by mutations in genes that encode enzymes present in ergosterol biosynthesis [2, 64, 65] . Resistance to flucytosine occurs with a decrease in drug uptake by cytosine permease or by changes in cytosine deaminase enzymes, that prevent the action of the antifungal agent [2] . The development of resistance to antimicrobial agents by microorganisms is inevitable. Factors such as the indiscriminate use of antibiotics and the current COVID-19 pandemic, as mentioned in previous topics, aggravate this situation. Thus, the need for efficient treatments and the search for new antifungal agents, which are not limited by resistance mechanisms is extremely important to eradicate the challenges associated with antifungal resistance and biofilm formation caused by C. albicans [4, 65, 71 ]. New molecules have been the target of several types of research in recent years because it is necessary to search for potential antifungal treatments that do not present resistance. These can be obtained from different sources such as natural products, synthetic agents or polymeric materials. Marine organisms, endophytic fungi, saponins, alkaloids, peptides and proteins were also investigated [65] . Peptides are molecules of great interest since they can be found naturally in the human body and some already have a function as antimicrobial agents [72] . Antimicrobial peptides (AMPs) display a large range of activities, being one of the first lines of defense in the human body as they are able to rapidly inhibit a broad spectrum of pathogenic microorganisms [72] . They can be isolated from prokaryotic and eukaryotic cells in the animal, plant, bacterial and fungal kingdoms. These peptides can play a fundamental role in the successful evolution of complex multicellular organisms. In general, they are characterized as amphipathic and cationic molecules with considerable variation in chain length, which can be composed of up to 50 amino acid residues and can be categorized according to their secondary structure [73] . Unlike conventional drugs, antimicrobial peptides have a low probability of acquiring resistance by microbial strains, probably due to their different mode of action [73] . The cationic properties of AMPs enable the interaction with the negative plasma membrane of the microorganism. Its affinity for the microorganism's membrane causes an accumulation on the surface, which allows rearrangements in the membrane structure and is responsible for the translocation of the peptide for the intracellular environment. This passage across the membrane and the interactions with intracellular targets allow AMPs to bypass some resistance mechanisms [74, 75] . Histatins are an important family of endogenous AMPs rich in histidine, that have antifungal activity against C. albicans, as wells as immunomodulatory, and pro-wound healing effects [76] . Therefore, it is a possible topical or systemic treatment, which can act alone or synergistically with other known drugs. Histatins are a family of small basic cationic peptides, which have a large presence of basic amino acids such as arginine, lysine and, mainly, histidine. With an isoelectric point of 6.5, histidine can modulate the cationicity of the peptide at low pH values. Its side chains are known as metal chelators, allowing the association of these peptides with metal ions [77] . Histatins peptides can be found in human saliva at concentration ranges of 50-425 µM [78] . They adopt a random conformation in aqueous solvents and α-helices structure in non-aqueous solvents. They are produced and secreted by the sublingual, parotid and submandibular glands. Secreted Histatins can undergo proteolytic degradation before reaching the mouth, and are also able to interact with other salivary molecules, becoming part of the salivary lining of hard and soft tissues [79] . These peptides were first described in the 1970s as enhancers of the glycolytic activity in some microorganisms. Around 1984, its bactericidal and fungicidal activities were described [78] . Histatins 1, 3 and 5 are the most relevant members of the family. All of them present linear structure and have 38, 32 and 24 amino acid residues, respectively, being seven of them histidines. The Hst5 primary amino acid sequence is DSHAKRHHGYKRKFHEKHHSHRGY and is characterized by a random secondary structure, presenting α-helices with only slightly amphipathic. The α-helices facilitate its entry into the pathogen's cell cytoplasm [77] . Being the one with the greatest antifungal action among the Histatins, it acts against pathogenic fungi such as C. albicans, Cryptococcus neoformans and Aspergillus fumigatus [78] . The antimicrobial activity of Hst5 is concentrated in the region of amino acid residues located in positions 11 to 24 from the C-terminal end, called the functional domain [80] . Furthermore, the amino acids Lys13, Arg12 and Glu16 were identified through mutational analysis, as important residues for the action of the peptide [81] . Although the mechanism of action of Hst5 in C. albicans has not been fully elucidated, it is known that the peptide is taken up by the cell, acting intracellularly, and causes ATP efflux and production of reactive oxygen species [78] . Data presented by Moffa et al. suggest that coating oral surfaces with Hst5 in the form of a salivary film is able to reduce colonization by C. albicans on epithelial cell surfaces [43] . Although it has efficient antifungal activity when tested in vitro, Hst5 has its action reduced in the oral cavity by some interactions with metals, salts and proteins found in saliva. After its secretion, Hst5 undergoes proteolytic degradation by native enzymes present in saliva resulting in a reduction of its antifungal activity. Such proteolytic degradation represents one of the greatest challenges in the use of Hst5 as a therapeutic agent [38] . With the proteolytic cleavage, it is expected that some biological properties of the peptide also disappear. However, data presented by Helmerhorst et al. show that the initial phase of Hst5 proteolysis does not eliminate its antifungal properties. The initial degradation mixture proved to be as active as the intact peptide in antifungal assays, demonstrating that oral fluid-mediated proteolysis may be an intrinsic biological property of saliva [82] . Another important barrier for the use of Hst5 as a topical treatment is related to the limited activity that the peptide exhibits when present in total saliva, even in high concentrations. The processes that may help explain this factor are the binding of Hst5 with salivary salts and metals, and the dynamic turnover of salivary proteins [83] . Although the use of antifungal peptides as a treatment has a low probability of resistance development, it was found that C. albicans can become resistant to Hst5 after successive exposure [79] . C. albicans has several mechanisms to prevent death by Hst5 and is able to tolerate the presence of the peptide at low levels. C. albicans presents a group of Saps enzymes that is already known for causing the proteolytic cleavage of Hst5 [84] . Studies have shown the preference of Saps for basic or hydrophobic amino acids as cleavage sites. It was shown that Sap6, which is secreted by the fungus during the hyphae growth, reduces the Hst5 activity. The result was proven by Puri et al., through the inactivation of this enzyme by heat, who observed the non-inactivation of the activity of the peptide [35] . Bochenska et al. demonstrated that cleavage occurs first between residues K17 and H18 of Hst5 by Saps [85] . Another mechanism for C. albicans to avoid the action of Hst5 is binding the Msb2 protein to the peptide. Msb2 is a mucin-like sensing protein in the fungal plasma membrane, with a high molecular weight. Studies indicate that binding Msb2 to Hst5 negatively affects the activity of the peptide. In addition, the Msb2 protein also acts for stabilizing the cell wall and promoting the growth of C. albicans filaments [35, 86] . To overcome the obstacles found in the use of Hst5 as an oral topical treatment against C. albicans, new mechanisms were proposed. Common ways of manipulating AMPs such as Hst5 include shortening of the peptide and amino acid substitution [72] . The introduction of unusual amino acids and modifications in the terminal regions could preserve the peptides from proteolytic degradations. In addition, reducing the size of the peptide to prevent protease attack and to decrease the cost of production is also an option. The use of efficient drug delivery systems, such as encapsulation in liposomes, for better stability and reduction of peptide toxicity, and use of tetrahedral DNA nanostructures, for their editability, biocompatibility and transportation efficiency as delivery vehicles, were also reported as a strategy to promote its use in therapy [67, 87] . The 12-residue Hst5 fragment called P-113 is one of the smallest fragments with efficient activity. It has antifungal action similar to the original peptide, with high activity on strains resistant to fluconazole. Tests for modifications in amino acid residues in the structure of P-113 were performed by Rothstein et al., with the aim of improving the stability and activity of the peptide. These modifications make it a potential peptide for therapeutic use, without the obstacles found in the molecule mother [39, 40] . Helmerhorst et al., as well as Lu et al., also presented some Hst5 proteolytic fragments, resulted from fungal Saps, saliva proteolysis or synthesized derivatives, that keep their antifungal activity close to or the same as the original peptide and have the advantage of not been being easily degraded [36, 82, 88] . Using amino acid modifications, Ikonomava et al., showed that substitutions of K11R-K17R residues in the Hst5 structure increased the stability of the peptide [89] . This analog can also be efficient against biofilms, once it changes one of the peptide's main cleavage sites by Saps, and by that, reduces the biofilm viability [71] . Combinations of different peptides are also proposed to increase antifungal activity. Han et al. proposed the hybridization of Hst5 fragments with halocidin, a peptide that exerts its activity by attacking the cell membrane of C. albicans. All of the six hybrids generated, di-PH2, di-WP2 and HHP1, showed strong activity against different strains tested without showing cytotoxicity to epithelial cells [90] . It is important to consider here the association between Hst5 and some metals, such as the ones mentioned in the topic ""Candida albicans: morphology and virulence"" in this review. This association can intensify the antifungal effect of this peptide. Using the solid phase peptide synthesis (SPPS) strategy, it is possible to produce only the active fragments for this type of association. There are some studies in the literature that demonstrate this approach, such as those describe in the topic below. Several transition metals, such as Ni, Zn, Cu, Co and Fe, as well as alkali and alkaline earth metals, such as Ca and Mg, are present in human saliva in different concentrations. Amino acids present in the sequence of Hst5, such as aspartic acid, glutamic acid, histidine, tyrosine, and serine, are known for their ability to bind to metals. Thus, 13 out 24 amino acid residues of Hst5 are potential ligands for metallic coordination, through stable complexes formed by bonds between metallic cations and coordination groups such as side chains of amino acids [83, 91] . The metallic center is able to improve the peptide's specificity, bioavailability, solubility and stability [91] . The properties of the Hst5-metal bond were studied for decades through in vitro investigations [92] . Such studies demonstrate the importance of coordination with metals, such as Zn (II) and Ni (II), for the secondary structure of the C-terminal region and for the α-helix conformation of Hst5. Coordination with a metallic ion can lead to differences in the interaction of the peptide with macromolecules [41, 42] . The binding of metal with Hst5 can result in physiological actions related to the protection of the enamel and inhibit bacterial growth by decreasing the metal concentration. This inhibition is possible because the peptide is capable of sequestering ions necessary for microbial survival, in addition to the formation of reactive oxygen species, commonly associated with redox-active metals [92] [93] [94] . Two important binding motifs were revealed by the functional and structural characterization of the N-terminal domain of Hst5: the amino-terminal DXH motif, known as ATCUN (amino-terminal copper and nickel binding unit) motif, and the HEXXH binding motif, characteristic of several metalloproteases, appears once in the Hst5 chain, and binds to Zn (II). They are both represented in the Hst5 structure in Figure 1 . The dissociation constants of Hst5 with Cu (II) and Zn (II) are quite low, reaching nanomolar values, which indicates that such metals are able to bind to Hst5 motifs in saliva under physiological conditions [93, 95] . The specificity loss and conformational destabilization of copper and zinc sites can be associated with a decrease in antimicrobial activity [96] . Several transition metals, such as Ni, Zn, Cu, Co and Fe, as well as alkali and alkaline earth metals, such as Ca and Mg, are present in human saliva in different concentrations. Amino acids present in the sequence of Hst5, such as aspartic acid, glutamic acid, histidine, tyrosine, and serine, are known for their ability to bind to metals. Thus, 13 out 24 amino acid residues of Hst5 are potential ligands for metallic coordination, through stable complexes formed by bonds between metallic cations and coordination groups such as side chains of amino acids [83, 91] . The metallic center is able to improve the peptide's specificity, bioavailability, solubility and stability [91] . The properties of the Hst5-metal bond were studied for decades through in vitro investigations [92] . Such studies demonstrate the importance of coordination with metals, such as Zn (II) and Ni (II), for the secondary structure of the C-terminal region and for the α-helix conformation of Hst5. Coordination with a metallic ion can lead to differences in the interaction of the peptide with macromolecules [41, 42] . The binding of metal with Hst5 can result in physiological actions related to the protection of the enamel and inhibit bacterial growth by decreasing the metal concentration. This inhibition is possible because the peptide is capable of sequestering ions necessary for microbial survival, in addition to the formation of reactive oxygen species, commonly associated with redox-active metals [92] [93] [94] . Two important binding motifs were revealed by the functional and structural characterization of the N-terminal domain of Hst5: the amino-terminal DXH motif, known as ATCUN (amino-terminal copper and nickel binding unit) motif, and the HEXXH binding motif, characteristic of several metalloproteases, appears once in the Hst5 chain, and binds to Zn (II). They are both represented in the Hst5 structure in Figure 1 . The dissociation constants of Hst5 with Cu (II) and Zn (II) are quite low, reaching nanomolar values, which indicates that such metals are able to bind to Hst5 motifs in saliva under physiological conditions [93, 95] . The specificity loss and conformational destabilization of copper and zinc sites can be associated with a decrease in antimicrobial activity [96] . Mass spectroscopy studies show that the formation of the Cu (II)-peptide complex by the ATCUN motif is a necessary pre-requisite for the oxidative activity of Hst5 [95] , being related to the increased production of reactive oxygen species after cellular uptake of Hst5, which can triplicate total intracellular levels. Copper is present in eukaryotic cells metabolism and is an important metal for cell survival [97] . The entry of Hst5 into fungal cells can lead to a competition for this metal, which can be prejudicial to the cell, even Mass spectroscopy studies show that the formation of the Cu (II)-peptide complex by the ATCUN motif is a necessary pre-requisite for the oxidative activity of Hst5 [95] , being related to the increased production of reactive oxygen species after cellular uptake of Hst5, which can triplicate total intracellular levels. Copper is present in eukaryotic cells metabolism and is an important metal for cell survival [97] . The entry of Hst5 into fungal cells can lead to a competition for this metal, which can be prejudicial to the cell, even leading to cell death. Only one site for Cu (II) binding was found in Hst5, with high affinity and in a 1:1 ratio. Susceptibility tests, performed by Conklin et al., demonstrated that the binding constant was high, showing specificity between the peptide's motif and the metal [92, 93] . On the other hand, Frączyk demonstrated that serine phosphorylation may be an important mechanism of metal ion binding regulation since it weakens the stability of Cu (II) complexes [98] . Tests to assess the influence of Cu (II) ions on the antifungal activity of Hst5 showed a decrease in the EC50 value, from 5.15 µM (of Hst5 alone) to 1.36 µM, after binding to the metal [92] . Data suggest that Hst5 has three zinc-binding sites, two of them with higher affinity and one with lower affinity. It has already been discovered that Ca (II) ions interfere with peptide bonds and some metals, such as Zn (II). Thus, when the Ca (II) is present, only one of the sites with the highest affinity for zinc ions are detected, and only this one presents high selectivity [93] . Experiments carried out by Sonia Melino et al., with Hst5 in a hydrophobic environment, demonstrated the induction of peptide dimerization by zinc ions, which supports its fusogenic activity [42] . Thus, it is believed that the antimicrobial action of Hst5 can be influenced by specific molecular interactions, such as membrane aggregation by charge interaction, structural stabilization of the functional domain induced by Zn (II) and destabilization of the lipid bilayer [42] . The Hst5-Zn (II) complex also influences the antibacterial activity of the peptide, being able to induce the fusion of small negatively charged unilamellar vesicles and the hydrolysis of nucleic acids, and also increases the surface adsorption capabilities of Hst 5 at a broad pH range [95, 99] . On the other hand, the binding of Zn (II) to the peptide offered little protection against proteolytic degradation [83] . Iron is one of the most abundant metallic ions in saliva, with a concentration that varies according to the diet. In the human body, it is mostly linked to other compounds, which help nourish invading pathogens. It is believed, based on the data presented by Puri et al., that the sequestration of iron by Hst5 reduces the availability of nutrients for the pathogen. However, iron-binding negatively affects the antifungal activity of Hst5 against C. albicans. This negative influence may result from the change in the secondary structure of the peptide, which affects the binding to the fungus cell wall [83] . Susceptibility tests have already demonstrated the complete loss of Hst5 antifungal activity in the presence of Fe (III) [92] . Circular dichroism studies show that Hst5 can bind up to 10 iron equivalents, and the increase in iron concentration in the structure is inversely proportional to the antimicrobial activity of the peptide. The results of Puri's studies also demonstrated changes in the iron absorption genes of C. albicans treated with Hst5, showing that the binding of the peptide to iron may also contribute to a mechanism of death interfering with cellular iron metabolism. It is also possible that Hst5 can bind to intracellular iron, redistributing the cell's reserves and leading to malfunction of the cellular perception of the metal level. The mitochondrial dysfunction in the Hst5 death mechanism can be explained by the location of iron redistributed around the mitochondria, an organelle that is extremely sensitive to metal [83] . Due to the affinity with Ni (II) in the ATCUN motif, it is expected that the metal is interacting with Hst5 in the human mouth [100] . The binding to the metal can have an impact on the peptide's conformation increasing the stability of the α-helix, which can induce a significant difference in the peptide's interaction with other macromolecules. The binding with Ni (II) can facilitate the Hst5 and DNA binding by locating all positive side chains on one side of the molecule [41] . However, there is still no certainty about the influence of Ni (II) ions on the antimicrobial activity of Hst5. On the other hand, calcium has shown to be a major inhibitor of the antifungal activity of Hst5 against C. albicans, at physiological concentrations. It may be the ion responsible for the decrease Hst5 detection in saliva. The inhibition of the binding between Hst5 and C. albicans appears to be one of the main effects demonstrated by extracellular Ca (II) [101] . Studies performed by Dong et al. showed that not only was there a reduction of up to 90% in fungal cell death in the presence of Ca (II) but also the efflux of ATP was interrupted. Similar studies were performed for salivary anions Cl − , CO 3− and for Mg (II). For the Cl − , CO 3− , there was no reduction in the binding between the peptide and the fungal cell, but there was a decrease in ATP efflux [101] . In the presence of magnesium, there was an inhibition of up to 40% of death by Hst5, and a reduction in ATP efflux of approximately 40%. The inhibitory effects resulting from the presence of metallic cations were more pronounced than the effect for anions. The interference of calcium is much higher than the interference of magnesium, which still presents a minimal inhibitory effect within the physiological concentration ranges. The additional effect of dissociation between Hst5 and Ca (II) suggests that instead of binding to the peptide, the ion interrupts its binding to C. albicans cells [101] . The information about metallic complexation effects is summarized in Table 1 . Calcium uncertain Inhibits antifungal activity Suppresses ATP efflux Interrupts the bond between peptide and fungus cell [101] Magnesium uncertain Minimizes antifungal activity Decreases ATP efflux [101] The association between metal and Hst5 has a wide diversity and variation, as described here. Several metals demonstrated improvements in the original peptide, being marked as potential antifungal agents with a great interest for study and development. However, it is not yet a largely explored research area. Although it is possible to find studies about Hst5 associated with metals, not all of them explore the antifungal activity against fungal pathogens such as C. albicans. There are several other metals associations that can be made with Hst5, as it has many amino acids in its chain that are able to bind to metals, another possibility is the binding to other motifs present in the Hst5 amino acid chain not yet widely studied. It is also important to consider other possibilities, such as the SPPS for new peptides fragments and analogs based on the Hst5 original chain. These are just a few possibilities to be explored that can bring interesting results to help overcome the problem of antimicrobial resistance.@story_separate@As described here, the growing increase in antimicrobial resistance, possibly intensified by the COVID-19 pandemic, has caused worldwide concern about its consequences. C. albicans, being the main cause of fungal diseases, must be monitored carefully. Although it is mainly associated with mild topical cases of the disease, C. albicans is already resistant to important drugs such as fluconazole, nystatin and amphotericin B. The resistance to these drugs favors the evolution of simple cases for more severe infections, which are associated with high morbidity and mortality rates. The increase in the use of drugs that no longer have the expected efficacy can aggravate the resistance problem. The similarity between fungal and human cells impairs the development of new drugs, that must be more specific for fungal cells and not cause toxicity to human organisms. The use of peptides as antimicrobial agents is promising, and Hst5 has already shown good action against C. albicans cells. However, the peptide has disadvantages in its stability in physiological environments, such as the oral cavity, and some mechanisms of resistance to its action can already be observed in fungal cells. The search for improvements in Hst5 action already includes several methodologies, such as the exchange of amino acid residues and the use of fragments of the original peptide. The association of Hst5 with metallic ions is an alternative not yet widely explored, but already very promising for certain metals. There is a greater number of studies describing the binding sites between peptide and metal, as well as the modulation of their activity after association. However, few studies investigate the antifungal capacity of Hst5 after binding to a wide variety of metals. Many of these metals are present in the oral cavity, such as Ni, Zn, Cu, Co and Fe, and can naturally bind to Hst5. For this reason, one important strategy is a wide investigation of Hst5 antifungal activity after the binding to metals. In summary, we present here some possibilities for using Hst5, some of them include a change in the amino acid chain, development of hybrid peptides and synthesis of smaller fragments. All these possibilities can promote the increase in the antifungal potential of Hst5. However, the focus here is the association between Hst5 and metals, producing metallopeptides. This is a field with several possibilities to be explored, that certainly could contribute to the development of new antifungal therapies that can overcome the resistance barriers presented by C. albicans.","Usually caused by Candida albicans, buccal candidiasis begins with the morphological transition between yeast and hyphal cells. Over time and without the correct treatment, it can be disseminated through the bloodstream becoming a systemic infection with high mortality rates. C. albicans already shows resistance against antifungals commonly used in treatments. Therefore, the search for new drugs capable of overcoming antifungal resistance is essential. Histatin 5 (Hst5) is an antimicrobial peptide of the Histatin family, that can be found naturally in human saliva. This peptide presents high antifungal activity against C. albicans. However, Hst5 action can be decreased for interaction with enzymes and metal ions present in the oral cavity. The current work aims to bring a brief review of relevant aspects of the pathogenesis and resistance mechanisms already reported for C. albicans. In addition, are also reported here the main immune responses of the human body and the most common antifungal drugs. Finally, the most important aspects regarding Histatin 5 and the benefits of its interaction with metals are highlighted. The intention of this review is to show the promising use of Hst5 metallopeptides in the development of effective drugs."
"Machine Learning is one of the powerful and influential technology in today's world. In 1959 Arthur Samuel an American computer scientist coined this term with the statement that ""It gives computer the ability to learn without being explicitly programmed"". Artificial Intelligence and Machine Learning researches the assessment, examination and advancement of calculations that can gain up from and make prediction on given data sets. Machine learning is an interdisciplinary field that utilizes algorithmic mathematical, procedures, and a use of artificial intelligence which enable computer systems and other electronic devices to learn and get it. Machine learning investigates the examination and development of calculations that can gain from and make prediction on given data sets. Among the diverse kinds of Machine Learning methods, an urgent refinement is drawn among is supervised and unsupervised learning [1] . In Supervised machine learning the computer program is ""prepared"" on a pre-characterized set of ""preparing models"", which at that point encourage its capacity to achieve an exact end when given new information while in unsupervised machine learning the program is given a pack of information and must discover examples and connections in that. Machine learning is divided into different classes as follows. Classification of machine learning as follows: 1. Supervised Learning 2. Unsupervised Learning 3. Semi-supervised Learning 4. Reinforcement Learning 1. Supervised Learning: It is also called as the inductive or predictive learning model. In the supervised learning, the prediction of the future outcome is based on the historical labeled data. The machine learning models are trained on the basis of labeled data for the outcome which consists of the input parameter and we know the expected outcome form the given data set. The model can then be used to predict the samples with unknown labels by calculating the features for that sample, similar used for training the model [2] . One of the issues with the usage of these models to the data is their selection. A solution to this problem is Meta-Learning which selects the attributes from the feature set and look for correlations between those attributes and performance of algorithms [3] . For example, Classification of persons whether the person is male of female based on the given data set, machine learning algorithm will learn based on the features and some patterns in the data and classify based on the training data. Supervised learning algorithm classified into two types of category, classification, and regression algorithm. (a) Classification Algorithms: This type of algorithm classifies the data into some classes of some labels within the dataset. For the classification, we have algorithm like K-nearest Neighbor (KNN) [4, 5] . (b) Regression Algorithm: Algorithm like Linear regression and Logistic regression determines the mathematical relationship between the different data points within the dataset [6] . These algorithms are used in the predicting the output dependency and two or more variables. Regression algorithm can be classified into the linear regression and logistic regression. Logistic regression includes Support Vector Machine (SVM) [7] , Random Forests, and decision tree algorithm [8] . 2. Unsupervised Algorithm: Unsupervised algorithm is known as the descriptive models where the output is unknown and we don't have any idea that what the algorithm will spit out from the input data. The input data for the training is unlabeled for unsupervised machine learning. The algorithms belonging to this category are used to cluster the data based on the similarity between the data points. However, these algorithms differ in their functionality for data clustering. For example, K-means clustering, the data is clustered into the different group based on some properties between the different input variables [9, 10] . (a) K-means Clustering: In the k-means clustering, the collected data is grouped together in a similar cluster based on their similar properties in the data points. It is a combination of two words k and means, K refers to no. of cluster of centroids' in the group and means refers centroid centre point with respect to that centroid or cluster formed with in the given data set [11] . The commonly used data clustering method is k-means clustering where k is the number of clusters to which data is divided [12] [13] [14] . Deciding the number of clusters is tricky and data-dependent, and is often decided by elbow method, which works on heuristics. 3. Reinforcement Learning: It is a new type of learning technique where the algorithm learns and behaves based on the previous action within a problem. for every decision algorithm will work on the score whether it is positive of negative based on that machine will took the decision that what to do next. This type of learning uses the concept of agent-environment. The agent takes the input and current state of the environment for changing the state by an action. The-changed state is further shared using reinforced signal. The action selected by the agent is based on the score whose value should be as large as possible. Reinforcement model works on trial and error and hence follows heuristics For the algorithm to take decision is depend upon the process called as the Markov Decision Process [15] . In recent year's reinforcement learning algorithm works in so many areas, e.g., in 2016 AlphaGo game use the reinforcement learning for and beat the world champion [16] . 4. Semi-supervised learning: Is a technique that uses the small amount of labeled data for the training purpose within the large amount of unlabeled data sets. By using the labeled data will allow the algorithm to reduce the pattern and helps in the identifying the relationships with in your target and the information which your dataset contains already has [17] , e.g., if you have a dataset of records where the thousands of record are known and rest of the data is unknowns then the semisupervised learning model will automatically classify that based on the behavior on the previous learn model and the algorithm will build the quick model on the basis of labeled data and applies it on the unlabeled data set in case of credit card fraud detection of bank loan approval task in the banking system, web page classification on the web, speech recognition and some in bioinformatics for genetic sequencing [18] (Fig. 1 ).@story_separate@Image is a multidimensional signal, which requires certain operations for the extraction of useful information. Information extraction from the various image modalities are not straightforward and have certain issues or challenges associated with it. To list few, noise associated with the images, large amount of data for transferring images from one place to other digitally. Few image processing challenges in the computer vision and machine learning are as follows: Image compression, enhancement, Recognition, and visualization [19] . With the help of using machine learning lot of work is going to development of appropriate solutions using image processing algorithms. Here are some of the image processing challenges in which the machine leaning work is going on are as follows: Modern information and communication technologies include transferring images from one place to another e.g., television signal digitization. Image compression enables the sending and receiving of image frames using the available bandwidth [19] . Compression deals with reducing the size of images in order to make them transferrable at a faster rate, depending on the application. Compressing an image is tricky and requires good precision so that compressed and decompressed image should represent the same information. Designing a compression algorithm is a twostep process consisting of encoding the information while compressing and decoding while decompressing. Image enhancement is a technique of enhancing the quality of image. Every image acquisition system has a noise content associated with it. The noise makes it hard to acquire a clean image. Image with higher noise content makes it difficult to extract plateful information. Hence, image denoising is one of the predominant challenges in image processing and requires high level of expertise to deal with it. Machine learning algorithm enhances the quality of images, below there is discussion of some of the algorithm used for the image enhancements. Image recognition deals with the identification and classification of objects in the image. This is a hard problem for the computer systems to process as these systems recognize images by just their pixel intensity values. A typical image recognition system tries to identify the pattern by looking into the texture color shapes of the objects in an image and classify the objects. Building a generic image recognition system is difficult to identify large number of objects. Moreover, it is easy to figure out patterns if the objects are similar but relatively harder for alike objects with different color, texture, or shapes. Artificial intelligence algorithm finds out the patterns within the image and classify accordingly. It is one of the subdomains of Computer Graphics and deals with generation of models and objects. The challenging part of the visualization is to model the dynamic objects. Dynamic objects are the objects that changes as a function of time like moving hairs, curtains, trees, etc. Secondly, the generated models should be genuine which is computationally expensive and requires high computational configuration. Before understanding the technique of denoising of image, we have an idea about the noise and what are its cause and how it effect in the digital images. Let us understand the concept of noise. In the digital image processing noise is a topic, which makes lot of confusion in the students, research scholars or any other person who is hearing this term noise. Just in case of sound noise, refer to the audible distortion, in case of image it is visual distortion in the image. For example: if you took photograph with a closed cap on the lens, the resulting photo isn't black totally it is approximate to black there must be some hinge, random brightness or some kind of distorted pixels in the image. In digital sensor noise cause by the sensors when attempting to capture tiny white light. In the real word scenario our camera is trying to focus on capturing the dark matter on the image as a result the electrical signal windup and as a fleck or noise [20] . Machine Learning algorithms are capable of removing the noise with in the image and helps in the denoising in the images. There are different type of noise found in the image while capturing the image and this can be removed with the help of using machine learning. In every image, there is always some kind of noise due to physical properties of noise, so technically we can say that every image contains some kind of noise. • Fixed Pattern Noise: This sort of noise incorporates what is called as ""hot pixels,"" which are characterized as such when a pixel's intensity far outperforms suppresses that of random noise arbitrary variances/fluctuations. Fixed pattern noise generally appears for the most part and shows up in long exposures and is exacerbated by higher temperatures. Fixed example clamor is special in that it will show nearly a similar circulation of hot pixels whenever taken under similar conditions (temperature, length of exposure, ISO speed). The fixed pattern noise is more offensive and is easier to remove from the captured image due to its repetitive nature. Camera internal electronic circuits has to just reveal the repetitive pattern of noise and just applying some algorithm subtract this noise reveal out the true color image [21] . • Random Noise: Random noise is also called shot noise/photon noise, which is categorized by intensity and color fluctuations above and below the actual image intensity. The light composed of photons, which are discrete, random in nature. There will consistently be some random, irregular noise at any exposure introduction length and it is most impacted by ISO speed in camera. The random pattern noise commotion changes regardless of whether the exposure camera settings are similar or identical. The light emits and reflects everything you see the image. However, this thing is not fixed every time there is always graininess in the image. E.g. a very dim light bulb may emit on an average of 500 photons of light per second, but every time individual second will be a bit different-486 photons, 528 photons, 466 photons, 481 photons, 560 photons, and so on. On the off chance that, if you are taking a one-second long image of this light, you won't get the very same outcome each time. This is what photographers call ""shot noise/random noise/photon noise"" in an image. Random noise is less pragmatic than the fixed pattern noise in the latest imaging devices, but a slight amount of noise could create more errors than the fixed pattern noise and difficult to remove [22] . • Bending Noise: This type of noise is also called as the digital noise and it is depended on the digital image device, internal electronics of cameras in which image is being captured. This noise is also visible in the high ISO speed and shadows in an image, when an image is extremely brightened or white balance on an image depending upon the camera model [23] . Unwanted of unnecessary information within an image like as blurred objects, corners, unseen lines, edges, artifacts, disturbed background sense contribute the noise. This noise is produced form the CCD (Charged Coupled Device), CMOS (Complementary Metal Oxide Semi-Conductor) sensors with in the digital image devices. To reduce this redundant noise, prior dectection and learning of model needs to be develop. In some cases mathematical function like Modulation transfer function (MTF), point spreading function (PSF) are used for quantitative and qualitative analysis of mode of noise model [23] . For visual perception of human being color image provide the more and accurate information as compare to the grayscale images. Color enhancement is the key issue in the high-quality pictures and some other HDTV cameras. The quality of images is easily affected by the light and weather condition which leads to suffer from the loss of information. The are some color enhancement technique such as gamma correction technique, histogram equalization, contrast stretching, Contrast-limited adaptive histogram equalization which are older one and give the mean performance in the Root Mean Square deviation (RMSE), Peak signal to noise ratio (PSNR) and mean absolute error. The newly developed algorithms are used with the machine learning model give us the better accuracy for the color enhancement. These are the algorithm such as Retinex, Homomorphic and Wavelet Multiscale technique are popular for the image enhancement [24] . With the help of machine learning color enhancement is done in various domains like underwater animal detection and classification [25] , Iris Recognition [26] , Smart laser surgery [27] , Brain image enhancement [28, 29] , Ultrasound image enhancement [30] etc. Colored image provides and hold a vast amount of information regarding object in image. It is difficult for the human eye to recognize and analyze each and every little potion of image such as color intensity and texture with in an image [31] . In colored images we need an algorithm which segments out all the parts with in an image and gives us the better results especially in case of the satellite image because they contain lot of noise with It and it is a trivial task of computer. Color enhancement is more difficult in case of color image rather than the gray scale image due to the following reasons. 1. In case of color we need to consider vector instead of scalar image due to presence of color. 2. Complexity of image is also a problem in case of color image. Color or contrast enhancement is another technique in which the intensity of pixel is changes to maximize or enhance the density of pixel with in image. The term ""contrast"" used for the separation of the dark and bright areas within an image. Due to contrast enhancement we are able to remove the dark areas from the image and we are able understand the content within an image [32] : Mathematical equation: a and b are the upper limits for the 8-bit gray scale picture, c and d are lower and upper value of histogram. Image Enhancement Techniques: This provide the information for human to understand the image by interpretation and perception of viewer against image via providing better input for automated image processing techniques. Image enhancement also classified into the two type of category: • Spatial and Frequency Domain: In the special domain we directly deal with the image pixels. People do the manipulation with the pixels with for the enhancement in the image. And in case of the frequency domain we change the frequency of pixels and change the image into the frequency. So, this states that we have need to apply the Fourier transform within the image computed first and after that we have to apply the inverse Fourier transform in order the get the resultant image [33] . • Histogram Equalization: is a technique which normalize the contrast with in the image by using the histogram equalization. It is based on the idea of near-uniform probability distribution function. It redistributes the probability distribution function within an image. For example, if in an image there are peaks and valley, after applying the histogram it will normalize the peaks and valleys will be shifted to normal curve. This results in improving the image contrast. There are types of the Histogram equalization namely Global Histogram Equalization (GHE), Adaptive Histogram Equalization (AHE), Block based Histogram Equalization (BHE) [34, 35] . In GHE each pixel with in an image assigned a new value based on the cumulative distribution function. To perform Global Histogram Equalization (GHE), the first original histogram of the grayscale picture should be adjusted or equalized. The aggregate/cumulative histogram from the input picture should be evened or equalized out to 255 by making a new force an incentive by applying [34] . n j = count of jth pixel, N is the no of pixels in horizontal and vertical direction in an image. • Homomorphic Filter: Homomorphic filter work in the principle of normalization of brightness and increase the contrast across the image. This will help the user to see the dark area within the image. For the removal of multiplicative noise, Illumination and reflectance we use the homomorphic filter. Since illumination and reflectance are combined multiplicatively, the components that are made added substance by taking the logarithm of the picture intensity, so that therein frequency domain linearity is formed. Illumination or brightening varieties can be thought of as a multiplicative noise and can be decreased by separating in the log domain area. • Retinex: In 1964 this theory was first proposed by Edwin Land. Multi-Scale Retinex (MSR) and Multi-Scale Retinex with modified color restoration are the other technique in the Retinex [36] . There is another technique called the single-scale Retinex method proposed by the Jobson, in which estimate the illumination by using the low pass filter for an input color image. In recent year, wavelet transform becomes a famous tool for the image processing. Wavelet transform (WT) is a powerful mathematical tool for the processing of images of multiple resolutions. It provides a septal and frequency characteristic with in an image. WT transform for an image the high-frequency part stores the original image details and the low frequency or imaginary part is stored with in the low-frequency part in an image [37] . The imaginary and low frequency part determine the dynamic image with in the image, but in case of the low frequency of the annotation there is the loss of information, so that why some of the information is stored in the high-frequency domain that is why the image reconstructed by the Inverse Wavelet Transform has the more details and widely used for the image processing [37, 38] . Image sharpening belongs to the category of spatial filtering in the image processing deals with the enhancement of detailed information within the images [39] . Sharpening of the images increases the brightness within the image. This could be done via using the high pass filter within the image. On the spatial regions there is small image features and image features correspond to the detailed information about high-frequency components of an image. Image sharpening is dependent on the two factors which are resolution and acutance. The resolution of the image deals with the no of pixel within the image more the pixel in the image more will celerity or sharpness within the image so this doesn't concern with the subjective nature of image. Acutance is little bit more complicated to understand and is linked with the subjective measure of image dealing with the edge with in the image. Edge on the image has more contrast appear more accurately in the image and human visual system. So, to increase the acutance within the image there is only one way to increase the acutance within the image at the edge contrast [40, 41] . Technique developed by Google like RAISER: Rapid and Accurate Image Super-Resolution ""use machine learning to produce high quality of images from low resolution of images from 10 to 100 times faster than the currently available methods"". SISR (Single Image Super Resolution) is the technique which converts the low-resolution images into the high resolution [42] . This method is based in the upscaling the image in the linear interpolator including the nearest neighbor in the image [43, 44] (Figs. 2,  3 and 4) . Grayscale images contain only black and with color. It permits the removal of small regions that are disjoint forms the larger objects without distorting the small features within the large objects. Neural networks have been proposed and a variety of works in binary reconstruction of grayscale images [45, 46] . This technique is mainly used in X-ray images and MRI images and helps in the detection of cancer. The interpretation of these gray scale images is difficult task and depends on the expertise and experienced radiologist. Thus, extracted features were classified with the help of Artificial Neural Network. In medical imaging diagnostic the detection of presence [44] of metal within the body which makes it important to diagnose of detect the metal object with in the body with the help of x-ray image or MRI CT images [47] . The CT images are classified into two categories one is high density metal and low-density tissues with in the human body. Within the sight of a metal object, linear attenuation coefficient at the limit of the metal changes out of suddenly, and the identification of the metal boundary is identical to transfer a signal with sharp edge. Not quite the same as regular CT recreation, where the center focuses is to infer the density appropriation inside the field of view and is frequently tested by the missing of solid projection signals behind the metal objects in body, here we estimate a paired binary picture. Mathematically, recreation of such a picture is considerably more manageable on the grounds that there is no missing information issue here. That is, the projection information close by is adequate for us to characterize the metal boundary with in inside the patient [48, 49] (Figs. 5 and 6).  • Easy to acquire: straightforward computerized digital cameras can be utilized along with basic frame stores, or minimal low-cost scanners or thresholding might be applied to gray level pictures or images. • Low storage: close to 1 bit/pixel, frequently this can be diminished as such pictures are entirely amiable to compression in the image (for example run-length coding). • Simple handling and processing: the calculations by the algorithm are by and large a lot more straightforward than those applied to gray level pictures/images obtained through cameras. • Limited application: as the representation is just an outline silhouette, application is restricted to undertakings where inside detail isn't required as a distinctive characteristic. • Does not stretch out to 3D: The 3D idea of items can once in a while be represented to by outlines silhouettes (What could be compared to binary processing preparing utilizes voxels, spatial inhabitance occupancy of little small cubes in 3D space). • Specialized lighting is required for outlines: it is hard to get solid, reliable binary image without limiting, restricting the environment. The simplest example among is model is an overhead projector or light box. The development of technology in our society we can expect that the image sensing device detects the things around you. Image segmentation is an important step for any image processing and computer vision algorithm. Analyzing and extracting and object form and image is an important for building intelligent machines for our surroundings. Segmentation will help in the retrieval of images form a large-scale database for content-based image retrieval system software. In a region, a group of connected pixels are there with similar properties. Edge detection is segmentation by finding similar pixels on their boundary. This can be termed as the binary image classification at pixel level. To solve this problem use of fixed and adaptive and feature selection in concurrence with the use of Support vector machine [49] . In this case the first work was done by David Marr in 1970 and then first success full work done in the David Lowe in 1987 [49] . There was improvement in the Algorithm by Shi and Malik, 1997. The image segmentation is the process of partitioning the image into different segments. This is done through the different patterns based on the pixel's similarity within the image. Segmentation is the way toward recognizing, distinguishing objects in the dataset from their environmental surroundings factors in order to encourage the creation of geometric models. For instance, in clinical biomedical imaging it is regularly important to measure the shape, surface area, or volume of tissues in the body. Once the dataset is segmented, those quantities are easily measured. The image segmentation is needed to identify the content within the image. Image segmentation is used to classify the data within the image. Image segmentation is used in almost every field ranging from the automated driving, medical cancer diagnosis, Handwritten digit recognition, underwater object classification/detection, food industries, etc. It has a vital role and more important among other problems in image processing. Due to introduction of machine learning algorithm computer researchers developed new algorithm to automated segmentation and edge detection within the image. Algorithm like neural network and other clustering algorithm will classify the segmented part within the image. Hence there lot of work is needed to be done for image segmentation and edge detection. The objective of the edge detection is to find the pixels in the picture that relate to the edges of the object found in the picture captured through the cameras. This is normally finished with a first and second derivative estimation following by a test which denotes the pixel as either having a belong to the place with which an edge is there or not. The outcome is a binary image which contains just the recognized or detected object edge pixels. Edge detection is the fundamental tool for the image segmentation. There are several tools and software that are used for the image segmentation and for the edge detection also. For the image segmentation, every method is not appropriate so there are several techniques which are used for the image segmentation are as follows [50] . • Region-based Segmentation • Edge-based Segmentation This is beneficial where the light object in the shady background. It will convert the multi-level image into the grayscale image. The separation of the object forms the background is done by selecting the values threshold value of T. Local thresholding and Global thresholding. When the T is not constant it is called as the local thresholding and when T is constant global thresholding. • Feature-based Clustering: Clustering the process of grouping the individual together who have similar properties and dissimilar properties into another cluster [51] . Good quality clustering produces high intracluster and low inter clustering properties. Issues arise in the feature-based clustering while dealing with the image are as follows: -How to represent the image. -How to organize the data from the image. -How to classify the image into a certain cluster (Table 1) Clustering is further classified into the Fuzzy C-means clustering and K-means clustering. K-means is the fast, robust, and simple unsupervised learning method for the clustering. Fuzzy clustering allows the object which form different cluster with membership. It is an effective method for the pattern recognition.  Edge detection, identification is an image processing method used to find and distinguish the sharp discontinuities with in a picture captured from camera. Edge detection is as often as possible the initial phase in recouping data of information from pictures. One of the eldest classical examining studies in computer vision is image processing in which further most of research work in done in edge detection or identification. There are many edge detection operations are available, which recognizes vertical, level, horizontal, corner, and step edges in an image. The quality, nature of edges identified by these operators is profoundly subject to, noise, clamor, lighting conditions, objects of similar intensities and the density and the thickness of edges in the scene [52] . There are two alternatives which are used for the detection of edges in the image are as follows. 1. Classification of all the pixels that satisfy the criteria of homogeneous. 2. Detection of all the pixels that are on the border in different homogenous areas (Fig. 7) . Instead of using the classical edge detection method neural network or deep convolutional neural network are used more widely for the classification of this purpose (Fig. 8) . Cardio vascular edge detection using the neural networks to perform the flow of blood flow simulation. In this method is used to identify the blood vessels in the entire region of image for image segmentation. This method used a fully connected convolutional neural network for classification of image segmentation of cardiovascular disease within the lung nodules [53, 54] (Fig. 9 ). Mathematical equation for the loss functions in the deep neural network Fig. 9 Cardiovascular edge detection using neural network [55] Brain tumor classification with the help of deep learning is possible. Convolutional neural network is used for the training the model on the brain tumor data set, testing is performed on the unlabeled data set and the accuracy is measured. Automated segmentation and detection is also possible with the help of these Deep learning based algorithms [56] . Image compression is the method of minimizing the size of the image by minimizing the sizes in bytes of graphics file with reducing the quality of the image. This will create more space and allow storing more images in an available memory size. Today on the internet ninety percent of the data is in the form of image and videos. Thus, most of the companies will use the data compression technique in order to run out of space. Machine Learning algorithms like support vector machine combines with the DCT discrete cosine transform achieve the level as compared to the RBF and multilayer preceptor [54, 57] . DCT is based on the JPEG compression algorithm one of the most widely used image compression algorithms. In the resulting value of the matrix it divides the whole image into pixel of squares and apply a discrete cosine function [57] . Image compression with the help of machine learning: • Neural Network: NN generates the rules to adjust and compute the complexity of image compression. They are generally composed of an input layer, hidden neurons, and an output layer. There may be one or more layer of hidden neurons. The hidden layer networks are logic functions that, based on input from one or more neurons in preceding layers will output information to one or more neurons in subsequent layers [58, 59] . Each of the connections between the neurons is designed to weight the input into the next neuron, hence if, for example, neuron A on input layer, outputs the value 2.46 to neuron B on hidden layer, there may be a weight, or bias, between both that doubles up the value, and consequently neuron B receives 4.92 as an input. In this case, the weight for the connection (synapses) was 2, doubling up the value, but this weight can be modified by giving a network training data. If a Neural Network is provided with a sufficiently large training data set, eventually the value of the weights in the synapses will be such that the results obtained from a neural network computation will be close to the expected results. While applying neural network method in image we can reconstruct and compress the image from the following provided image data set on which machine learning model is trained [60] . Fast data transmission in industrial scale on IoT devices is possible due to machine learning algorithm for the image compression [61] . In medical science for the detection of diabetic retinopathy is possible because of the image compression and machine learning image processing plays a vital role in the development of better treatment for diabetic patients [62] . • Genetic Algorithm: Genetic algorithms (GA's) are based on the processes of evolution and natural selection. They are a subset of evolutionary algorithms. Genetic algorithms take an iterative approach to problem-solving, generally following these steps [63, 64] . -Initialization: A population of algorithms is generated (randomly or semirandomly) to solve a particular problem. E.g. x = a + b, x = 2b − 3c, and x = a + b − c for deriving the quadratic equation. -Selection: The algorithms to be combined are selected, based on the proceeding of fitness if it is not the first iteration. -Crossover: Parent algorithms are combined to produce new children algorithms, the operation used to combine them is a factor to be determined by the supervisor, and may have a significant effect on the computational efficiency of the process. E.g. x = 2b − 3c, and x = a + b − c are added to produce 2x = a + 3b − 4c -Mutation: A random number or factor is added to the algorithm, mimicking the process of mutation in nature. For our example, this could be 2x = a + 3b − 4c + 8. This will generate new, potentially unique, algorithms for solving the particular problem -Proceeding of Fitness: The generated algorithms are tested against a training set, determining the fitness of the solutions. The solutions that are inaccurate above a certain threshold are dropped, and the rest are iterated through the process again, going to step 2: selection This process is repeated until a maximum number of iterations are taken or the solution is close enough to the training set. Combining the machine learning algorithm and compression algorithm: • GA and DCT • Neural Network and DCT Genetic Algorithm is one of the most common used optimization algorithms; so in image compression, this could be used for the optimizing the fractional compression and DCT (Discrete Cosine Transform). In DCT for optimal compression genetic algorithm could be a better solution for the optimization to improve the quantization with in the image.GA also applied in the fractional image compression. In fractal compression are searching the domain blocks and transforming the domain block to match the range blocks, it is these processes that are optimized by the genetic algorithm from Mtira and Morthy (1998) [64] . Neural networks have been used to improve image compression extensively. Both as standalone methods as well as combined with other techniques, traditional or more novel approachs. Setiono and Lu used a standalone neural network in order to compress images, using the image as input data for the network, and the reconstructed (compressed) image as the output. The images used where black and white, and the compression ratio achieved was about 10, producing good quality, albeit noticeably lossy, images. Figure shows Lena, uncompressed on the left, and compressed with the neural network on the right. The loss of information is particularly noticeable around the hair and the band on the hat, due to this being high-frequency areas [64] . Parodi and Passaggio approached the compression problem by combining DCT and Neural Networks. The approach they take to first divide the image into low and high activity area blocks, which will be compressed at different ratios and by different neural networks. The high and low activity areas are classified as such by using DCT's; high activity areas are those with higher coefficients within the DCT transform, indicating that they contain a wider range of frequencies. Each of this image is posteriorly provided to the corresponding neural network, either high or low capacity, with a number of input neurons proportional to the size of the block to be processed. The images are then compressed by the neural network, which uses the original block as a target for the learning process. The results obtained indicate a significant improvement in image quality over standard neural network compression of images, without compromising compression ratio, they achieve higher PSNR and lower MSE. In recent years there is growing interest in emotional intelligence in the humancomputer interaction. For the facial expressional analysis there is need for the compute there is need for the computer to interact naturally with the user via speech, body gestures to display emotions. One of the important way humans display emotions is through facial expressions via vocal, visual and other physiological means like Neutral, anger, disgust, fear, joy, sadness, surprise. Support vector machine and neural network can classify the facial expression with a speed and accuracy. Data set Cohn and Kanade's DFAT-504 have images of 100 of university students age ranging from 18 to 30 years [65] (Fig. 10 ). • Face Finding-FaceReader finds a precise position of the face via utilizing the well-known Viola-Jones calculation. • Modeling-A precise 3D modeling demonstrating of the face is made, which depicts more than 500 key points with in the face • Classification-A neural network system utilizes more than 10,000 pictures to arrange the basic emotional expressions, passionate articulations, and various properties of facial expression • Deep face classification-This procedure permits FaceReader software to straightforwardly order the face from picture pixels utilizing an artificial neural network system to perceive patterns with in the image. This permits the product to break down the face regardless of whether a part of it is covered up with (Fig. 11 ). The pi chart indicates the emotions of human facial expression analysis software works by following these consecutive steps • Multiclass Support Vector Machines (SVM): Are supervised machine learning algorithms that investigate, analyze, group information, and classify the data, and they perform well while predicting, classifying human facial expressions. In any case, they possibly do so when the pictures are made in a controlled lab setting with steady head postures, brightening and a constant illumination [66] . • Support Vector Machine: SVMs perform less well when characterizing pictures are captured ""in the wild,"" or in unconstrained, unspontaneous, uncontrolled settings. Along these lines, the most recent training machine leering or deep learning architecture being explored are altogether profound as deep neural network systems which perform better under those other available architectures. Convolutional Neural Networks (CNN) are right now considered the go-to neural systems for picture characterization, since they get on designs small patterns of a picture, for example: curve of an eyebrow or lips style, nose style etc. • Convolutional Neural Network: CNNs apply kernels, which are matrices smaller than the image, to chunks of the input image [67] . By applying kernels to inputs, new initiation lattices, at times referred to as feature maps, are created and gone as a contribution, pass the input to the next layer of the network. Along these lines, CNNs process increasingly granular elements inside a picture and make a better via classification between the two similar at recognizing two comparable emotion classification. VGG16 is the state-of-the-art architecture for the CNN network with 16 fully connected layers, with 3*3 convolutional and 2*2 pooling layers [68, 69] (Fig. 12 ). • ResNet50: It is one the most popular CNN architecture for the face recognition. It has the additional mapping capacity as compare to the VGG16 networks [71] ( Fig. 13 ). • Recurrent Neural Networks (RNN): Utilize dynamic transient behavior while the classification of an image. This implies when an RNN forms an input information model, it doesn't simply take a data at the information from that example model. It additionally takes a data from past sources or layer with in the training model from the images, which are utilized to give further output. In FER, the setting could be past picture frame of a video clip [72] . • The thought of this methodology approach is to catch and capture the transition between facial patterns example after some time, permitting these progressions to turn into extra additional information data points which focuses and support the characterization. For instance, it is conceiving possible to catch the changes in the edges of the lips as an articulation expression goes from natural to happy, cheerful by smiling, rather than the simply the edges of a smile from an individual image frame ( Fig. 14 ; Table 2 ). • Edge detection algorithm • Pattern detection algorithm • Expression analysis algorithm • Edge Detection Algorithm The point at which the image brightness changes sharply and organized into the lines or curves are termed as the edges. Edge detection is the fundamental tool in the image processing especially in the computer vision and particularly playing the role in the feature extraction. Feature detector such as Scale Invariant Feature Transform SIFT (DoG), Harris, and SUSAN are one of the good methods which yield high quality of features but due to too much computationally intensive nature for the use in real-time application of any complexity [74] . Canny edge detector is an edge detection technique which uses a multi-stage algorithm which is developed by the John F. Canny in 1986 to detect a wide range of edges in an image. Machine learning can be used to derive a feature detector which can process the PAL video less than seven percent of processing time. ML can compare with Harris detector (120%) and SIFT (300%) faster at full frame rate [75, 76] ( Fig. 15 ). Working of SIFT algorithm: SIFT algorithm is widely used and can be divided into the following parts as follows [77] : 1. Constructing a scale space This is the underlying initial arrangement. You can create internal representation of the original image to make sure that there is scale invariance. This is finished by creating a ""scale-space"". 2. LoG Approximation: The Laplacian of Gaussian is incredible for finding intriguing interesting points (or key points) in a picture image. Be that as it may, it's computationally expensive. In this way, we cheat and surmised approximate it using the representation created earlier. 3. Finding key points with the super-fast estimate approximation, we currently attempt to discover out the key points. These are maxima and minima in the Difference of Gaussian picture we have to figure out. 4. Get rid of bad key points at Edges, light illumination and contrast and low complexity areas are bad key point. Eliminating these points make an algorithm efficient, productive, and strong and robust toward the feature learning. A method like the Harris Corner Detector is used here for the edge and curve detection in objects. 5. Assigning a direction to the key focuses a direction is determined for each key point. Any further computations are done comparative with this direction. This adequately cancel out the impact of direction, making it turn invariant. 6. Generate SIFT includes Finally, with scale and rotation invariance set up, one more representation is produced. These sides particularly distinguish features of the objects in an image. The algorithm will be implemented in the Open Cv. Repetitive sequence within the image called pattern. Pattern in the images can be either seen physically or can be found with the help of mathematics by applying some technique. In case or colored image, there should be more than one pattern in the image. Pattern detection is the process of classification of image data based on the supervised learning or statically information extracts out form the unlabeled image data. Pattern reorganization has done some great work in the speech recognition, Speaker identification, multimedia document recognition (MDR), and medical image analysis and could be used in the biometric identification and Fraud detection also. It could be done via supervised learning (Classification, Regression), Clustering, ANN, and reinforcement learning. In the literature, so many algorithms are available for the classification like support vector machine for multi-class pattern recognition, ANN, CNN, etc (Fig. 16 ). Pattern detection in medical image analysis Face expression technology could be used in the variety of applications such as access control and surveillance and identity authentication. Human being uses the facial expression to interact with the socially. Since the rise of artificial intelligence proceeded with research interests for empowering computer system frameworks to perceive the expressions and to utilize the emotive data inserted in them in humanmachine interfaces. Research activity in face recognition have been increased in the past couple of years. SVM is recently proposed and widely used algorithm for the facial expression analysis. The Support Vector Machine (SVM) classification trains, identifies the different displacement patterns features form unknown sample images and based on the learning experiences it classifies the different facial expressions like anger, fear, joy, sorrow provided during the training period ( Fig. 17 ; Table 3 ). Technique developed by the Google team that incorporates the machine learning in order to produce the high-resolution images from the low scale image. Its 10-100 times better than the currently available algorithm and can be run on the mobile devices [78] (Fig. 18 ). Facial expression analysis pipeline using support vector machine SVM Upsampling: Is the process of producing an image of larger size with significantly more pixel and higher image quality from low quality of images. The term up sampling is associated with the process of resampling in Digital image signal processing (Fig. 19 ). and X U , p (m) , and those with matched labels are considered to have high confidence and their corresponding pseudo labels X C i , s (m) , X C i ⊂ X U are determined. 5. Fine-tune the pre-trained 3D-DPNet using X C i , s (m) and X L , y (m) . 6. Repeat 2 to 5, until i = N . 7. The labels of X T were obtained using the parameters of the last iterations of 3D-DPNet. Output the labels of X T .@story_separate@• As the human species evolved human learned the things via sensing organs and learns, understand the daily or new activities day by day. As the evolution in the technology human tries to mimic the human brain behavior on computers with the help of some programmed algorithm. Machine learning is such a field which when combines with the computer vision solve most of the today's problem. Here, in this book chapter, we have discussed and tries for find out some of the problem of computer vision with the use of ML algorithms. We have discussed how image compression, image enhancement and noise removal technique, automated segmentation like problem will be solved with the help of machine learning. • Broadly Machine learning is composed of Supervised, Unsupervised, and semisupervised ML. Algorithms like KNN, k-means falls into this category, there will be further improvement day by day in these algorithm as we have a lot of data for the training our model on different datasets. • Image compression is one of the important areas of research now these days as we have better quality of cameras which are capable of capturing the highresolution images. Thus, transferring and storing these images on the storage system, transfer the data from one place to another require a development of new algorithms thus Machine learning helps a lot and we can develop a new image compression algorithm. • Image processing use machine learning a lot. Automated image segmentation to edge detection, color enhancement, and visualization is possible due to machine learning. In Medical Science image processing use a lot in X-RAY, MRI, and CT scans also. Image Recognition, visualization is also one more task in image processing, thus visualization of underwater object, human body organs detection, cancer/lesion detection, and recognition is popular field of computer vision and use machine learning algorithms a lot. Denoising of images is done through the machine learning. Now we have such an algorithm which can do the automated de-noising of noise from the noisy image. • Due to machine learning algorithm like Neural network, genetic algorithm is trained on the medical image data thus it is become possible to diagnose the patient automatically. As a result, more accurate and precise diagnosis and treatment are possible in the hospitals. The increase in the data and computing power makes the automated diagnosis more easily and prediction algorithms help a doctor in diagnosis. • Images captures form the satellite, mobile phone, or digital cameras are large in size, due to ML algorithm it is able to compress the size of image automatically without any loss of information is possible. Applying ML algorithm in image processing enhances the colors of the image. • Facial expression analysis is done with the help of Deep learning classification. On the web there are facial expression datasets are available and via using these data set we can train our models or we can develop a new algorithm also. Facial expression algorithms read our facial feature based on these they predict the emotion or mood of human body. • Thus, in this book chapter author has tried to provide the new advancement in the field of computer vision and artificial intelligence/machine learning. As the technology is advancing day by day there is explosion in the data also and we need some algorithms to compress, classify, label this huge amount of data having knowledge and a skill of machine learning and image processing one can gain develop new algorithm also for the better understanding of content between the images or videos. Author Contribution In the era of pandemic of COVID-19, Mr. Ajay Sharma 1 (Ph.D. Research Scholar Dept of Bioinformatics JUIT) has prepared all the Manuscript of the book Chapter Most of the data, paper collection, and written part is done by the Ajay Sharma. Mr. Ankit Gupta 2 (Ph.D. Research Scholar Interactive Technologies Institute (ITI/LARSyS Madaria) has written the introduction part of the book chapter and helps in mining latest research articles for this book chapter. Dr.Varun Jaiswal (Ex. Assist Director, National Centre for Disease Control NCDC New Delhi, Current Assist prof Gachon University Dept of Biotechnology) has revised the prepared manuscript and find out the correction where it will be needed. The book chapter contains some of the novel work. While planning and designing the book chapter entitled ""Solving Image Processing Critical problems using Machine Learning"" author should contain in mind that this book chapter helps those readers who don't have any or little knowledge about image processing to those who are sound in imaging. Thus, keep in mind author has divided the book into several sections like easy, intermediate, and modest. In easy part, reader can understand the theory behind the image processing algorithm and machine learning and intermediate part contains the working and the modest part contains the mathematics algorithm that could be understood by those who have sound knowledge in image processing.","The history of vision can go back around 543 BC. From fossil studies, researchers found out that no. of animal species floats out and soon develops the first animal with eyes. As evolution in bigger species around fifty percent of neurons in our body are involved in the visual processing. Vision allows human to perceive, comprehend, and understand surrounding them while computer vision aims to duplicate the impact of human vision electronically in the form of images. The history of making artificial vison starts around 1545, Gemma Frisius, and Encylopedie in eighteenth century. The foundation period of the concept lies from 1943 to 1956, during this period research is cantered towards understanding the concept of machine learning intelligence, artificial neural system, and automata theory computation. The first work in the field of Artificial intelligence in computer vision and image processing was done in MIT called “Summer Vision Project”. The rise of artificial intelligence starts and it is used widely in every field of technology. As the technology advances machine learning is used in almost every field. This book chapter provides you some details how the machine learning is used in image processing and to solve the current problem and challenge in computer vison like: Denoising, Image compression, Image color enhancement, segmentation, etc. Machine learning algorithm like Neural Network, Support Vector Machine, Genetic Algorithm, Convolutional Neural Network, etc. were discussed in the book chapter."
"As the Corona Virus Disease 2019 (COVID-19) pandemic spread rapidly throughout the world, there has been a growing concern regarding the risk of infection amongst people who use drugs (PWUD) (Dubey et al., 2020; Farhoudian et al., 2020) . In Norway, the first person was diagnosed with COVID-19 infection on February 26th, 2020 and the first COVID-19 related death was confirmed on March 12th. The same day, the Norwegian government declared a national lockdown and kindergartens, schools, universities, training facilities, restaurants and libraries were closed. Gathering of more than five persons was prohibited and strict regulations were implemented on travelling both domestically and internationally. To address the concerns regarding COVID-19 positive PWUD, isolation units for COVID-19 positive PWUD opened in the two largest Norwegian cities, Oslo and Bergen, in March/April 2020. Admissions were voluntary and the units had a liberal treatment policy for opioid substitution and tranquilizers. However, very few PWUD were diagnosed with COVID-19 in the beginning of the pandemic in Norway. We therefore wanted to explore the knowledge and perceptions towards COVID-19 among PWUD. In this cross-sectional study among PWUD, we examined the respondents' knowledge of common COVID-19 symptoms, their willingness to test if they experienced COVID-19-related symptoms and if they knew of the services available for COVID-19 positive PWUD. Finally, we examined drug availability and prices as experienced by the respondents.@story_separate@We included 226 PWUD between May 13th and June 30th, 2020 in Oslo, Bergen and Kristiansand. Oslo and Bergen had open drug scenes, while no such scene existed in Kristiansand. An interview-administrated questionnaire was developed in close collaboration with representatives for PWUD and professionals. The questionnaire included background characteristics, questions about the substances (including alcohol) used, OMT status, availability of substances and changes in drug prices in the illegal drug market during the COVID-19 pandemic. The specific substances asked for were alcohol, tranquilizers, heroin/other opioids, cocaine/amphetamine and other substances (should be specified by the respondent). The term ""tranquilizers"" includes both prescribed medications as well as medications obtained on the illegal drug market. The participants responded to questions about the common COVID-19 symptoms and if they currently experienced any of these symptoms. The symptoms included body aches, shortness of breath, cough, stomach pain, headache, changes in taste or smell, sore throat and fever. We also investigated willingness to take a COVID-19 test if experiencing symptoms. The participants were also asked if they knew of any COVID-19 services especially tailored towards PWUD in their city. The questionnaire took three-five minutes to complete. The study also included an intervention in terms of informing participants who were not aware of the COVID-19 symptoms or available services. We recruited the interviewers through the users' organizations and through different low-threshold services for PWUD in the three cities. The sample is a convenience sample. Any individual, above 18 years, using any of the substances mentioned above could be included. Participants were recruited via phone by social workers or by outreach workers, low threshold service staff or peers from user organizations near the open drug scenes and at low-threshold services. The open drug scenes in Oslo and Bergen are areas of the towns were substances are relatively openly bought and sold on the illegal market. Of the interviews, 60 (27 %) were peer-to-peer interviews, 38 (17 %) were performed by outreach street workers, 52 (23 %) by employees from low-threshold housing, 27 (12 %) by social service workers, and 49 (22 %) were performed by employees in low threshold daytime services. The refusal rate was not recorded. In total, we excluded 14 questionnaires, either because the respondent had participated previously (duplicates) or because the respondent did not complete the questionnaire. We submitted the study to the Regional Ethics' Committee and the Data Inspectorate at the University of Oslo, and both bodies concluded that the questionnaire was anonymous and therefore did not need approval. We gave a short sheet of information to each participant to read or the interviewer read it aloud to the participant. In the questionnaire, the respondent had to confirm that he/she had received the information about the survey and how the information he/she gave would be handled. We conducted the statistical analyses in Stata 15.0. Multiple binary logistic regression models were estimated with no/yes outcomes: 1. Familiarity with COVID-19 symptoms 2. Awareness of COVID-19 services tailored towards PWDU and 3. Willingness to take a test if experiencing any symptoms. We included the following independent variables into each of the three models: gender, age, the main drug of choice, OMT status and recruitment city. Adjusted odds ratios (aOR) and 95 % Confidence intervals (CI) were reported. The majority (73.0 %) of the 226 participants were males. The mean age was 44.1 years (range 18-78 years). Overall, 54.0 % of the participants injected drugs. More than half of the sample (54.9 %) was in opioid maintenance treatment (OMT). Furthermore, 47.8 % of the sample had applied for/been in or considered applying for substance use treatment the preceding two months. The participants most commonly reported heroin/other opioids as their current main drug of choice (35.8 %), followed by cocaine/ amphetamine (25.2 %), and cannabis (11.9 %). The participants reported to currently use an average of 2.3 substances including alcohol (SD = 1.1), ranging from one to five. The proportion of the participants reporting to currently use the following substances (main drug of choice plus additional substances) was: Cocaine/amphetamine (61.0 %), cannabis (59.7 %), heroin/other opioids (54.8 %), tranquilizers (52.6 %) and alcohol (33.2 %). There were no statistically significant differences between genders. Overall, 65.9 % of the sample was familiar with the common COVID-19 related symptoms (Table 1) . Body pain/aches was the most commonly endorsed (19.9 %) by the participants of COVID-19 related symptoms, followed by shortness of breath (16.8 %) and cough (12.4 %). The majority (63.7 %) of the sample was not aware of specifically designed COVID-19 services available for PWUD in need of isolation. Almost all of the participants (91.2 %) stated their willingness to take a test if they experienced any COVID-19-related symptoms. A minority (35.4 %) of the sample reported a current drug shortage. Shortage was reported for tranquilizers (31.3 % of those reporting shortage), followed by cannabis (7.5 %). A majority (61.5 %) reported an increase in prices of drugs since the COVID-19 outbreak. Among the 139 reporting an increase in drug prices, the majority (69.8 %) reported cannabis to have become more expensive. Those in OMT had three times higher odds of being familiar with COVID-19 symptoms compared to those not in OMT (aOR = 3.4, 95 % CI 1.7, 6.8) (Table 2) . Likewise, those in OMT had higher odds of being aware of services available for COVID-19 positive PWUD (aOR = 2.7, 95 % CI 1.1, 6.3). OMT status was only significantly associated with being aware of services for males, not for females. This study represents a snapshot of the situation during the early pandemic phase in Norway, but it highlights a more general phenomenon; the need for tailored messaging specifically towards vulnerable groups. Early in a crisis, such as the COVID-19 pandemic, the findings from this study emphasize the importance of reaching out to PWUD, both those in treatment, but also those outside formal treatment. Our findings suggest that OMT may play an important role in COVID-19 prevention, as current and previous OMT patients were more likely to be aware of COVID-19 symptoms, as well as COVID-19 services available for PWUD. It is encouraging that treatment engagement seems to play an important role in COVID-19 prevention, but it also means that a special effort is needed in order to reach PWUD not in treatment. PWUD not in treatment have an increased risk of morbidity and mortality (Degenhardt et al., 2011; Mathers et al., 2013) and is therefore a particularly vulnerable population that needs to be included in COVID-19 prevention interventions, likely with specifically targeted messaging across appropriate information platforms. During the early pandemic it was a rapid development in the general knowledge about COVID-19, however it was less emphasis on specifically targeted messaging towards subpopulations. This may have rendered vulnerable groups additionally vulnerable. In situations with societal change and rapid developments, the importance of clear and updated information targeted towards a range of subpopulations is critical. Two thirds (66 %) of our sample were familiar with COVID-19 related symptoms. Still, the results clearly indicate the need for better information among PWUD about the symptoms of COVID-19, since a third of the sample were not familiar with the symptoms. Lack of knowledge regarding COVID-19 symptoms could be one reason for the low proportion in our sample reporting any such symptoms. A large proportion of PWUD is known to have chronic somatic diseases (Bech et al., 2019; Reimer et al., 2011) . There may be several reasons why the participants did not report symptoms related to COVID-19: They might not have any symptoms, they might miss the symptoms due to intoxication, they might interpret any symptoms they may have as withdrawal symptoms, or they might be so used to having different somatic symptoms that they do not recognize/report them (Yoshimasu, 2012) . There has been very few reports of COVID-19 positive PWUD from Norway during the early phases of the pandemic. However, due to the possibility of symptoms not being detected in PWUD, it would be of interest to test for COVID-19 antibodies in this particular population. Almost all the participants (91 %) reported willingness to test for COVID-19 if they experienced any symptoms. We have not been able to identify similar studies among PWUD. However, if the high proportion of participants in our sample is a reflection of attitudes in the target population, it is important to ensure information of test availability, easy access to test facilities, and to ensure proper care of those testing positive, in safe and professional settings. Only 1/3 of our sample reported a drug shortage, but more than 60 % reported an increase in drug prices. Cannabis in particular appears to have become more expensive, followed by illicit prescription drugs. This finding is in line with other European countries where there also have been reports of inflated retail prices for cannabis (EMCDDA and EUROPOL, 2020) . 3missing ""Are you familiar with Covid-19-related symptoms?"". 2missing ""Are you aware of Covid -19 services available for PWUD in your city?"". 2missing ""Would you take a test if experiencing any Covid-19-related symptoms?"". 3missing ""Do you know any Covid-19 infected person(s)?"". 3missing ""Are you, to the same extent as previously, able to buy your regular substances?"". 6missing ""Are substances more expensive?"". *Other=Heroin, stimulants or everything. a Medications that require a doctor's prescription, most often benzodiazepines. In our study, it includes both prescribed and illegal medications. b Heroin/other opioids, stimulants, alcohol, everything. Notes: Odds ratios are adjusted for recruitment city (Oslo, Bergen and Kristiansand) in addition to other variables in table, but estimates not shown in the table. aOR = adjusted odds ratios, CI = confidence interval, OMT = opioid maintenance treatment. *** P < 0.001 and ** P < 0.01. The participants shared characteristics with problematic PWUD in two other Norwegian studies in terms of age, gender, drug use and current OMT (Gjersing and Bretteville-Jensen, 2018; Madah-Amiri et al., 2019) . This suggests that our findings may be generalized to persons who use drugs beyond our sample. Peer interviewers conducted almost a third of the interviews, which further strengthens our findings, because they have a better knowledge of the drug using surroundings and know many PWUD. On the other hand, there are also some study limitations. Selfreported interview data are open to recall bias, under-and overreporting and imprecise estimation. They are also open to social desirability bias; where the participants may underreport socially undesirable attitudes and behaviors, and to over-report more desirable attitudes (Latkin et al., 2017) . It is possible that the high proportion reporting willingness to test is a consequence of this bias. It is also a limitation that we did not collect any information on the non-responders, nor did we collect the refusal rate. However, one of the interviewers, who conducted 50 of the interviews, estimated that approximately 1/4 refused participation. Gabrielle Welle-Strand: Planned and managed the project, developed the questionnaire, recruited the interviewers, entered about half of the interviews into the database, responsible for all drafts and the final manuscript. Svetlana Skurtveit: Helped with analyses, gave feedback on all drafts of the manuscript including the tables, and approved the final manuscript and tables. Thomas Clausen: Gave feedback on the questionnaire and the project proposal, gave feedback on all drafts of the manuscript including the tables, and approved the final manuscript and tables. Christine Sundal: Performed 50 of the interviews, gave feedback on all drafts of the manuscript including the tables, and approved the final manuscript and tables. Linn Gjersing: Responsible for the analyses, gave feedback on all drafts of the manuscript including the tables, and approved the final manuscript and tables. The authors report no declarations of interest.@story_separate@The main finding was that current or recent OMT experience (i.e. treatment engagement) was associated with improved knowledge of common COVID-19 symptoms and about available services. Additionally, 66 % of the 226 interviewed participants were familiar with COVID-19 related symptoms and almost all the participants (91 %) stated their willingness to undergo testing if they experienced COVID-19 related symptoms. Furthermore, our findings indicate a change in the Norwegian drug market in the two months following community lockdown, in particular in terms of an increase in the price of cannabis.","BACKGROUND: Little is known regarding what people who use drugs (PWUD) know about COVID-19 related issues and changes in the drug market due to COVID-19. We therefore conducted a survey to explore these issues. METHODS: In a cross-sectional study, we interviewed 226 PWUD from three Norwegian cities in May/June 2020. Participants completed an interview-administrated questionnaire. Three separate multiple binary logistic regression models were estimated with the outcomes (no/yes): 1. Familiarity with COVID-19 symptoms, 2. Awareness of COVID-19 services tailored towards PWUD and, 3. Willingness to take a COVID-19 test. RESULTS: The mean age was 44.1 years and 73 % were males. Fifty-four percent were injectors, and heroin/other opioids (35.8 %) and cocaine/amphetamine (25.2 %) were the most common main drugs used. Overall, 54.9 % were in opioid maintenance treatment (OMT). The majority (65.9 %) stated they knew the COVID-19 symptoms. Almost all the participants (91.2 %) reported they would take a COVID-19 test if experiencing relevant symptoms. The majority (63.7 %) were not aware of COVID-19 services available to PWUD. OMT patients were more likely to be familiar with COVID-19 symptoms (aOR = 3.4, 95 % CI 1.7; 6.8), and to be aware of COVID-19 services (aOR = 2.7, 95 % CI 1.1; 6.3). Overall, 35.4 % reported reduced drug availability, mainly for tranquilizers, while 61.5 % reported increased drug prices, mainly for cannabis. CONCLUSION: Drug treatment may play an important role in COVID-19 prevention, as those in OMT were more likely to be aware of symptoms and of availability of services."
"Numerous mitigation measures have been introduced in an e ort to prevent the spread of coronavirus in the UK. These include restrictions of movement, social distancing, mandatory use of face coverings in certain settings and engagement in test, trace and isolate procedures when necessary. Critically, the e ectiveness of these measures for preventing transmission is dependent on the extent to which they are known, understood, accepted and adopted in time. However, throughout the pandemic, research indicates variation in the extent to which people are willing and able to adhere to guidance. [1] [2] [3] [4] Although social distancing and self-isolation behavior during lockdown can be crudely defined as being 'adherent' or 'not-adherent', it is likely that there is a more nuanced scale of adherence. 5 Attempts have been made to challenge the view that adherence should be considered a dichotomy. Fancourt et al. 6 use the terms 'complete' and 'majority' adherence to compare those who follow all the guidance all the time with those who follow some of the guidance, or for some of the time. Williams et al. 5 refer to 'overt rule breaking' and 'subjective rule interpretation' to di erentiate between those who were deliberately breaking the rules, and those who are interpreting inconsistent or constantly changing guidance to suit their needs. However, these terms do not capture the complexities underpinning decisions to adhere to the guidance, and the risk that this may bring. People may be acting conscientiously, engaging only in activities in which they are unlikely to come into contact with anyone, attempting to minimize the risk of transmitting or catching the virus. 5 Alternatively, people may be leaving their home out of necessity, in order to buy food or medicine, or to provide care for a vulnerable person. It is still unclear how the public are making decisions about what they should and should not do, what they actually are doing, and how safe this is. Periods of lockdown may be particularly challenging for those from the lowest income backgrounds and individuals from Black, Asian and minority ethnic (BAME) communities who are less able to engage in social distancing measures, and are less able to work from home and self-isolate when required. 2 Emerging evidence from the Mental Health Foundation's Mental Health in the Pandemic study also indicates that a higher proportion of members of BAME communities are experiencing financial concerns, fear and anxiety than members of the non-BAME population. Furthermore, people from BAME communities are more likely to be in precarious work and where furloughing may not have been o ered. 7 Understanding and supporting adherence to mitigation measures among this population is therefore critical. The aim of this study was to gain a better understanding of how people from low-income and BAME communities are adhering to social distancing and self-isolation measures during the COVID-19 pandemic, and to explore in detail the reasons underpinning this behavior.@story_separate@Participants over the age of 18 years from BAME, and lowincome White backgrounds were recruited via social media channels. We invited interested individuals to contact the research team via email. Potential participants were sent an information sheet about the study. All interviews were conducted via the telephone or using the online platform Zoom. Audio-recorded verbal consent was obtained. Interviews were conducted between the 8th and 31st July 2020 and lasted between 21 and 55 min. At that time, nonessential shops and places of worship were allowed to open, and in England, groups of six were allowed to meet outside. People were still required to stay 2 m apart, and isolate if they, or their household, experienced symptoms of COVID-19. Face masks were compulsory on public transport, and from the 24th July were also mandatory in shops. Participants were asked about their understanding and perceptions of government mitigation measures, and their decisions about social distancing and self-isolation behavior during lockdown. Following the stages of thematic analysis, 8 two researchers independently read transcripts and assigned initial codes to the data. Possible themes were identified and refined through discussion. Data were checked against an initial framework and refinements made as necessary. For each theme in the framework, charts were developed, and relevant text copied verbatim. Charts were used to identify common concepts within and between participants, and explanations sought for divergence. Participants were given the opportunity to discuss the analysis and interpretations with the researcher team via Zoom or telephone meetings. Two participants engaged in these discussions, contemplating how their behavior fit with the identified categories of adherence, and providing feedback on the final themes. A total of 20 participants (13 female) took part in the interviews. Participants were between the ages of 18 and 65 years and from Black African and Black Caribbean (N = 4), Asian 9 and White (N = 7) ethnic groups. The average (mean) Index of Multiple Deprivation decile was 4.15. Four participants reported that they had had COVID-19, or symptoms of COVID-19 in the household. Thematic analysis showed that participants engaged in active evaluation of infection risk and control measures, following which three context-specific patterns of adherence were identified ( Fig. 1) . Participants were eager to understand how they could protect themselves, their households and their communities, but often struggled to keep up-to-date with and make sense of the 'constantly changing' advice and recommendations (Table 1 -Quote 1). There was evidence of a lack of understanding of terms such as self-isolation, and how to self-isolate safely (Quote 2). Participants were unclear as to whether they should be isolating (Quote 3), or shielding (Quote 4), and felt uniformed about the number of cases of COVID-19 in their local areas (Quote 5). Due to a lack of scientific certainty surrounding the guidance, messages were often considered to be 'open to interpretation' (Quote 6). Participants described a need to decide for themselves how to respond to the information they were receiving, and to use their judgement, rather than simply following the guidance (Quotes 7 and 8). Decisions appeared to be made on the basis of their individual situations, putting the health and needs of their family ahead of government guidance (Quote 9). Participants described a willingness to adhere to mitigation measures in order to protect themselves and their households from the virus ( Table 2 -Quote 1), or to protect others around them, for example, if and when they had experienced symptoms of COVID-19 (Quote 2). Increased e orts were taken by participants from vulnerable groups to protect themselves (Quote 3) or vulnerable members of their households. Many of the participants who considered themselves or their households to be vulnerable, and felt that the risk of exposure to the virus was high, reported engaging in additional, precautionary measures to protect themselves and their families (Quote 4). Super-adherence was particularly prominent among vulnerable participants who did not consider government recommendations to be su cient for protecting them (Quote 5). A second pattern of adherence included breaking lockdown rules if it was perceived as safe to do so (Table 3) . Partiallyadherent behaviors were justified by participants, either because they were genuinely perceived as being low risk or because there were su cient inconsistencies in key messages to allow participants to present their behavior as low risk. Low risk behaviors included those that were considered unlikely to contribute to the transmission of COVID-19 (e.g. those that do not result in close contact with others), as well as behaviors that were considered safe for the individual participant. As an example of the former, one participant described a willingness to leave the house on more than one occasion, a behavior that was not permitted at the time, because he considered it very unlikely that he would come into contact with others (Quote 1). Behaviors that were considered safe for the individual were usually based on individual perceptions of risk, with those who did not consider themselves to be at high risk describing how this had made them less inclined to adhere to social distancing guidelines (Quotes 2 and 3), whereas potentially overlooking the risk to others. Any apparent ambiguities or inconsistencies in information could be used to justify partial-adherence (Quotes 4 and 5). One participant explained how she had allowed her son to play with his friends as key worker children were allowed to remain in school (Quote 6). Another participant was willing to meet a friend during lockdown because she reasoned that it was no di erent from seeing others' outside at a distance (Quote 7). A third participant, who described himself as low risk, outlined how breaches of lockdown among influential figures reduced his willingness to restrict his own lifestyle (Quote 8). Necessity-driven partial-adherence Participants described situations in which they felt they had no choice but to break the rules around social distancing or self-isolation. Participants described a need to find a balance between staying safe and maintaining their mental health and wellbeing (Table 4 : Quote 1), or to continue to work because of financial concerns and responsibilities (Quote 2). Indeed, there was perceived pressure from those in management positions to return to work-even when it was against o cial advice (Quote 3). One participant who lived in rented accommodation felt under pressure to allow her landlord to enter her home for maintenance purposes, even though she did not feel comfortable allowing him to do so (Quote 4). Other necessities included for religious purposes (Quotes 5 and 6), or to provide support for bereavement (Quote 7). A common motive for breaking social distancing guidance was for the sake of their own mental health and wellbeing, or that of their friends and family. One participant described how she had met with her son during lockdown as she was struggling with her anxiety (Quote 8). This participant later described going out during the lockdown period to meet a friend who was also struggling to cope with social distancing measures. Social contact with anyone outside the household was prohibited at the time (Quote 9). One parent was particularly anxious about the mental wellbeing of her children, and described how she had allowed her children to meet with friends before lockdown restrictions were lifted because she felt that they had needed it (Quote 10). Growing evidence highlights the substantial impact of the lockdown measures on individuals from BAME communities and those on low-income, 9 with these individuals facing additional barriers to adherence to government imposed mitigation measures. 2 In line with previous research, participants in the current study reported engaging in behaviors that were not always in line with the government's social distancing and self-isolation advice. However, these acts of partialadherence were not always high risk or avoidable. We suggest that participants made risk-adapted decisions based on their perceptions of the degree of transmission risk entailed by the behavior (for themselves and others), in relation to the importance of the activities they wanted or needed to undertake. We outline three context-specific patterns of adherence: (i) caution-motivated super-adherence, (ii) risk-adapted partial-adherence and (iii) necessity-driven partial-adherence. 'She's got her church friends that goes round. But I think they just sit in the garden or sit in the kitchen, the two of them and do their bible studies' (Participant 08, BAME Female). 'I did then meet up with another friend who was nding lockdown dif cult, which we were not supposed to at that point. We met at a distance on a walk. I felt mentally I needed that' (Participant 16, White Female). Quote 10 'They've gone out for the last two months. They started going out to do exercises and go and meet up with friends' (Participant 04, BAME Female). Our findings highlight the need for di erent forms of intervention, as well as additional research into the impact and risks associated with these patterns of adherence. One pattern of adherence involved participants engaging in measures that were additional to those recommended by the government, and continuing to adhere to strict social distancing guidance after restrictions were lifted. Although participants in the current sample were able to continue with more stringent social distancing measures in the short term, it is critical that support is available for vulnerable individuals from BAME communities and those on low-income to be able to maintain this level of adherence when necessary. As much research highlights that social distancing is particularly problematic among these individuals, 2 support is urgently required for vulnerable individuals who need to engage in additional protective measures when government-imposed restrictions are lifted. A second pattern of adherence involved infringing rules around social distancing if it was perceived as safe to do so due to risk of transmission of COVID-19 being low (riskadapted partial-adherence). Participants in the current study described leaving the home for physical activity on multiple occasions, or to meet with others at a safe distance outside the home (behaviors that were not permitted at the time). These behaviors were justified by participants as they were viewed as low risk; either because the participant would not be in close contact with others, or because alternative methods of protection (hand hygiene and face coverings) were used. Classifying this behavior as 'risky' in the same way as those who engage in high risk (e.g. indoor) contact may be unhelpful, particularly as physical activity is likely to have a positive impact on wellbeing. 10, 11 With essential social distancing measures in place this form of partial-adherence could potentially be a lower risk way of obtaining much needed social support. In some situations, participants justified breaking social distancing rules because they did not consider themselves or their household to be vulnerable. The potential impact on transmission of COVID-19 beyond their household did not appear to have been considered. Other participants used comparisons to other situations in order to provide justification for their partial-adherence, such as key worker children being allowed to remain in school. However, the extent to which these behaviors or situations are genuinely low risk may be questioned. Indeed some participants, particularly those who considered themselves to be of low risk, appeared to be using information selectively to justify ignoring di cult social distancing rules. The cumulative impact of small acts of nonadherence is still unknown. 12 A final pattern of adherence involved engaging in potentially risky behavior due to a perceived need or pressure (necessity-driven partial-adherence). This could be motivated by a need to maintain the mental health and wellbeing of themselves or others, to continue to work and earn a living, to deal with emergencies or for religious reasons. These participants perceived a critical need to engage in these behaviors and felt that they had no choice in the matter. These pressures are likely to be greater among individuals from BAME communities and those on a low-income, who are less able to work remotely or adhere to social distancing and selfisolation guidance. 7, 9 In order to improve engagement with lockdown measures, it is crucial that financial, tangible and social support is available. What is already known on this topic Current understanding of adherence to social distancing and self-isolation has viewed adherence as a dichotomy, with the majority of research focusing on prediction rather than understanding adherence. Indeed, numerous surveys have identified influences such as age, 13 gender, 13 and ethnicity, 2 perceptions of risk, 14 behavior of others, 15 access to help and support, 3 trust in the government and the e ectiveness of mitigation measures 15, 16 and already having had COVID-19 17 on behavior. However, to date, research has not focused on exploring, in detail, what people are doing, why, and how safe it is. Our research has identified di erent patterns of adherence among BAME individuals and those on low income, each with di erent associated implications and risks. Although previous research depicts an overall lack of adherence to mitigation measures, we highlight that there are at least three patterns of adherence, and di erent forms of intervention will be needed to support individuals to protect themselves, their households and their communities from COVID-19 and the imposed mitigation measures. This may include provision of practical and social support for those who need it. Further research is needed to explore the impact and risks associated with categories of adherence, including the cumulative impact of small episodes of non-adherence at a population level. Although the individual breaking lockdown may consider themselves to be at low risk of the more serious consequences of COVID-19, the aim of the lockdown was to reduce contact between people to reduce the burden of disease overall in the population. Additional research is needed to understand the true impact of risk adapted partial-adherence on transmission of COVID-19. Although every e ort was made to recruit a diverse and representative sample, we acknowledge that our use of social media may have resulted in a biased sample. Much of our recruitment was via COVID-19 support pages, and previous research has shown that use of social media during the pandemic is associated with increased levels of anxiety 18 and misinformation. 19 It is therefore possible that our samples of volunteers are not representative of those who do not use social media for COVID-19 related support or information. Likewise, participants did not necessarily have symptoms of COVID-19, and were therefore discussing breaches of social distancing, rather than self-isolation. Responses may have been di erent among a population who had experienced symptoms of COVID-19. Our study may also have been influenced by response bias. It is possible that participants were unable to accurately recall attitudes and behaviors at the start of the pandemic, or did not feel able to disclose risky or substantial breaches of lockdown to the research team. Although participants in the sample were willing to share examples of partially-adherent behavior, they may not have been willing to share experiences of more risky behavior during the interviews. Finally, interviews were conducted in July 2020. During this period, lockdown measures were being eased, and cases COVID-19 were falling. Alongside changing rules and guidance, knowledge, attitudes and behavior also change rapidly. Attempts to transfer the results of this study to other populations, or periods of lockdown must be made with caution.@story_separate@Although participants reported partially-adherent behavior, this was the result of a complex decision-making process regarding the risks and benefits of engaging in the behavior, often with clear attempts to reduce risk as much as possible. Participants appeared to actively make decisions to engage in behaviors that they considered to be safe and/or necessary, leading to three patterns of adherence. Our findings highlight the need for di erent forms of intervention, as well as additional research into the impact and risks associated with these patterns of adherence. authors reviewed the manuscript, approved the final content and met authorship criteria.","BACKGROUND: Evidence highlights the disproportionate impact of measures that have been introduced to reduce the spread of coronavirus on individuals from Black, Asian and minority ethnic (BAME) communities, and among those on a low income. An understanding of barriers to adherence in these populations is needed. In this qualitative study, we examined the patterns of adherence to mitigation measures and reasons underpinning these behaviors. METHODS: Semi-structured interviews were conducted with 20 participants from BAME and low-income White backgrounds. The topic guide was designed to explore how individuals are adhering to social distancing and self-isolation during the pandemic and to explore the reasons underpinning this behavior. RESULTS: We identified three categories of adherence to lockdown measures: (i) caution-motivated super-adherence (ii) risk-adapted partial-adherence and (iii) necessity-driven partial-adherence. Decisions about adherence considered potential for exposure to the virus, ability to reduce risk through use of protective measures and perceived importance of/need for the behavior. CONCLUSIONS: This research highlights a need for a more nuanced understanding of adherence to lockdown measures. Provision of practical and financial support could reduce the number of people who have to engage in necessity-driven partial-adherence. More evidence is required on population level risks of people adopting risk-adapted partial-adherence."
"The COVID-19 pandemic has posed a global threat affecting people from all backgrounds (1). Healthcare workers (HCWs) inevitably carry a high risk of contracting the disease (2, 3) . Several studies have shown significant disparity in the severity of COVID-19 and outcomes based on ethnicity, among other factors (4-8). Multiple factors including comorbidities and social deprivation have been proposed to contribute to high mortality in Black, Asian and Minority Ethnic (BAME) people (5) (6) (7) (8) . Even after adjusting for inherent differences, people of BAME backgrounds are twice as likely to die from COVID-19 as compared to their white counterparts (9) . This is also seen in HCWs in the UK National Health Service (NHS), where the BAME community makes up 20% of the overall workforce but accounts for two-thirds of COVID-19 related deaths (10). Furthermore, BAME doctors form 44% of NHS doctors, and 94% of the mortality statistics (11) . Population based data from China and Italy has shown that men appear to be at a higher risk of COVID-19 infection (12, 13) . However, studies from HCWs in other countries suggest a higher proportion of females (average 70%) in COVID-19 (14, 15) . This may be due to a higher number of frontline HCWs being female. At least one analysis of HCW who died in the UK showed that 39% of nurses and 94% of doctors were male. In addition, among those who died, 71% of nurses and 94% of doctors were from BAME backgrounds. (11) . Gender differences have been observed in other outbreaks such as Severe Acute Respiratory Syndrome and Middle Eastern Respiratory Syndrome, where significantly higher fatality rates were reported in males (16, 17) . The disproportionately high death rate from COVID-19 in HCWs from BAME background appears to be only partially explained by age, gender, socio-demographic features and underlying health conditions (6, 8) . Thirteen percent of respondents in the NHS Staff survey in 2019 reported discrimination; due to ethnicity (45%), gender (22%) and religion (6%) (18, 19) . The same survey showed 31% staff experienced bullying or harassment at work. A survey conducted by the British Medical Association (BMA) during this pandemic suggested 64% of staff from BAME background felt pressured to work in settings with inadequate personal protective equipment (PPE) as compared to 33% of their white colleagues (20,21). Studies from our group have previously shown that, amongst HCWs, BAME background and adverse workplace measures were predictors of higher risk of 23) . A meta-analysis has confirmed that viral spread is reduced with the use of eye protection, face masks and social distancing (of greater than one metre) in healthcare settings and supports their use in minimising exposure to healthcare staff (24). Various risk assessment frameworks and scores now include ethnicity and gender as variables (25,26,27), however these appear to be mostly based on extrapolation of data obtained from population studies, rather than specific data on HCWs. This study explores the contribution of gender and religious identity in addition to workplace measures, as well as being reprimanded (for asking or wearing PPE) in risk analysis for hospital doctors who have self-reported COVID19.@story_separate@An online survey was designed to explore the hypothesis that hospital doctors had a variable risk of COVID-19, due to differential treatment based on their gender or religion. This would manifest in differential rates of (a) access to PPE, (b) compliance with social distancing (SD) at work and (c) access to employer supported self-isolation (SI) when identified as 'vulnerable' based on Public Health England (PHE) guidance (28,29). Primary outcome was a self-reported diagnosis of COVID-19 confirmed by a positive viral swab test or self-isolation with symptoms of COVID-19 as per PHE guidance where a test was not undertaken. The online survey link was sent to all members of both the organisations and doctors from wider communities in the UK, using email and social media. The survey specified an implied consent to share the data and results with appropriate agencies or organisations involved directly or indirectly in HCWs and COVID-19 pandemic measures. No personal identifiable information was collected. Data was stored at the BAPIO/BIHR office in compliance with UK General Data Protection Regulations. A convenience sample of survey responses was planned to be collected over a fourweek period; similar to previous surveys (22,23). The survey results are reported as cross-tabulation of proportions between the different primary categorical variables (based on gender and religion). Descriptive statistics were used for primary categorical variables. Univariate analysis was conducted between groups of categorical variables using Fisher Exact 2-tailed test (GraphPadPRISM®). Multivariable model was constructed including demographic (age-group and number of household members, ethnicity, gender, religions), clinical setting (teaching, nonteaching or mental health trusts) and exposure to COVID-19 (areas caring for COVID-19 patients, PPE, SD). Non-significant variables from univariate analysis were excluded from final models. Regression analysis was conducted using SPSS v26 software (IBM Inc., USA) and reported as odds ratio (OD), 95% confidence interval (CI) and significant when p-value <0.05 (non-significant values were reported as 'ns'). All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. Workplace measures a) Work in areas -Patients with COVID-19 (suspected or confirmed) are cared for; Patients with Non-COVID-19 only are cared for; Both b) Access to PPE to do the job safely -Strongly agree; Somewhat agree; Neither agree nor disagree ; Somewhat disagree; Strongly disagree c) Able to comply SD at work -All of the times; Most of the times; Some of the times; A few of the times; None of the times d) Able to negotiate changes in work -Work from home; Work in low COVID-19 risk areas; Virtual consultations; None allowed by employer; Other; Not applicable e) Reprimanded from wearing or asking PPE -Always; Usually; Sometimes; Rarely; Never f) Redeployed to an area that cares for -COVID-19 patients (Suspected or confirmed); Non-COVID-19 patients; Both of the above; None of the above (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The survey received 1206 responses between 26 April and 29 May 2020. Table 2 shows the characteristics of the respondents and Table 3 summarises the status of workplace measures reported by the respondents. Majority (65.6%) were working in a teaching hospital setting, 38.8% were over 50 years of age, 70.9% were male, 93.7% were from BAME background and their religious identities were Hindu (44.5%), Muslim (32.1%) or Christian (10.4%). About a quarter identified themselves as 'vulnerable' according to PHE defined criteria. Age distribution of the respondents is shown in Figure 1 . COVID-19 diagnosis was confirmed in 104 (8.6%) and, 213 (17.7%) were in self-isolation due to symptoms compatible with COVID-19 (suspected COVID-19) as shown in Figure 2 . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 19, 2020. Figures 3 and 4) . All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. Our analysis showed no gender differences in accessing to PPE, ability to comply with SD, redeployment or working in high risk areas (Table 3) . A higher proportion of female respondents reported confirmed or suspected COVID-19 (30% versus 25%; p =0.04). Male respondents had a higher proportion of confirmed cases (9.6% versus 6.3%, p =0.07). The majority of respondents identified themselves as Christians (n=125, 10.4 %), Muslim (n=387, 32.1%) or Hindu (n=537, 44.5%). The remaining respondents (n = 157, 13%) who identified themselves as Sikh, Jewish, Buddhist, or with no religion (see Table 3 ) were in small numbers and thus were excluded from analysis. Amongst Christians, 95 were from BAME background, whilst 30 were white.  Univariate analysis: All variables related to workplace measures (except re-deployment) were significantly associated with higher risk of COVID-19 (Table 4 ). There was a higher self-reported COVID-19 in respondents below the age of 50 years. Other variables; such as number of household members, ethnicity or vulnerability were not significant (Table 4) . Model I: This model included Hindu and Muslim respondents only, thus excluding 282 respondents (125 Christians and 157 'others' and with 'no religious' identity). In this model, none of the demographic variables were significant predictors of COVID-19. Out of the six variables determining occupational risk, inadequate PPE was an independent predictor for COVID-19 (OR 2.22 (95% CI 1.31 -3.76, p = 0.003). Model II: This model compared Hindu (547), Muslim (387) and Christian-BAME respondents (95) (excluding 30 white respondents) ( Table 5 ). In this model, none of the demographic variables were found to be significant predictors of COVID-19. Inadequate PPE remained the only independent predictor for self-reported COVID-19 (OR 2.29 (95% CI 1.22-4.33, p =0.01)). All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 19, 2020. Discussion COVID-19 pandemic continues to be a major public health challenge. As far as we are aware, that this is the first survey that has studied gender and religion in the context of hospital doctors and risks of self-reported COVID-19. Hospital doctors are at an increased risk due to a higher exposure while caring for COVID-19 patients but also due to inconsistent access to appropriate PPE and compliance to SD at work (22, 23, 24) . This is in addition to any applicable population-based risk factors (such as age, gender and comorbidities (4-9,12,24). Many researchers have suggested risk assessment frameworks to minimise harm to those at highest risk (25,26) but these appear to be based on models of clinical risks and extrapolation of general population data. More recently, there has been a suggestion to include occupational factors in such a framework (27). We have previously reported data on HCWs including hospital doctors from the UK, demonstrating workplace measures and ethnicity were independent predictors of COVID-19 (22,23). The current study further explores additional characteristics such as gender and religion as risk factors COVID-19. We found that women were more likely to report a diagnosis of COVID-19 but this was not found to be significant on multivariate analysis. Our study population included a higher proportion of women under 40 years of age (32% versus 17%), who were more likely to report a diagnosis of COVID-19. This may be representative of the demographics of the NHS frontline workforce (18, 19) . We found that gender and age were not independent predictors of COVID-19 in our study, in multivariate analysis. There is an excess risk of intensive care admissions and mortality from COVID-19 in men and those above 70 years (4). Some NHS trusts have already started risk stratification and are selectively redeploying BAME staff above 55 years, away from high risk areas (30,31). All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 19, 2020. . https://doi.org/10.1101/2020.06. 15.20125450 doi: medRxiv preprint This survey was open to all hospital doctors in the UK, however most responses received are likely from members of the two organisations representing doctors from Indian sub-continent heritage. Hence, it is not surprising that a significant majority of our respondents were from a BAME background and from three major religions practiced in the Indian sub-continent. Religious identity was not found to be statistically significant in determining risk, when adjusted for other factors in the multivariable analysis (Table 5) . Compliance with social distancing remains a challenge. Almost 2/3 rd of hospital doctors reported not being able to comply with social distancing and this was associated with increased risk of COVID-19. In the home, overcrowding and multigenerational households are also factors linked to higher exposure and hence increased risk to people from BAME background. Our survey in hospital doctors did not support this hypothesis. Data presented in the paper using a cut-off of five household numbers, but it was not significant even when analysing for a threshold of 2 and 3 (similar to average household numbers in UK (32). This could be because the socio-economic backgrounds of BAME hospital doctors are not comparable to the general population. PPE is known to be one of the key measures ensuring safety of staff from occupational risk of COVID-19. There has been continued debate in the profession regarding the supply and timely delivery of appropriate PPE. We, and others have previously reported that many healthcare workers were not getting access to PPE as per PHE or WHO recommendations. [ref] In this survey, 61% hospital doctors reported appropriate access to PPE which is an improvement from 22% demonstrated previously (22,23). However, after adjusting for confounding variables, inadequate PPE remained an independent predictor with two-fold increased risk of COVID-19, in this cohort. Lack of PPE may be associated with a degree of anxiety and stress for staff, in high risk clinical settings. In a previous survey by BMA, 64% of BAME staff felt pressured to work in settings with inadequate PPE (20). We found almost 30% hospital doctors reported being reprimanded for requesting PPE or risk avoidance measures (such as social distancing or redeployment in lower risk areas) and this was more commonly reported by Muslims. It would not be surprising that doctors facing discrimination are unlikely to raise concerns about inadequate workplace measures. The 2019 NHS staff survey and data from workforce race relations standards 2019 report (WRES) (18, 19) indicates that overall 13% staff reported discrimination and another 31% reported facing bullying and undermining behaviour. The proportions were higher for BAME staff. Ethnicity was reported as the most common reason (eight times higher compared to the religious identity). Our survey cohort is not directly comparable with the NHS staff survey as all our respondents were doctors and majority were male and BAME background, compared to 7.9% doctors 76% female and 20-40% from a BAME background). The fact that one-third of hospital doctors' reported being reprimanded is deeply concerning. If hospital doctors (who have a more favourable educational and socioeconomic background) report facing this degree of discrimination, it is likely that the experience may indeed be worse in other HCWs, more so from BAME backgrounds. This needs to be addressed by NHS organisations and staff support groups. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 19, 2020. . https://doi.org/10.1101/2020.06. 15.20125450 doi: medRxiv preprint This study has a few limitations. A key comparator to workplace measures would have been between Caucasians and black ethnic respondents which had lower representation in our survey. General limitations to online surveys are also applicable to our survey.@story_separate@This survey contributes to the growing evidence of risk factors for COVID-19 amongst BAME doctors. Although the NHS has introduced risk assessment frameworks, these are based on demographics, and the scored on individual characteristics but not occupational or organisational influences. Access to PPE, although improved compared to results from April, still remains prevalent and inadequate access resulted in doubled the risk of COVID-19 for hospital doctors. Inability to comply with SD at work poses a similar challenge. Gender and religion did not contribute to additional risk, after adjusting to other variables in this study. The unfortunate culture in the NHS, of being reprimanded or experiencing bullying and undermining contributes to an unsafe workplace for staff and where mistakes are more likely to lead to harm for patients. Hence, the focus needs to be on developing a culture of openness where the concerns can be raised safely and appropriate measures are taken to mitigate risks for staff and patients alike. All rights reserved. No reuse allowed without permission. (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 19, 2020. . https://doi.org/10.1101/2020.06.15.20125450 doi: medRxiv preprint","The novel coronavirus pandemic is posing significant challenges to healthcare workers (HCWs) in adjusting to redeployed clinical settings and enhanced risk to their own health. Studies suggest a variable impact of COVID-19 based on factors such as age, gender, comorbidities and ethnicity. Workplace measures such as personal protective equipment (PPE), social distancing (SD) and avoidance of exposure for the vulnerable, mitigate this risk. This online questionnaire-based study explored the impact of gender and religion in addition to workplace measures associated with risk of COVID-19 in hospital doctors in acute and mental health institutions in the UK. The survey had 1206 responses, majority (94%) from BAME backgrounds. A quarter of the respondents had either confirmed or suspected COVID-19, a similar proportion reported inadequate PPE and 2/3 could not comply with SD. One third reported being reprimanded in relation to PPE or avoidance of risk. In univariate analysis, age over 50 years, being female, Muslim and inability to avoid exposure in the workplace was associated with risk of COVID-19. On multivariate analysis, inadequate PPE remained an independent predictor with a twofold (OR 2.29, (CI - 1.22-4.33), p=0.01) risk of COVID-19. This study demonstrates that PPE, SD and workplace measures to mitigate risk remain important for reducing risk of COVID-19 in hospital doctors. Gender and religion did not appear to be independent determinants. It is imperative that employers consolidate risk reduction measures and foster a culture of safety to encourage employees to voice any safety concerns."
"Apart from being a world-changing calamity, the present novel coronavirus pandemic is an intellectual challenge for biologists, statisticians and applied mathematicians. Modelling efforts that purport to predict the course of the pandemic and the effect of public health policies, usually take the form of substantial individual-based models and are implemented in code taking thousands of lines. Their predictive ability is disputed but it is doubtless that they do not help us to understand the pandemic. We suggest exactly the opposite: we formulate essentially a two-equation model of one aspect of the pandemic, and claim that it can very simply explain the following puzzling phenomenon: in many countries the rate of appearance of new cases is linear. As an example, we present the data for Sweden in Figure 1 [1]. In fact, Sweden is a good case to work with as there are no complications to do with lock-down; similar graphs can be created, from example, from the data for the state of Georgia [2], among many others. The modelling of an epidemic on the population level usually divides it in cohorts such as Susceptible, Infective and Recovered (a so-called SIR model), plus possibly some further sub-populations (e.g. Asymptomatic or Exposed (SEIR models)) [3] . The evolution of these cohorts is then modelled using rate equations that include the probability that the disease is transmitted through random contacts between them, amongst other events. In doing this, time is considered as a continuous variable. However, in order to understand the linear growth phenomenon mentioned above, we believe that it is essential to include the public response to the data that are usually made available on a daily basis. Indeed, we would argue that capturing the response of the population to the information stream is essential if the model is to be of use in truly understanding the pandemic. Therefore, in our approach we will consider time as a discrete variable measured in days, and develop a model for the discrete evolution of the number of infectives from day-to-day. Although unusual, this approach has been successfully used elsewhere in epidemiology; for a recent example, please see [4] II. MODELS We derive, in its simplest and most illuminating form, a system of two difference equations for the rate of growth of new positive test results and the number of people that have been exposed to the virus; that is, we neglect the asymptomatics. The time variable n that we use is measured in days. We denote the average latent period (here and below we use epidemiological data from [5, 6] ) by L; it is about a week. It is known (again, see [5, 6] ) that individuals start shedding virus and so are infective very soon (1-2 days) after exposure and about 4-5 days before the appearance of symptoms. Once the simplest model is derived, we consider the case with asymptomatics, which does not offer any substantial new illumination, but is more realistic.@story_separate@Let us call the number of positive tests on day n, T (n). Then, not taking into account false positives and negatives, but not assuming that every person showing active symptoms is tested, (1) Here J(n) are people who have shown COVID-19 symptoms on day n, and qJ(n) is the fraction of those who have been tested on that day, and D s (n) are the positively testing members of the public who show no symptoms (perhaps yet). The subscript s is to indicate that this is only from a sample. Now, if the rate of testing is p, D s (n) = pD(n), where now D(n) is the population numbers of people who have virus by PCR but do not show symptoms yet. Let us denote by E(n) people who got exposed on day n. In a model without asymptomatics, Here L is the latent period and for simplicity we have assumed that people become infectious immediately after exposure. Now we need to model the dynamics of E(n). (A1) Since the numbers of infectives are very small compared to the number of susceptibles S(n), we assume that the number of susceptibles is roughly constant and that S(n)/N ≈ 1, N being the total population size. (A2) We assume that the number of infectives available for infecting the rest of the population on day n is approximately D(n) as p is small (of the order of 2 · 10 −4 in the UK). Thus, we assume that the 2 . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 22, 2020. . moment a person shows symptoms of the disease, she is removed from circulation by hospitalisation or quarantine. That is, we are making an assumption of perfect isolation. It follows from the reasoning above that people who are exposed at time n, E(n), are determined from the following simple equation: where the other arguments of f will be discussed later. (A3) We assume that f (·, (D(n)) can be written as f (·, D(n)) = cg(·)h((D(n)). The constant c which Hethcote and van den Driessche [7] call ""constant contact rate"" in our view should only incorporate the probability that an encounter between a susceptible and an infective leads to disease. So presumably wearing face masks or other personal protection measures will be expected to reduce c. We take h(D(n)) to be a monotone increasing bounded function with the properties that h(0) = 0. e.g. a function of Michaelis-Menten type; see [7] for other examples. (A4) We assume that the function g expresses the information stream of the population, that is, it is the translation of the information that people have into behavioural strategies governing the contact rates of the population (the same function governs also the contact rates between two susceptibles as there is no sure-fire way to determine in a contact between people not showing symptoms who is infected and who is not). (A5) We assume that the information stream is dominated by the rate of increase of the numbers of new positive tests. It would be interesting to investigate models in which g is a function of more than the last day's data, or of undominated maxima in the number of new cases, but we assume here for simplicity that R(n) is a reasonable proxy for the information stream. In other words, we assume that g(·) is a function of R(n). Common sense suggests that it is a monotone decreasing function defined on R + . A possibility is g(z) = A 1 + Bz r , r ≥ 1. ( Then g(0) = A can be interpreted in terms of the norms of sociability in a population. The logic is that if the public is aware of high rate of increase in new cases, it becomes more risk-averse. Note that the information stream is in terms of what is publicly known. Thus the dynamics of the exposed cohort is governed by E(n + 1) = cg(R(n))h(D(n)). What we have to say about COVID-19 is then summarised in one sentence: If the information stream is based on the number of new cases (for which R(n) is a proxy) and quarantining/hospitalisation of symptomatic cases is perfect, linear increase in the number of positive tests is to be expected. This is obvious. Clearly from (1), at a fixed point (R * , E * ) and cg(R * )h(LE * ) = E * which apart from the fixed point (R * , E * ) = (0, 0), in which disease is stopped, may admit a unique non-trivial fixed point, the E-component of which solves 3 . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted June 22, 2020. . (If such a fixed point does not exist, the epidemic disappears.) If this fixed point is stable, the number of positive tests necessarily grows linearly and from that rate of growth, the number of newly exposed people can be estimated. Note that the value of this equilibrium rate is an increasing function of c and also of L since the function g is monotone decreasing. Under reasonable assumptions on g and h (for example, h being of Michaelis-Menten type and g as in (2)) it is easily seen for (4) that E * is a decreasing function of both p and of q, since the right-hand side of (4) is monotone increasing and g is monotone decreasing. Under these assumptions on h and g, the equilibrium number of positive tests will grow (sublinearly) with p and q as is to be expected. A similar analysis with the same conclusions, can be performed in the case when the information stream is a weighted averageR(n, M ) of the rates from a number M of days, i.e. ifR(n, M ) = w k = 1; the value of the steady rate is independent on M or the weights w k , but these of course influence the stability of the fixed point. This model does not add much to our understanding from the previous model, and the purpose of this subsection is simply to show that it subtracts nothing either. We need to introduce three new parameters: α and β, and K. α and β are both in (0, 1). α measures the proportion of exposures leading to an asymptomatic state (realistically this seems to be about 0.4 − 0.5) and β measures how infectious is an asymptomatic individual relative to an infected one. K > L is the average duration of an asymptomatic disease. We need just to modify both (1) and (3) as now the testing also finds some of the asymptomatics who are beyond the latent period. Now J(n) = (1 − α)E(n − L). E(n + 1) = cg(R(n))h(I ef f (n)), where the number of people available for effective infection on day n is The argument from now is as before. For example, if indeed α ≈ 0.5 and as in the UK, q ≈ 0.2, with R * in the UK being approximately 2000, we have that E * ≈ 20000, i.e. the number of people exposed to the virus each day is about 10 times the number of new cases.@story_separate@We found the linear growth rate of the number of COVID-19 positive tests puzzling and have provided a simple framework in which such a dynamic can be expected. In other words, our elementary analysis is in the framework of Peircian abduction, for a good review of which see Psillos [8] . The linear rate is ""democratically"" determined by the behaviour of the individuals as well as by the rate of testing. We also presented reasons why our assumptions are sensible. We hope the present work is a contribution to the effort to ""come to grips"" with the pandemic, albeit in a very rough-and-ready and partial fashion; this 4 . CC-BY 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted June 22, 2020. . rough and ready way still allows us, if we have access to additional information, such as that available for the UK from the KCL and ZOE site [9] to estimate the number of asymptomatics, exposed, and effective spreaders. As a last remark note in the proposed model, government strategy, expressed in the parameters p and q that determine the published numbers of new cases, directly influences individual behaviour, a feedback loop that does not seem to have been sufficiently discussed. This feedback has to be understood thoroughly in order to craft more effective public health policy.","We present an elementary model of COVID-19 propagation that makes explicit the connection between testing strategies and rates of transmission and the linear growth in new cases observed in many parts of the world. An essential feature of the model is that it captures the population-level response to the infection statistics information provided by governments and other organisations. The conclusions from this model have important implications regarding benefits of wide-spread testing for the presence of the virus, something that deserves greater attention."
"With the rapid development of the protein sequencing techniques, the number of protein sequences is growing rapidly. In contrast, the number of protein structures is growing slowly, for examples, by March 2020, there are 561 911 proteins in the UniProtKB/Swiss-Prot database [1] , although there are only 162 043 determined structures deposited in Protein Data Bank (PDB) [2] . The computational techniques are keys to reduce the gap between the protein sequences and their structures and Inspired by the information retrieval task in natural language processing, the ranking methods are based on the techniques derived from the information retrieval field. The test proteins (query proteins) search against the training proteins (template proteins), and the template proteins are sorted according to their similarities with the query proteins. The query proteins are considered to be in the same fold as their corresponding top hits of the template proteins. The ranking methods are different in the measurements of the protein pairwise similarities [8] . The profile-based alignment methods [9, 10] and HMM-based alignment methods [11, 12] are widely used approaches for calculating the pairwise similarities. However, these methods failed to detect the meaningful hits of the template proteins when the sequence similarity is low. The classification-based methods consider the protein fold recognition task as a multiple class classification problem. These methods are different in feature extraction methods [13] and machine learning classifiers [14] . The protein pairwise similarities calculated by the alignment approaches are widely used features as well [15] . Because the profile-based features generated by the PSI-BLAST contain the evolutionary information, they are used as discriminative features for protein fold recognition [16, 17] . Ding and Dubchak propose a computational predictor based on Support Vector Machines (SVMs) and Neural Networks for protein fold recognition [18] . Polat and Dokur introduce a method based on a new neural network called Grow-and-Learn network [19] . In order to merge the different features, the multiview modeling is employed for protein fold recognition [20] , where different features are treated as different views of proteins. Recently, the deep learning techniques have been applied to this field. For these methods, the deep learning models are trained with a more comprehensive database to learn the foldspecific features, and these features are then incorporated into traditional classifiers, such as SVMs and Random Forest (RF), to evaluate the performance on smaller independent datasets [14, [21] [22] [23] . The meta-methods combine the ranking methods and the classification-based methods, for examples, TA-fold [24] ensembles a classification-based method SVM-fold and the ranking method HHsearch. Its assumption is that if the HHsearch cannot detect the hits of template proteins with high confidence, the prediction results of SVM-fold are used as the final results. This framework is also employed by some later methods for protein fold recognition [17] or related tasks [25] . They are different in the ranking methods, classification-based methods and their combinations [17] . All these aforementioned methods contribute to the computational investigation of protein fold recognition task. However, these methods are only based on the pairwise similarity between two proteins or the similarities between proteins in two different protein folds. In fact, as shown in the SCOPe database [26] , the homology relationship of proteins is in a hierarchical structure, and therefore, in order to recognize the fold of a test protein, its global interactions with other proteins should be considered as well. In this regard, several methods attempt to incorporate the multiple protein interrelations into the prediction by considering the relationship between the test proteins and training proteins, for examples, Fold-LTR-TCP [27] employs the triadic closure principle (TCP) to re-rank the ranking lists based on the protein similarity network, and generates more accurate rank lists. CMsearch [28] is based on cross-modal learning, which constructs two networks to represent the sequence space and structure space. ENTS [29] is an algorithmic framework to improve the large scale similarity search performance. All these three predictors achieve the state-of-the-art performance based on the protein similarity networks. However, there are still some errors in their predictive results. For examples, for Fold-LTR-TCP predictor, some test proteins in different folds are predicted to be the same fold, and some test proteins in the same fold are predicted as from different folds. CMsearch and ENTS also incorrectly recognize the folds of some proteins. These approaches only consider the relationship between the training proteins and test proteins to construct the protein similarity network, and ignore the relationship among the test proteins, and the relationship among the training proteins. In order to overcome the disadvantages of the exiting methods, we are to propose a novel predictor called FoldRec-C2C for protein fold recognition by using three re-ranking models to incorporate the interactions among proteins into the perdition framework based on protein similarity network. Proteins in the same clusters share similar characteristics, and tend to be in the same protein fold. In this regard, FoldRec-C2C employs the seq-to-seq model, seq-to-cluster model and cluster-to-cluster model to measure the relationship between the test proteins and the training proteins, the relationship among the training proteins and the relationship among the test proteins, respectively. FoldRec-C2C is the first predictor to incorporate these three kinds of relationships into one framework for protein fold recognition so as to reduce the prediction errors.@story_separate@The LINDAHL dataset constructed by Lindahl and Elohoosn [30] is a widely used and rigorous benchmark dataset to evaluate different computational predictors [20, 21, 30] . Therefore, this dataset is employed in this study to facilitate the fair performance comparison among various methods. There are 976 proteins in this dataset, and 38 folds with multiple proteins are used as the targets. The proteins in this dataset are split into two subsets with roughly equal number of proteins. In order to rigorously simulate the protein fold recognition, proteins from different subsets are in different superfamilies and families. The 2-fold cross-validation is employed to evaluate the performance of the predictor based on these two subsets. Most of the existing methods treat the protein fold recognition as a classification task or a ranking task. These methods detect the fold of a query protein mainly based on the protein pairwise similarities. In contrast, the CMSearch [28] , ENTS [29] and Fold-LTR-TCP [27] are based on protein similarity network. As a result, these methods can consider the relationships among proteins in the dataset, and accurately recognize the protein folds. Inspired by this method, in this study, we propose the FoldRec-C2C predictor to recognize the fold of the query protein by considering three kinds of relationships among proteins of the benchmark dataset based on the protein similarity network, including the relationship between the test proteins and the training proteins, the relationship among the test proteins and the relationship among the training proteins. The flowchart of FoldRec-C2C is shown in Figure 1 . In order to measure these three kinds of relationships, we use three re-ranking models, including seq-to-seq model (S2S), seq-tocluster model (S2C) and cluster-to-cluster model (C2C). FoldRec-C2C only requires the protein sequences in FASTA format as inputs. The Learning to Rank (LTR) model is a supervised ranking algorithm, including a training phase and a prediction phase. The LTR is trained with the training set to rank the test proteins against the training proteins. For more information of the LTR for protein search, please refer to [31] . The ranking results of the LTR are then fed into the S2C model to generate the seq-to-cluster ranking list for the following processes. The relationship between the test proteins and the training proteins is measured by the seq-to-seq model based on a similar approach introduced in [27] , and then the relationship among the training proteins is considered by the seq-to-cluster model. Finally, the relationship among the test proteins is incorporated into the predictor by the cluster-to-cluster model. The relationship among these three re-ranking models is shown in Figure 2 . The seq-to-seq model is one of the most widely used ranking methods for measuring the pairwise similarity between a query protein in the test set and a template protein in the training set. In this study we employed a recent proposed seq-to-seq model based on the supervised LTR [27] . As discussed in previous study, discriminative features are important for constructing the computational predictors [32] . Following [27] , the LTR was constructed based on various features (HHSearch [11, 12] , DeepFR [21] , Top-n-gram [33] and 84 features [15] ) to measure the protein pairwise similarity. The software tools and its parameters are given in Supplementary Tables S1 and S2. For more detailed information of this method, please refer to [27] . Although the seq-to-seq model can achieve good performance, it is suffering from two errors: (i) some test proteins in different folds are predicted as in the same fold; (ii) some test proteins in the same fold are predicted as from different folds. The reason is that the seq-to-seq model ignores the relationship among test proteins, and the relationship among the training proteins. In this regard, the seq-to-cluster model and the cluster-to-cluster model are proposed. In this section we will first introduce the seq-to-cluster model. Can we correct these two kinds of errors with the help of the correct predictions in their corresponding clusters by considering the relationship among the test proteins and the relationship among the training proteins? To answer this question, the seq-to-cluster model is proposed, which will be introduced in Figure 2 . The relationship among the three re-ranking algorithms, including seq-to-seq, seq-to-cluster and cluster-to-cluster models. followings. where m represents the number of test proteins, n represents the number of training proteins, s i,j is the similarity between test protein i and training protein j. SS can also be represented as: where, S T i is the row vector of the matrixS. SSN is the normalized matrix of SS, which can be calculated by:  where, sn i,j can be calculated by: infinite norm of S T i , respectively. Normalization of the ranking results is critical for recalculating the scores of clusters in the training samples [34] . This normalization method (cf. Eq. 4) is better than other methods for protein fold recognition, such as Min-Max [35] . The training proteins belong to the same fold are clustered into one group. The similarity c i,f between the test protein i and the training cluster f can be calculated by: where k is the total number of training proteins in the training cluster f , the ln 2 sn i,j +1 is the KL divergence derived from [36] . The sequence and cluster similarity matrix SC can be represented as: FoldRec-C2C Figure 3 . The pseudo codes of seq-to-seq model, seq-to-cluster model and cluster-to-cluster model. As discussed above, the seq-to-cluster model is able to solve the first error. Here, we propose the cluster-to-cluster model to overcome the second error by considering the relationship among the test proteins. Its assumption is that the test proteins in the same cluster tend to be in the same fold. If some test proteins in the cluster are correctly predicted, the other proteins in this cluster will be assigned as the same fold. In order to consider the relationship among the test proteins, the similarity network of all the test proteins is constructed based on the HHblits [12] with default parameters. This network can be treated as a weighted digraph, where the test proteins can be viewed as the vertices, and weighted edges reflect the similarity between two test proteins, whose values are the Prob values in the range of (1, 100) generated by HHblits. Because the similarities of some protein pairwise are too low to be detected by HHblits, the test protein similarity network is a disconnected digraph. In order to apply the clustering methods, it should be converted into a complete graph. The disconnected digraph of the test proteins can be represented as: where h i,j represents the similarity of protein i and protein j calculated by HHblits. H is then converted into a complete graph G: where g i,j is the similarity of protein i and protein j, calculated by: In this study, we employ the spectral clustering [37] as the clustering method to divide the test proteins into different groups. The matrix G is an adjacency matrix, based on which the eigenvectorx and the eigenvalue λ can be calculated by [37] : where L is a Laplacians matrix [38] , which can be calculated by [37] : where D is a diagonal matrix representing the degree of each vertex in G, which can be calculated by [37] : Based on the eigenvectorx and the eigenvalueλ, the eigen matrix is constructed to cluster the test proteins [39] . The similarity matrix SC between test proteins and training clusters is normalized by Eq. 4. As a result, the normalized matrix SCN is represented as:  where cn i,f represents the similarity between the test protein i and the training cluster f . SCN can also be represented as: where SCN T i is the row vector of the matrixSCN. The spectral clustering is then performed on the SCN to group the test proteins into d clusters. Given a test cluster l with p test proteins, the candidate set Q of cluster l can be generated by: where q i represents the highest similarity of ith test protein in the test cluster l, which can be calculated as follows: The similarity between the test cluster l and the training cluster f can be calculated by: Finally, the similarity matrix CC generated by the cluster-tocluster model is represented as:  The fold type of the test proteins in the test cluster l is predicted as the fold type of the training cluster sharing the highest similarity with cluster l. The pseudo codes of seq-to-seq model, seq-to-cluster model and cluster-to-cluster model are shown in Figure 3 . The source code and data of FoldRec-C2C can be downloaded from http:// bliulab.net/FoldRec-C2C/download. The test proteins in a test cluster are considered to be in the same fold as the training cluster with the highest similarity score calculated by Eq. 17. The accuracy is the ratio of the number of correctly predicted proteins (CN) to the number of all predicted proteins (N) [16] : Furthermore, the specificity-sensitivity curves [21, 30] of various methods are plotted to more comprehensively evaluate the performance of different predictors. The Performance of three re-ranking algorithms for protein fold recognition In this study, three re-ranking algorithms are incorporated into the in the proposed FoldRec-C2C predictor, including seq-toseq model, seq-to-cluster model and cluster-to-cluster model. Among these three methods, the seq-to-cluster model improves the seq-to-seq model by considering the relationship among the training proteins, and the cluster-to-cluster model further improves the seq-to-cluster model by considering the relationship among the test proteins. Table 1 lists the performance of three FoldRec-C2C predictors based on the three re-ranking algorithms. From this table we can see the following: (i) among the three methods, the FoldRec-C2C predictor based on the seqto-cluster model outperforms the FoldRec-C2C predictor based on the seq-to-seq model, indicating that the first error (some test proteins in different folds are predicted as in the same fold) can be fixed by considering the relationship among the training proteins; (ii) The FoldRec-C2C predictor based on the cluster-tocluster model achieves the best performance among the three predictors, indicating that considering the relationship between the test proteins and training proteins, the relationship among training proteins, and the relationship among test proteins is able to overcome not only the first error, but also the second error (some test proteins in the same fold are predicted as from different folds). Therefore, we conclude that the cluster-to-cluster model is suitable for protein fold recognition. The clustering method is one of the core steps in FoldRec-C2C, which clusters the test proteins into different groups, and proteins in the same cluster tend to have similar protein fold. For the test proteins, their protein similarity network was constructed based on the pairwise similarities between two test proteins detected by HHblits. The protein similarity network is a weighted undirect graph representing the relationship among test proteins, where the vertices represent proteins and the weighted edges represent the similarity between two vertices. Based on the undirect graph, the clustering methods divide the test proteins into different clusters. Spectral clustering method [37] and affinity propagation method [40] are two state-of-theart graph-based clustering methods. The aim of both spectral clustering and affinity propagation is to find the best cuts to divide the graph into multiple subgraphs. The affinity propagation finds the high weighted edges in an iteration manner. If two vertices are connected by an edge with positive weight, they are considered to be in the same cluster, otherwise, they are in different clusters. The spectral clustering constructs a Laplacians matrix, based on which the eigen matrix can be obtained by calculating the eigenvalues and eigenvectors, and then the clusters are generated based on the eigen matrix. The results of the two FoldRec-C2C predictors based on these two clustering methods are shown in Table 2 , from which we can see that both the two clustering methods achieve high performance, and the spectral clustering method is better than the affinity propagation method for clustering the test proteins. These results indicate that the graph-based clustering methods are accurate strategies for clustering the test proteins for protein fold recognition. In the protein fold recognition field, 34 state-of-the-art computational methods are compared with the proposed FoldRec-C2C, including PSI-BLAST [9] , HMMER [41] , SAM-T98 [42] , BLASTLINK [30] , SSEARCH [43] , SSHMM [43] , THREADER [44] , FUGUE [45] , RAPTOR [46] , SPARKS [47] , SP3 [48] , FOLDpro [49] , HHpred [50] , SP4 [51] , SP5 [52] , BoostThreader [53] , SPARKS-X [54] , FFAS-3D [55] , RF-Fold [15] , DN-Fold [56] , RFDN-Fold [56] , DN-FoldS [56] , DN-FoldR [56] , HH-fold [24] , TA-fold [24] , dRHP-PseRA [10] , MT-fold [20] , DeepFR (strategy1) [21] , DeepFR (strategy2) [21] , DeepFRpro (strategy1) [21] , DeepFRpro (strategy2) [21] , DeepSVMfold [22] , MotifCNN-fold [57] and Fold-LTR-TCP [27] . Among these 35 methods, the Fold-LTR-TCP and FoldRec-C2C are based on the protein similarity network, especially the FoldRec-C2C predictor is able to measure the relationship between the test proteins and the training proteins, the relationship among the training proteins, and the relationship among the test proteins. Table 3 shows the accuracies of the 35 different methods. We can see the followings: (i) the methods based on the features derived from deep learning techniques (DeepFRpro, MotifCNN-fold and DeepSVM-fold) are better than the those based on the rule-based features; (ii) Fold-LTR-TCP improves the predictive performance by considering the protein similarity network describing the relationship between the test proteins and the training proteins, and re-ranks the results by TCP; (iii) similar as Fold-LTR-TCP, the proposed FoldRec-C2C is also based on the protein similarity network, but this network is more comprehensive, which not only describes the relationship between the test proteins and the training proteins, but also contains the relationship among the test proteins, and the relationship among the training proteins. Furthermore, FoldRec-C2C is able to correct the errors of Fold-LTR-TCP by using the proposed cluster-to-cluster model. The specificity-sensitivity curves [21, 30] of various methods are also plotted to more comprehensively evaluate their performance, and the results are shown in Figure 4 , from which we can see that the three FoldRec-C2C predictors obviously outperform the other competing methods. In order to further explore the reasons why the proposed FoldRec-C2C predictor can correct the two errors discussed in section 'Seq-to-cluster model', the final predictive results of the test proteins in the LINDAHL dataset are visualized in Figure 5 (a), where the test proteins and training proteins are shown as blue points and green points, respectively. The test proteins in the same cluster are connected by blue lines, and the test proteins in different clusters are connected by black lines, meaning that although their similarities can be detected by HHblits, they are not in the same cluster based on the results of spectral clustering method. If two clusters are connected by the red line, all the proteins in these two clusters are in the same protein fold. Two examples were selected to show how the proposed cluster-to-cluster model solves the aforementioned two errors. One example is the prediction of the test proteins in fold 2_1 (SCOP ID). This protein fold contains 19 proteins and 10 proteins in the test and training set, respectively. Figure 5(b) shows the predictive results of the FoldRec-C2C based on S2S, where the gray lines indicate the similarity scores between any test protein and training protein calculated by the S2S, and the predictive results are shown in red lines. Figure 5(c) shows the results of FoldRec-C2C based on S2C, where the similarity scores between any test protein and cluster in training set calculated by the S2C are shown in gray lines, and the predictive results are shown in red lines. Figure 5(d) shows the results of FoldRec-C2C based on C2C, where the read lines represent the similairty scores between the cluster in the test set and the cluster in the training set, which can be considered as the final predictive results of FoldRec-C2C. From Figure 5(b-d) we can see the followings: (i) S2C is more accurate than S2S, and C2C is the most accurate model which can correctly identify all the test proteins in the fold 2_1; (ii) although the test proteins in the fold 2_1 were clustered into two clusters by spectral clustering method, both the two clusters are correctly connected to the cluster of fold 2_1 in the training set, indicating that even the spectral clustering method fails to correctly cluster all the test proteins, the C2C model is able to correct this error. Another example is the prediction of the test proteins in fold 4_50 (see Figure 5(e-g) ). This protein fold contains six proteins and one protein in the test and training set, respectively. From it we can see the followings: (i) the S2S model incorrectly detects the test proteins in fold 4_50; ii) the S2C model correctly predicts some of these proteins by considering the relationship among training proteins, but it still fails to predict some proteins; (iii) The C2C model correctly predicts all these proteins in the fold 4_50 by considering both the relationship among test proteins, and the relationship among training proteins. These two examples show that the proposed FoldRec-C2C predictor based on C2C can correct the errors caused by the S2S model. The reason is that the false positives and negatives predicted by S2S are corrected by the correctly predicted proteins in the same cluster detected by the S2C and C2C. Therefore, FoldRec-C2C outperforms the other existing methods. • Protein fold recognition is critical for protein structure and function prediction, and the computational methods are playing important roles in this field. • In this study, the FoldRec-C2C predictor is proposed for protein fold recognition, which is based on the cluster-to-cluster model. FoldRec-C2C considers the relationship among the test proteins, the relationship among training proteins, and the interactions between test proteins and training proteins. • Experimental results on a widely used and rigorous benchmark dataset show that FoldRec-C2C outperforms other 34 state-of-the-art predictors. • The source code and data of FoldRec-C2C can be downloaded from http://bliulab.net/FoldRec-C2C/do wnload.@story_separate@As a key technique to predict the protein structures, protein fold recognition is attracting more and more attentions. Therefore, we proposed the FoldRec-C2C predictor based on the protein similarity network for protein fold recognition. To consider a global interactions among the proteins in this network, three re-ranking algorithms are used to model three kinds of relationships in the protein similarity network. The seq-to-seq model measures the relationship between the test proteins and the training proteins, based on which the seq-to-cluster model improves the seq-to-seq model by considering the relationship among training proteins as well. The cluster-to-cluster model is proposed to further incorporate the relationship among the test proteins. Future study will focus on constructing more accurate protein similarity network to reflect the fold level relationship among proteins, and exploring more accurate re-ranking algorithms to take the advantages of the global interactions among proteins. Because the cluster-to-cluster model is a general algorithm, it would have other potential applications in bioinformatics, such as noncoding RNA and disease association prediction, protein complex prediction, etc.","As a key for studying the protein structures, protein fold recognition is playing an important role in predicting the protein structures associated with COVID-19 and other important structures. However, the existing computational predictors only focus on the protein pairwise similarity or the similarity between two groups of proteins from 2-folds. However, the homology relationship among proteins is in a hierarchical structure. The global protein similarity network will contribute to the performance improvement. In this study, we proposed a predictor called FoldRec-C2C to globally incorporate the interactions among proteins into the prediction. For the FoldRec-C2C predictor, protein fold recognition problem is treated as an information retrieval task in nature language processing. The initial ranking results were generated by a surprised ranking algorithm Learning to Rank, and then three re-ranking algorithms were performed on the ranking lists to adjust the results globally based on the protein similarity network, including seq-to-seq model, seq-to-cluster model and cluster-to-cluster model (C2C). When tested on a widely used and rigorous benchmark dataset LINDAHL dataset, FoldRec-C2C outperforms other 34 state-of-the-art methods in this field. The source code and data of FoldRec-C2C can be downloaded from http://bliulab.net/FoldRec-C2C/download."
"Abstractive text summarization focuses on generating a summary of a text from its main ideas, not by replicating the most salient sentences, rather by generating new sentences and/or rephrasing existing sentences so that the key semantics and overall meaning of the original text remain intact in summary. It has a wide range of applications in our daily life − from media monitoring, search marketing, email filtering, newsletter production to question-answering chatbots, we are frequently exposed to abstractive summarization. Due to its ability to generate fluent and coherent summaries, abstractive summarization is an important and challenging area of research in Natural Language Processing and has got enough attention in the last few years. While most of the previous studies (See et al., 2017; Lebanoff et al., 2018; Gehrmann et al., 2018; Chowdhury et al., 2020; Chung et al., 2020) on abstractive summarization use only textual data as the input modality, some studies (Shah et al., 2016; Palaskar et al., 2019) have recently focused on incorporating multimodal signals as the input to enhance the quality of text summary. Intuitively, humans can comprehend the gist of an occurrence more quickly by watching relevant images or videos than by only reading a text document, and therefore we believe that multimodal data can also reduce the difficulties for machines to interpret the context. Motivation: With the emergence of multimedia technology and the rapid growth of social media video-sharing platforms such as Youtube and Vimeo, multimedia data (including text, image, audio, and video) have increased dramatically. Specifically, during the COVID-19 outbreak in the last six months, there has been a steep rise in various e-learning platforms, resulting in a drastic increase of online video tutorials and academic presentation videos. However, such videos often do not have the text meta-data associated with them, or the existing ones fail to capture the subtle differences with related videos (Wang et al., 2012) . Additionally, different modalities in most of these videos are asynchronous with each other, leading to the unavailability of subtitles. In this work, we address the task of generating an abstractive text summary of a given academic presentation video so that the viewers can acquire the gist of the presentation in a short time, without watching the video from the beginning to the end. For this purpose, we incorporate automatic speech recognition (ASR) and optical character recognition (OCR) generated text transcripts and capture tonal-specific details of the speaker in addition to extracting semantics and sentics from the video, which are jointly optimized to produce a rich and informative textual summary of the entire presentation. We also show the generalizability of our model on the non-academic dataset (instructional videos). State-of-the-art and Limitations: The existing studies on abstractive text summarization with multimodal signals include multimodal news summarization (Li et al., , 2016 Chen and Zhuge, 2018) and summarization of instructional videos (Palaskar et al., 2019) . However, all of them use images and/or short videos as the visual modality, which do not generalize on long videos. The generated summaries by these systems are also one or two lines long, and therefore, not suitable for longer academic videos (such as course lecture, conference tutorials). Some other closely related studies include image and video captioning (Mun et al., 2017; Iashin and Rahtu, 2020; Shen et al., 2020) , video story generation (Gella et al., 2018) , video title generation (Zeng et al., 2016) and multimodal sentence summarization ; but all of them deal with short videos or images which are not appropriate for our application. The lack of previous studies on this task can be attributed to the absence of a suitable benchmark dataset. In a very recent work, Palaskar et al. (2019) studied the task of summarization of instructional videos on the How2 dataset (Sanabria et al., 2018) , which is the only existing dataset for abstractive text summarization with multimodality. However, the How2 dataset consists of short videos, with an average duration of 90 seconds only. The ground-truth text summaries of this dataset have an average length of 33 words, which are very small as well. Our Contributions: In this paper, we explore the role of multimodality in abstractive text summarization for academic presentation videos of diverse duration and introduce a new resource to further enable research in this area. More specifically, our main contributions in this work are as follows: 1. We curate the first large-scale dataset, Audio VIdeo lAnguage daTasEt (AVIATE), for abstractive text summarization using multimodal inputs for academic presentation videos of diverse duration. To collect the videos for this dataset, we scraped 6 publicly available websites and accumulated paper presentation videos from 28 well-known international conferences in computer science and social science. To obtain the transcripts of these videos, we apply Deep Speech (Hannun et al., 2014) , a pre-trained endto-end automatic speech recognition (ASR) system. We use the abstracts of corresponding research papers as the ground-truth summaries, which ensure adequate quality and uniformity. In contrast to How2, AVIATE contains longer videos and larger ground-truth summaries, which help the deep learning models trained on AVIATE to generalize the performance on other datasets. 2. We introduce several baselines to show that multimodal frameworks are substantially more effective when compared to their unimodal variants for abstractive text summarization. 3. We propose Factorized Multimodal Transformer based decoderonly Language Model (FLORAL), which uses an increasing number of self-attentions to inherently capture inter-modal and intra-modal dynamics within the asynchronous multimodal input sequences. FLORAL demonstrates the utility of pre-trained language model (LM) for summary generation in relatively low-resource setups over traditional encoder-decoder based networks. 4. For the videos of AVIATE, we show the importance of OCR generated text transcripts, which contain keywords and informative phrases displayed on slides in academic presentations. To fuse ASR and OCR generated texts, we introduce a novel guided attention based fusion mechanism which attends the complementary features in both the sources and filters out repetitive and redundant words. After the incorporation of OCR transcript, the baselines and FLORAL yield [0.7 − 3.6] ROUGE-L points performance improvement on AVIATE. 5. FLORAL reports benchmark results in terms of both automatic and manual evaluation metrics on How2 for short videos. It beats the best baseline by 1.39 ROUGE-L points. On AVIATE, FLORAL also turns out to be highly effective − it beats the best baseline by 2.74 ROUGE-L points. 6. Finally, we report the transferability of FLORAL between How2 and AVIATE. When trained on AVIATE and tested on How2, FLORAL yields 49.9 ROUGE-L score, which is only 6.9 points less than ROUGE-L obtained when both trained and tested on How2. The diverse-length videos of AVIATE make the model transferable, which is tremendously effective for practical applications. Reproducibility: To reproduce our results, we present detailed hyperparameter configurations in Table 1 and Section 5.1. Moreover, we also supplement our submission with full AVIATE dataset and source code of FLORAL 1 .@story_separate@Abstractive text summarization with multimodal inputs has gained increasing attention in recent years with the surge of multimedia data on the Internet and social media. Unlike unimodal text summarization systems, which are vastly studied, multimodal approaches make use of visual and acoustic modalities in addition to the textual modality, as a valuable source of information for generating a fluent and informative summary. A few existing experiments (Li et al., 2017 have shown that compared to unimodal text summarization systems, multimodal summarization can improve the quality of generated summary by using the information in the visual modality. Unimodal Text Summarization: Unimodal text summarization systems can be broadly classified into two approaches -extractive and abstractive summarization. Extractive summarization systems, which are robust and straightforward, involve the selection of phrases and sentences from the source document to generate the summary. Existing literature on extractive summarization has structured the decision either as binary classification over sentences (Cheng and Lapata, 2016; Nallapati et al., 2017) or classification followed by ranking (Fang et al., 2017; Narayan et al., 2018; Du et al., 2020) . On the other hand, abstractive text summarization systems involve generating novel sentences either by rephrasing or using new words to capture the overall meaning of the source document, making it more advanced and closer to human-like interpretation. Rush et al. (2015) was the first to apply modern neural networks to abstractive text summarization. Their approach is based on the attention mechanism and has later been augmented with recurrent decoders (Chopra et al., 2016) , hierarchical attention networks (Nallapati et al., 2016) , variational autoencoders (Miao and Blunsom, 2016) and pointer-generator (PG) (See et al., 2017) architecture, further improving performance of the summarization task. proposed a PG-derived structure that tends to preserve structural dependencies from the source into the summaries. Chowdhury et al. (2020) improved the work of by adding a structural attention based encoder to implicitly capture long term dependency relations in the summarization of lengthy documents. Recently, transformers have been used to effectively encode sequential data with great success when pre-trained for language modeling or language masking and subsequently fine-tuned (Radford et al., 2018; Devlin et al., 2019) and thus, can be used on relatively low-resource setup without overfitting. Text Summarization with Multimodality: Abstractive text summarization with multimodality deals with the fusion of textual, acoustic and visual modalities for summarizing a video document with a text precise that outlines the content of the entire video. Multimodal information is very useful in learning human-like meaning representations (Baroni, 2016; Kiela, 2017) . Since text rarely occurs in isolation in the real world, it becomes very effective to use all available information to optimize the quality of the summary jointly. The existing literature on multimodal text summarization include multimodal news summarization Chen and Zhuge, 2018; Li et al., 2016) and summarization of instructional videos (Palaskar et al., 2019) . Li et al. (2017) were the first to collect a multimodal corpus of 500 English news videos and articles with manually annotated the summaries. However, the size of this dataset is very small. presented the YouCookII dataset, containing instructional videos for cooking recipes with temporarily localized annotations for the procedures. introduced the notion of multimodal summarization with multimodal output, which takes the news with images as input, and finally outputs a pictorial summary. Most recently, Palaskar et al. (2019) studied the task of summarization of instructional videos on the How2 dataset (Sanabria et al., 2018) , which can be considered as the closest task to ours. However, all existing multimodal text summarization methods focus on summarizing images and/or short videos and generate oneor two-line long summary, and thus, can not be generalized to longer videos.  To enable the exploration of abstractive text summarization using multimodal signals and to generalize the task for videos of different lengths, we introduce AVIATE, the first large-scale multimodal text summarization dataset with videos of diverse duration, compiled from academic paper presentations. Currently, the only existing benchmark dataset relevant to our task is the How2 dataset (Sanabria et al., 2018) , which includes short instructional videos on different topics like cooking, sports, indoor/outdoor activities, music, etc. Our study reveals that deep neural models trained on such short videos fail to produce satisfactory results on longer videos. Moreover, the facial expression of the speakers in academic talks and presentations often plays an important role to preserve the most informative frames, which is not always the case for the How2 dataset. The How2 dataset consists of 2, 000 hours of short instructional videos, where the training, validation, and test set contain 73, 993, 2, 965, and 2, 156 videos respectively, with an average length of 90 seconds. Each video in this dataset is accompanied by a human-generated transcript and a 2 − 3 sentence ground-truth summary. The average length of transcripts and summaries is 291 and 33 words respectively. To collect conference presentation videos, we identified 28 academic conferences in computer science and social science, spanning over various domains such as Machine Learning, Natural Language Processing, Data Mining, Computer Vision, Computational Linguistics, Semantic Web, and Complex Systems. Most of the videos of our dataset come from conferences like NDSS, ICML, NeurIPS, ACL, NAACL, CVPR, EMNLP, ISWC, KDD, etc. To collect the oral and spotlight presentations of these conferences, we scrapped six different academic online video repositories, namely Videolectures.NET 2 , ACL Anthology 3 , CVF Open Access 4 , ICML 5 , NeurIPS 6 , and NDSS Symposium 7 websites. All the paper presentation videos are accompanied by an abstract, which we use as the ground-truth summary. Thus, unlike the How2 dataset, we did not annotate the summaries ourselves, which significantly improved the quality of ground truth summaries, and hence of the entire dataset. AVIATE consists of a total of 8, 201 videos, which spans over almost 2, 300 hours. Among them, we use 6, 680 videos for training, 662 for validation, and 859 for testing. The length of summaries is mostly between 100 − 300 words, with an average of 168 words. A brief source and duration statistics of AVIATE is presented in Figure 1 . Transcription: Since we collected all the videos from six different sources, not all of them had subtitles or transcripts readily available. This is particularly the case for videos from ACL Anthology and Videolectures, which contribute the majority of the AVIATE dataset. In the case of videos from NDSS, ICML, NeurIPS, and CVF Open Access corpus, subtitles are available for those videos which are present on Youtube. To maintain uniformity in the quality of transcripts, we apply Deep Speech (Hannun et al., 2014) , a pre-trained end-to-end speech recognition algorithm, to extract transcripts for all the videos. To ensure the quality of Deep Speech generated transcripts, we manually transcribe 300 randomly selected videos from our dataset. A low word error rate (24.19%) of the Deep Speech model for those videos indicates the satisfactory standard of the transcripts. An additional normalization step, which includes formatting 8 entities like numbers, dates, times, and addresses, helps us to further reduce the error rate to 20.12%. Figure 2 shows a comparison of video length and ground-truth summary length distribution for AVIATE and How2. For both datasets, longer videos 2 http://videolectures.net/ 3 https://www.aclweb.org/anthology/ 4 https://openaccess.thecvf.com/ 5 https://icml.cc/ 6 https://nips.cc/ 7 https://www.ndss-symposium.org/ 8 For example, labeling 'September 16, 2017' as 'september sixteenth twenty seventeen'. generally have a longer ground-truth summary, which leads to an overall positive correlation between video duration and ground-truth summary length. The average length of AVIATE videos is almost 12 times more than that of How2 videos. The longer videos and lengthier summaries in AVIATE make it harder than How2 to train on, which is explained in Section 6. In this section, we describe our proposed system, Factorized Multimodal Transformer (Zadeh et al., 2020) based Language Model (FLORAL) for abstractive text summarization using multimodal signals. Figure  3 shows the overall architecture of FLORAL. It takes a video, its corresponding audio and text transcript as input and generates an abstractive textual summary. A video generally has three distinct modalities -visual, textual, and acoustic, which supplement each other by providing complementary information, and thus when fused, separately contribute to generating richer and more fluent summaries. The first part of FLORAL extracts unimodal features using respective unimodal feature extraction networks. This phase does not consider the contextual relationship between the three different modalities. In the next part, unimodal features are processed using the Factorized Multimodal Transformer (FMT) based decoder-only network over multiple steps, which in turn generates one summary word in each step. After every step, the generated word is appended to the source text with a delimiter. Therefore, FLORAL considers the entire summarization problem as a language modeling task, simplifying traditional encoder-decoder architecture. The remaining part of this section discusses individual modules of FLORAL in detail. The visual features are extracted using a pre-trained action recognition model, ResN eXt − 152 3D Convolutional Neural Network (Hara et al., 2018) trained on the Kinetics dataset (Kay et al., 2017) to recognize 400 different human actions. All the frames, computed at a rate of 5 FPS, are first preprocessed by resizing, center-cropping, and normalization to have a resolution of 112 × 112. For every 16 non-overlapping frames in a video, ResN eXt − 152 extracts a 2048 dimensional feature vector. Therefore, the result is a sequence of feature vectors per video rather than a global one. The sequential feature vector, , is then used as the visual embedding input to the FMT. The acoustic modality is expected to contribute information related to tonal-specific details of the speaker (Tepperman et al., 2006) . To achieve this, we obtain low-level features from the audio stream for each video. Similar to Castro et al. (2019) , we use the popular speech processing library, Librosa (McFee et al., 2018) and perform the steps mentioned next. First, the audio sample for a video is stacked as a time-series signal with a sampling rate of 16000 Hz. Next, we remove the echos and background noise from the audio signals by integrating it with Audacity instance 9 , which is a free and open-source audio editor. Then, we segment the audio signals into d w nonoverlapping windows with a window size of 25 ms and successive window shift of 10 ms to extract low-level features that include Mel Frequency Cepstral Coefficients (MFCCs) with hamming window and the related temporal derivatives. Padding and segmentation are performed to achieve a fixed-length representation of the audio sources which are otherwise variable in length. At last, we concatenate all the extracted features to compose a d a = 512 dimensional joint representation for each window. Final MFCC features are obtained by applying a log Mel frequency filter bank over 0 to 8000 Hz and applying discrete cosine transformation (DCT). Similar to the visual features, the audio features, u a = {u a i } la i=1 , are also sequential for every video sample and are then used as the acoustic embedding input of FMT. Guided Attention: At first, we represent the text in both ASR and OCR-generated transcripts using pre-trained BERT (Devlin et al., 2019) , which provides dynamic embedding for every word. In particular, we use the sequence of 768-dimensional hidden states at the output of the last layer of the BERT model. Let F ∈ R n×768 and H ∈ R m×768 be the BERT representations for ASR and OCR texts respectively, where n and m are the respective token counts. The guided attention mechanism begins with defining an affinity matrix C ∈ R n×m , whose element c ij denotes the similarity between the feature vector pairs, h i ∈ R 768 and f i ∈ R 768 : where W b ∈ R 768×768 is a correlation matrix to be learned during training. Subsequently, we compute a normalized weight α h ij to denote the relevance of the i th ASR-generated word to j th OCR-generated word. Therefore, the weighted summation of the ASR transcript, a h j , can be represented as, Since our goal is to emphasize the dissimilar features between the ASR and OCR transcripts, we define the relevance matrix R(f i , a h j ) as cosine distance between the attended ASR sentence vector a h j and OCR word embedding f i - Now, the weighted summation of all word embeddings produces the modified ASR representation U computed as, where R(f i , a h j ) acts as a filter for the ASR encoding f i . Finally, we concatenate the attended ASR word representations with OCR word embeddings to get the sequential textual features u t = {u t i } lt i=1 , which is used as the textual embedding input of FMT. The pre-trained Language Model (LM) has recently been shown to have superior performance in abstractive summarization, particularly to enhance sample efficiency (Khandelwal et al., 2019) . This decoder-only network, known as Transformer LM, takes a pre-trained transformer as its base module and treats summarization as a language modeling task where each generated summary word in every step is appended to its source article. We extend the concept of Transformer LM to a multimodal setting, where we use Factorized Multimodal Transformer (Zadeh et al., 2020) based Language Model (FLORAL) for multimodal sequential learning. After each step of summary generation, we append the generated summary word to its source text transcript, along with a delimiter, and train the transformer on this reformulated data. FLORAL has three crucial advantages over traditional encoder-decoder based summarization networks: 1. In contrast to encoder-decoder architecture, FLORAL uses a single network to encode the source and generate the target, and thus, avoids the loading of same pre-trained weights into separate encoder and decoder. 2. Compared to the encoder-decoder network, FLORAL has fewer number of parameters. 3. Most critically, all the parameters of FLORAL can be pre-trained. Since there is no available large-scale multimodal corpus, we pre-train FLORAL on the text-only 2-billion word corpus 11 based on Wikipedia, called WikiLM (Khandelwal et al., 2019) , and fine-tune on the AVIATE and How2 datasets. Factorized Multimodal Transformer (FMT) (Zadeh et al., 2020) , which is the current state-of-the-art model for multimodal emotion recognition and multimodal speaker traits recognition on well-studied IEMOCAP (Busso et al., 2008) and POM (Park et al., 2014 ) datasets, applies seven distinct self-attention mechanisms to simultaneously capture all possible uni-modal, bi-modal, and tri-modal interactions across its multimodal input. We use 11 https://github.com/tensorflow/tensor2tensor layers, which inherently capture inter-modal and intra-modal dynamics within the asynchronous multimodal input sequence. Blue, red and green colors are used to illustrate the propagation of visual, acoustic and textual features within FMS. the FMT architecture as the backbone of our decoder-only Transformer LM. Before feeding into FMT, the unimodal embeddings are resampled using a reference clock so that modalities can follow the same frequency (Chen et al., 2017) . Additionally, zero paddings are used to unify the length of all samples of the entire dataset to a desired fixed length L. Hence, the i th data point consists of three distinct sequences of embeddings corresponding to three modalities -visual, acoustic, and language: where x i ∈ R L×dx and tar i ∈ R M ×dy are the inputs and target summaries respectively, M is the length of the summary; d x , d y denote the input and output dimensionality at each time step respectively; N is the total number of samples within the dataset. Positional embeddings are also added to the input. The FMT consists of a stack of Multimodal Transformer Layers (MTL), which captures factorized dynamics within multimodal data and aligns the time asynchronous information both within and across modalities using multiple Factorized Multimodal Self-attentions (FMS), each of which has 7 distinct self-attention layers. Each attention has a unique receptive field with respect to modalities f ∈ F = {L, V, A, LV, LA, VA, LVA}. The high dimensional output of FMS is controlled by a summarization network S 1 to have a reduced dimension R L×dx which goes through feedforward and normalization layers. If there are a total of P number of FMS units inside MTL, the dimensionality of the normalization layer is R P ×L×dx which is again mapped to R L×dx using a secondary summarization network S 2 . The output of the last MTL of FMT, thus computed, is fed into a Gated Recurrent Unit (GRU) to have a d y dimensional predicted summary word embedding, Summ i . The summary word predicted by the FMT in the first step, Summ 1 , is appended to the text transcript and fed into the same FMT in the next step to predict the second summary word, Summ 2 . This process is continued until the model generates a stop-word or a predetermined summary length is reached. We only compute loss over the target sequence, as suggested by Khandelwal et al. (2019) . To explore the role of multimodality in abstractive text summarization, we conduct multiple experiments evaluating textual and visual modalities separately and jointly on both How2 and AVIATE datasets. Additionally, we investigate the role of OCR-generated text for the academic presentation videos in AVIATE for improving summary generation. We train FLORAL using Pytorch framework on NVIDIA Tesla T4 GPU, with 16 GB dedicated memory, with CUDA-10 and cuDNN-7 installed. We pre-train all the parameters of FLORAL using WikiLM (Khandelwal et al., 2019) , and fine-tune on the summarization datasets (How2 and AVIATE). Similar to encoder-decoder models, we only compute loss over the target sequence. In Table 1 , we present the details of hyper-parameters used in the baselines and in FLORAL. We compare the performance of the following extractive and abstractive unimodal and multimodel text summarization models both on How2 and AVIATE datasets.  • Lead3 is the most common baseline which simply selects the leading three sentences of the document as its summary. • KLSumm (Haghighi and Vanderwende, 2009 ) is a greedy algorithm that minimizes the Kullback-Lieber (KL) divergence between the original document and the ground-truth summary. • TextRank (Mihalcea and Tarau, 2004 ) runs a modified version of PageRank on a weighted graph, consisting of nodes as sentences and edges as similarities between sentences. • LexRank (Erkan and Radev, 2004 ) is a graph-based algorithm that represents sentences as vertices, and edges represent the similarity. • Pointer Generator (PG) (See et al., 2017) network is one of the most popular sequence to sequence (seq2seq) summarization architectures. PG allows both generating words from the vocabulary or copying from the source document. • Pointer Generator-MMR (Lebanoff et al., 2018) uses MMR along with PG for better coverage and redundancy mitigation. Here MMR computes a similarity score of sentences with the source text and modifies the attention weights for a better summary generation. • CopyTransformer (Bottom-up Abstractive Summarization) (Gehrmann et al., 2018) uses the transformer parameters proposed by . It uses a content selection module that over-determine phrases in the source document. • Multimodel Hierarchical Attention (Palaskar et al., 2019) extends the work of Libovický and Helcl (2017) , which was originally proposed for multimodal machine translation. This model fuses visual and textual modalities and captures the context of visual and textual features along with hierarchical attention to generate summaries. • MulT Encoder-Decoder is an encoder-decoder based summarization architecture, which uses MulT (Multimodal Transformer for Unaligned Multimodal Language Sequences) model (Tsai et al., 2019) as its encoder and decoder unit. • FMT Encoder-Decoder is an encoder-decoder network, similar to MulT encoder-decoder. This baseline uses Factorized Multimodal Transformer (Zadeh et al., 2020) as the encoder and decoder units. • MulT LM is MulT-based architecture. This is most akin to our proposed FLORAL model; only the FMT module of FLORAL is replaced by MulT (Tsai et al., 2019) to have this multimodal summarization baseline. We present a quantitative analysis of the summaries using the standard metrics for abstractive summarization -ROUGE-1 (R-1), ROUGE-2 (R-2), and ROUGE-L (R-L) (Lin, 2004; Graham, 2015) that measure the unigrams, bigrams, and longest common sequence between the ground-truth and the generated summaries, respectively. Additionally, we perform extensive qualitative analysis using human experts to primarily understand the fluency and informativeness of the summaries. We also analyze the word distributions in the transcriptions and summaries. At first, we evaluate the performance of commonly used extractive and abstractive text summarization models both on the How2 and AVIATE Table 2 : Ablation results after incorporating OCR generated text into the ASR generated text transcript using guided-attention for different extractive and abstractive unimodal and multimodal text summarization systems on AVIATE. datasets. Note that the average length of text transcripts in How2 is much less than that of AVIATE. Following our intuition, PG-based text summarization networks perform relatively well on How2 as shown in Table 3 ; but their performance drastically drops on AVIATE. This result can be attributed to the fact that attention-based encoder-decoder networks often fail to capture long-term dependencies when the source text is long and noisy. Hence, we decide to use transformer-based pre-trained BERT (Devlin et al., 2019) as the text-embedding layer in our model. In addition to text-only models, we train two video-only models -the first one uses a single convolutional and pooling layer for feature extraction from the entire video, while the second one applies a single layer RNN over these vectors in time. We observe in Table 3 that even using only action features in the videos leads to almost competitive R-1, R-2, and R-L scores compared to text-only models, in some cases often better than extractive text-only systems. This result demonstrates the importance of both modalities for summarization. Model  Since the AVIATE dataset is composed of conference presentation videos, we observe that in almost 94.8% videos in the entire dataset, the speaker shows slides during the presentation. The text in these slides is succinct and contains the most important key-phrases which are crucial for summary generation. Table 2 shows the performance improvement for every summarization model when the OCR is fused with ASR transcript using our guided attention mechanism. We also consider direct concatenation of OCR transcript with the ASR-transcript; however, it resulted in lower performance as compared to guided attention fusion. The guided attention ensures the filtering of redundant and repetitive words in OCR and ASR transcripts. For every summarization model, we only use the first 500 tokens of the OCR transcript. We did not consider incorporating OCR for How2 as this dataset only contains instructional videos, and there is no text shown in the frames of instructional videos. Table 2 shows that unimodal extractive text summarization models, namely KLSumm, TextRank and LexRank, yield an improvement of [2.1−2.3] R-1 points, [0.1 − 0.3] R-2 points and [0.6 − 6.5] R-L points after incorporating OCR-generated text. Similarly for abstractive summarization, the very popular PG-MMR network produces 0.5, 1.25, and 2.3 points performance improvement in terms of R-1, R-2, and R-L scores, respectively. The other abstractive summarization networks, namely PG, Hi-MAP, CopyTransformer, also support our hypothesis and show an improvement of [0.5 − 4] points in terms of all three evaluation metrics. Influenced by the performance of unimodal summarization models, we incorporate the OCR transcripts into all of our multimodal baselines. Supporting our intuition, the multimodal systems obtain significant performance enhancement with OCR transcripts as shown in Table 2 . The multimodal hierarchical attention model, MulT, and FMT-based encoder-decoder models show [0.8 − 1.5] points improvement in the R-L score. Our proposed FLORAL model yields the highest performance boost with OCR among all the multimodal systems, showing 3.87, 4.66, and 2.95 point enhancement in R-1, R-2, and R-L scores respectively. The performance boost can be easily attributed to the keywords in the OCR-generated transcript, which guides the text-embeddings to attend the most important portions in a very long ASR transcript. Hence, in the rest of our discussion, we always report results with (ASR + OCR) transcript, fused with guided attention, as the textual modality. Table 3 shows the ROUGE scores for different unimodal and multimodal text summarization systems on the How2 and AVIATE datasets. Among the unimodal variants, the abstractive text summarization systems generally perform much better than the extractive systems, especially on AVIATE. Note that despite being a very strong extractive baseline, Lead3 does not perform well on AVIATE, as the text transcripts of academic presentation videos do not tend to be structured with the most important information at the beginning. The two video-only models, simple conv-pool action features and action features with RNN perform very close to the abstractive textonly baselines, which clearly indicates the necessity of visual modality in addition to the textual modality. 12 As presented in Table 3 , the MulT, and FMT multimodal baselines and the proposed FLORAL model beat most of the unimodal systems by a large margin, on both the datasets. This result is expected because of the inherent ability of MulT and FMT to capture the intra-model and inter-modal dynamics within asynchronous multimodal sequences and incorporate diverse information in a single network. Overall, the combination of visual, acoustic, and textual signals significantly improves over the unimodal variants, with an improvement of 1.57, 3.04, and 3 R-1, R-2, and R-L points on How2 and 6.86, 7.1 and 4.41 on AVIATE. We manually investigate some video samples of AVIATE where the multimodal system generates a better summary than the unimodal system. In most of these samples, the textual transcript is very noisy and contains many irrelevant words that are not much required for the summary generation. Figure 6 shows an example training instance of the AVIATE dataset with three different modalities. A closer look into the ASR and OCR transcripts reveals the presence of irrelevant and noisy words. For example, the very first sentence of the ASR transcript ""hi i'm lisa ann hendricks and today"" does not contribute to the summary generation. As a result, these samples require additional cues for performance improvement, which are availed from the multimodal signals. The variation of outputs from various unimodal and multimodal summarization networks for a single video sample is shown in Table 9 . Table 3 shows that the performance of unimodal and multimodal summarization systems on How2 as compared to AVIATE. In contrast to prior work on news-domain summarization (Nallapati et al., 2016) , the seq2seq model performs the best among all unimodal systems on How2, achieving 55.32, 23.06, and 53.9 R-1, R-2, and R-L scores, respectively. As indicated by Palaskar et al. (2019) , the PG model performs lower than seq2seq on How2 due to the lack of overlaps between input and output, which is the important feature of PG networks. Among the multimodal systems, our proposed FLORAL model yields the best results; however, the other multimodal baselines reach almost competitive ROUGE scores compared to FLORAL on this dataset. Noticeably, despite having a simple structure, the multimodal hierarchical attention model performs very well on How2. On this dataset, FLORAL achieves 56.89, 26.93, and 56.80 R-1, R-2, and R-L scores, respectively, which are [0.1 − 2] points higher than the scores achieved by other multimodal baselines. AVIATE contains longer videos than How2, resulting in longer transcripts and ground-truth summaries. As shown in Table 3 , the best performing unimodal summarization model on AVIATE is CopyTransformer. As the ASR and OCR generated summaries are very long, the extractive systems do not perform well on this dataset. While PG and seq2seq yield 23.32 and 23.81 R-L scores respectively, CopyTransformer produces a 27.06 R-L score, outperforming all other unimodal systems. The superior performance of CopyTransformer over PG and seq2seq can be attributed to the self-attention mechanism of transformers which helps to capture long-term dependencies. The incorporation of visual and acoustic modalities significantly improves the ROUGE scores on this dataset. FLORAL beats all the transformer-based encoder-decoder networks and language models. FLORAL produces 37.13, 11.04 and 31.47 R-1, R-2 and R-L scores respectively, where the second-ranked model on AVIATE, MulT-LM obtains 33.47 R-1, 4.12 R-2, 28.73 R-L scores, which are almost [2.7 − 7] points lower than that of FLORAL. Since AVIATE contains 6, 680 training samples, which may not be enough for today's deep neural models, the factorization mechanism on FMT, which allows an increasing number of self-attention to better model the multimodal phenomena, results in its superior performance, without encountering difficulties even on the relatively low-resource setup of AVIATE. Pre-training of all the parameters of FLORAL also has an immense impact, which helps in beating all other baselines by a significant margin. Table 3 also shows that all the unimodal and multimodal summarization models obtain almost [18 − 25] points higher R-1 and R-L scores and [3 − 6] points higher R-2 score on How2 over AVIATE. For example, FLORAL yields 56.89, 26.93, and 56.80 R-1, R-2, and R-L scores on How2 and 37.13, 11.04 and 31.47 R-1, R-2 and R-L scores on AVIATE. We can observe from Table 3 that all the baseline models as well as FLORAL yield higher R-1, R-2 and R-L scores on How2 than AVIATE. The overall better performance of every system on How2 than AVIATE can be attributed to two factors -firstly, the text transcripts of How2 are manually annotated. In contrast, we use ASR and OCR outputs as the transcripts for AVIATE. The large margin of ASR and OCR errors in some of the train and test samples significantly affect the model performance. Secondly, since the video length, transcript length, and reference summary length are much longer in AVIATE than How2, the summarization task becomes more challenging in AVIATE. Furthermore, since AVIATE comprises many scientific presentation videos, the audio transcript contains complex academic words, leading to a larger dictionary for the language generation task. Overall, the results in Table 3 conclude that the AVIATE dataset is more exacting than How2, indicating room for further research with fine-grained and sophisticated multimodal models for long videos. In our next experiment, we demonstrate how the summarization task becomes more challenging with longer videos. We divide the AVIATE dataset into three portions -short videos (duration less than 10 minutes), medium videos (duration between 10 minutes and 30 minutes) and long videos (duration more than 30 minutes). We split each portion in 4 : 1 ratio and train and test all the multimodal systems on each segment. Table 4 shows the performance reduction of each model with the increase in video length. In general, we observe that all four multimodal baselines yield R-L score in the range of [27.03 − 34.09] on the short videos. However, the score reduces to [23.19 − 28.69] for the long videos. The performance of FLORAL also decreases from short to medium and long videos; however, the span of reduction of R-L score is only [0.39 − 0.64], which is relatively less than all other baselines. We also notice that the LM-based systems generally capture long-term dependencies better than traditional encoder-decoder based systems. The complementarity of multiple modalities in the performance of FLORAL is shown in Table 5 . To understand the importance of visual modality, Table 5 : Significance of multimodal cues in FLORAL. The combination of visual, textual, and acoustic signals significantly improves over the unimodal variants, with a relative improvement of R-1, R-2 and R-L scores of 9.99%, 8.11% and 11.80% respectively over the best unimodal variant. we feed zero input in other two modality channels of FLORAL and continue the process for all three modalities. We observe that the textual modality provides the best performance among unimodal variants. The addition of visual and acoustic features improves significantly over the unimodal baselines and achieves the best performance -with an increase in R-1, R-2 and R-L score of 9.99, 8.11 and 11.80 respectively over the best unimodal variant. Table 6 : Transferability of the proposed FLORAL model on the two available multimodal abstractive text summarization datasets -How2 and AVIATE. The network is trained on the dataset in each row, and is tested on the dataset shown in each column. The second row indicates the performance of FLORAL on the How2 videos whose transcripts are generated from ASR. Medium Videos Long Videos R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L 6.1.5. Transferability of FLORAL Table 6 shows the transferability property of FLORAL between How2 and AVIATE. When trained and tested on the same dataset, FLORAL produces the best ROUGE scores, which is expected. However, when trained on AVIATE and tested on How2, FLORAL yields an R-L score of 49.90, which is just 6.9 decrease in R-L score (11.83% reduction in performance) than the one when trained and tested on How2. The vice-versa is not true, i.e., when trained on How2 and tested on AVIATE, the performance drop is drastic (26.56% reduction in performance). As the videos in How2 have human-annotated transcripts and those in AVIATE have ASR-generated transcripts, for fair comparison of transferability, we extract the ASR transcripts of the How2 videos and train FLORAL. The results of this experiment are shown in the second row of Table 6 . We observe that the ASR transcript reduces the test performance on How2, which is expected due to the noise in the ASR output. The transferability score on AVIATE improves a bit, but the performance drop is still heavy (25.51% reduction in performance). From all these experiments, we can conclude that since the videos of How2 are very short, the learned weights do not perform well for longer videos. However, AVIATE consists of diverse-length videos, and thus, the trained model on AVIATE yields good results on How2 as well. Table 7 shows the transferability of FLORAL across short, medium and long videos of AVIATE. When trained on the long videos, FLORAL performs the best across all three portions. However, when trained on short videos, the model can not learn long-term dependency for lengthier videos. The same property supports the results on Table 6 . Since the How2 dataset contains only short videos, the model does not perform well when trained on How2 and tested on AVIATE. In addition to ROUGE scores, we conduct a qualitative analysis by performing a human evaluation to understand the standard of the summary outputs. Following the abstractive summarization human annotation work of Grusky et al. (2018) , the summaries were evaluated by five annotators 13 to rate the generated summaries on a scale of [1 − 5] on four parameters - informativeness, relevance, coherence, and fluency. For the evaluation, we randomly sampled 300 videos from the test sets of How2 and AVIATE. Table  8 shows the average human evaluation scores for 4 text-only, 1 video-only and 3 multimodal models. In general, we observe that PG has difficulty in summarizing articles with repetitive information and tends to assign a lower priority to less occurring important keywords. The extractive summarization systems sometimes pick sentences extraneous to the summary. For example, we notice some summaries generated by KLSumm starting with ""Good afternoon everyone, I am ·"", which is the very first line of the transcript. In contrast, the multimodal summarization models generate summaries with greater relevance and informativeness. Our proposed FLORAL model obtains high scores on informativeness, relevance, and coherence on AVIATE, but sometimes seems to generate less fluent summaries. This fluency problem mostly stems from errors in ASR and OCR generated text. Some of these phenomena are illustrated with instances from AVIATE in Table 9 . We also analyze the word distributions of the ground-truth summaries and different system-generated summaries. The density curves in Figure 5 shows that for both How2 and AVIATE, the abstractive unimodal and multimodal summarization models generate summaries shorter than the ground-truth summary. The average length of summaries is highest for CopyTransformer. Interestingly, FLORAL and PG generated summaries are similar in length. However, FLORAL outperforms PG by a large margin, which illustrates that for improvements in ROUGE scores, an informative summary is more crucial than a lengthier summary. Ground-truth - We study the problem of semi-supervised question answering-utilizing unlabeled text to boost the performance of question answering models. We propose a novel training framework, the Generative Domain-Adaptive Nets. In this framework, we train a generative model to generate questions based on the unlabeled text, and combine model-generated questions with human-generated questions for training question answering models. We develop novel domain adaptation algorithms, based on to learn richer context-aware model on the insight and the human-generated data distribution. Experiments show that our proposed framework obtains substantial improvement from unlabeled text. FLORAL (ours) 31. 47 We study the problem of semi-supervised concepts unlabeled text to boost the performance of without without models. We propose a novel training framework, the Generative Domain-Adaptive Nets. In this framework, we train a database model and generate concepts based on procedure on how partitioning in the levels between t, and combine model-generated attention with human-generated types for training associations directed-generation models. We develop novel algorithms, based on model, to understand the discrepancy between the generated data results and the human-generated data distribution. Experiments show model obtains improvement from text. MultT LM 28.73 In learn paper are neural paper, we propose a new model and the paper, we study demonstrated the character score We investigate the problem answering utilizing unlabeled text to understand trained models. we train a understanding model to generate understanding based on the text, and combine trained understanding with human generated understanding to training data trained we assume like, on a public unsupervised Subsequently, prediction trained to learn richer context-aware model on the insight In trained facilitates smaller annotations previously reported understanding understanding on approach and questions along five perform two then performance The the semantic best dataset and the proposed MultT En-De 27.2 We present the problem of supervised new utilizing text of new new models. We propose a problem model review a new model In this paper, we propose a simple model Experimental resultsprove the standard model achieves method to then the proposed among review model to also performance based on the proposed CoNLL-2012 dataset. In this we train a new model to generate a model and combine model. of machine morphology into more prediction on the drawback of the system classes. using error-correcting codes collection. We evaluate investigation of NMT and induced Experiments errors. shed light affect vs. scores on a word its dataset with the proposed based CopyTrans. 27.06 We propose a novel method for novel method for state-of-the-art question answering we show that the method achieves state-of-the-art performance on the state-of-the-art performance of the proposed method on the systems over sequential text tasks or as independent, parallel tasks. In this framework model generate text trained benefits of the new semantic high a image and at them as HA 26. 12 We propose the novel model has the paper, we propose a generative model In both learning can can the benchmark model To capable to also performance of existing the pipelined of the model-generated model: distribution for the human-generated data distribution. Experiments show that our proposed framework to the consistency of the art data distribution and event feedforward network. The an unsupervised dependency framework performance and the human data distruction . PG 23.81 In this paper we consider the problem of learning a deep neural network, we propose a novel neural network architecture based on novel neural network architecture that is trained end-toend trainable convolutional neural network (CNN) architecture is able to train a convolutional neural network architecture that is capable of achieving state-of-the-art performance compared to state-of-the-art performance on three benchmark datasets. PG-MMR 22.63 We propose a novel method for object detection based on a novel object detection method that uses a novel model based on the posterior distribution of the posterior distribution over the parameters of the number of claims and We show that models can be used as well as compared to In this paper, we study the a algorithm that the proposed method can outperforms the state-of-the-art methods on a large number of Table 9 : Comparison of ground-truth summary and outputs of 7 different unimodal and multimodel abstractive text summarization systems -FLORAL, MultT LM, MultT Encoder-Decoder, CopyTransformer, multimodal hierarchical attention (HA), Pointer Generator (PG) and Pointer Generator with MMR (PG-MMR) -arranged in the order of best to worst ROUGE-L scores in this table. Red highlighted text indicates a positive correlation of context w.r.t. ground-truth summary while blue color represents a negative correlation with ground-truth summary. Figure 6 : Example of AVIATE dataset with three different modalities. To obtain the text transcripts from the acoustic modality, we apply Deep Speech (Hannun et al., 2014) , a pre-trained end-to-end automatic speech recognition (ASR) system. We extract the text shown in the slides in the presentation videos using Google OCR Vision API. We use the abstracts of corresponding research papers as the ground-truth summaries.@story_separate@In this paper, we explore the role of multimodality in abstractive text summarization. All the previous studies in this direction have used either images or short videos as the visual modality and generate one or two lines long summary, and thus, fail to perform on longer videos. Moreover, there exists no benchmark dataset for abstractive text summarization of medium and long videos. In this work, we introduce AVIATE, the first large-scale dataset for abstractive text summarization with videos of diverse duration, compiled from paper presentation videos in renowned academic conferences. We then propose FLORAL, a Factorized Multimodal Transformer based decoder-only Language Model, which uses an increasing number of self-attentions to inherently capture inter-modal and intra-modal dynamics within the asynchronous multimodal sequences, without encountering difficulties during training even on relatively low-resource setups. To evaluate FLORAL, we perform extensive experiments on How2 and AVIATE datasets and compare them against several unimodal and multimodal baselines. Overall, FLORAL achieves superior performance over previously proposed models across two datasets.","In recent years, abstractive text summarization with multimodal inputs has started drawing attention due to its ability to accumulate information from different source modalities and generate a fluent textual summary. However, existing methods use short videos as the visual modality and short summary as the ground-truth, therefore, perform poorly on lengthy videos and long ground-truth summary. Additionally, there exists no benchmark dataset to generalize this task on videos of varying lengths. In this paper, we introduce AVIATE, the first large-scale dataset for abstractive text summarization with videos of diverse duration, compiled from presentations in well-known academic conferences like NDSS, ICML, NeurIPS, etc. We use the abstract of corresponding research papers as the reference summaries, which ensure adequate quality and uniformity of the ground-truth. We then propose {\name}, a factorized multi-modal Transformer based decoder-only language model, which inherently captures the intra-modal and inter-modal dynamics within various input modalities for the text summarization task. {\name} utilizes an increasing number of self-attentions to capture multimodality and performs significantly better than traditional encoder-decoder based networks. Extensive experiments illustrate that {\name} achieves significant improvement over the baselines in both qualitative and quantitative evaluations on the existing How2 dataset for short videos and newly introduced AVIATE dataset for videos with diverse duration, beating the best baseline on the two datasets by $1.39$ and $2.74$ ROUGE-L points respectively."
"Vaccine hesitancy has been defined by the World Health Organization as ""the delay in the acceptance or refusal to vaccinate despite the availability of vaccine services."" [1] A number of factors have been linked to increased vaccine hesitancy. These include concerns about the safety and efficacy of a vaccine, which has been shown to be a factor among all races and ethnicities [2] [3] [4] [5] and applies to healthcare workers as well the public [6] . A lack of concern about the seriousness of a disease also increases hesitancy [2, 7, 8] . Matters related to the ease of getting vaccinated, such as whether one has healthcare coverage is also a factor [4, 8] . Trust in the system that promotes and administers the vaccine is also a factor, especially for American Blacks [2, 7] . With regard to COVID-19 vaccine, Reiter et al. [8] found Americans more willing to be vaccinated if they were worried about the disease, felt the vaccine was safe and effective, and if their healthcare provider recommended it. They were less willing if they were non-Hispanic Black. A recent study by Khubchandani et al. [9] found that Hispanics, as well as African Americans, showed higher COVID-19 vaccine hesitancy than Whites or Asians, as did those with less education and those who were not concerned about being infected. Nguyen et al. [10] reported results of studies of changes in vaccine hesitancy between September and December 2020, dates which were pre-vaccine authorization and postvaccine authorization, respectively, in the U.S. Intent to be vaccinated increased from 39.4 to 49.1%, and lack of intent decreased from 38.1 to 32.1%. The largest increase in intent occurred among adults 65 years and older. Lack of intent was highest among young adults, women, non-Hispanic Blacks, adults living in nonmetropolitan areas, adults with lower educational attainment, having lower income, or without health insurance. Despite the fact that initial federal and California prioritization schemes for deciding who gets vaccinated first relied on occupational categories, such as healthcare providers, educators, first responders, or food and agriculture workers, few studies have specifically addressed various occupational groups to assess their vaccine hesitancy. Betsch [6] reported that healthcare workers' worry about safety of a vaccine outweighed concern for others when making decisions about vaccination. The motivation for employing the survey was to determine which demographic and occupational groups should be targeted by efforts to reduce COVID-19 vaccine hesitancy, and what factors related to COVID-19 vaccine hesitancy should be addressed by a campaign to increase vaccination rates. The survey research was designed to answer the following questions: 1. What is the level of vaccine hesitancy among different demographic and occupational groups across a large (population 3,175,130) Southern California county? 2. What concerns determine willingness to be vaccinated in each group?@story_separate@Sample A convenience sample of 25,000 respondents was assembled by asking the 35 members of a county community vaccine taskforce to contact their constituents by email and request responses to the survey via the internet using SurveyMon-key™. In order to increase representation of low-income and minority respondents, a coalition of community clinics was contracted to provide approximately1300 face-to-face or telephone interviews with clinic clients who did not have emails. The final number of respondents was 26,324. The survey was conducted during the months of October and November, 2020. The Survey chosen was a short form of the 5-C Scale of Psychological Antecedents of Vaccination developed by Betsch et al. [11] . The 5C scale is based on a model developed by the SAGE Working Group on Vaccine Hesitancy [12] and work by Larson et al. [13] and especially the taxonomy for determining vaccine uptake described by Thompson et al. [14] . It measures agreement with five statements related to Confidence in the vaccine, Complacency about the disease, Convenience of getting vaccinated, whether one is a person who Calculates risks and benefits, and Concern for others as a reason for getting vaccinated. Betsch et al. [11] studied the effectiveness and statistical characteristics of both the complete 15-item 5-C Scale and a Short Form, 5-item scale. The shorter, 5-item scale, with some modification, was used in our survey. The scale was available, online and in person, in 7 languages: English, Spanish, Farsi, Korean, Chinese, Vietnamese, and Khmer (Cambodian). Following the format of Betsch et al., the survey asked five statements, each one related to one of the five areas of concerns about receiving a vaccine. Responses to each statement were on a 7-point scale from strongly disagree to strongly agree. Three statements, related to confidence, calculation and concern for others were scored positively, so that higher scores (agreement) meant less hesitancy and two items related to complacency and convenience, for which higher scores indicated more hesitancy, were reverse-scored in the statistical analyses. Willingness to be vaccinated was measured in terms of agreement on the 7-point scale with the statement: ""If a vaccine is available, I plan to be vaccinated."" Respondents also answered questions about age, gender, ethnicity, education, primary language, plus 11 occupational categories. The Complete survey is available from the senior author on request. Significant differences in willingness to be vaccinated related to differences in age, gender, ethnicity, education, primary language and occupation were assessed using oneway analyses of variance, employing Welch's ANOVA, as a protection against bias due to unequal sample sizes and nonhomogeneity of variances. Games-Howell t-tests were used to compare individual means. All significance tests were two-tailed. Multiple linear regression was used to assess the strength of each of the 5-C questions in predicting willingness to be vaccinated within the overall sample and within each demographic and occupational group. The demographic and occupational makeup of the sample is presented in Table 1 . Women, non-Hispanic Whites, college educated, 35-54 year olds and those for whom English was their primary language were overrepresented compared to the county population, which, according to the 2010 census, is 39.8% non-Hispanic White, 33.7% Hispanic, and 17.7% is Asian, although only 1.5% is non-Hispanic Black. The over 75 population was underrepresented in our sample (2.9% vs. 5.3% in the county). More than half of the respondents were either office/technical/professional workers or in education. The sample was not representative of the total Orange County population, however the size of the sample allowed analysis of the responses of a number of demographic and occupational subgroups of interest. Due to unequal sample sizes and lack of homogeneity of variance, differences between groups were tested using Welch's ANOVA and follow-up multiple comparisons were tested for significance using the Games-Howell method. There were too few respondents in the ""other"" category of gender, and males and females were compared using a t-test for samples with unequal variances. Most of the groups had mean scores between 4 (neutral) and 5 (slightly agree) as shown in Fig. 1 . Willingness to be vaccinated differed by age (F (3,3436.84) = 173.40, p < 0.001). Willingness increased with age, with the exception that 18-34 year olds were more likely than 35-54 year olds to agree to be vaccinated (Fig. 1) . Follow up comparisons with the Games-Howell statistic showed that all age groups differed significantly from one another (p < 0.001). Race/ethnicity also showed a significant effect on willingness to be vaccinated (F (4, 1729.87) = 188.07, p < 0.001). Asians were most likely to want to be vaccinated, followed by non-Hispanic Whites, then others, Hispanics, and non-Hispanic Blacks. All racial/ethnic groups differed significantly from one another (p < 0.001). Level of education also showed significant differences on willingness to be vaccinated (F ( 4, 3463.96) = 56.47, p < 0.001). Follow-up comparisons with the Games-Howell statistic showed that those with no high school diploma differed from those with a high school diploma (p < 0.01) and those with some college ((p < 0.001). Those with a high school diploma differed from those with a graduate degree (p < 0.01). Those with some college differed from everyone (p < 0.001) except those with a high school diploma, and those with a 4-year degree differed from those with a graduate degree (p < 0.001). The most and least educated groups were most willing to be vaccinated. The number of respondents who had primary languages other than English was small enough in some cases to make the results only suggestive and they are not shown in Fig. 1 . However, the overall Welch's ANOVA was significant (F ( 6, 618.38) = 64.86, p < 0.001). Those who spoke languages other than English or Spanish didn't differ significantly from one another, and all were more willing to be vaccinated than those who spoke English or Spanish (p < 0.001), which didn't differ from each other. Not shown in Fig. 1 , males were more willing to be vaccinated than females, (t (12,963) = − 20.73, p < 0.001. The mean of mean scores across all the occupations was 4.57, which corresponded to an answer halfway between neutral and slightly agreeing to be vaccinated. Figure 2 shows that retired persons and students were the most willing to be vaccinated, followed by disabled or unemployed, other, healthcare workers, office, professional and technical workers and educators. First responders were the least willing to be vaccinated followed by construction, maintenance and landscape workers, homemakers, housekeeping, cleaning and janitorial workers, and retail and food service workers. The overall differences between occupational groups on willingness to be vaccinated were significant using Welch's ANOVA (F (11, 2853.64) = 67.54, p < 0.001). Paired comparisons using the Games-Howell statistic showed that retired persons were significantly more willing than all other occupations except students (p < 0.001), and students were more willing than all the rest of the groups (p < 0.001; disabled and unemployed, p < 0.005). Disabled Willingness and unemployed were more willing than first responders (p < 0.001), retail and food service workers (p < 0.05), educators (p < 0.05), construction, maintenance and landscape workers (p < 0.001) and homemakers (p < 0.001). Healthcare workers were significantly more willing than first responders (p < 0.001), construction, maintenance and landscape workers(p < 0.05) and homemakers (p < 0.001). Educators and office and technical or professional workers were significantly more willing than first responders (p < 0.001) and homemakers (p < 0.001). First Responders were less willing to be vaccinated than everyone (p < 0.001; retail/food service p < 0.05) except housekeeping, cleaning and janitorial workers, homemakers, and construction, maintenance and landscape workers. Construction, maintenance and landscape, retail and food service, housekeeping, cleaning and janitorial, and homemakers did not differ significantly from one another. Every factor from the 5-C measure significantly predicted willingness to be vaccinated, with the highest correlations being with confidence with the safety of the vaccine (r = 0.723, p < 0.001), concern with protecting others by being vaccinated (r = 0.574, p < 0.001), and believing COVID-19 was serious enough to merit vaccination (r = 0.478, p < 0.001). The relationship with convenience of being vaccinated (r = 0.214, p < 0.001) and calculating the pros and cons of vaccination (r = − 0.038, p < 0.01) were lower, and the latter relationship was negative. Following Norman [15] and Sullivan and Artino [16] we treated our 7-item Likert scale as a continuous variable and used a stepwise multiple regression model employing all five 5-C factors to predict agreement with the willingness to be vaccinated question. Table 2 shows the results of the step-wise multiple regression analysis of the relationship of five factors to willingness to be vaccinated. The R 2 was highly significant. For the sample as a whole, confidence in the safety of the vaccine was the strongest predictor of willingness to be vaccinated, followed by concern for protecting others and whether or not one believed that COVID-19 was serious enough to warrant vaccination. Multicollinearity was not a factor according to the variance inflation factor (VIF). Separate multiple regressions were carried out for each demographic and occupation group. All were significant at the < 0.001 level. Confidence in the safety of the vaccine was the strongest predictor for every group. Concern for protecting others was the second strongest predictor for 13 of 15 demographic groups and 8 of 11 occupational groups (excluding ""other""). college degrees, first responders, construction, maintenance and landscape workers and housekeeping, cleaning and janitorial workers all gave greater weight to whether COVID-19 was a serious enough disease to merit vaccination than to concern for protecting others by being vaccinated. Neither convenience of getting vaccinated nor whether one calculated the pros and cons of getting vaccinate was a strong predictor of willingness to be vaccinated. In all cases in which calculation was a significant predictor, the correlation with willingness was negative. Males and non-Hispanic White or Asian respondents were more willing to be vaccinated than females or Hispanic or non-Hispanic Black respondents. Older respondents were more willing to be vaccinated than younger, except that those age 18-34 were more willing than those age 35-54, perhaps because of the large number of students in the younger group (24% compared to 1.1%). The most and least educated groups were most willing to be vaccinated. English as a second language was not associated with greater hesitancy in those whose primary language was Farsi or any of a number of Asian languages. The low vaccine hesitancy among Hispanics and non-Hispanic Blacks found in this study is important and alarming, especially in the Southwestern US, which has a high Hispanic population and where COVID-19 infection and death rates are higher than for other racial/ethnic groups. Andrafsky and Goldman [17] projected that life expectancy at birth in Hispanics and Blacks in the U.S. decreased as a result of COVID-19 by 3.05 and 2.10 years, respectively, compared to 0.68 years for Whites. Chen et al. [18] reported that, since the pandemic started, in California, excess mortality has been highest among older adults, males, Black and Latino residents, and those without a college degree. Comparing March through April to May through August of 2020, Hispanics and those without a high school degree had the greatest increase in excess deaths. Hispanic excess deaths increased from 16/million to 51/million during this period. That Hispanic and non-Hispanic Blacks were the least willing to be vaccinated among racial/ethnic groups in our study compounds the problem of their vulnerability to the disease. Vaccine hesitancy has been well studied among healthcare workers [6] , but there are fewer data available on vaccine hesitancy in other occupational groups, and the present findings provide some insight into a number of occupational sectors, some of which have been given priority in terms of receiving vaccines in the U.S. (e.g., educators, first responders, food service workers). In general, with the exception of first responders, those ""white collar"" occupations requiring more education, such as educators, office and professional or technical workers, and healthcare workers were more willing to be vaccinated than those ""blue collar"" occupations requiring less education, such as housekeeping, cleaning and janitorial, retail and food workers, and homemakers. First responders were an exception, where 74% of them had 4 year or graduate college degrees, yet they were the least willing to be vaccinated of any occupational group, despite being given priority for vaccination in California and many other states. Willingness to be vaccinated was related most strongly to concerns about the safety of the vaccine across all demographic and occupational groups, and to a lesser extent, with protecting others by being vaccinated and to the question of whether COVID-19 is a serious disease. It was not highly related to convenience of being vaccinated or to whether one said they calculated the risks versus benefits of being vaccinated. Since carrying out this survey, COVID-19 vaccines have become available. In California, vaccine rates have lagged for Hispanics and Blacks, compared to non-Hispanic Whites and Asians, most recently with rates for Hispanics and Blacks at about half their level of representation in the state's population [19] . The survey was administered prior to any COVID-19 vaccine being available, and the research of Nguyen [10] showed that vaccine hesitancy within the US declined in December, after the first vaccines were authorized for emergency use. With increasing evidence of the safety of vaccines, it is likely that hesitancy declined among our respondents after the introduction of the vaccines. The survey that is the basis for this study was carried out as part of an activity by a community vaccine taskforce and the results have provided insights used in the development of approaches to reducing vaccine hesitancy in the local county, particularly directed toward under-vaccinated populations such as Hispanics, food service workers and first responders, all of whom were among the most hesitant in our survey. The online version contains supplementary material available at https:// doi. org/ 10. 1007/ s10900-021-00987-0. Author Contributions All authors participated in the design of the study. CD, AP and C Condon participated in data collection, and data analysis. CD, JQ, KK, and DD participated in implementation of the survey. CD wrote the draft of the paper and all authors, including CC, participated in editing it. Funding No external funding supported this research.@story_separate@Willingness to be vaccinated against COVID-19 varied significantly by gender, age, race/ethnicity, and level of education as well as by occupation. Being Hispanic, non-Hispanic Black, younger, female, first responders or blue collar workers was associated with less willingness to be vaccinated. Nevertheless, some of the same concerns were related willingness to be vaccinated across all groups. Confidence in the safety and efficacy of the vaccine, concern for protecting others and belief in the seriousness of the disease were all associated with greater willingness to be vaccinated. Some of the least willing occupational groups in this study, i.e., first responders and construction, maintenance and landscape workers and housekeeping, cleaning and janitorial workers, had less belief in the seriousness of the disease. These results provide suggestions about which demographic and occupational groups need to be targeted in efforts to reduce vaccine hesitancy and provide some direction on what issues need to be addressed for each group.","Willingness and reasons to be vaccinated against COVID-19 were examined among 26,324 respondents who completed a survey on willingness and questions related to Confidence in vaccine safety, Complacency about the disease, Convenience of vaccination, tendency to Calculate risks versus benefits, and Concern for protecting others. Willingness to be vaccinated differed by age (p < 0.001), by race and ethnicity (p < 0.001) and by level of education (p < 0.001). Willingness generally increased with age and education. Asians were most willing to be vaccinated, followed by non-Hispanic Whites, Hispanics, and non-Hispanic Blacks (p < 0.001). Occupational groups differed in willingness (p < 0.001). Retired and students were more willing than all others (p < 0.001) followed by disabled or unemployed, healthcare workers, and educators. First Responders were least willing to be vaccinated (p < 0.001) followed by construction, maintenance and landscaping, homemakers, housekeeping, cleaning and janitorial workers, and retail and food service. The strongest predictor of willingness was confidence with the safety of the vaccine (r = 0.723, p < 0.001), followed by concern with protecting others by being vaccinated (r = 0.574, p < 0.001), and believing COVID-19 was serious enough to merit vaccination (r = 0.478, p < 0.00). Using multiple regression, confidence in safety was the strongest predictor for all groups. Protecting others was strongest for 13 of 15 demographic groups and 8 of 11 occupational groups. College educated, non-Hispanic Whites, first responders, construction, maintenance and landscape workers, housekeeping, cleaning and janitorial workers all gave greater weight to complacency about the disease. These results can help in designing programs to combat vaccine hesitancy. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s10900-021-00987-0."
"The COVID-19 pandemic continues to cause a pressing and ongoing challenge to global public health. While over 100 million have recovered worldwide, it is increasingly acknowledged the effects of COVID-19 can ripple beyond the acute presentation, with growing evidence of chronic symptoms and new multisystem disease having implications for future health service planning. 1 Termed 'long Covid' or 'post-acute Covid syndrome', various prevalence estimates are reported. The Office for National Statistics estimates that over a four week period, 1.1 million individuals in the UK self-reported long COVID-19 symptoms persisting over four weeks, with 13.7% of 20 000 individuals continuing to experience symptoms >12 weeks. 2 Self-reported symptom data from the Covid Symptom Study smartphone app of over 4000 patients mainly across the UK and US noted lower estimates. 3 In addition to persistent symptoms, evidence is also emerging of new end-organ dysfunction in those who recover from acute infection, with a potential to negatively impact cardiovascular, 4 respiratory, 5 metabolic, 6 haematological, 7 it is estimated that 80% of COVID-19 cases are mild, with only 3.5% of cases in England requiring hospitalisation at the start of the first wave, 12 and 10.5% requiring hospitalisation cumulatively since the start of pandemic. 13 Notably, patient group letters, 14 surveys, 15 and . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.@story_separate@The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint qualitative studies highlight a high proportion of patients with persistent debilitating symptoms who either had no access to testing or tested either positive or negative yet were not hospitalised. 16 Few studies have compared outcomes across the spectrum of COVID-19 severity post-acute infection, with findings to date limited in generalisability owing to small cohort sizes and selection biases. 15 Understanding the nature and burden of post-COVID-19 sequelae across different patient groups is crucial to shaping effective rehabilitation services that can provide adequate and tailored support to those affected. In this study, we used a large UK primary care longitudinal dataset, broadly representative of the UK population, to investigate new primary care-recorded symptoms, diseases, prescriptions and healthcare utilisation in patients post-acute infection, comparing outcomes between those managed in the community and those hospitalised. We used the Clinical Practice Research Database (CPRD) Aurum, a nationally representative database of anonymised primary care electronic healthcare records, which holds data on symptoms, diagnoses, prescriptions, test results, immunisations, consultations, hospitalisations and specialist referrals for over 39 million patients across the UK, covering approximately 19% of the UK population. 17 It is one of the largest longitudinal databases worldwide and its use has been extensively validated. 18 Clinical information is entered using SNOMED CT codes, while prescriptions are recorded using British National Formulary codes. Data from patient records are . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint only used if of a certain standard of quality. For participating general practices, data from secondary care encounters is also fed back into primary care records and CPRD Aurum. The study population included individuals aged 18 years or over, registered with a general practice contributing to CPRD Aurum. Cases of COVID-19 were identified from 1st August -17th October 2020. Patients' index date was their COVID-19 diagnosis date. Eligible patients were categorised as community or hospitalised COVID-19 patients, depending on hospital admission for COVID-19 within two weeks of index date. Patients were followed up to three months, with censoring at the earliest of transfer out of practice, death or end of follow-up (Fig. 1) . Patients with evidence of any investigated outcome preceding their COVID-19 diagnosis were excluded from individual analyses to ensure we captured outcomes due to COVID-19 infection rather than pre-existing factors. Outcomes were also determined for the same cohort at 6 and 12 months prior to each patient's index date. This enabled evaluation of outcome patterns pre-COVID-19 (12 months prior), at the beginning of the pandemic (6 months prior), and post-COVID-19, in the same patients. This was important as changes in healthcare utilisation during the pandemic have been recognised and may influence outcome events. 19 Baseline characteristics included the most recent measurement of body mass index (BMI) within five years of index date. Smoking status and the Charlson Comorbidity Index (CCI) were . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint identified at any time point before COVID-19 diagnosis. (Fig.1) . CCI was identified using a previously published algorithm. 20 Outcomes were considered as symptoms and diseases most likely to affect patients postinfection, guided by previous literature. Codelists were reviewed by a clinician and are accessible at: https://github.com/NHLI-Respiratory-Epi/code_lists/blob/main/25_Long_Covid/Long_Covid_codelists. Specifically, we identified new symptoms, diseases, prescriptions and healthcare utilisation. New symptoms were chosen in concordance with the NICE 2020 guideline on common symptoms persisting post-acute infection. 10 For symptom, prescription and healthcare utilisation outcomes, a new event was defined as the first occurrence four weeks after COVID-19 diagnosis, in line with the current NICE definition. For disease outcomes, a new event was defined as the first occurrence after COVID-19 diagnosis. Patients with any of the defined symptoms in the preceding month prior to COVID-19 diagnosis were excluded from analyses. For diseases and prescriptions, a 12-month exclusion window was applied. (Fig. 1) . The list of outcomes studied can be found in the appendix (p 3). Baseline characteristics are presented as frequencies (%) for categorical data and median with interquartile ranges [IQR] for numerical variables. Event rates and 95% confidence intervals for . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint each outcome were calculated as the number of patients who experienced the outcome divided by person-time at risk. To understand which patients may be at higher risk of post-COVID-19 outcomes in those managed in the community, event rates were stratified by sex and age (above and below 50 years old). Cox regression analysis was performed to compare outcome event rates between hospitalised and non-hospitalised cohorts. Finally, we examined the frequency of ten outcomes (anxiety, breathlessness, fatigue, muscle pain, chest pain, chest tightness, insomnia, palpitations, lung fibrosis, and bronchodilator prescription) among the non-hospitalised subgroup. The ten outcomes were those for which there was evidence of an increase in event rates post-COVID-19 relative to prior timepoints. All statistical analyses were conducted using Stata 16. Graphs were created using R 4.0.3. We extended the two-week window for identifying hospitalised COVID-19 cases to three and four weeks, respectively. A further analysis identified symptom and prescription outcomes two weeks after COVID-19 diagnosis instead of four weeks. While there has not been any specific patient or user group involvement in the design of this study, patient involvement will be facilitated in communication of findings to patients in long-COVID clinics to guide their ongoing management and care. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) Table S1 ). . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 13, 2021. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted April 13, 2021.  For most symptoms, hospitalised patients had higher event rates than the community group (Fig.   2 ). These included breathlessness, cough, joint pain, chest pain, fatigue, abdominal pain, nausea, skin rashes, dizziness, fever, diarrhoea, cognitive impairment, and delirium. The largest differences between hospitalised and community patients were respectively noted for rates per  . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. Table S2 ). There were non-significant differences of general and neuropathic pain, muscle pain, headache, paraesthesia, insomnia, ear/nose/throat symptoms and anorexia (Appendix Table S5 ). Palpitation rates were the same in both groups post-COVID-19 but higher rates of chest tightness and tinnitus were noted in the community group, although absolute rates were very low (<10 per 100 000 person weeks) (Appendix Table S2 ). Regarding most diseases, hospitalised patients had higher event rates than the community group ( Fig. 3) . These included all cardiovascular and haematological conditions, diabetes, adrenal disease, renal failure and arthritis. The largest differences between hospitalised and community patients were respectively noted for rates per 100,000 person-weeks Table S3 ). Rates of asthma, lung fibrosis, GORD, liver disease, anxiety and depression were not statistically significantly different between groups (Appendix Table S3 and S6). . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint By contrast, absolute rates of lung fibrosis were higher in the community group, although rates were very low (<5 per 100,000 person-weeks). There were no events for either thyroid disease or inflammatory bowel disease in either group. Prescription of all medications occurred more commonly in the hospitalised than the community group post-COVID-19 (Fig. 4) . For analgesics, rates respectively per 100,000 person-weeks  The hospitalised group utilised more healthcare (including GP visits, referrals, A&E, hospitalisation) than the community group post-COVID-19, with a 2.7-fold difference in rates Table S5 ). Symptoms Both groups experienced an increase in rates for chest pain, fatigue and breathlessness post-COVID-19 relative to 12 months prior (Fig. 2 , Appendix Table S2 ). Rates increased for some . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint symptoms for only those hospitalised post-COVID-19 relative to 12 months prior, with nausea showing the largest increase. Although absolute rates were very low, small increases in rates of chest tightness, tinnitus, insomnia and palpitations over the same period were only noted in the community group. For both groups, rates of cough were lower post-COVID-19 relative to prepandemic rates, while general and abdominal pain, headache, delirium, dizziness and earache remained similar. Lower rates of hypertension, stroke and diabetes were noted at 6 months prior relative to other timepoints in both groups (Fig. 3 , Appendix Table S3 ). While rates of renal failure, diabetes and adrenal disease remained relatively stable in the community group post-COVID-19 relative to 12 months prior, rates of renal failure and diabetes increased 2.92 and 2.37 fold, respectively, in the hospitalised group. VTE rates increased in both groups, but significantly more in the hospitalised group. By contrast, rates of depression were very similar post-COVID-19 relative to those prepandemic in both groups. At all timepoints, those hospitalised had higher prescription rates for each medication type than the community group (Fig. 4) . Rates of diuretics were broadly similar post-COVID-19 in both groups relative to pre-pandemic rates (Appendix Table S4 ). While rates for inhalers and analgesics remained similar over the same time period for the community group, rates increased for those hospitalised (bronchodilators: 2.35 fold; ICS 2.2 fold; paracetamol 6.75 fold; NSAIDs 1.9 fold; opiates 1.64 fold). . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint Differences in healthcare utilisation post-COVID-19 between the two groups showed a similar pattern to those at both prior timepoints. However, while healthcare utilisation increased in both groups post-COVID-19 relative to pre-pandemic levels, this was much higher in the hospitalised group (61.2% increase v. 28.5%). Healthcare utilisation was lower 6 months prior relative to other timepoints for each group (Appendix Table S5 ). Overall, men <50 had the lowest rates of symptoms, disease, and prescriptions. There were differences in age whereby older adults had higher rates of breathlessness, chest pain, cognitive impairment, dizziness, delirium, muscle pain, cough, diabetes, arthritis, VTE, and opioid, paracetamol, and diuretic prescriptions compared to younger adults. Older adults also had higher rates of cardiovascular disease, notably in men. Women had higher rates of fatigue and older women in particular had higher rates of joint pain compared to men. Younger women had higher rates of headache and anxiety compared to men and higher rates of skin rash, depression, and sore throat compared to men and older adults. (Fig.   5 -7, Appendix Tables S7-S18). The majority of the community COVID-19 population (43,390 of 45,272 [95.8%]) did not experience any of the ten outcomes identified as having increased event rates post infection . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint relative to the 6 and 12-month prior periods. A total of 1,882 (4.2%) individuals experienced at least one of these outcomes. Anxiety, breathlessness, chest pain, fatigue, and bronchodilator prescriptions were the most frequent outcomes. Approximately 25% of patients experienced anxiety or breathlessness, 15% chest pain, 13.3% fatigue, and 16.7% received a new bronchodilator prescription, of which 90.3% were short acting beta-agonists. Classification of patients as hospitalised cases at three or four weeks yielded similar results to using a two week window. The number of patients classed as hospitalised cases within three weeks of a positive test was 1,633 (3.5%); within four weeks this increased to 1,814 (3.9%). Analyses of event rates that identified symptom and prescription outcomes from two weeks after COVID-19 diagnosis showed similar results to those described in figures 2-4. (appendix Tables S19-S22) This is the first population-based study in the UK investigating symptoms, diseases, prescriptions and healthcare utilisation among people hospitalised or managed in the community following COVID-19 diagnosis. For most outcomes, hospitalised patients had higher event rates than the community group. However, there were pertinent differences between groups, with the post-COVID-19 community group having higher rates of chest tightness, tinnitus and lung fibrosis, thus highlighting important differences in post-COVID-19 sequelae and suggesting that post-COVID-19 follow up and management strategies will need to be tailored appropriately. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint Further in-keeping with the lower rate of outcomes in those managed in the community in comparison to those hospitalised, a post-acute burden of sequelae was captured in only 4.2% of cases managed in the community. Anxiety, breathlessness, chest pain and fatigue were most frequently reported, alongside prescriptions for bronchodilators. Furthermore, age and sexspecific differences in outcomes were noted, with older adults experiencing higher rates of most symptoms, cardiovascular disease, diabetes, VTE and analgesic prescriptions such as paracetamol and opiates. In addition, women had higher rates of fatigue, with higher rates of headache, anxiety and depression in younger women. While primary care consultation rates have been shown to be lower in men than women and may account for some of the sex-specific differences noted, consultation rates in men and women with comparable underlying morbidities tend to be similar. 21 While healthcare utilisation increased in both groups post-COVID-19 relative to pre-pandemic levels, this increase was significantly higher in the hospitalised group. Nevertheless, healthcare utilisation in the community group increased 28.5% in the post-COVID-19 period relative to prepandemic levels, highlighting a need to ensure adequate provision of care for this population. This increase since pre-pandemic levels also suggests that lack of access to healthcare following the second wave is less of a problem than in wave one; however, evidence indicates this can nevertheless still be difficult. 16, 19 Contrary to our findings however, a Norwegian study suggested that mild COVID-19 does not persist to cause a need for healthcare beyond two months following a positive test. 22 . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.  There is a growing body of literature on post-acute COVID-19 outcomes among people who have been hospitalised, [23] [24] but little that compares those managed in hospitals with those managed in the community. Our findings are in keeping with the few such studies that exist, whilst adding a depth of understanding of the situation in the UK. A study from Israel found a substantially lower prevalence of ongoing issues in the community population compared with hospitalised cohorts in other studies, the most common being fatigue, myalgia, runny nose and shortness of breath. 25 Small studies investigating lung function in the non-hospitalised post-acute COVID-19 population have also found that over two months post infection, 46% of patients remained symptomatic, with lower lung function in this group than asymptomatic patients. 26 A US-based study comparing post-acute COVID-19 sequelae in those with mild, moderate and severe illness found older age groups were more likely to report persistent symptoms, the most common being fatigue (13·6%) and anosmia (13·6%). 27 Another study from the Netherlands and Belgium found a larger median reduction in symptom number at 80 days follow-up in those nonhospitalised compared with those hospitalised. 15 However, only 0.7% of their respondents were symptom-free at 80 days, highlighting that surveys and healthcare record data do provide different magnitudes of effect. Indeed, the aforementioned Israeli study which used both methods found differences in prevalence between self-reported symptoms and health records. 25 Whilst . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint survey estimates of symptom burden in those non-hospitalised are much higher than in our study, this is most likely due to selection bias, coupled with a higher tendency towards symptom reporting in surveys and in those with suspected COVID-19. 15, 25 Persistent fatigue in both those hospitalised and not has been a common finding in several studies. 3, 25, 27 In common with other studies, we found high rates of post-COVID-19 diabetes in the hospitalised 24 ; diabetes was also one of the diseases with the largest hospital-community differences. A bidirectional relationship has been postulated between diabetes and COVID-19, with diabetes leading to higher risk of infection and worse outcomes but also some evidence that COVID-19 may precipitate diabetes. 28 This is complicated by the fact there has been a reported reduction in diagnosis of type 2 diabetes during the pandemic. 29 Likewise, renal impairment and VTE have been recognised post hospitalisation. 7,30 Our study purposefully only included COVID-19 patients from wave two, when testing capacity was much higher, thereby limiting potential selection biases. That our proportion of hospitalised patients is in keeping with UK national estimates increases our confidence that our study population is broadly representative. Whilst we cannot ascertain whether symptoms recorded on primary care records were directly due to COVID-19 or other conditions, we did investigate event rates among the same cohorts 6 and 12 months prior to contextualize our findings. In addition, we did include a window of no symptoms to ensure diseases, symptoms and prescriptions captured were new and not pre-existing to the COVID-19 diagnosis. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint Risk of misclassification of diseases and symptoms, an inherent weakness of studies of this nature, was minimised by using previously validated codelists wherever possible and creating codelists tailored to the objectives of this study. We were unable to capture the effect of socioeconomic status as these data are not available in primary care records and accept that this is a limitation. Nor have we been able to consider the severity of our investigated outcomes. Given the relatively short follow-up period, we may be missing some symptoms and diseases which occur later in the trajectory of long-Covid. For this reason, we plan to repeat this analysis in the future. It is also likely that we will have missed some cases of new onset symptoms or diseases post-COVID in those patients who choose not to seek medical care and manage symptoms independently with over-the-counter medications. Furthermore, qualitative studies have revealed perceived barriers in primary care accessibility and limited understanding of long-Covid among clinicians. 16 These factors may also lead to underreporting and under-recording of symptoms/diseases. With over 4 million individuals recovered from acute COVID-19 in the UK at the time of writing, 13 our findings of multi-system symptom and disease burden, with a predominance in those hospitalised, has significant implications for future healthcare service planning. While healthcare utilisation increased relatively more in those hospitalised, there was nevertheless an increase in those managed in the community too, suggesting current healthcare service provision may need to be moulded to meet this increasing demand. Furthermore, given the significant interest in long-Covid globally and calls for further research in assessing interventions in . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint individuals continuing to suffer ongoing effects of COVID-19 who have not been hospitalised, findings from this study are timely. To date, the focus has overwhelmingly been on studies assessing outcomes in hospitalised COVID-19 patients, with a significant paucity of studies exploring outcomes in those with milder disease who did not require hospitalisation. The multisystem nature of symptoms and diseases noted in both non-hospitalised and hospitalised cases highlights the importance of providing integrated multidisciplinary care in post-COVID-19 management. • Persistence of symptoms and new organ dysfunction post-COVID 19 have been recognised in several small observational studies but this has been primarily in . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint hospitalised patients with more severe disease. • Few studies compare outcomes between non-hospitalised and hospitalised individuals, with studies to date limited by small cohort sizes and selection biases; no large population-based cohort studies exist assessing outcomes between groups. • Hospitalised patients had higher rates of most post-COVID-19 sequelae compared to those managed in the community, with additional age and sex-specific differences in outcome rates for the latter. • Healthcare utilisation in the community group increased 28.5% post-COVID-19 relative to pre-pandemic. However, only a small proportion (4.2%) of this group experienced outcomes resulting in increased event rates post infection relative to prediagnosis; anxiety, breathlessness, chest pain and fatigue were most frequently reported. • This large population-based study complements ongoing work exploring outcomes post-COVID-19, while also highlighting that post-COVID-19 management strategies will need to be tailored to specific patient group needs. Contributors: JKQ conceptualised the study and all authors contributed to study design. HRW, CG, AK, AM, CI, and RS created codelists for outcomes of interest. HRW, CG, CK and AM . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. The funder had no role in study design, data collection, analysis or interpretation, or manuscript writing. All authors had full access to all the data in the study and had final responsibility for the decision to submit for publication. HRW, CG, AK, CK, AM, CI, MW have nothing to declare. RG is a current employee of Gilead Sciences, outside the submitted work. JKQ reports grants from AUK-BLF, The Health Foundation, grants and personal fees from AZ, BI, GSK, Bayer, grants from Chiesi, outside the submitted work. This research was supported by the National Institute for Health Research (NIHR) Imperial . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021.  The corresponding author confirms that the manuscript is an honest, accurate, and transparent account of the study being reported, that no important aspects of the study have been omitted and that any discrepancies from the study as originally planned have been explained. Linked pseudonymised mortality data from the Office for National Statistics (ONS), socioeconomic data from the Index of Multiple Deprivation (IMD), and secondary care data from Hospital Episode Statistics (HES) were provided for this study by CPRD for patients in England. Data is linked by NHS Digital, the statutory trusted third party for linking data, using identifiable data held only by NHS Digital. Select general practices consent to this process at a practice level, with individual patients having the right to opt-out. Use of HES and ONS data is Copyright © (2018), re-used with the permission of The Health & Social Care Information . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021.  This study used existing data from the UK CPRD electronic health record database, this data resource is accessible only to researchers with protocols approved by the CPRD's independent scientific advisory committee; therefore, no additional unpublished data are available. All data management and analysis computer code are available on request. The study protocol and analysis plan are available in the associated supplementary material. The Corresponding Author has the right to grant on behalf of all authors and does grant on behalf of all authors, a worldwide license to the Publishers and its licensees in perpetuity, in all forms, formats and media (whether known now or created in the future), to i) publish, reproduce, distribute, display and store the Contribution, ii) translate the Contribution into other languages, create adaptations, reprints, include within collections and create summaries, extracts and/or, . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint abstracts of the Contribution, iii) create any other derivative work(s) based on the Contribution, iv) to exploit all subsidiary rights in the Contribution, v) the inclusion of electronic links from the Contribution to third party material where-ever it may be located; and, vi) license any third party to do any or all of the above. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. ; https://doi.org/10.1101/2021.04.09.21255199 doi: medRxiv preprint . CC-BY-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted April 13, 2021. @story_separate@We have shown that across symptom, disease, prescription and healthcare utilisation outcomes, people who were hospitalised with COVID-19 had higher event rates in the post-acute phase compared with those managed in the community. Among the latter, post-acute COVID-19 outcomes were higher in those over 50 years old and in women. Of those managed in the community with any post-acute burden, anxiety, breathlessness, chest pain and fatigue were the most frequently reported. Studies with longer follow-up will help provide further insight into the longitudinal trajectory of post-COVID-19 sequelae, however it appears that ongoing needs in those admitted to hospital or managed in the community will differ.","Objective To compare post-COVID-19 sequelae between hospitalised and non-hospitalised individuals Design Population-based cohort study Setting 1,383 general practices in England contributing to Clinical Practice Research Database Aurum Participants 46,687 COVID-19 cases diagnosed between 1st August to 17th October 2020 (45.4% male; mean age 40), either hospitalised within two weeks of diagnosis or non-hospitalised, and followed-up for a maximum of three months. Main outcome measures Event rates of new symptoms, diseases, prescriptions and healthcare utilisation in hospitalised and non-hospitalised individuals, with between-group comparison using Cox regression. Outcomes compared at 6 and 12 months prior to index date, equating to first UK wave and pre-pandemic. Non-hospitalised group outcomes stratified by age and sex. Results 45,272 of 46,687 people were non-hospitalised; 1,415 hospitalised. Hospitalised patients had higher rates of 13/26 symptoms and 11/19 diseases post-COVID-19 than the community group, received more prescriptions and utilised more healthcare. The largest differences were noted for rates per 100,000 person-weeks [95%CI] of breathlessness: 536 [432 to 663] v. 85 [77 to 93]; joint pain: 295 [221 to 392] v. 168 [158 to 179]; diabetes: 303 [225 to 416] v. 36 [32 to 42], hypertension: 244 [178 to 344] v. 47 [41 to 53]. Although low, rates of chest tightness, tinnitus and lung fibrosis were higher in the community group. 4.2% (1882/45,272) of the community group had a post-acute burden, most frequently reporting anxiety, breathlessness, chest pain and fatigue. In those non-hospitalised, age and sex differences existed in outcome rates. Healthcare utilisation in the community group increased 28.5% post-COVID-19 relative to pre-pandemic. Conclusions Post-COVID-19 sequelae differ between hospitalised and non-hospitalised individuals, with age and sex-specific differences in those non-hospitalised. Most COVID-19 cases managed in the community do not report ongoing issues to healthcare professionals. Post-COVID-19 follow-up and management strategies need to be tailored to specific groups."
"Coronavirus disease 2019 (COVID-19) is a primarily respiratory tract infection caused by a newly recognized betacoronavirus named SARS-CoV-2, firstly diagnosed in China (Wuhan), in December 2019 [1] . Since then, the outbreak of this infection has spread rapidly across the globe. As of March 15, 2021, 87 .994 critically ill patients and 2.668.036 deaths had been reported [2] . The clinical spectrum of COVID-19 ranges from asymptomatic infection to severe respiratory failure [3] . Piacenza is a small city of Northern Italy very close to Codogno, the first city where a COVID-19 patient was identified in Italy. Consequently, the local hospital was quickly changed in a ""COVID-19 hospital"" [4] to manage a sudden increase in COVID-19 patients requiring hospital admission. The knowledge of COVID-19 patient characteristics and risk factors associated with intensive care unit (ICU) admission and mortality is still limited. Older age, male sex, comorbidities, lower ratio of arterial partial pressure of oxygen/fraction of inspired oxygen (PaO 2 /FiO 2 ) and higher SOFA score (Sequential Organ Failure Assessment) are independently associated with worse outcome in those admitted to the ICU [5] [6] [7] . However, only few studies analyzed the clinical characteristics and predictors of mortality in COVID-19 patients admitted to ICU in Italy [8, 9] . The definition of risk factors for mortality are mandatory to guide ICU capacity and resource allocation. The aim of this study was to develop a clinical prediction model for 28-day mortality in critically ill COVID-19 patients admitted to ICU.@story_separate@a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 This study was approved by the Local Ethics Committee and was conducted at Guglielmo da Saliceto Hospital of Piacenza. We retrospectively analysed a cohort of consecutive critically ill patients admitted to our ICU from Feb 22, 2020 to Apr 3, 2020 diagnosed with SARS-CoV-2 pneumonia, according to WHO interim guidance [10] . All the data were fully anonymised before the access and a random alphanumeric code was used to identify each patient in the database. COVID-19 infection was diagnosed by a positive result of real-time reverse transcriptasepolymerase chain reaction (RT-PCR) assay of nasal and pharyngeal swabs. Critically ill patients were defined as those admitted to ICU who required mechanical ventilation or had a fraction of inspired oxygen (FiO 2 ) of at least 60% or more [11] . Pregnant women, children (those younger than 18 years of age) and patients with two negative RT-PCR assay were excluded from the study. Informed consent was collected in only a small amount of patients due to the rapidly worsening of their clinical conditions. The ethics committee allowed this conduct since the early COVID-19pandemic phase has seriously hampered the ability to achieve a traditional informed consent before study enrolment. We reviewed all the electronic medical records to collect demographic, clinical, laboratory and radiologic data from the hospital management software within the first 24 hours of ICU admission. The following laboratory variables were considered: complete blood cells count, C-reactive protein (CRP), creatinine, glucose, total bilirubin and procalcitonin. Data from high-resolution chest computed tomography (CT) performed within 2 days of ICU admission were collected. CT lung pattern were defined as Patchy Ground-Glass Opacities (GGO), diffuse GGO, mixed consolidation + GGO or consolidation. The presence of bilateral lungs involvement, the visual assessment of lung involved percentage [12] and the presence of lung consolidation were also considered. Visual quantification was used to classify patients as the percentage of lung parenchyma affected by COVID-19 lesions. A radiologist with five years of experience performed the evaluation of each lung CT. Patients' clinical history including demographic data, medical comorbidities, Covid-19 symptoms duration before hospitalization were also collected. Lung protective ventilatory strategies were adopted and patients were treated according to current guidelines [13] . A descriptive statistics was carried out. Continuous variables are reported as median and interquartile range while categorical data as relative number and percentage. Shapiro-Wilk test was used to test normality of distribution. We used the Mann-Whitney U test, χ2 test, or Fisher's exact test to compare differences between survivors and non-survivors. Potential predictors variables of 28-day mortality were firstly chosen based on their ease measurement during the ICU admission or for their previously showed role as mortality predictor [5, 14] . Due to the high clinical and radiological homogeneity of critically ill COVID-19 patients admitted to our ICU during the study period, we decided to use a Cox model to consider time-dependent covariates. A Kaplan-Meier survival estimates were used to evaluate the 28-day survival. The association of risk factors with 28 day-mortality was assessed in univariable and multivariable Cox proportional hazards regression models. The proportional hazard assumption was tested by plotting the Nelson-Aalen cumulative hazard function and Schoenfeld residuals test. A forward regression analysis was used to select variables accepted in the multivariable model. Factors for which p values were less than 0.1 in univariable analysis were used as candidate variables for multivariable approach. The Akaike information criterion was used to compare different regression models and to select the most parsimonious model. Model performance was assessed via discrimination and calibration measures. To assess for discrimination, the C statistic was used. A calibration curve was implemented by comparing the predicted probabilities and the actually observed proportions, using the Stata module ""pmcalplot"" [15] . The TRIPOD (transparent reporting of a multivariable model for individual prognosis or diagnosis) guidance was used to conduct this study and to report the results of the prediction model [16] . For internal validation of the model, a non-parametric bootstrap (1000 replications) of the original model was run. The bootstrapped samples were created by drawing random samples with replacement from the development database. The prediction model was fitted on each of bootstrap samples. To adjust for optimism after model development, estimates of a uniform shrinkage factor (the average calibration slope from each of the bootstrap samples) were obtained and multiplied by the original β coefficients to obtain optimism adjusted hazard ratios for each variable [17] . Results are expressed as hazard ratio with 95% confidence intervals (95%CI) and p values. Statistical significance was set at a two tailed P value <0.05. STATA MP, version 16.0 (STATA Corp., Texas, USA) was used for the analysis. 242 patients with a confirmed SARS-CoV-2 infection were admitted to our ICU during the study period and represent the studied population. Two other patients were excluded due to negative RT-PCR findings for SARSCoV-2. The median age of the patients was 64 years (56-71 IQR) and 196 (81%) were male. Almost one comorbidity was present in 147 patients (61%) of which hypertension was the most common (46.7%), followed by diabetes (15.3%) and heart disease (14.5%), ( Table 1 ). The most common findings at hospital admission were respiratory symptoms and fever (97.5% and 92.1% respectively), followed by gastrointestinal manifestations, mainly vomiting and diarrhea in 18.6%. Eighty-five patients (35.1%) died within 28 days after ICU admission and the median time from ICU admission to death was 11 days (IQR 6-18), (Fig 1) . The comparison of patients characteristics showed a higher prevalence of obesity (defined as BMI of at least 30 kg/m 2 ) in the non-survivors compared to survivors (18.8% vs 9.6%, p = 0.03, respectively). Non-survivor patients were older than survivors, with a median age of 66 (60-73 IQR) years in non-survivors and 62 (55-69) years in survivors (p = 0.0002) ( Table 1) . The median time from respiratory symptoms onset to hospital admission was not different in the two groups (7 days, 6-10 IQR in non-survivors vs 7 days, IQR 7-10 days in survivors, p = 0.67) as well as the length of hospital stay prior to ICU admission (4 days, 1-7 IQR in nonsurvivors vs 4 days, 1-6 IQR in survivors, p = 0.69). At ICU admission, 26.9% of the patients were treated with C-PAP for almost 1 day (IQR 1-3) while 177 (73.1%) required immediate mechanical ventilation and 80 patients (35%) required the use of prone position ventilation. All the patients received dexamethasone 6mg once daily for 7-10 day while only five patients received compassionate-use remdesivir. Laboratory findings at ICU admission are resumed in Table 2 . Lymphocytopenia (< 1×10 9 / L) occurred in the totality of the patients and no difference was found between survivors and non-survivors (p = 0.84). Higher white blood cell (WBC) and neutrophils count was found in non-survivors compared to survivors (WBC 12.1 x 10 9 /L, IQR 8.2-18.5 in non-survivors and 10.3 x 10 9 /L, IQR 7.5-13.5 in survivors, p = 0.005; neutrophils 11 x 10 9 /L, IQR 7.2-17.3 in non-survivors and 9 x 10 9 /L, IQR 6.4-12.4 in survivors, p = 0.003). Non-survivor patients presented a reduced platelets count (p = 0.002) and increased procalcitonin levels (p = 0.001). High-resolution chest CT was performed in 229 (95%) patients. CT findings are summarized in Table 3 . A consolidation + GGO pattern was the most common (53.7%) followed by diffuse GGO (24.9%). No difference in term of CT pattern was observed between survivors and non-survivors (p = 0.92). Bilateral lung involvement was present in 100% of the non-survivors and in the 97.3% of the survivors (p = 0.30). The extent of lesion on CT was very similar in the two groups and no differences were found (p = 0.69). Check of the proportionality assumption before regression revealed no violation (χ 2 = 10.02, p = 0.53). At univariable analysis diabetes (HR 1.80, 95% CI 1.07-3.04, p = 0.03), age (HR 1.05, 95% CI 1.02-1.08, p = <0.001), obesity (HR 1.99, 95% CI 1.15-3.45, p = 0.01), WBC count (HR 1.06, 95% CI 1.03-1.10, p<0.001), neutrophils count (HR 1.07, 95% CI 1.03-1.11, p<0.001), high-sensitivity C-reactive protein value (HR 1.03, 95% CI 1.00-1.05, p = 0.02), procalcitonin (HR 1.04, 95% CI 1.01-1.06, p = 0.002), SOFA score (HR 1.78, 95% CI 1.57-2.02, p<0.001), lactate (HR 1.02, 95% CI 1.00-1.04, p = 0.02), PaO 2 /FiO 2 (HR 0.99, 95% CI 0.98-0.99, p<0.001) were associated with 28-day mortality. Table 4 ). The C-statistic for the predicted 28-day mortality risk showed very good discriminatory capacity equal to 0.821 (95% CI 0.766-0.876) and 0.822 (95% CI 0.770-0.873) in the original and bootstrap models, respectively. The estimated bias was 1.1 � 10 −3 (95% CI 1.9 � 10 −2-3.4 � 10 −- ). The calibration plot revealed good agreements between the observed and expected probability of death (Fig 2) . The COVID-19 pandemic is a worldwide novel challenge for critical care systems since it has strongly proved ICU capacities. In the present study, multivariable Cox proportional hazards regression identified several prognostic markers for 28-day mortality. After adjustment for other factors, age, obesity, procalcitonin, SOFA and PaO 2 /FiO 2 were independently associated with 28-day mortality in critically ill COVID-19 patients. The majority of our patients (73%) were admitted to the ICU because of acute hypoxemic respiratory failure that required mechanical ventilation. The need for mechanical ventilation among COVID-19 patients admitted to ICUs ranges from 29.1% in one Chinese study [18] to 89.9% in a U.S. study [19] and 88% in an Italian study [8] . In this context, several studies have investigated the factors associated with death or ICU admission but limited information exist in Italian population for the prognostic factors associated with mortality in critically ill COVID-19 patients. The ICU worldwide mortality for COVID-19 respiratory failure is 25.7% [20] . In Italy, a rate of 25.6% [8] was initially reported but a few months later the same authors reported a mortality rate of 48.7% in a subsequent study [9] . In the current study, the 28-day mortality rate of COVID-19 critically ill patients was 35.1%. This data is close to the average of the two previously mentioned mortality rates and it is similar to what was reported for ARDS [21] . However, as Quah outlined it in a letter to editor, almost a half of patients were still in ICU when previous studies of ICU mortality were published [20] . On the contrary, at the time of writing this paper, no patients were still in ICU as they were deceased or discharged. This element increase the meaning of our data since all the patients concluded the 28-day follow-up. In our study, the patients were mainly middle-aged men with hypertension and the most common initial symptoms were fever and respiratory symptoms such as cough and dyspnea. These findings are in concordance with previously published studies [7, 8, 22, 23] . In fact, the age was independently associated with an increased risk of 28-day mortality in the multivariable analysis. This is not unexpected since this variable was extensively associated with adverse outcome [9, 24, 25] . Obesity was another important predictor of 28-day mortality (p = 0.04). This finding seems related to the chronic inflammatory state in obese patients [26] that can increase the excessive cytokine response to viral infection leading to adverse outcome [27, 28] . As we previously reported, obesity and morbid obesity were risk factors for death in critically ill COVID-19 patients [29] . An increase in procalcitonin levels was reported as an indicator of disease severity in COVID-19 patients [30] and as a risk factor for mortality [31] . Our findings seems in line with these evidences since an increase in procalcitonin levels is associated with increased 28-day mortality rates at multivariable analysis (p = 0.04). Interestingly, in our patients the presence of diabetes was not associated with an increased mortality risk. This is in contrast with many case series reporting that people with diabetes are at higher risk of COVID-19-related mortality [32] and ICU admission with poor outcome than people without diabetes [33] . However, some factors rarely considered such as type of diabetes, length of the disease and related complications, type of treatment and glycaemic controls during the infection could have affected the outcome. The lymphocytopenia observed in our patients confirms that they were critically ill COVID-19 patients since a low lymphocyte count is related to the severity of disease [34] . Higher Sequential Organ Failure Assessment (SOFA) score on admission was independently associated with an increased 28-day mortality risk (HR 1.37, 95% CI 1.01-1.05, p = 0.04). In fact, as it was previously published, this score is a highly sensitive marker of inhospital mortality in COVID-19 patients and can be considered as a risk-stratification tool for critical COVID-19 patients [35] . Moreover, a low PaO 2 /FiO 2 ratio at ICU admission was an independent risk factor associated with 28-day mortality. This is not unexpected since acute respiratory failure is the leading feature in critical COVID-19 patients. Even if male are at higher risk for mortality in the overall population, any difference in mortality rate could not be demonstrated between male and female patients once admitted to the ICU as previously reported by Nachtigall in a large group of critically ill COVID-19 patients hospitalized in Germany [36] . As it was previously published, a lung involvement >50% is associated with ICU admission in hospitalized patients [37] . On the other hand, patients with well-aerated lung parenchyma less than 73% are at increased risk for ICU admission or death [38] . Interestingly, in our patients, the radiological findings at chest CT were approximately the same in survivors and non-survivors and no predictive ability was found. Since the median time from symptom onset to the ICU admission as well as the length of hospital stay prior to ICU admission were similar in survivors and in non-survivors (p = 0.67) it is possible to argue that the observed lung abnormalities are related to the disease time course. Consequently, in our study it is not possible to verify the rule of radiological data to predict mortality. A high percentage of patients required mechanical ventilation since ICU admission and the principal reason for ICU admission was related to the severity of respiratory failure. We can suppose that disease severity was similar in survivors and in non-survivors. Therefore, due to the characteristics of our sample a validation of the clinical prediction model is needed. Many prognostication model for patients with COVID-19 were recently developed but a possible risk of bias was outlined due to the limited use of validation techniques [39] . For these reasons, we decided to perform an internal validation to prevent model over-fitting and to obtain a reduction of potential false positive prediction estimates. The bootstrap technique was used since it provides stable estimates with low bias of predictors [40] and it is considered as a central technique to correct overfitting and to quantify optimism in model performance [41] . To our knowledge, this is the first model of 28-day mortality in critically ill COVID-19 patients that was internal validated and it is the third study about critically ill COVID-19 patients requiring ICU admission in Italy. Moreover, our patients were admitted to ICU in a geographic area that is one of the first place where the COVID-19 outbreak spread across Italy. Our results were obtained from the first phase of the COVID-19 pandemic in Italy and helped us to improve our healthcare organization for the second pandemic phase. However, this model should be confirmed in the subsequent phases of this pandemic. Nevertheless, this study has several limitations. First, it is a retrospective study during a pandemic that overwhelmed the medical resources. Therefore, it is possible that some data present inaccuracies that might introduce some bias in the study results. Second, we did not collect data about complications during ICU length of stay such as secondary infection, organ failure or thrombosis. Thrombosis and thromboembolism have been reported as a relevant topic in COVID-19 critically ill patients with a prevalence up to 30% but these data were not clearly known at the time we admitted our patients to ICU. The same problem can be applied to Ddimer and IL-6 that we did not collect in every patient. Third, we did not collect the cause of death in our patients with COVID-19 but it is possible to suppose that hypoxemia was the leading cause of death. Forth, no data were collected about type of mechanical ventilation used along with pulmonary compliance and resistance even if two possible respiratory patterns were described [42] and a possible role in mortality rate could be supposed. Another major limit is the absence of an external validation for our model that we hope to perform in a subsequent cohort of COVID-19 critically ill patients.@story_separate@In this study we developed an internal validated prediction model for 28-day mortality of critically ill COVID-19 patients admitted to ICU with the use of simple and easy to collect clinical variables. Age, obesity, procalcitonin, SOFA score and PaO 2 /FiO 2 ratio emerged as independent predictors for mortality and should be carefully evaluated in these patients. We hope that these data might help a better organization of ICUs for the treatment of COVID-19 patients. Future studies with increased patients number and longer follow-up are needed to confirm our findings.","BACKGROUND: COVID-19 pandemic has rapidly required a high demand of hospitalization and an increased number of intensive care units (ICUs) admission. Therefore, it became mandatory to develop prognostic models to evaluate critical COVID-19 patients. MATERIALS AND METHODS: We retrospectively evaluate a cohort of consecutive COVID-19 critically ill patients admitted to ICU with a confirmed diagnosis of SARS-CoV-2 pneumonia. A multivariable Cox regression model including demographic, clinical and laboratory findings was developed to assess the predictive value of these variables. Internal validation was performed using the bootstrap resampling technique. The model’s discriminatory ability was assessed with Harrell’s C-statistic and the goodness-of-fit was evaluated with calibration plot. RESULTS: 242 patients were included [median age, 64 years (56–71 IQR), 196 (81%) males]. Hypertension was the most common comorbidity (46.7%), followed by diabetes (15.3%) and heart disease (14.5%). Eighty-five patients (35.1%) died within 28 days after ICU admission and the median time from ICU admission to death was 11 days (IQR 6–18). In multivariable model after internal validation, age, obesity, procaltitonin, SOFA score and PaO(2)/FiO(2) resulted as independent predictors of 28-day mortality. The C-statistic of the model showed a very good discriminatory capacity (0.82). CONCLUSIONS: We present the results of a multivariable prediction model for mortality of critically ill COVID-19 patients admitted to ICU. After adjustment for other factors, age, obesity, procalcitonin, SOFA and PaO2/FiO2 were independently associated with 28-day mortality in critically ill COVID-19 patients. The calibration plot revealed good agreements between the observed and expected probability of death."
"The first case of the peculiar virus was detected in Wuhan, China, in December 2019, and initially it was treated as pneumonia of unknown etiology. After analyzing the samples, a novel virus was detected, and it was declared novel coronavirus pneumonia [1, 2] . Later the name was given to this virus as severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) by the International Committee on Taxonomy of Virus [3] . The World Health Organization (WHO) on February 11, 2020, named this virus ""Coronavirus disease-19 (COVID-19)"" [4] . The first COVID-19 case was diagnosed in Pakistan on February 26, 2020, in the city of Karachi. Later on, it became impossible to control the spread of infection and soon it spread to the whole of Pakistan. With the increasing rate of incidence of disease, the number of patients with the COVID-19 disease or suspected of having the disease increased rapidly, and these patients were being received in emergencies and outpatient departments at an alarming rate due to which decision was made to postpone elective surgeries [5] . However, it was not possible to postpone emergency surgeries, and thus, healthcare professionals were at high risk of exposure to the disease and infection. The extensive spread of this disease caused the hospitals to continue prioritizing treatment of COVID-19 patients and deal with emergency surgeries only so as to reduce chances of mortality while postponing elective surgeries if possible. The purpose of this study was to analyze the surgical procedures of COVID-19-positive patients in the general surgery department performed during the ongoing pandemic in a tertiary care hospital.@story_separate@A total of 79 COVID-19-positive patients were provided with surgical services and subsequently analyzed. The mean age of those patients was 48.88 ± 16.62 years. The mean length of stay in the hospital was 2.10 ± 3.52 with indifference among gender and mode of treatment (either surgical or conservative). The study participants were 59.5% males and 40.5% females, and only 6.3% had a past surgical history. Most patients were admitted through the outpatient department (65.8%), and only a few were referrals from other departments (10.1%); 64.5% of patients were managed in general wards, 24.0% in critical care units, and 11.4% in intensive care units. Surgical intervention was done in 60.8% of the COVID-19-positive patients, while the rest 39.2% were conservatively managed. Among whom, 63.3% were discharged, 29.1% of them left against medical advice (LAMA), with a 7.6% death rate during the hospital stay. The frequent comorbidities were diabetes (27.8%) and hypertension (26.6%), although most patients had no comorbidities (49.3%). Symptomatic gall stones were the most frequent reason for surgical admission in COVID-19-positive patients, while the most frequent surgical intervention performed was laparoscopic cholecystectomy. Males were comparatively managed more frequently by surgical intervention and females been more conservatively managed (p = 0.037). Out of the six mortalities, five were surgically managed. Seventy seven percent of the surgically managed patients were discharged, and the majority of LAMA patients were being conservatively managed (p < 0.001). A retrospective clinical audit was conducted in a tertiary care hospital that receives surgical cases from almost all over the country. Ethical approval was granted prior to the execution of this intra-departmental audit. Both patients who were admitted to general surgery and visited on a consultative basis in other departments during the year 2020 were evaluated, and only those having COVID-19 polymerase chain reaction (PCR)-positive were included. Those with PCR-negative were omitted from the analysis. All the surgical procedures performed in these patients, along with those managed conservatively, were analyzed. Basic and demographic data of all patients were collected from electronic medical records. The data was assembled into Statistical Package for Social Sciences (SPSS, version 25.0) for Windows (IBM Corp., Armonk, NY). The data were defined as either mean and standard deviation or frequency and relative percentages. The normality of the data was verified by the Shapiro-Wilk test. Parametric analysis was used to interpret the disparity in descriptive statistics. Although the categorical results were compared by cross-tabulation, the degrees of significance were calculated either by chi-square test or Fisher's exact test according to the distribution of the data. A p value of less than 0.05 was considered significant (two-tailed). A total of 79 COVID-19-positive patients were provided with surgical services and subsequently analyzed. The mean age of those patients was 48.88 ± 16.62 years. The mean length of stay in the hospital was 2.10 ± 3.52 with indifference among gender and mode of treatment (either surgical or conservative). The study participants were 59.5% males and 40.5% females, and only 6.3% had a past surgical history. Most patients were admitted through the outpatient department (65.8%), and only a few were referrals from other departments (10.1%); 64.5% of patients were managed in general wards, 24.0% in high-dependency units, and 11.4% in intensive care units. Surgical intervention was done in 60.8% of the COVID-19-positive patients, while the rest 39.2% were conservatively managed. Among whom, 63.3% were discharged, 29.1% of them left against medical advice (LAMA), and 7.6% were expired during the hospital stay. The frequent comorbidities were diabetes (27.8%) and hypertension (26.6%), although most patients were having no comorbidities (49.3%). Symptomatic gall stones were the most frequent reason for surgical admission in COVID-19-positive patients, while the most frequent surgical intervention performed was laparoscopic cholecystectomy as shown in Table 1 . Table 2 has shown cross-tabulations of factors analyzed between conservative and surgically managed patients along with their outcomes. It has shown that males were comparatively managed more frequently by surgical intervention and females been more conservatively managed (p = 0.037). Out of the six mortalities, five were surgically managed. Seventy seven percent of the surgically managed patients were discharged, and the majority of LAMA patients were being conservatively managed (p < 0.001) as shown in Figure 1 .  LAMA: Left against medical advice. The whole world is affected by COVID-19 pandemic, and hospitals are flooded by COVID-19-positive patients whether it is an outpatient department or emergency department. This pandemic is spreading faster and faster by the day, affecting all healthcare systems and operations around the globe and Pakistan was no exception. Most hospitals in Pakistan stopped outpatient settings but not our hospital due to a huge influx of patients. The emergency department was the most affected in all of the hospital departments. We took necessary precautions to safely conduct surgeries with minimal contact amidst the pandemic. Various recommendations have been published by anesthesiologists regarding the equipment and protection required to do intubation safely [5, 6] . The ongoing research into the epidemiology, pathophysiology, and treatment regarding the patients infected with COVID-19 and its respective effects on public health for surgical treatment on individuals with suspicion or diagnosis of COVID-19 infection have not been of prime importance [7] . The most number of procedures performed is in the department of general surgery, and the same results were also reported in another study, with their top two primary interventions being gastrointestinal and general surgery [8] . As hospitals restarted elective surgeries, new protocols were made under the influence of studies that were researching COVID-19 infections. In a study, it was stated that some of the people infected with COVID-19 were asymptomatic, and in 78 patients who tested positive for COVID-19 infection, 42% were not showing any symptoms [9] . As further studies were undertaken, it was also suggested that sensitivity and specificity were significant when the patients showed symptoms but got worse when patients are asymptomatic [10, 11] . It is an infectious disease, but a considerable amount of COVID-19 patients were asymptomatic. So protocols were setup that any patient undergoing any surgical procedure whether elective or emergency was assumed to be positive until proven otherwise. It was also suggested in studies that the virus can live on contact surfaces for several hours despite being transmitted by droplets [6] . That posed a major risk for healthcare professionals if they happened to come into contact with these surfaces or risked transmitting the virus to their loved ones. Another set of protocols was made to completely disinfect these surfaces, and much effort was made to leave adequate time between two surgeries to disinfect the operating theater rooms properly. Another protocol was followed that both anesthesia and surgical members were reduced to a minimum during induction of patient in the operating theater room. The use of laparoscopy on patients is still controversial due to its use of gases, and Yu et al. suggested that you cannot ignore the fact that virus can also be transmitted via oro-fecal route [12] ; so better management of laparoscopic gases was needed. On the other hand, Morris et al. showed that laparoscopy can be done safely on gynecological procedures as this transmission is yet to be proven [13] . Keeping this in mind, 15% of laparoscopic cholecystectomy was performed and none of the patients developed any complication in our study, and one laparoscopic appendectomy was also performed without any postoperative event. Based on this data we can say that laparoscopic procedures are safe to perform until proven otherwise. Performing surgeries during a life-threatening viral pandemic has its ethical implications too. The use of gowns, gloves, personal protective equipment, anesthesia, operating theater, and staffing needed extra resources that needed to be reviewed regularly. The goal of our study was to show that as more and more elective surgeries get postponed, this phenomenon will directly affect emergencies as more patients will present in the emergency department. This growing number of positive patients and increasing resumptions of elective cases should not stop us from doing what healthcare professionals do which is managing the patients timely at the expense of workload and surgical planning. The limitations of this study are singlecenter design, a limited number of patients, retrospective nature, and lack of randomization in the study.@story_separate@This study was done to analyze the demographic factors associated with the outcomes of surgical interventions performed on COVID-19-positive patients.  As elective surgical procedures were halted during the peak of the first wave of COVID-19, our hospital was still performing emergent surgical interventions on COVID-19-positive patients. This study was done to analyze the demographic factors associated with the outcomes of those patients. One factor that was highlighted was a comparatively decreased length of hospital stay for general surgery patients as most of them were referred for home isolation or other COVID-19 isolation centers after undergoing primary surgical management. A substantial number of patients also went LAMA either due to the hesitation of being referred to a COVID isolation unit or other psychosocial factors that were not part of our survey domain.","Background and objectives The frequency of COVID-19-positive or suspicious patients grew steadily, and these patients were received in emergency and outpatient departments at an unprecedented pace for the need of an elective or emergent surgical assessment. We conducted this survey to document the number of surgeries performed on COVID-19-positive patients during the ongoing pandemic at a tertiary care center in Pakistan. Materials and methods A retrospective clinical audit was conducted in a tertiary care hospital that receives surgical cases from almost all over the country. Ethical approval was granted prior to the execution of this intra-departmental audit. Both patients who were admitted to general surgery and visited on a consultative basis in other departments during the year 2020 were evaluated, and only those having COVID-19 polymerase chain reaction (PCR)-positive were included. Those with PCR-negative were omitted from the analysis. All the surgical procedures performed in these patients, along with those managed conservatively, were analyzed. Basic and demographic data of all patients were collected from electronic medical records. The data were defined as either mean and standard deviation or frequency and relative percentages. The normality of the data was verified by the Shapiro-Wilk test. Parametric analysis was used to interpret the disparity in descriptive statistics. Although the categorical results were compared by cross-tabulation, the degrees of significance were calculated either by chi-square test or Fisher's exact test according to the distribution of the data. A p value of less than 0.05 was considered significant (two-tailed). Results A total of 79 COVID-19-positive patients were provided with surgical services and subsequently analyzed. The mean age of those patients was 48.88 ± 16.62 years. The mean length of stay in the hospital was 2.10 ± 3.52 with indifference among gender and mode of treatment (either surgical or conservative). The study participants were 59.5% males and 40.5% females, and only 6.3% had a past surgical history. Most patients were admitted through the outpatient department (65.8%), and only a few were referrals from other departments (10.1%); 64.5% of patients were managed in general wards, 24.0% in critical care units, and 11.4% in intensive care units. Surgical intervention was done in 60.8% of the COVID-19-positive patients, while the rest 39.2% were conservatively managed. Among whom, 63.3% were discharged, 29.1% of them left against medical advice (LAMA), with a 7.6% death rate during the hospital stay. The frequent comorbidities were diabetes (27.8%) and hypertension (26.6%), although most patients had no comorbidities (49.3%). Symptomatic gall stones were the most frequent reason for surgical admission in COVID-19-positive patients, while the most frequent surgical intervention performed was laparoscopic cholecystectomy. Males were comparatively managed more frequently by surgical intervention and females been more conservatively managed (p = 0.037). Out of the six mortalities, five were surgically managed. Seventy seven percent of the surgically managed patients were discharged, and the majority of LAMA patients were being conservatively managed (p < 0.001). Conclusion This study was done to analyze the demographic factors associated with the outcomes of surgical interventions performed on COVID-19-positive patients."
"Information security and privacy is an issue concerned with the proper supervision of data consent, notice, and regulations. More specifically, practical data privacy concerns often revolve around a few common questions: ""How data is legally collected or stored?"" and ""Whether or how data is shared with different parties?"" On-going research into information security and privacy strives to pin down frequent issues related to information security violations and possible solutions [1] . Recently discussed topics on use of technology such as contact tracing, quarantine tracker for combating COVID-19 [2] are one of few most critical aspects where data handling is such a big concerns. Data is one of the most important assets, companies and governments are concerned about. With the ever-growing amount of data in online space, companies find enormous value in collecting, sharing, processing, and using data for their own use. Big tech giants such as Google, Facebook, Twitter, Amazon, and eBay have been building their billion-dollar empires atop the data economy. In this data life-cycle, transparency in requesting consent, abiding by privacy policies, and managing and collecting data are important requirements for building trust and accountability with customers who expect privacy. While we have different ways to ensure the privacy of our physical data, we are losing control over our digital data by various means. We are frequently giving up a vast amount of sensitive information and revealing pieces of our existence on digital platforms. All online spaces we enter glean some aspect of our personal information.@story_separate@Different parties connect the pieces of information for mapping a very detailed personal profile and slowly manipulating us into changing our cognition on certain topics in different digital communication platform. We are aware from history that knowledge of someone's ethnic background, political or religious beliefs can be life threatening if it falls into the wrong hands. One of the many events that several researchers have argued relates to the topic of privacy violation and autonomy is the 2016 United States Presidential Election [3] , [4] . According to its study, Cambridge Analytica's methods of data collection and commercial use represent significant violations of personal autonomy and privacy, which is stated as psychological traits and, in particular, behavioral microtargeting [3] , [4] . It may also seem unusual when you and your friends pay different airfares because of the zipcode they live in. These real-life cases make it clear that our data security and privacy in online has been taken away gradually. Moreover, cyber-attacks such as, phishing email [5] , social engineering strategies for spear phishing [6] are evolving with technological advancement which are paving the way for attackers to trap users to get into their system for getting access of their personal information. Therefore, new threat landscapes are being spread so frequently to be addressed. The widespread usage of smartphones is allowing the data life-cycle to be used more efficiently for data collectors and leaving other parties (e.g., users, consumers) helpless. A Smartphone's ability to create easier modes of communication via instant messaging, mobile browsers, highly functioning cameras is allowing data collectors to grasp the information of users. Mobile apps are taking this process one step forward by advanced processing capabilities to store and process sensitive information as well, such as the user's location, lists of contacts, and personal photographs, which require adequate protection. A form of privacy-enhancing technology -privacy apps have been designed to play an important role in providing privacy-preserving environments with privacy mechanism, for example, smart encryption, secure session management, secure inter-process communication, and secure transport layers. To date, privacy apps are not explored on their privacy-preserving computation protocols [7] and to the best of our knowledge, there is not enough analysis of privacy apps' mechanisms and how they keep up to the privacy requirement standards in their base development process. While ensuring security and privacy involves developer industries, users, and government where each of these entities relies on others, this process requires consideration of both technology and regulations. Therefore, it is fair for any party to question if the necessary security and privacy mechanisms are in place they are supposed to or claimed to offer based on their service [8] . We have encountered literature where different self-made guidelines, catalogues and practices in different app industries on their development life cycle which may create conflicts of interest and will put the privacy of users at stake [9] . To put our understanding on point, we explored existing guidelines and frameworks which can provide certain requirements/criteria lists for ensuring security and privacy for mobile OS, in particularly, NIST.SP.800-163 for ""Vetting the Security of Mobile Applications"" [10] . NIST is a non-regulatory government agency that develops technology, metrics, and standards to drive innovation and economic competitiveness at U.S.-based organizations in the science and technology industry that assists in protecting information [11] . Compliance with NIST standards and guidelines has become a top priority in many high-tech industries. In our research, we have outlined our project for analysis of these ""Privacy App"" from forensics and policy point of view. For the part of forensic, we first utilized automated framework MobSF(Mobile Security Framework) for detecting app specific security and privacy concerns, followed by rigorous dynamic analysis to highlight vulnerabilities on information, accessibility, and transmission, purpose of requesting and processing it. We have also utilized testing tools (fiddler, SSL labs) for measuring the safety of data transmission and communication in run-time. Finally, we utilized N IST.SP.800 − 163, OWASP guidelines, Solove's Privacy Taxonomy [12] as a mixed method approach to assign how these ""Privacy apps'"" modules and components are keeping up with data protection component and if they are satisfying those requirements for ensuring security and privacy. Our goal of systematic evaluation of privacy apps is to identify missing pieces from both security and privacy point of view for developing novel frameworks to help identify and mitigate the security and privacy risks [13] that arise from smartphones applications in the long run. The paper proceeds as follows. In section 2, we extensively reviewed security and privacy related research on smartphone app to indicate why there still needs to consider additional techniques for preserve privacy framework. With substantial research evidence of apps security and privacy concerns and area for future scopes, in section 3, we designed our experiment model to conduct our assessment in 3 different ways (manual, static and dynamic). According to our model of analysis, we further described our steps independently for better clarification with retrieved results in section 4. In section 5, we took an additional approach for conferring our analyzed results with well-developed existing security and privacy guidelines (NIST, OWASP, Solve's Taxonomy) which has been recommend to be taken under consideration by researcher in case of security and privacy for a long time now. In Section 6 discusses our findings and implications, followed by a conclusion in section 7. Apple App Store and the Google Play Store are two most important marketplaces in the world for publishing apps. The popularity of smartphones is constantly growing, with an increased demand for applications that has resulted in serious privacy concerns. Smartphones' advanced processing capabilities are allowing most apps to store and process sensitive identifiable information. People are using different kind of apps for their daily life, even without realizing the potential negative impact. Mobile phones' progressive adoption in people's daily activities is shaping and defining mobile computing outburst. To get this situation under control, it is time to address apps' privacy issues and identify primary concerns from privacy and security point of views. In previous scholarly research and published studies, we have found assessments of privacy risks and analyses of particular types of apps, for example, mHealth, fitness apps and ebanking apps, etc. Those analyzed apps are mostly from the Android marketplace. Most of them considered doing their evaluation in terms of examining if apps have satisfied the current security and privacy legislation, and standards and certifications for security and privacy [14] , [15] . For our research, we have considered the privacy risks and suggested mechanisms recorded by NIST [16] and OWASP 1 . For our experiment, we chose iOS privacy apps to better understand the particular privacy mechanisms for certain privacy vulnerabilities which may not be present in regular apps. We explored the details about iOS application structure, Inter-process communication (IPC), iOS application publishing, and iOS application attacks from Apple developers' documentation. iOS is isolated in comparison to Android and has a mandatory access control (MAC) mechanism, with IPC options to minimize potential attacks. The iOS platform offers privacy and data protection advantages through uniform hardware/software integration, secure boot, hardware-backed keychain 2 , and file system encryption 3 . Despite having built-in security measures for apps, iOS app developers still need to worry about data protection because of the availability of mobile devices and the different sensors associated with apps installed on them. There is a varied amount of concern related to data protection, keychain management, Touch ID/Face ID authentication, and network security layers from functional as well as non-functional points of view. Keeping those in mind, there still needs to be security and privacy testing and reverse engineering for proper validation of security measures, including how they are working on run-time and how vulnerabilities can cause fatal privacy threats to users' personal information. An iOS application attack surface consists of all components of the application, including the supportive material necessary to release the app and to support its functioning. During this process, iOS application may be vulnerable to attack if it does not: validate all input by means of IPC communication or URL-schemes; validate all input by the user in input fields; validate the content loaded inside a WebView; Securely communicate with backend servers to avoid being susceptible to man-in-the-middle (MITM) attacks between the server and the mobile application; securely store all local data, or load untrusted data from storage; and protect itself against compromised environments, repackaging or other local attacks. After having all the advanced technologies included as part of a built-in design model in iOS, there still remain vulnerable situations stemming from smartphones' sensors to gaining access to users' information. We also found evidence of severe vulnerabilities that remained unaddressed and several new privacy issues from existing studies and different reports. According to their findings mobile apps are still vulnerable to attacks and complete security is not quite an achievable task, even when enforcing privacy and security requirements [17] . There are many well-known popular apps that process massive amounts of sensitive data for big data analytics and yet fail to provide basic protection of users' privacy due to their inappropriate implementation, poor design choices and lack of proper of guidelines from a validated organization (e.g., NIST, IAPP) [16] , [18] . There is an emerging shift toward mobile applications where the goal is to make life more comfortable in respect to health service, banking, shopping, fitness, and even dating [14] , [19] , [20] . This noticeable growth of mobile apps comes with growing concern for users' data privacy on their mobile devices. According to a Homeland Security study on mobile device security, threats to the Government's use of mobile devices are real and exist across all elements of the mobile ecosystem 4 . In order to ensure some level of privacy protection for mobile phone and app users, there is another kind of app that is being developed called privacy apps -a form of privacy enhancing technology. To preserve privacy and give users data protection 5 , there are many privacy enhancing technologies already available [21] . App developers are also designing different privacy apps to give protection to categorized data, for example, privacy apps for photos, videos, passwords, browsers, and adblocking. However, it is still questionable if those privacy apps actually protect privacy or are perhaps taking away part of users' data, and sharing and processing it for their own benefits. From a technological point of view, other concerns can be added to the earlier one: are those privacy apps following proper guidelines at their development phase, and are those guidelines comprehensive for all of the privacy apps out there? As those are intended to ensure privacy to users, it is necessary to analyze if those apps are including adequate privacy mechanisms and how secure those apps are to use. IAPP compares different guidelines for mobile applications in terms of privacy, security, data collection, retention, notice, and consent 6 . In this study, we are mainly utilizing Mobile Security Framework (MobSF) which is an automated, open source pen-testing framework capable of performing static, dynamic and malware analysis. This is mostly recommended for static analysis of security in mobile applications. It can be used for effective and fast security analysis of iOS mobile applications and supports IPA binary and zipped source code. It has a web service that consists of a dashboard which presents the results of the analysis, a documentation site, an integrated emulator, and an API that allows users to trigger the analysis automatically. For dynamic analyses, we used Fiddler, an HTTP debugging proxy server application that can record data shared over HTTP and other vendors and measure security. We have also utilized SSL Labs (https://www.ssllabs.com/ssltest/) from Qualys. SSL verification is necessary to ensure certificate parameters are as expected. There are multiple ways to check the SSL certificate for our analyses. After performing the analyses, we employed NIST mobile privacy guidelines to compare and contrast with three different analyses results. We utilized NIST guidelines for mobile apps privacy and security and OWASP Mobile Security Testing Guide [22] , [23] for analyzing selected privacy apps concerning privacy and security. Our goal is to provide systematic feedback about privacy mechanisms to the developers of those apps. We are analyzing privacy mechanisms of the selected apps to check if they meet the requirements of NIST guidelines and, at the same time, we are studying the comprehensiveness of our utilized mobile testing framework MobSF. Because of the ubiquitous terminology of ""privacy"" in our modern technology, it is challenging to address privacy issues within our existing testing framework. While we are using NIST and OWASP apps privacy guideline requirements, we are also pinpointing some of the requirements which are present in our guidelines but are not present in our experiment environment. In this section, we first present our overall app collection and criteria for selecting manageable counts of apps. Our experiments have been conducted on iOS privacy apps. Secondly, we describe how we conducted the assessment for investigating the security and privacy components offered by each app. We conducted our assessment with three different types of experiments: manual, static and dynamic analysis by the help of OWASP Mobile Security Testing Guide. In addition to providing a finding's report, we performed a NIST guideline auditing procedure to determine whether the reviewed apps have the privacy mechanisms needed to combat against the current threats landscape. To accomplish the analysis, our method includes two parts: data collection and analyses (Manual analysis, Static code Analysis, dynamic/ run-time analysis). Figure 1 presents the overall apps collection with our assigned categories. During our research, experiments progress through recording the results from frameworks for each apps and comparing their mechanisms to our selected guidelines. In the manual analyses, three kinds of assessments are done to assess general features, policies, and privacy settings. In the static analysis, we evaluated apps' privacy mechanisms by mobile security testing framework. To organize our overall set-up, we referenced research on apps security testing in different areas like mhealth, dating apps, fitness apps, followed by research on developers' views of testing before releasing apps. We studied their methodology to have detailed insights on testing [24] , [25] , [26] , [27] . The following sections will briefly present our methodology. For performing an initial screening of possible applications of privacy, we collected 532 apps from the App Store. We used a variety of keywords to find relevant apps, including, ""Privacy,"" ""Data Protection,"" ""Hide,"" ""Block,"" ""Concealment,"" ""Confidentiality,"" ""Privateness,"" ""Seclusion,"" and ""Solitude."" We used certain specifics (e.g., language used, review count, ratings, category, prices and short description of their functionalities) to select the most suitable ones for assessment. Our total initial collection introduced us privacy apps of different categories, for example, photo and video privacy apps, VPN/ Wifi privacy, password manager, transmission and encryption, ad blocking, document/file privacy and others. Figure 1 provides a presentation of our collected apps' data. To identify, collect, and evaluate a manageable number of privacy apps, we determined our initial inclusion criteria. We chose those apps which are free, with instructions written in English, with a review count of more than 10798 (where 10798 is the mean of review counts of the total listed 532 apps), and with an overall rating higher than 3.5. By applying the inclusion criteria, (price, language, review count, rating) we ended up selecting 50 apps. Table 1 includes the inclusion criteria. However, 50 apps were still not a manageable number for in-depth analysis. Depending on our experiment, we choose to select apps that belong to six main areas of privacy: (i) Browsing privacy apps, (ii) VPN and WiFi Privacy apps, (iii) Photos and Videos Privacy apps, (iv) Password Privacy apps, (v) Ad blocking apps and (vi) Figure 1 : Collected data of iOS privacy apps Texting Privacy apps. We are utilizing mobile testing framework and automated tools for our complete set of analysis (static and dynamic). Based on the criteria mentioned in table 1, we decided to select a total of 12 apps belonging to the 6 main categories, which are also open source. We selected our final apps for better comparison and contrast in regard to finding out the comprehensiveness of their privacy components. In our research, we have not directly mentioned name or other identifiers of analyzed apps. Therefore, we have decided to refer them as App 1 to App 12. Apps must be free Criterion 3 Apps review counts ≥ 10798 Criterion 4 Apps rating should be ≥ 3.5 In this section, we designed our assessment strategy for evaluating the privacy mechanisms of the 12 collected categorized privacy apps. Particularly, we aimed to answer the following three main research questions: What kind of privacy mechanism they are providing for protecting users' information in respect to our selected guideline NIST? What can be suggested to the app developer to consider while designing privacy for those apps? To find the answers for those above questions, we designed the following assessment strategies to carry on our experiment. 1. We first registered and installed all 12 selected apps from iOS App Store onto our experimental iOS device. Some of them required a valid Apple ID to create an app specific account during installation. We carefully read all the each apps general information and privacy mechanisms mentioned in the apps' specific page and, if needed, their particular redirected websites for more concrete information. After installation, we again carefully went through all scopes and objectives of each app in terms of privacy settings, (for example, registration, lock, authentication, key management, homepage privacy tips, auto lock, auto-clear when logout) to accurately design the whole process of our evaluation for conducting manual analysis. 2. After a general characteristics evaluation, we inspected different types of permissions those apps automatically turned in from users' devices. In addition, we inspected privacy policies from apps' web pages to check if they mentioned those permissions that they asked for or if it automatically turned on in users' devices. We also carefully noted those apps that did not have a detailed privacy policy on the App Store. As far as we know Apple requires all apps to have a privacy policy since October 3, 2018. They do not allow new apps to be accepted without a privacy policy, and existing apps will not be able to be updated without one. This requirement is strict, regardless of whether apps collect personal information from users or not. 3. After manual analysis, we completed an automated static code analysis utilizing framework MobSF (Mobile Security Framework). In this step, we have analyzed the IPA files on the framework to identify possible privacy and security vulnerabilities highlighted by different analyzers (binary analysis, security analysis) present in MobSF. We recorded our identified issues found on the static analyzer which are important to consider in building a comprehensive privacy design for apps, particularly privacy apps. 4. In this step, we performed a dynamic analysis for each app using Fiddler, a well-known web debugging proxy set-up. Every app was installed and tested to achieve the most accurate results of each app's performance at the time of its dynamic analysis. We also studied the manual communication of each app and third parties in terms of data transmission and sharing. In the design scheme of our overall experiment, represented in Figure  2 , this particular analysis is on the right side of the clients. This experiment's main idea is to find out the data collected from users' devices and their input through apps and how that information flows through different media and third parties. After finding transmission and communication channels, we analyzed the web server configuration to determine the privacy and security level of HTTPS data transmission. For this examination and scoring of the web server configuration, we chose to use a free on-line service, SSL Labs, which enables remote testing of a web server's security measures and privacy effectiveness against a host of current threats and vulnerabilities. 6. After having examined the apps with these three tools from different points of view, for example, quality of communication channel, transport layer security, generated apps permission, distribution of data among different media as static and manual analysis, we recorded and inspected privacy apps' mechanisms in terms of security architecture, application structure, inter-process communication, application publishing and application attack surface. 7. In this step, we summarized our findings for each app. In addition, we compared and contrasted those findings with NIST and OWASP Mobile Security Testing Guide requirements for iOS apps privacy and security. 8. Finally, based on finding related to the latest NIST requirements and OWASP Mobile Security Testing Guide requirements, we performed a number of checks in order to make some recommendations and suggestions for app developers, as well as for the mobile apps testing Framework community, to reconsider necessary modifications and changes for further improvement. Based on our overall analysis, our aim is to make sure that those apps are including privacy mechanisms as they claim in their apps' information page, and therefore to make suggestions for developer to follow proper privacy guidelines. In addition, we also attempted to take the NIST guidelines in perspective to mark down if the mobile testing framework have available options to represent and examine privacy mechanisms comprehensively. Our findings may help in the development of a comprehensive privacy design for apps development, inspection and screening. Based on our methodology, we have drafted manual analysis report from a privacy policy and general settings points of view. After that, we have created a static and dynamic analysis results table for each app in different scenarios, for example, apps permission (camera, microphone, location, contacts, Bluetooth, storage, memory, etc.), privacy architectural requirement, communication and inter process communication security, and policy based on particular evaluation. In manual analysis, we covered mainly three particular topics: Privacy policy, apps permission and general features related to privacy. Table2 represents the lists of existing characteristics to better understand the attributes to be factored in our evaluation as a form of score or percentage.  To maintain transparency on handing users' personal information provided through apps and to give an outline of the terms of use and to outline the terms of use of the apps, a comprehensive and clear privacy policy is important. According to the iOS platform's general criteria of publishing apps, they must have a privacy policy if the app involves collecting, processing or sharing personal data of users with other parties or even storing and processing user data for their own application development process 7 . Furthermore, an app needs a privacy policy even if it does not collect this kind of data itself but instead uses third-party tools like mobile analytics to collect and process data . iOS developers must read and agree to Apple Review Guidelines, a summary version based on their ""Program License Agreement (PLA)"" and other legal documents, in order to have their apps published on Apple App Store. iOS apps may get rejected if they do not add the URL to their privacy policy when they submit the app for review 8 . Our evaluation of privacy policies started with the language inspection to audit if policies are in standard English. Each apps policy met the requirements. Keeping iOS platform restrictions and App Store review guidelines in mind, we studied the privacy policy of the 12 selected apps, and we found that 2 of those apps (app 10 and 12) did not have detailed privacy policy regarding their data collection and sharing, even though those apps are intended for privacy protection. Most of the apps did provide privacy policy and some with dubious statement in terms of malicious or unintentional data leakage, data breach and sharing. We also found some nontransparent policies regarding sharing users' information with third parties, which somehow may meet the goals described in privacy policy. Another issue has been found in case of Cloud usage through apps for users' data storage and backup, for example, apps providing secure vault for storing file, images, and videos. Perhaps statements on data minimization and retention can be more clear and transparent. However, excluding only one selected app, their privacy policies did not explain how the app's Cloud security is performing and how privacy of that data is ensured, and most importantly how long that data will be there. Another significant point was privacy and security certification that has not been in practice in respect to our selected apps. Certification is a way to ensure credibility and build trust between users and organization. With the advancement of technology, most of the big tech giants and technological industries are concerned about valid product and service certifications which make them trustworthy to users/consumers. In the mobile apps scenario, this particular trend is missing. We found only 1 app out of 12 was maintaining privacy and security certification. While we started looking for standards followed in apps' development stage and compliance with privacy standards and principles, we found only 3 apps out of 12 meet this requirement. Overall, we can conclude that manual analysis presents a lack of consideration on transparent statement on storage backups in privacy policy, app's cloud security measurement, lack of practice in compliance with privacy standards and principles, and validation and audited by privacy and security certification in our evaluated 12 privacy apps. After thoroughly inspected privacy policy for each apps, we moved forward with apps general characteristics which includes both general and privacy features. For this stage of our work, we did not have any particular benchmark to collect specific information from apps specific web page or directly from apps while using those. We generally went through all the contents found in the Apps Store and screened through all the tabs and possible option during using those apps. We recorded the general features and the privacy and security components they mentioned and deployed to provide different functionalities and privacy preserving environment to their users. Some of these components are: users' control over their data, smart encryption, decoded privacy policy, privacy grading based on tracker, and extra privacy features, personalized biometric locks options, security audits, data backups and so on. From the collected information on general and privacy features, we have noticed a bunch of handful functionalities. With keeping a note on performance of apps, we found lack of information regarding the performance of those apps in case of constrained environment, for example, with low bandwidth, high traffic and so on. As all of the apps require an internet connection, apps performance is a kind of information that might be taken under consideration. At least, there should have information about those apps' performance statistics by some degree. In addition, these apps employ different privacy mechanisms, like encryption, which requires a high mathematical computation that can slow down apps' performance in run-time. We noticed only very few apps mentioned their consistency and lack of backing in different environment. From our observation, we found Only 3 of the 12 apps had good performance in a constrained environment. Table 2 shows the overall recorded report from our 12 selected privacy apps for iOS mobile device on their basic requirements. For preserving privacy of users' information on apps' platforms, one who is using those apps must grant permission to access personal information. This is sometimes useful if apps are using different information, for example, location, reminders to make our regular events convenient. While it is about privacy, users expect some level of privacy. If some permission request is not relevant of that apps' purpose, it might seems a bit dubious when there is not enough explicitly mentioned description and policy in app's web page. To analyze the permission requests of the selected privacy apps, we recorded the permissions listings from the IPA Manifest files of the 12 selected privacy apps. We categorized those permissions listings. Two main types of permission requests were found: severe permission and normal permission. In Figure 3 : Summary of Permission requests our category of permission, we decided to include all of the permission requests mentioned in the iOS platform. Those are: photo, calendar, camera, location when in use, location always, location description, microphone, Apple music, bluetooth, and contacts. Figure 3 summarizes the requested permissions and represents the permission requests found by utilizing Mobile Security Framework. From our experiment, we found that several apps have requested permission beyond their scope. For instance, four apps required access to the photo library and some of them are also requesting it without any obvious reason since we only had two apps in our list for the purpose of protecting photo and videos. While none of the apps in this study required any Bluetooth functionality or connectivity to a paired device, oddly, one of the applications requested for Bluetooth permission. According to our understanding, these additional permissions were requested for ad libraries, which exploit Bluetooth devices to track a user's location. Notably, iOS required apps that performed scanning for hardware identifiers, like WiFi or Bluetooth, to request the location permission in direct approach with short alert message in their device to ask for granting permission for obtaining location information. Nevertheless, one of the studied apps requested permissions to access location and coarse location. Three of the apps requested calendars permission while two asked for camera permission. While only three apps needed access to the calendar, one more asked for access to the contacts list. One application requested access to Apple music permission. Remarkably, in most cases, permission requested by those apps do not have explicitly any functionality justifying such permission requests. Figure 3 provides a graphical representation of overall permission requests. For the static analysis, we evaluated the privacy and security and permission of the apps in detail. We examined each app independently using MobSF framework. The analysis revealed several privacy and security issues summarized in Table 3 . Mainly we evaluated App transport security, static code analysis of IPA library and permissions. From 2016's Data submission, Global survey of OWASP, the top 10 categories are focused towards Mobile applications [28] . Insecure communication is one of top issues in mobile application since those applications are basically designed by client-server fashion while they transfer any information. We carry our mobile phone everywhere with us which make it more prone to network traffic where targeted attack is easier to perform. In most cases, mobile application use TLS/SSL at the time of authentication but not elsewhere. This can lead to data risk and session IDs. If adversaries get idea about users' information, that attack can be more targeted in different form. Poor SSL setup can also facilitate phishing and MITM attacks 9 . In the same way, insecure login function, insecure authorization and authentication have been creating a sparse attack vector by utilizing automated/bot attacks and custom-built tools. Here, we can mention our permission request analysis in our earlier section of this paper. If apps are performing the user's roles or permissions to the backend system as part of a request, then it clearly shows that this app has issues with authorization. From our experiment by MobSF Framework, we have found 83% of our smartphone privacy apps have insecure login function. For protecting system, there is a technology called ASLR (Address Space Layout Randomization) memory protection mechanism to help prevent attacks and shellcode from being successful. It esssentially protects system against buffer overflow attacks for which adversaries need to know where each part of the program is located in memory. ASLR randomly offsets the location of modules and certain in-memory structures to prevent this attack. 25% of our selected apps do not have memory protection mechanism. On iOS platforms, apps are compiled with an Automatic Reference Counting (ARC) flag, which is a compiler that provides automatic memory management that reduces privacy and security risks against memory corruption and vulnerabilities. We found a larger portion of those apps were compiled with a Position Independent Executable (PIE) flag that address Space Layout Randomization (ASLR) which is also a memory protection mechanism to reduce memory corruption related vulnerabilities, while some apps were compiled with a Stack Smashing Protector (SSP) flag that builds protection against Stack Overflows attacks. From our static analysis, we also found some issues, such as insecure random number generators, which appear quite often, though not all qualified as significant. In most cases, random number generators usage was not necessarily related to security or privacy violations. Our framework evaluation also showed that 67% of the apps have insecure API. Many of the apps do not use HTTPS while connecting, which is alarming, and raise several issues concerning WebViews components as we mentioned for API. 58% apps have an insecure SSL connection and we examined it in further in our analysis by utilizing SSL lab. In addition, we investigated more on Apps' transport Security. An application needs to have ATS (Apps Transport Security) enabled to have secure communication. Insufficient transport security can lead to great impact on confidentiality of users' information, more specifically, this is a wide area of research in respect to the practice of data transmission of eHealth apps [29] , as well as safety issues regarding data integrity [30] , [31] . In case of iOS, this is a privacy feature that should be enabled by default when new apps are installed and enforces secure connections. ATS requires that all HTTP connections made with the URL Loading System-typically using the URLSession class-use HTTPS. It also includes extended security checks that conduct server trust evaluation prescribed by the Transport Layer Security (TLS) protocol and the main task of ATS to block connections that fail to meet minimum security specifications. It is also possible to remove and minimize requirements for communication with specific servers using the NSExceptionDomains key. From our app collections, we have found 3 apps have an insecure transport layer. Two of those three have their ATS disabled on ""NSAllowsArbitraryLoads"" for webviews. Another has ATS disabled for ""Facebook.com"", ""Nomobileleads.com"" and ""Trymobilevpn.com"" domains. Table 4 presents the status of ATS security level and issue found from our experiment. During our dynamic analysis, we evaluated the apps in run-time using the selected apps on our devices to identify their communication channels. We considered their corresponding privacy and security attributes to find out if they transmit sensitive and personal data or any media that is not mentioned in their primary information over the Internet to unauthorized parties [32] [33] . We have identified some data types from previous researches and grouped accordingly, for example, multimedia, location that apps transmitted, registration and log-in data, e-mails, device I.D., search queries, OS information, and chat sessions. First, we examined the ATS (Apps Transport Security) mentioned in the record of static analysis to validate if potential insecure communication exists as found from static information. In iOS, App Transport Security (ATS) is used for security checks. When iOS operating system builds connections with NSURLConnection, NSURLSession and CFURL to public host-names, it requires some enforced requirement which is included in ATS. To maintain a secure transport, ATS should be enabled by default for applications running on iOS. When there are inconsistencies in enabling ATS for particular domains, it creates an insecure connection. Therefore, for any connection made to an IP address, unauthorized domain names of local are not protected with ATS 10 . Overall, the requirements of ATS are following: HTTP connections are not allowed. X.509 Certificate has a SHA256 fingerprint and must be signed with at least a 2048-bit RSA key or a 256-bit Elliptic-Curve Cryptography (ECC) key Transport Layer Security (TLS) version must be 1.2 or above and must support Perfect Forward Secrecy (PFS) through Elliptic Curve Diffie-Hellman Ephemeral (ECDHE) key exchange and AES-128 or AES-256 symmetric ciphers. According to these requirements, we recorded the ATS overall status and causes for 12 selected privacy apps. After the apps' transport security analysis, we can see that some of the apps' App Transport Security (ATS) is disabled on the domain ""NSAllowsArbitraryLoads:' True. Deactivating ATS means allowing insecure communication with particular unauthorized servers, and therefore allowing insecure media loads for apps web views [31] . Table 4 shows the result of ATS issues, status with description. We also performed a privacy and security analysis while users interacted with those apps. We identified web traffic and data transmission nature by using Fiddler web debugging tool. This tool has a web filter and also a proxy. Normally the developer uses these tools for testing their application. Sometimes, with all changes in SSL, applications can be blocked, and it is difficult where this application is trying to go. In those cases, developers troubleshoot by using Fiddler to find the websites that create those exclusions. Apart from our previously described evaluations and different types of analysis, we also proceeded to an additional evaluation process in order to check and validate the requirements that the apps should meet in order to ensure data protection for users. We briefly studied NIST: NCCoE Component for Risk assessments, which include threat source, threat event, vulnerabilities, and some others. For our particular assessment and validation, we chose to delve into threat events and countermeasures to combat those. From NIST, we found 12 threat events, which is called T12 [34] , and which includes: unauthorized access, credential theft, confidentiality and integrity, violation of privacy, network communication, unencrypted communication, device unlock code, storage vulnerabilities, device compromise, data loss, and unauthorized storage [22] . Using the NIST risk assessment, we created our list of countermeasures for seven primary threats and the requirements for those measures. Our selected measures for comprehensive privacy design included: architecture and design, data storage, cryptography, authentication, network communication, and code quality. With briefly defined protection mechanisms and the threat definition of NIST 1800-21: Mobile Device Security requirements and mobile application testing tools and methods presented in OWASP, we performed an evaluation to compare and contrast. In this section, we reevaluated the results from previous sections and aligned them with the Figure 4 : Final apps presentation with percentage of requirements requirements of NIST and OWASP guidelines to find out what they were lacking [22] , [23] , [35] . From our examination, we concluded that the requirements showed in Table 5 may help mobile apps privacy testing community to reconsider a few mechanisms and add a few features. We included the results for functional data protection requirements of NIST, such as privacy design and architecture, encryption, secure transmission or/and strong authentication. We present our results for the 12 apps accordingly. Table 5 shows the final results with NIST requirements. Smartphone app developers have many opportunities to create, collect, and share data about their users. Users might be unaware of the data collection, particularly when it is performed by sensors running in the background. Although this data can be used to create a better customer experience, it can also be used to make unsettling inferences about the app users' habits, lifestyles, locations, and other information [36] . These are creating privacy risks. While these are privacy apps, the issues can be more broadly serious. Privacy apps are mainly based on preserving users' privacy. However, there still needs to be analyses to validate these kinds of apps if they are including proper privacy mechanisms and following privacy specific guidelines. Despite the privacy risks of this unprecedented access to data, many app developers are neither privacy nor security experts. The app development workforce is highly fragmented. Apps are often initially developed by independent developers or small start-ups, as opposed to large, established corporations. This fragmented market means that many independent developers with limited privacy experience and fewer personnel and resources are making privacy decisions about their users' sensitive data and privacy mechanisms. To examine how app developers make privacy decisions, including what kind of privacy guidelines and mechanisms they are using, our study sheds light a on the lack of privacy mechanisms in existing privacy apps (the 12 selected privacy apps). US government agencies, trade associations, and advocacy groups have released app developer guidelines, and different documents describe how developers can protect user privacy. For example, the Federal Trade Commission released a staff report on mobile privacy disclosures, and the California Attorney General provided recommendations for privacy in the mobile ecosystem. To synthesize these different documents, the International Association of Privacy Professionals (IAPP) created a Web tool that lets readers access, search, and compare 10 different privacy guidelines from the US, Australia, and Europe 11 . We examined the documents in the IAPP Mobile App Privacy Tool. For more technical guidance for mobile apps developers, NIST also published a comprehensive guideline with privacy threats and requirements. The guidelines often overlap, making it feasible to comply with most or all procedures. For our evaluation process, we have used the NIST guideline to compare our experimental results. For our experiment and analyses, we selected 12 privacy apps and to avoid legal issues, we chose to present them as App 1-12, rather than revealing their names. We performed three forms of analyses: manual, static and dynamic. From the very first analysis, we obtained apps' general and privacy features provided and claimed apps' specific sites ( Table  2) . We were able to see almost perfect privacy features that have been used to develop their privacy apps. All of the apps include smart encryption, extra privacy registration PIN, secure communication, and secure data management, which are the most important criteria to provide privacy to users. In this stage, we have also done permission analyses with each apps' IPA file to investigate if they are allowing any dangerous permission or not. Unlike android apps, they are not giving a lot of dangerous permission [14] . Still, a few of the apps are requiring dangerous permissions like photo (4 apps), calendars (3 apps), camera (2 apps), location (1 app), Bluetooth (1 app), music (1 app), contacts (1 app). From the static analysis, we recorded a deficiency in coding in terms of log in, random number generator, SQLite database, etc. We have also found insecure connections in apps' transport security for 3 apps from them and those are severe where even ATS is not enabled. As privacy apps, we expected not to have any third party involvement. However, almost all the apps have third parties involved in users' data. Though the number are less than any android or any other apps in iOS, this is still concerning in terms of privacy apps. We have identified HTTP connection to 3rd parties per SSL with grades where there exist some grades that are not expected for privacy apps. At the end of all experiments, we compared our results with NIST and OWASP guidelines to validate our findings. We have observed a huge gap in what we have got in our initial manual analysis in apps specific sites and what we got from our analyses result. There is scope for improvement of these apps from the permission requirement, HTTP connection, Apps Transport security point of view. As those apps are developed by multiple developers, they might follow different privacy guideline and requirements. In this case, we can suggest them to utilize comprehensive apps privacy guideline@story_separate@Privacy apps includes mechanism that can ensure a certain level of data protection among cellphone. To validate those apps credibility, there needs a concrete guideline and certification process in their development life cycle. Nowadays, it is common in a wide marketplace of apps for developers to follow different self-regulatory guidelines. Even though the availability of development tools and comparably easy ways to publish apps in the market, amateurs do not even follow guidelines to ensure criteria of privacy mechanisms which eventually make users vulnerable. In particularly, for privacy apps development, it is crucial to follow widely recognized privacy guidelines. Through our research, we assessed the current state of practices for developing privacy apps. Our analyses of selected privacy apps identified their lacking in security and privacy mechanisms that can lead users to great vulnerabilities in case of data transfer, duration of data storage, inter-process communication, apps transport security, and apps permission requests, Our comparison and contrast with our findings based on NIST guidelines and another operational guideline (OWASP) requirements and controls highlighted the shortcomings of those apps. In addition, it also showed the lacking in the comprehensiveness in the framework that we utilized for our experiment which do not measure up to privacy mechanisms very well since those are basically developed to lean solely towards security aspects. Our overall results may help developers with further improvement of privacy apps' design and development. For easily implementable privacy standards for apps development, a comprehensive privacy design with proper requirements will be a good start.","With smartphone technologies enhanced way of interacting with the world around us, it has also been paving the way for easier access to our private and personal information. This has been amplified by the existence of numerous embedded sensors utilized by millions of apps to users. While mobile apps have positively transformed many aspects of our lives with new functionalities, many of these applications are taking advantage of vast amounts of data, privacy apps, a form of Privacy Enhancing Technology can be an effective privacy management tool for smartphones. To protect against vulnerabilities related to the collection, storage, and sharing of sensitive data, developers are building numerous privacy apps. However, there has been a lack of discretion in this particular area which calls for a proper assessment to understand the far-reaching utilization of these apps among users. During this process we have conducted an evaluation of the most popular privacy apps from our total collection of five hundred and twelve to demonstrate their functionality specific data protections they are claiming to offer, both technologically and conventionally, measuring up to standards. Taking their offered security functionalities as a scale, we conducted forensic experiments to indicate where they are failing to be consistent in maintaining protection. For legitimate validation of security gaps in assessed privacy apps, we have also utilized NIST and OWASP guidelines. We believe this study will be efficacious for continuous improvement and can be considered as a foundation towards a common standard for privacy and security measures for an app's development stage."
"The Santa Ana winds (SAWs) of Southern California (SoCal) are notorious for spreading catastrophic wildfires (Moritz et al. 2010) and influencing air quality (Aguilera et al. 2020) . However, SAWs are also known to produce extreme heat narrowly focused along the densely populated coastal zone (Gershunov and Guirguis 2012; Clemesha et al. 2017 ). The Great Basin-a high inland desert at an elevation of > 1200 m (Fig. 1 )-is the source region for air masses implicated in SAW, that are driven by a regional pressure gradient force (PGF) between the Great Basin and offshore of California Abatzoglou et al. 2013) . Often associated with amplified anticyclonic flow aloft (Hatchett et al. 2018) , the lower tropospheric PGF drives northeasterly winds that warm via adiabatic compression as air flows from the elevated terrain of the Great Basin over the 3000 m Transverse and lower Peninsular ranges to reach maximum temperatures at sea level (Fig. 1) . The cooler and denser Great Basin air relative to the maritime airmass over California promotes acceleration of the wind over the lee-slopes of coastal topography. Local and regional variation in SAW results from the range of downslope windstorm mechanisms involved, including strong cross-mountain flow and varying atmospheric stability structures (Durran 1990; Hughes and Hall 2010; Cao and Fovell 2016; Abatzoglou et al. 2021 ) in addition to katabatic (Hughes et al. 2011; Kolden and Abatzoglou 2018) or gap flow (Huang et al. 2009 ) components of terrain-forced downslope winds. While the typical lower tropospheric regional PGF ( Fig. 1) is most frequently established during winter and the coldest Great Basin airmasses occur when nights are longest in December and January, these two main SAW ingredients can co-occur any time from early fall to late spring. This determines the SAW season (Guzman- Morales et al. 2016 ). In early fall (September-October) and occasionally in late spring (April-May), when Great Basin temperatures are only moderately cool and synoptic pressure gradients develop, SAWs can cause record-breaking coastal heat waves as air descends at the dry adiabatic rate (9.8 °C per 1000 m). Many of the all-time heat records at coastal SoCal locations were registered during fall with the first SAWs of the season. For example, on September 25, 1978, SAW drove temperatures to 40.5 °C in downtown Los Angeles. 1 Even in winter, SAWs can result in anomalous coastal heat that can catch vulnerable communities off-guard. On February 27, 2020, for example, Los Angeles International Airport recorded 29.4 °C with 30.6 °C recorded at Camarillo Airport, 2 while 17.9 °C is the normal maximum temperature for SoCal's coastal zone for this day. As we shall see below, over the last 71 years of record, two of the ten all-time high maximum temperatures in SoCal's coastal zone were associated with SAWs. Surface maximum temperatures are further increased by intense insolation under clear skies and the presence of a dry airmass. Additionally, synoptic wave breaking and isentropic drawdown induced from terrain-influenced circulation further warm the surface . Such conditions of warm, dry winds and strong solar heating are emblematic of SAWs. Offshore winds and solar heating are especially important for promoting anomalous heat in spring, when coastal sea surface temperatures are seasonably cool (~ 13 °C) and persistent coastal low-level cloudiness otherwise cools SoCal's coastal zone (Clemesha et al. 2016; Iacobellis and Cayan 2013) . SAWs also have important societal impacts including on public health. Off-season excessive heat has been linked to premature mortality in coastal SoCal (Kalkstein et al. 2018) . Schwarz et al. (2020) tied heat-health hospitalizations directly to SAW events; these impacts may be worsened by smoke when SAWs fan wildfires (Aguilera et al. 2020) . Many coastal communities are composed of vulnerable populations with reduced adaptive capacity, e.g. no air conditioning (Guirguis et al. 2018) , further exacerbating heat-related SAW impacts. In addition to impactful heat, SAWs can produce extremely cold conditions along the coast. Cold SAWs have been documented in the popular press. 3 As we show, many of the absolute coldest days on record occurred during or directly preceding SAWs. To our knowledge, hot and cold ""flavors of SAWs"" have not been documented in the academic literature. We therefore investigate both flavors of SAWs to see what, if any, dynamical differences exist between cold and hot SAWs. We initially hypothesized that GB snow cover promotes cooler airmasses that favor cold SAWs. Yet we find that snow is only part of an intricate reality, which includes fundamentally different synoptic setups resulting in hot and cold flavors of SAWs. Improved understanding of SAW flavors will result in more accurate determination of wildfire risk, more skillful predictions at longer lead times, better warnings for impact-based decision support (Uccellini and Ten Hoeve 2019), more useful climate change projections, and improving resilience to the greatest impacts of SAWs, including public health and safety via thermal extremes and wildfire. Multi-decade SAW climatologies have been constructed and analyzed for climate-scale behavior (Abatzoglou et al. 2013; Guzman Morales et al. 2016 -hereafter GM'16, Rolinski et al. 2019 . Focusing mainly on wind, these studies identified patterns of climate variability in SAW activity, highlighting regional climate forcings including El Niño-Southern Oscillation (ENSO) and the Pacific Decadal Oscillation (PDO). Climate change is expected to diminish SAW activity (Hughes et al. 2011 ) by eroding SAW frequency in the early and late season (Guzman Morales and Gershunov 2019, hereafter GMG'19) with trends projected to emerge early in the twenty-first century. SAW-driven coastal temperature anomalies have not been studied and their climatology has not been assembled. As the Great Basin is projected to warm more rapidly than the coastal zone , we expect SAW-driven coastal temperature extremes may warm at a greater rate than the background climate. It is thus timely to understand the past, current, and future behavior of Santa Ana winds as well as the compound impacts they generate via wildfires (Small 1995; Westerling et al. 2004; Moritz et al. 2010; Rolinski et al. 2016; Kolden and Abatzoglou 2018) , air quality (Delfino et al. 2009; Leibel et al. 2019; Aguilera et al. 2020a, b) , and temperature extremes (Schwarz et al. 2020 ) on coastal SoCal-a marine-influenced, densely populated region where public health is acutely impacted by heat (Guirguis et al. 2014 (Guirguis et al. , 2018 and wildfire smoke (Aguilera 2021a; b) . Our goal here is to understand and describe hot and cold flavors of SAWs, their historical climate-scale behavior, their drivers, connection to wildfire, and observed trends over the past seven decades.@story_separate@An hourly record, spanning 1948-2012, of dynamically downscaled SAW activity on a 10 × 10 km grid was constructed, validated against the available observations, analyzed, and presented by GM'16. The SAW Regional Index (SAWRI) was also constructed for SoCal and later updated and converted to daily values using a hybrid dynamicalstatistical downscaling of the NCEP/NCAR Reanalysis 1 (Kalnay et al. 1996 ) (R1D-SAWRI) by GMG'19. The version of R1D-SAWRI used here constrained the number of SAW days by spatial extent filtering. Only days with local (grid-wise) conditions in at least ~ 60% of the SAW domain were considered SAW days. R1D-SAWRI spans January 1948 to December 2018 (71 years). We use observed daily maximum and minimum temperature (Tmax and Tmin, respectively) data from First Order and Cooperative Observer meteorological observations interpolated onto a 6 × 6 km grid using inverse distance weighting of the four nearest stations to each grid cell, down-weighting stations close to other stations, and applying a fixed lapse rate for interpolating in complex topography (Livneh et al. 2013 (Livneh et al. , 2015 . Tmax and Tmin anomalies were computed relative to their seasonal cycle at each 6 × 6 km grid cell. The seasonal cycle was modeled, separately for Tmax and Tmin, via double (annual and semi-annual) harmonics fitted to daily temperatures and regressed out of the daily temperature data (Gershunov and Roca 2004) . Following GM'16 and GMG'19, we used SAWRI to identify and quantify the pattern of coastal warming due to SAWs (Fig. 2a, b) . A pattern of anomalous warming associated with all SAW events is readily apparent along the low-elevation coastal zone. The region corresponding to the warmest 20% (Tmax > 1.8 °C) of local temperature anomalies due to SAW conditions is the region we refer to as coastal SoCal (delineated by black lines in Fig. 2b ). We isolate and delineate this spatial pattern via the + 1.8 °C anomaly isotherm that corresponds to the 80th percentile of anomalous Tmax average during SAW days over the coastal SoCal domain. The coastal de-seasonalized temperature indices (CTmax and CTmin) for SAW and non-SAW days were constructed daily by spatial averaging of Tmax and Tmin anomalies over the coastal zone delineated in Fig. 2b and over all SAW and non-SAW days of the SAW season (September-May). Note that SAWs themselves impact the CTmax and CTmin seasonal cycles, with a mean of 4 and 12 SAW days in October and December, respectively. Figure 2c presents the resulting annual time series along with fitted trend lines. Similarly, we compute analogous daily averages of temperature anomalies for the western Great Basin (GBTmax and GBTmin) defined as the square region over the Great Basin delineated on Fig. 2a -this is the primary region where the SAWs are rooted. We also categorize SAW days into hot and cold SAW varieties based on their positive and negative CTmax values as well as the extreme 10% hottest and 10% coldest SAW days that fall above the 90th and below the 10th percentiles of CTmax, respectively (Fig. 3a) . Thus all SAW days are classified as hot or cold SAWs according to whether the maximum coastal temperature anomaly is positive or negative, while the extreme hot and cold SAWs are highlighted. When analysis is performed over SAW events (only for duration and minimum relative humidity assessments, Figure S1 ), we classify hot (cold) SAW events based on their positive (negative) mean CTmax. Events with mean absolute CTmax below the 5th percentile of all event means (|CTmax|< 0.27 °C, which amounted to 5% of all SAW events) were considered undefined and were discarded from analyses focusing on SAW events. Daily, gridded 4 km resolution snow water equivalent (SWE) reanalysis spanning October 1981-September 2018 (Zeng et al. 2018 ) was used to compute daily snow coverage for hot and cold SAW days over the western Great Basin (Fig. 2a) . For each grid cell, we assign 1 and 0 snow coverage values for SWE > 0 and SWE = 0, respectively. and 10 m R1 wind field (black arrows) over the larger Western US region. The SoCal and western Great Basin domains, considered in this study, are shown in black boxes. The full extension of the Great Basin, as shown on a, is added for reference. b Enlarges the SoCal region, inset on a, and shows composites of Tmax (color shades) and downscaled wind fields (black arrow). The region delineated with thick black lines corresponds to the warmest 20% (Tmax > 1.8 °C) of local temperature anomalies due to SAW conditions (coastal SoCal). c Shows the annually-and spatially-averaged coastal Tmax index (CTmax) for SAW (solid) and non-SAW (dotted) days with fitted linear trends, which are significant with 95% confidence at 0.13 and 0.23 °C/decade, respectively for SAW and non-SAW days. Correlation between SAW days and non-SAW days CTmax time series is 0.46 Additional data sets include daily precipitation data evaluated on the same 6 × 6 km grid as temperature (Livneh et al. 2013 (Livneh et al. , 2015 and wildfire observations including start dates, acres burned, and fire perimeters from the California Department of Forestry and Fire Protection's Fire and Resource Assessment Program (FRAP: https:// frap. fire. ca. gov/ frap-proje cts/ fire-perim eters/). We also use hybrid statistical-dynamical downscaled relative humidity data (RH) produced by a statistical downscaling model (Localized Constructed Analogs-LOCA; Pierce et al. 2014 forced with hourly ERA5 reanalysis humidity fields. Since humidity data at the desired 3 km resolution is not readily available from observations, we trained LOCA with the relative humidity field simulated by the WRF model (Skamarock et al. 2008) , resulting in a hybrid statistical-dynamical downscaling scheme covering the state of California. WRF in turn was forced with 6-h data from the National Centers for Environmental Prediction (NCEP) FNL (Final) Operational Global Analysis (NCEP 2000) . The purpose of using this hybrid scheme (downscaling ERA5 4 using LOCA trained on WRF output) rather than using the WRF output directly was to extend the length of the WRF output, which was only available over the period 2003-2018 (16 years) , to the full period ERA5 is available, 1979-2019 (41 years). Our previous analyses of LOCA downscaled humidity indicates that errors in the downscaled field with respect to the training data are about 0.5% in the mean with a RMSE of about 2% . The National Weather Service (NWS) identified heat waves and wildfires associated with SAWs in ""A History of Significant Weather Events in Southern California"". This report documents remarkable (not comprehensive) cases from 1859 to 2017, and is used here for reference purposes of our R1D-SAWRI record. We note that every Santa Ana wind event associated with wildfires or heatwaves, with the exception of a SAW-driven heatwave on 09/26/1963 that has been documented in the NWS report, is also detected by R1D-SAWRI. The highest absolute average Tmax along coastal SoCal (absolute values of CTmax) typically occurs in September (Table S1a ). Seven out of the ten absolute hottest CTmax days occurred in September, including the overall record heat (39.5 °C averaged over SoCal's coastal zone on September 27, 2010), which was associated with Rossby wave breaking and terrain-induced circulations ), but not with a SAW event. Two of the ten absolute warmest CTmax days on our record were associated Fig. 3 a Daily CTmax versus SAWRI, extreme SAWRI is depicted with a dark red line on the x-axis, and the CTmax thresholds for the top 10% hottest and coldest SAW days are marked with red and blue lines, respectively, on the y-axis. Heat waves and wildfires associated with SAW events from NWS report ""A History of significant weather events in Southern California"" are marked in green circles and red diamonds, respectively. b Mean frequency of hot and cold SAW days by month. Extreme top 10% hottest and coldest days are depicted in bright red and blue sections respectively 4 ERA5 data used in this work was downloaded from the ECMWF Copernicus Climate Data Store, https:// doi. org/ 10. 24381/ cds. adbb2 d47. with SAWs ( Table S1a ). The hottest SAW-driven CTmax occurred on September 24, 1978, trailing the overall record by 1.5 °C. Five of the top ten SAW-associated absolute hottest days occurred in September, three in October, one in April and one (the second hottest) in June of 1981-a highly unusual, extremely late-season SAW event. The hottest SAWs, relative to seasonal normal conditions, however, tend to occur in April-May (Table S2) , when they create a distinct contrast from otherwise seasonably cool temperatures associated with cool coastal sea surface temperature and the onset of coastal low-level cloud season (Clemesha et al. 2016; Iacobellis and Cayan 2013) . These conditions spell a cool start to the Mediterranean dry and warm season in coastal SoCal. This seasonal coastal coolness amplifies the relative coastal warm anomalies associated with hot SAWs. Eight of the ten hottest relative CTmax days occurred in April and May; four of them were SAWs. On the cold side of the SAW spectrum, three of the absolute coldest 10 days on record were SAW days. The latest such event occurred in December 1990 and was SAWrelated, while the other nine days occurred prior to 1973. Five of the 10 coldest SAW days occurred in 1949 from three separate SAW events in early January, late January and mid-February. The coldest SAWs demonstrate a greater range of maximum wind speeds than the hottest SAWs, which tend to be on the weaker side (Fig. 3a) . For both hot and cold days, whether SAWs or not, the greatest anomalies are found in CTmax rather than CTmin. We therefore focus on CTmax going forward. A sizable minority (28%) of SAW days are anomalously cold (Fig. 3a, b) . Cold SAW frequencies peak during peak SAW season in December and January when ~ 38% of all SAWs were historically cold, with a majority of extreme cold SAW days in these months (Fig. 3b) . Extreme (top 10%) hot SAW days occur most frequently in January and February (~ 0.75 year −1 ) but early fall and late spring months have the highest relative proportion of extreme hot SAW days. Hot Santa Anas tend to be longer lasting (~ 4 days on average compared to ~ 3 days for the cold SAWs- Figure S1a) , with slightly longer duration for extremes of both flavors. Hot SAWs also tend to be drier in terms of RH than their cold counterparts ( Figure S1b ). Both hot and cold Santa Ana winds involve broad regions of high sea level pressure (SLP) over the interior Western U.S. (Figs. 2 and 4) . This region of high SLP is centered approximately in northern Utah, on the northeastern edge of the Great Basin, for hot SAWs (Fig. 4a, b) . The extreme hot SAW composite displays ~ 5 °C positive temperature anomalies in the northwestern GB and ~ 10 °C at the SoCal coast (Fig. 4b) . During cold SAWs (Fig. 4c, d) , the interior high pressure intensifies and expands, splitting into two centers: one in eastern Idaho/southwestern Montana and the other in the northwestern GB (northwestern Nevada/southeastern Oregon). Besides cold SoCal (negative anomalies of 5-10 °C), extreme cold SAWs start with cold Tmax anomalies down to nearly − 10 °C in the western GB (Fig. 4d) . Tmin anomalies in the western GB show the greatest magnitudes, however (Fig. 5) . Cold SAWs involve tighter SLP gradients extending into California and further north along the Sierra Nevada. In addition to temperature anomalies observed along the north and central California coast as well as the western slope of the Sierra Nevada (Figs. 2a, 4a, c) , this provides evidence supporting coordination of SAWsboth hot and cold-with northern California's Diablo winds (Smith et al. 2018a) . In SoCal, the northeasterly SAWs and their associated PGF values turn slightly more northerly for cold compared to hot SAWs (Figs. 4, 5) . The synoptic scale upper-level circulation pattern conducive to cold SAWs displays a positively tilted ridge adjacent to the western coast of North America indicative of anticyclonic Rossby wave breaking (Ryoo et al. 2013 ) and strong baroclinicity (Fig. 6 ). Hot SAWs, however, appear to be associated with neutrally-tilted high amplitude flow around a blocking high centered at the California coast (Fig. 6 ). This behavior is stable from month-to-month across the SAW season ( Figure S2 ) and suggests different synoptic causes for the two flavors of SAWs: cold SAWs associated with transient disturbances (short waves) and planetary wave breaking, whereas hot SAWs are linked to stationary planetary waves, specifically anticyclonic flow around a blocking high. The coldest SAWs tend to be driven by the strongest pressure gradients pushing northeasterly winds into SoCal ( Figure S3 ), which tend to be somewhat stronger and more northerly than those associated with the weaker hot SAWs (Figs. 5 and S3). Based on our dynamical interpretation, we expect widespread cold-frontal precipitation in the days preceding cold SAWs and dry conditions/limited precipitation preceding hot SAWs. This would be consistent with gradual Great Basin warming/abrupt cooling prior to hot/cold SAWs ( Figures S4-S5) . Nonetheless, negative Great Basin Tmin anomalies still occur during hot SAW days ( Figure S5a ). Figure S6 shows precipitation by month accumulated and composited over the five days preceding cold and hot SAWs. The entire Western US, including the GB and SoCal, accumulates precipitation on the days preceding cold SAWs. Hot SAWs are preceded by precipitation over the northwestern US, while the Southwest remains dry. This is the case throughout the SAW season, with the wet/dry contrast particularly pronounced during the most active SAW season (November-February). The majority of the Great Basin (i.e., areas aside from the highest mountains) is characterized by ephemeral snowpacks that accumulate during storms and later melt, a process that can happen multiple times during the cool season (Hatchett 2021 ). An element accentuating the difference between hot and cold SAWs is additional radiative cooling of airmasses during cold SAWs by the ephemerally snow-covered Great Basin. Indeed, composite evolutions of snow cover leading up to cold and hot SAWs indicates snow depletion/accumulation in advance of hot/cold SAWs (Fig. 7) . The coldest SAWs tend to start with anomalous positive snow cover leading up to the event. However, the sample of extreme cold SAWs is severely reduced for this result as most cold SAW days occurred in the early half of the record, while the snow reanalysis data begins in October 1981. Precipitation and snowpack data support the distinct synoptic setups leading to hot and cold SAWs. Great Basin ephemeral snow cover associated with these contrasting synoptic dynamics further explains part of the temperature differences between the two flavors of SAWs. These findings suggest the risk of wildfire should decline during cold SAWs, which tend to be preceded by wetting rains over SoCal ( Figure S6 ) that increase fuel moisture. Moreover, the transient nature of synoptic disturbances associated with cold SAW dynamics should, in principle, make them shorterlived than the hot SAWs associated with more stable and more persistent circulation regimes. Although some of the strongest SAWs are of the cold variety (Fig. 3a) , given the tendency of cold SAWs to be preceded by wetting rains and hot SAWs to be warmer, drier, and of longer duration ( Figure S1 ), we expect larger wildfires in SoCal to be more frequently associated with hot SAWs. The data corroborate this expectation (Fig. 8) . Acres burned by fires started during SAW conditions show that 90% of the large fires and 95% of the burned area occurred during hot SAWs. The maximum acres burned for a single cold SAW wildfire is 31,447; all wildfires exceeding this size ignited and grew during hot SAW episodes and commonly during extreme winds (SAWRI > 90th percentile). Because early-season cold SAWs are associated with little preceding precipitation, they can also fan already burning wildfires that have been ignited previously-this was the case in early September 2020, when an early-season cold SAW spread wildfires that started during extreme heat (not associated with SAWs) events of August. The interior Southwest is among the most rapidly warming regions of the contiguous US (USGCRP 2018). We therefore expect SAWs to reflect this inland warming, imprinting it episodically onto SoCal's coastal region. CTmax displays seasonally (September-May) averaged warming trends amounting to 0.9 and 1.6 °C over the entire sevendecade time period, respectively, for SAW and non-SAWdays (Fig. 2c ). There are fewer SAW than non-SAW days resulting in smaller annual samples and greater variability of SAW compared to non-SAW CTmax. Moreover, the seasonal SAW CTmax index is biased towards December when SAW frequency is highest (GM'16). Importantly, monthly trends in SAW versus non-SAW Tmax display very different seasonalities (Fig. 9) . Over the 71-year record, coastal temperatures associated with SAWs have been significantly increasing in January, February and March (JFM; mean warming of ~ 3.5 °C). Weaker warming trends for non-SAW days were observed over SoCal with similar warming across months (Fig. 9a) . Monthly temperature trends over the Great Basin (Fig. 9b, c) show the same seasonal pattern of warming, focused on JFM during SAW days and nights and were of comparable magnitude to the CTmax (SAW) trend. On the other hand, October-December (OND) trends are negative for SAW-associated Tmax over the Great Basin. Non-SAW Great Basin Tmax does not display significant trends except in March, June and July, while non-SAW Tmin trends are positive in all months except November, December and February. The strongest and most consistent warming is observed for SAW-associated Tmin over the Great Basin and CTmax (SAW) in JFM. Non-SAW Tmin warming is also strongest in January and March (Fig. 9c) . March displays the most consistent warming trends observed over the SoCal coast and over the Great Basin (Tmax and Tmin) for both SAW and non-SAW days. Exploring the seasonality of SAW-related CTmax trends, we have to consider what is causing the seasonality of warming in the Great Basin and the broader intermountain west. The timing and magnitude of SoCal and Great Basin trends is consistent with the strongest observed warming of inland temperatures, particularly in spring (Hoerling et al. 2013) . This seasonality of western inland warming has been associated with declining snowpack and earlier snowmelt as part of spring's progressively earlier start observed since the 1970's (Cayan et al. 2001) . With continued warming observed across all months over the Southwestern US, snow accumulation has been decreasing as more of the precipitation falls as rain (Knowles et al. 2006; Lynn et al. 2020) . The warming, accentuated in spring, is also causing a tendency for snow to melt earlier (Mote et al. 2018) . This likely leads to stronger regional warming through contemporaneous snow-albedo and delayed soil-moisture-related feedback mechanisms. It is noteworthy, however, that the Great Basin has not warmed as much as the surrounding interior Southwestern U.S., particularly in December, when it cooled, and in January ( Figure S7 ). In February and March, GB warming was on par with the rest of the West. In March, Western U.S. warming has been substantial and widespread (Cayan et al. 2001) . Figure S7 corroborates the robustness of this spring warming trend. While the seasonal pattern of GB warming plays an important role, the breakdown of causes behind CTmax and GB Tmax/Tmin trends may differ by month. The relative activity (prevalence and intensity summarized in degree days- Fig. 9d ) of warm vs cold SAWs appears to modulate the nature and seasonal structure of CTmax trends. During January and March we see significant positive and negative trends in both hot and cold SAW activity, respectively. February is the only other month that fits into this pattern, although not significantly so. Fig. 6 . 500 mb heights composited on hot and cold SAW days (a, b) and on top 10% hot and cold SAW days (c, d, respectively) The online version contains supplementary material available at https:// doi. org/ 10. 1007/ s00382-021-05802-z. Funding Partial funding for this work was provided by University of California Office of the President MRPI Grant MRP-17-446315, the California Energy Commission EPC-16-093, the U.S. Geological Survey grant G14AP00076, and the National Oceanic and Atmospheric Administration's International Research Applications Program award A18OAR4310341. This study contributes to DOI's Southwest Climate Adaptation Science Center activities and NOAA's California and Nevada Applications Program award NA11OAR43101. We thank an anonymous reviewer for helpful comments. Availability of data and material The Santa Ana wind regional index and coastal temperature indices used and produced in this article are available here: https:// wecli ma. ucsd. edu/ data-produ cts/. Code availability We will make any of our code used here available upon request. The author declares that there is no competing interest. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.@story_separate@Two distinct flavors of Santa Ana winds emerged from our analysis of SoCal coastal temperatures associated with SAWs: hot and cold. Extreme expressions of these SAW flavors have resulted in some of the hottest and coldest temperatures recorded in SoCal's coastal zone in the past 71 years. These two flavors of SAWs result from very different synoptic setups and they impact wildfire hazard differently. Hot SAWs are associated with high-amplitude anticyclonic flow around blocking high-pressure systems centered over the California coast setting up a surface southwestward pressure gradient force directed from Nevada into California. The warming of the Great Basin starts a few days prior to and peaks a couple of days after SAW onset. In contrast, cold SAWs are set up by baroclinic anticyclonic Rossby wavebreaking associated with transient cold-frontal cyclones moving eastward across the West. Cold SAWs are preceded by widespread precipitation over the western US and accumulation of snow over the GB followed by a cold post-frontal airmass settling into the freshly snow-covered GB prior to the onset of cold SAWs. The surface high associated with this cold airmass is broader and extends further into the western GB, resulting in cold SAWs being somewhat more northerly then their warm northeasterly sisters. The strongest SAWs in terms of windspeed tend to be of the cold variety, while the driest and longest events tend to be of the hot variety. The differing synoptic origins and land surface conditions favored by hot and cold flavors of SAW brings up important questions regarding the predictability and mesoscale dynamics involved in each SAW flavor. For instance, do the transient synoptic waves preceding cold SAW show less predictability compared to the quiescent anticyclonic conditions associated with hot SAW? How do observed mesoscale wind patterns vary between SAW types? Do hot SAW events tend to be gustier than cold SAWs by virtue of large-scale forcing favoring increased mesoscale gravity wave breaking? Are cold SAW events more likely to have flows channelized down canyons and through terrain gaps (Rolinski et al. 2019) due to their stronger katabatic component? State-of-the-art reanalysis products such as ERA5 (Hersbach et al. 2020 ) are sufficient to broadly identify downslope winds (Abatzoglou et al. 2021) , however their 25-50 km horizontal resolutions remain too coarse to capture the interactions of flow and terrain at the meso-γ scale (2-20 km; Thunis and Bornstein 1996) . Answering these questions can be addressed by applying high-resolution numerical weather models to produce regionally downscaled climatologies (e.g., Hughes and Hall 2010; Rolinski et al. 2016; Smith et al. 2018a) . Forecast skill metrics for both SAW flavors can be calculated and compared using a reforecast approach or by evaluating archived operational model output (e.g., High Resolution Rapid Refresh Model; Benjamin et al. 2016) . Case studies following the approaches of Cao and Fovell (2016) and Fovell and Gallagher (2018) are also recommended to test the sensitivity of forecast skill and dynamical responses to varying land surface characteristics (e.g., snowpack conditions in the Great Basin). Wildfires in SoCal are clearly partial to hot SAWs (Fig. 8) . Although cold SAWs tend to be windier, they are usually preceded by precipitation over wind-and fire-prone coastal topography. Besides not being associated with precipitation over SoCal, hot SAWs tend to have lower relative humidity and are generally longer lasting. These differences result in 90% of the SAW-driven wildfires and 95% of the area burned being associated with hot SAWs. The impacts associated with hot SAWs extend beyond the immediate coastal heat, wildfire, and smoke. Many of SoCal's mountains are highly susceptible to damaging and deadly postfire debris flows (Oakley et al. 2017 (Oakley et al. , 2018 and landslides (Rengers et al. 2020) for multiple years after wildfire has occurred. Changes in fire severity and intensity are also driving type conversions of native chaparral ecosystems towards grasslands, resulting in losses in biodiversity (Syphard et al. 2018) . In terms of downslope wind-driven anomalous heating patterns, both flavors of SAWs appear to be coordinated with other downslope wind regimes of California, including Sundowner winds of the northern Transverse Ranges (Smith et al. 2018b; Hatchett et al. 2018) and Diablo winds of Northern California (Smith et al. 2018a ). This potential coordination needs to be studied in more detail to evaluate onset timing and seasonality differences and spatial extents and magnitudes of warming and wildfire occurrence. Besides identified regional-scale differences in hot and cold SAW direction, the interaction of circulations with local topography may amplify how these flavors of SAWs influence temperature and wind patterns differently. This can be studied with finer-resolved wind data and modeling experiments. However, the propensity of cold SAWs to be preceded by rain as well as their higher RH and shorter duration appear to notably diminish the fire hazard compared to the hot SAWs that are of longer duration, drier, and warmer. The hottest ten SAW days have occurred throughout our 71-year record, while the coldest SAWs display a clear preference for the early decades. This is consistent with the Fig. 7 Great Basin snow coverage 15 days before and after SAW days. Thick black line marks the median, boxes lower and upper limit correspond to the 1st and 3rd quartiles, respectively, and whiskers extend to the farthest extreme values. Colored bars correspond to snow cover on SAW days (at x = 0, around which compositing was done) for each category, a-d. Red dashed line marks the percentage of snow coverage over the Great Basin domain (42%) averaged from November to January. e, f Show the differences of cold minus hot SAW days and top 10% cold minus hot SAW days, respectively ◂ strong seasonality of the observed trend in our coastal temperature index, the CTmax, which increased significantly in January, February and March, but not in other months. This JFM warming amounts to ~ 3.5 °C since mid twentieth century and almost twice the background (non-SAW) warming. It is produced by a commensurate seasonality of warming in the Great Basin during SAW events and a decrease/increase in cold/hot SAW activity comprising frequency and intensity. This change may be exacerbated by the gradual loss of snow cover in the Great Basin as part of a West-wide trend (Knowles et al. 2006; Mote et al. 2018) . The JFM CTmax warming trend reflects the preference of the coldest SAWs for the 1940s-1960s. The hottest SAWs, occurring disproportionately in fall, when no significant long-term trends Fig. 8 Histograms of acres burned (a) by wildfires in coastal SoCal that started during hot (red) and cold (blue) SAW episodes. Domain map (b) and fire perimeters associated with wildfires occurring during hot and cold SAW days have been detected, are spread uniformly over the seven decades of record. The new understanding of SAW flavors allows us to ask more informed questions about how SAWs will evolve amidst a warming climate to be addressed in future work. In view of these results, studies of future SAWs (Hughes et al. 2011; Miller and Schlegel 2006 ; Guzman Morales and Gershunov 2019) and consideration of future wildfire risk (Yue et al. 2014; Jin et al. 2015; Williams et al. 2019; Goss et al. 2020 ) focused on SoCal could be updated to resolve and incorporate trends in hot and cold flavors of SAWs, which are differentially related to wildfire. The diminishing SAW activity projected by GMG'19, specifically, will be revisited in future work to nuance those projections with respect to SAW flavors. The fuel-drying potential of warming SAWs should also be assessed. The winter/spring CTmax warming that has occurred already suggests an increasing potential of warmer and drier SAWs to dry out coastal vegetation and, particularly in anomalously dry winters, enhance the coastal Fig. 9 Tmax trends by month in °C per decade over the 71-year record averaged over SoCal (a) and the Great Basin Tmax (b) and Tmin (c). Monthly trends of cold and hot SAW ""activity"" measured in CTmax degree days (monthly sums of hot and cold CTmax excur-sions) that reflect both frequency and intensity of hot and cold SAWs (d). Red dots mark trends that are statistically significant with 95% confidence wildfire season even into spring. Such spring wildfires have occurred in very hot SAWs in May 2014. 5 This work was initially motivated by the public health impacts of SAW-driven coastal heat waves (Schwarz et al. 2020 ) and SAW-driven wildfire smoke (Leibel et al. 2019; Aguilera et al. 2020b Aguilera et al. , 2021a in SoCal's densely populated coastal zone. Impacts from heat waves and wildfires compounded in August and September 2020 to harm California during the preparation of this manuscript and prior to the traditional onset time of SoCal's wind-driven autumn wildfire season. These events, further compounded and complicated by the SARS-CoV-2 pandemic, highlight the urgency of improving our understanding and prediction of the key weather ingredients that shape SoCal's heat waves and wildfires. By documenting the underlying mechanisms that drive hot and cold SAWs and outlining the instrumental influence that SAWs exert on hazardous weather and fire extremes in SoCal, we hope that our results will inform the implementation of early warning systems to protect vulnerable coastal communities. As climate change bolsters both heat waves (Gershunov and Guirguis 2012) and wildfires (Williams et al. 2019; Goss et al. 2020) in California, evolving integrated early warning systems are urgently needed to mitigate risks to public health and to improve emergency preparedness to these increasingly prevalent risks. This work is a step towards that goal in California and other regions of the world with similar exposures and possibly even greater vulnerabilities to extreme weather events.","Santa Ana winds (SAWs) are associated with anomalous temperatures in coastal Southern California (SoCal). As dry air flows over SoCal’s coastal ranges on its way from the elevated Great Basin down to sea level, all SAWs warm adiabatically. Many but not all SAWs produce coastal heat events. The strongest regionally averaged SAWs tend to be cold. In fact, some of the hottest and coldest observed temperatures in coastal SoCal are linked to SAWs. We show that hot and cold SAWs are produced by distinct synoptic dynamics. High-amplitude anticyclonic flow around a blocking high pressure aloft anchored at the California coast produces hot SAWs. Cold SAWs result from anticyclonic Rossby wave breaking over the northwestern U.S. Hot SAWs are preceded by warming in the Great Basin and dry conditions across the Southwestern U.S. Precipitation over the Southwest, including SoCal, and snow accumulation in the Great Basin usually precede cold SAWs. Both SAW flavors, but especially the hot SAWs, yield low relative humidity at the coast. Although cold SAWs tend to be associated with the strongest winds, hot SAWs tend to last longer and preferentially favor wildfire growth. Historically, out of large (> 100 acres) SAW-spread wildfires, 90% were associated with hot SAWs, accounting for 95% of burned area. As health impacts of SAW-driven coastal fall, winter and spring heat waves and impacts of smoke from wildfires have been recently identified, our results have implications for designing early warning systems. The long-term warming trend in coastal temperatures associated with SAWs is focused on January–March, when hot and cold SAW frequency and temperature intensity have been increasing and decreasing, respectively, over our 71-year record. SUPPLEMENTARY INFORMATION: The online version contains supplementary material available at 10.1007/s00382-021-05802-z."
"Antimicrobial Resistance (AMR) has become one of the dominant health challenges of our times. Antibiotic resistance occurs as a natural evolutionary process in bacteria, but can be accelerated by a number of factors [1, 2] . More specifically, the excessive and inadequate use of antibiotics in both humans and animals leads to the wide spread of resistant bacteria and their antimicrobial resistant genes (ARGs) [3] [4] [5] . AMR has severe adverse effects on humans, healthcare systems, farm animals, agriculture, environmental health, and, consequently, on national economies [6] . AMR is a challenging threat undermining key features of current medical care at enormous costs in terms of patient mortality and morbidity, but also in terms of patient treatment expenses [7, 8] . Modern, mainstream antibiotic therapeutic strategies are responsible for their own regression by actively selecting for resistant strains, compelling the need for supporting the continuous discovery of new antibiotics in order to remain ahead of the AMR challenge [9] . Therefore, it is urgent to prolong the lifespan of current antibiotics while research and development of new-generation antibiotics takes its course. In addition, it is important to implement efficient control measures for antibiotic use in order to slow down the need for continuous discovery of new antibiotics [1] . @story_separate@Although new time-saving technologies have been introduced to obtain antimicrobial resistance data, the classic, conventional technologies are still being used. These mainly include culture-based and molecular-based approaches. More recently, microscopy-based and spectrometry-based approaches have also been incorporated in the tools for developing diagnostics.  Although new time-saving technologies have been introduced to obtain antimicrobial resistance data, the classic, conventional technologies are still being used. These mainly include culture-based and molecular-based approaches. More recently, microscopy-based and spectrometry-based approaches have also been incorporated in the tools for developing diagnostics. Culture-based methods rely on the phenotypic resistance detection by evaluating the bacterial growth in the presence of antibiotics, and can be classified in two categories, manual and automated. Manual tests include agar dilution, gradient test, disk diffusion, and broth microdilution antimicrobial susceptibility testing methods. The automated commercial platforms (VITEK®2 COMPACT, Sensititre™ ARIS™ 2X, and Alfred 60AST system) use some of the aforementioned methods. Broth dilution-based platforms typically use ready-made cartridges or plates including positive controls and gradient concentrations of antibiotics. Sensititre panels belong to the category of microdilution methods. Typically, such panels are plastic multi-well micro-titer plates precision-dosed with dried antimicrobial agents. For instance, the Sensititre panel method was used for the determination of the susceptibility of carbapenem-resistant Klebsiella pneumoniae to polymyxins [21] . Such platforms usually offer real-time growth monitoring and minimum inhibitory concentration (MIC) analysis through their comprehensive databases which include a broad spectrum of organisms. The above-mentioned technologies offer qualitative and quantitative data for the strain under investigation. For example, dilution methods and Epsilometer tests (E-tests) provide quantitative values [22] for the minimum inhibitory concentration (MIC), as the lowest concentration of a given antimicrobial which prevents the visible overnight growth of a culture [23] . Disk diffusion provides a zone of inhibition. E-Test belongs to the gradient test methods [24] and is especially useful for fastidious microorganisms [25] , such as Campylobacter spp. [26] . Various methods have been traditionally employed regarding the phenotypic analysis for susceptibility of bacteria to antibiotics, and different standards, criteria, and guidelines have been proposed by several international organizations for the interpretation of Alfred 60 antimicrobial susceptibility testing (AST) results. The European Committee on Antimicrobial Susceptibility Testing (EUCAST) and the Clinical and Laboratory Standards Institute (CLSI) in the USA are two of the main organizations responsible for the annual revision and update of the AST standards. However, several discrepancies have been observed in the interpretation of the criteria regarding different bacterial species. For example, in the case of amikacin resistant Escherichia coli, a more stringent susceptibility breakpoint is provided by EUCAST (≤8 mg/L) compared to CLSI (≤16 mg/L) [22] . Molecular-based assays addressing the detection of ARG can offer advantages over phenotypic assays, such as multiplex targeting and more precise characterization and detection of AMR genes. For some taxonomic units, susceptibility breakpoints have not been established, and molecular-based methods represent an acceptable alternative. Another advantage is the elimination of isolate purification since non-purified polymicrobial samples can be used. Moreover, they allow for relatively quick adaptation to newly introduced resistance factors [27] . Nevertheless, molecular-based assays for AMR detection have some limitations. Molecular-based methods are not capable of defining MIC. Besides, some ARGs could be missed in terms of both sensitivity and coverage since they can only detect resistances that are searched for and not newly evolved ones. Moreover, the wide diversity of different genes related to AMR poses a challenge in assay development due to the cost involved, thus competing with phenotypic assays is sometimes difficult. However, advancements in the field of molecular based techniques are gaining a place in routine diagnostics [28] . Molecular-based methods for detecting ARGs as well as their expression take advantage of the developments in amplification and nucleic acid hybridiza-tion techniques [29] . Molecular-based techniques can offer ARGs detection in a fast and sensitive manner. ARGs encode the ability of bacteria to survive and grow in the presence of antibiotics. In the past, scientists were solely targeting a small fraction of ARGs, but with the decrease in the cost of next-generation sequencing (NGS) technologies and the subsequent expansion in bacterial whole genome sequencing (WGS), the availability of ARG targets in various databases has enormously been expanded [30] . In the following sections, nucleic acid amplification-based techniques, such as polymerase chain reaction (PCR) and isothermal techniques, as well as DNA microarrays, will be discussed. PCR is the most commonly used nucleic acid amplification technique for the detection of ARGs [31, 32] . More recently, real-time [33] , quantitative [34] , digital [35, 36] , and multiplex [37] PCR assays have further boosted clinical acceptance of genetic testing. The changes in NGS and WGS have impacted the availability of ARG targets, paving the way for high throughput quantitative PCR (HT-qPCR), which is comparatively fast, convenient, and allows for simultaneous investigation of a large number of ARGs [30] . HT-qPCR is cost effective and it has already been employed in many studies for the analysis of ARGs stemming from various sample types [38] . For example, Wang et al. used HT-qPCR to provide a comprehensive profiling of ARGs in bacteria isolated from park soils [39] , whereas a novel high-throughput screening method (simultaneous screening 48 isolates against three antibiotics) employing HT-qPCR, tested the antimicrobial susceptibility of Orientia tsutsugamushi clinical isolates [40] . Xu et al. demonstrated the versatility of chemically synthesized double-stranded (ds) DNA, which can be employed as a qPCR standard for ARGs offering comparable performance, in terms of sensitivity and reliability, to natural DNA. This qPCR method has been successfully used with various sample types, such as animal feces, soil, and surface water [41] . A multiplex real-time PCR was used for AMR characterization in Neisseria gonorrhoeae including resistance to ciprofloxacin, ceftriaxone, cefixime, azithromycin, and spectinomycin. Although this methodology accurately detected mutations generating resistance to antibiotics employed for gonorrhea treatment, the low assay sensitivity prohibits the direct application for diagnostic testing in clinical specimens. Nevertheless, it can be used as a screening method for AMR in gonococcal isolates since it is faster than current conventional culture-based AMR testing [42] . Wang et al. developed a singleplex and a multiplex real-time PCR assays for methicillin resistant S. aureus (MRSA) in pediatric samples. The assay proved fast, reliable, and capable of detecting and differentiating MRSA and methicillin susceptible S. aureus MSSA [43] . Two decades ago, ligation mediated PCR (LM PCR) coupled with low denaturation temperature method has been proposed leading to specific melting-profile DNA patterns, both fungal and bacterial isolates. This method is suitable for strain characterization and differentiation [44] . This method has been used for epidemiological typing of various pathogens, such as extended-spectrum-beta-lactamase-producing Escherichia coli [45, 46] as well as Enterococcus faecium, Staphylococcus aureus, Klebsiella pneumoniae, Acinetobacter baumannii, Pseudomonas aeruginosa, and Enterobacter [47] . A more recent development, in molecular biology, is the use of isothermal DNA amplification eliminating the need for thermocycling, which is indispensable in the case of traditional PCR methods. Several methods of isothermal nucleic acid amplification have been developed, such as strand displacement amplification (SDA), transcription mediated amplification (TMA), nucleic acid sequence-based amplification (NASBA), rolling circle amplification (RCA), recombinase polymerase amplification (RPA), loop-mediated isothermal amplification (LAMP), and helicase-dependent amplification (HDA) [48] . These methods have paved the way for the implementation of rapid, next-generation molecular diagnostics [49] . The main advantages of the isothermal over the conventional PCR-based methods are the circumvention of thermocycling, which in turns lead to low power consumption and reduced analysis time. Thermocyclers are no longer needed, since a water bath or a hotplate can regulate the temperature [50] . Moreover, unlike PCR, isothermal amplification is faster and more sensitive [51] since it does not depend on discrete thermal cycles, but rather relies on continuous amplification, which can yield traceable amplicons in less than 10 min. Another advantage offered by some isothermal methods, such as LAMP, RCA, and HDA is the elimination of template denaturation and the tolerance to biological components for LAMP and HDA [52] . Moreover, although some isothermal methods have complex primer design (e.g., LAMP) they offer greater specificity compared to PCR. A recent evaluation of several isothermal methods in terms of simplicity, sensitivity, cost, and reproducibility showed that LAMP and RPA hold great potential for point-of-need (PON) diagnostics employed in low resource settings. Both of them are single step (incubation at a single temperature) and require minimum amount of DNA template [50] . Isothermal methods are also preferable for microfluidic-based approaches due to all of the aforementioned reasons [53] . In addition, LAMP amplicons can be detected even with naked-eye through turbidity or color change [54] . On the other hand, isothermal methods also have some limitations. Multiplexing approaches of isothermal methods are less successful, since the difficulty of the experimental design is increased [55] . Furthermore, some isothermal amplification methods have complex reaction mechanisms and need several primers, for example LAMP needs 4-6 primers, or several enzymatic steps are involved, such as in NASBA [52] . During the last two decades, significant investments in engineering, reagent formulations, and software have resulted in the commercialization of in vitro diagnostic (IVD) products based on PCR and isothermal nucleic acid amplification technology (NAAT) [56] . The integration and automation of processes, such as nucleic acid extraction, purification, amplification, and detection, coupled with sophisticated data analysis software have led to integrated and automated platforms (discussed in subsequent sections of this review article) providing accurate results [57] . A DNA microarray is a tool, which allows for the assessment of the bacterial genomic diversity. This approach relies on the detection of the presence or absence of genes in a target organism when compared to a reference strain or genome. Initially, DNA microarrays were based on glass slides [58] , which were spotted with numerous specific DNA probes relying on reference genes present in a characterized strain for which the whole-genome sequence was available. Comparative genomic hybridizations were performed followed by the analysis of the hybridization results. However, the use of glass slides as well as fluorescent dyes made the process costly and time-consuming. Nonetheless, there have been numerous advancements in the DNA microarray technology during the past two decades [59] . A fast and simple DNA labeling system based on biotinylated primers specific for the linkers has been developed for disposable microarrays [60] . A DNA microarray for the simultaneous (multiplex asymmetric PCR amplification) detection of ARGs among Staphylococcus clinical isolates based on fluorescently labeled PCR products has been developed [61] . More recently, Havlicek et al. proposed a rapid cartridge based, melting curve assay for the detection of pyrazinamide resistant Mycobacterium tuberculosis [62] . The assay can be automatically implemented using a closed cartridge coupled with a battery powered Alere™ q analyzer, as a point-of-care test in resource-limited settings [62] . In this section, some of the most promising non-conventional methods for AST will be described. Those method include: sequencing, matrix-assisted laser desorption/ionization time-of-flight mass spectrometry (MALDI-TOF MS), and Fourier transform infrared (FTIR) spectroscopy. The first DNA sequencing methods were developed in the mid-1970s and were able to decode hundreds of nucleotide bases of DNA per day. At that time, the two most widely accepted methods were the chain terminator [63] and the chemical cleavage procedures [64] . Single-base resolution was enabled by polyacrylamide gel electrophoresis for each basespecific reaction. In 1995, the first complete bacterial genome (Haemophilus influenzae, 1,830,137 bp) was obtained with the first automated sequencers employing fluorescence chemistry based on the Sanger method [65] . Until 2005, the Sanger sequencing prevailed as the primary sequencing technology. Although these first-generation sequencing methods had low throughput, they could produce high-quality, relatively long DNA sequences. Multiple sample sequencing was feasible by integrating numerous capillaries on the same instrument, thus enabling the sequencing of each individual sample. The major technical advancement of next-generation sequencing (NGS) was multiplexing, allowing for the simultaneous analysis of thousands of samples. Typically, a NGS workflow comprises DNA extraction and fragmentation, adaptors ligation, DNA amplification, and sequencing. In second generation sequencing, or short-read sequencing, the template amplification encompasses intrinsic drawbacks, such as copying errors, sequence-dependent biases, and information loss. In 2005, the 454 pyrosequencing platform was introduced [66] . Pyrosequencing is based on the detection of pyrophosphate release along with the light generation on nucleotide incorporation, unlike the chain termination with dideoxynucleotides used in Sanger sequencing. The Illumina platforms, which use synthesis technology where reversible terminator nucleotides labeled with fluorescence are incorporated into DNA strands and visualized via their fluorophore excitation, were subsequently incorporated with the same aim [67] . On the other hand, the third-generation sequencing, first developed in 2011 by Pacific Biosciences, is a real-time and single molecule based long-read sequencing relying on an optical approach coupled with a zero-mode waveguide on a nanostructured device [68] . Oxford Nanopore Technologies developed another approach relying on DNA molecules movement through a nanopore and measuring an electrical signal changing analogously to the base presently passing the pore [69] . These newly introduced second and third generation sequencing approaches have paved the way for single genome sequencing, as well as for the characterization of complex microbial communities and the identification of antibiotic resistance determinants [70] . Whole metagenome sequencing (WMS) and analysis of genetic material in patient samples allows for the identification of ARG directly from clinical specimens without the need for prior isolation or identification of specific bacteria. Bacterial sequence data availability has increased due to the advancements in sequencing technologies. Improved computational methods coupled with the continual cost decrease (due to the intense competition among different companies) made sequencing an affordable and viable tool for ARG identification, characterization, and surveillance [71] . Numerous methods, tools, and databases (Table 1 ) have been reported in recent years for the detection of genetic determinants related to AMR from WGS [72] and WMS data [73] . These evolving methods and technologies act as complementary tools to traditional culturebased methods, providing opportunities for rapid and sensitive resistance determination in uncultivable and cultivable bacteria. More information on the use of databases for AMR detection can be found in two recent reviews [74, 75] . The organization of sequencing data is considered a crucial pre-processing step prior to ARG analysis. Short reads, produced by technologies like Illumina, could be processed employing assembly-based methods (sequencing reads are initially assembled into contiguous fragments (contigs) followed by annotation where comparison takes place with public or custom reference databases), or directly analyzed utilizing read-based methods where resistance determinants are forecasted by mapping reads to a reference database [75] . A main advancement facilitating resistome surveillance is the established power for AMR prediction from solely genomic data. Various studies along with those focused on foodborne pathogens have demonstrated a high (>96%) concordance between the presence of known mutations or ARGs and MIC of various antimicrobials [76] [77] [78] [79] . In addition, a growing body of evidence shows that it is feasible to predict AMR and sometimes also the MIC of an antimicrobial, by employing machine learning techniques to genome sequencing data [80, 81] . Although long-read sequencing platforms can provide comprehensive entire genome capturing, they require substantial investment not only in equipment, but also in laboratory expertise. In addition, such systems typically require substantial quantities of DNA (i.e., more than 5 µg) and longer preparatory time, and they have higher error rates as compared to short-read sequencing platforms. Alternative sequencing platforms relying on nanopore technology are considered capable of providing libraries of high quality from long reads, as well as producing closed bacterial genomes. In addition, advantages, such as portability and affordability, less laboratory space, and on-site sequencing, have been highlighted [82] . The MinION nanopore system (Oxford Nanopore, Oxford, UK), is a portable (palm-sized, 100 g), real-time device for DNA and RNA sequencing, able to detect changes in ionic current upon DNA or RNA passing through the nanopores. In 2012, pyrosequencing was suggested as an innovative, rapid tool for the detection of Yersinia pestis strains towards fighting bioterrorism. The detection and identification relied on virulence genes, which led to an assay based on pyrosequencing for characterizing ARG profiles was developed by Amoako et al. [83] . Pyrosequencing was also evaluated as a tool for the detection of clinical drug-resistant Mycobacterium tuberculosis. The pyrosequencing assay was capable of reliably and robustly detecting resistance-associated mutations in M. tuberculosis isolates with great specificity (96-100%) [84] . The efficiency of the pyrosequencing was evaluated based on the rapid detection of resistance to fluoroquinolones (FQs), rifampicin (RIF), kanamycin (KAN), and capreomycin (CAP) in M. tuberculosis clinical isolates [85] . The sensitivity of the assay for detecting the resistance to RIF, FQs, CAP, and KAN was 100%, 100%, 40%, and 50%, respectively, with 100% specificity. This assay was considered as a fast and effective method for the detection of mutations associated with drug resistance in M. tuberculosis clinical isolates [85] ; however, it has been superseded by other sequencing technologies (see below). WGS for predicting AMR in non-typhoidal Salmonella was evaluated in human and food isolates employing v2 or v3 chemistry with paired-end 2-by 25-or 2-by 300-bp reads on the MiSeq platform (Illumina, San Diego, CA, USA) [86] . The data suggested that acquired resistance is highly correlated with the presence of known resistance determinants, useful for risk assessment linked to drug use in food animal production [86] . Velez et al. proposed the use of WGS for the determination of the occurrence of ARGs in Streptococcus uberis and Streptococcus dysgalactiae isolates, stemming from dairy cows [87] . A paired-end 125 bp sequencing was implemented using the Illumina HiSeq 2500 platform with v4 chemistry. In addition, they investigated the relation between genomic and epidemiological characteristics and phenotypic AMR profile. The outcome showed the association between a number of unique ARG sequences and phenotypic resistance (MIC data) [87] . Zhao et al. tried to identify AMR genotypes for Campylobacter investigating the correlation between resistance genotypes and phenotypes employing in vitro AST and WGS [88] . A strong correlation (99.2%) was observed between resistance phenotypes and genotypes. These outcomes suggested that WGS is a reliable resistance indicator (for tetracycline, ciprofloxacin, nalidixic acid, erythromycin, gentamicin, azithromycin, clindamycin, telithromycin, and florfenicol). From these initial screenings, several studies [74, 89, 90] also highlighted that WGS is a powerful tool for AMR surveillance programs [88] . More recently, an ongoing epidemiological change was studied using WGS revealing the co-existence of antibiotic resistance and virulence factors in carbapenem-resistant Klebsiella pneumoniae isolates, suggesting that this finding should be taken into account for future genomic surveillance studies [91] . Plasmids are capable of transferring ARGs among bacterial isolates. Nonetheless, plasmids are difficult to assemble from short-read WGS data. Berbers et al. used short and long read WGS sequencing to characterize ARGs on plasmids as well as establishing their localization [92] . Due to the rising concern of the spread of ARGs, it is of crucial importance to establish their location, especially when they are in mobile elements. Risk assessment of AMR spread was feasible by overcoming the challenges of plasmid reconstruction when employing the combination of long and short read sequencing [92] . Nanopore sequencing has been widely used on viruses [93] , yeasts [94] and for performing de novo bacterial assembly [95] . It has also been used for identifying viral pathogens [96] , undertaking metagenomics studies [97] and detecting ARGs [98] . The MinION nanopore sequencer was implemented to resolve the structure as well as the chromosomal insertion site of a composite antibiotic resistance island in Salmonella Typhi [99] . It was also employed for the identification of the position as well as the structure of bacterial AMR determinants in a multidrug-resistant (MDR) strain of Enteroaggregative E. coli [100] . Long-read analysis of WGS data facilitated the identification of mobile genetic elements where AMR determinants were positioned and revealed the combination of various AMR determinants co-located on the same mobile element. These findings provided a deeper understanding regarding the transmission of co-located AMR determinants in MDR E. coli [100] . Schmidt et al. showed that MinION could successfully identify bacterial pathogens as well as acquired resistance genes without culturing directly from urine samples within 4 h [101] . This study highlights the importance of WMS-based diagnosis towards adjusting antimicrobial therapy [101] . The Oxford Nanopore MinION long read DNA sequencing device was exploited for the detection of ARGs, the assessment of ARGs' taxonomic origin as well as to decoding their genetic organization and possible correlation with mobilization markers. Based on the findings, targeted intervention measures could be implemented in order to mitigate the risks of ARGs transferring among sites and, thus, improve biosecurity practices in hospitals and other environments [102] . Nanopore se-quencing was also used for the fast determination of plasmids, virulence markers, phages and ARG in Shiga toxin-producing E. coli [82] . More recently, MinION nanopore sequencing was employed for rapid pathogen, plasmids and ARG identification in bacterial DNA extracted from positive blood cultures [103] . After only 10 min of sequencing, pathogen identification was possible. The detection of predefined ARGs and plasmids stemming from monoculture experiments was achieved within 1 h employing raw nanopore sequencing data. This is one crucial difference between Illumina and nanopore sequencing. Nanopore sequencing offers real-time data availability whereas when Illumina is used, the data become accessible once the sequencing run is finished [103] . The use of the MinION sequencer was also examined both for whole genome generation and characterization of Streptococcus suis. The genomes from the MinION sequencer were capable of accurately predicting the multilocus sequence type (8 out of 10 samples) and identifying AMR profiles (100% of the samples) [104] . The ultra-long read Nanopore sequencing technology was used for AMR detection in Mannheimia haemolytica [105] . De novo assembly generated a complete genome for a non-resistant and an almost complete assembly for a drug resistant strain. Successful ARG detection was achieved with only 5437 MinION reads [105] . Contrary to phenotypic tests, providing information solely related to AST, NGS, can reveal the molecular basis of the AMR resistance. The acquired information can be fed in monitoring schemes, aiding the understanding of the events leading to resistance acquisition. Furthermore, NGS is capable of characterizing novel mechanisms of resistance when they are detected. This can be achieved by sequencing isolates previously proven to be phenotypically resistant, thus providing an exquisite added value when compared to various nucleic-acid based techniques (e.g., PCR) [106] . Matrix-assisted laser desorption/ionization time-of-flight mass spectrometry (MALDI-TOF MS) can be used for the detection of AMR, alternatively to traditional genotypic or phenotypic bacterial characterization [107] [108] [109] [110] [111] . MALDI-TOF MS relies on the cellular proteome and is capable of profiling proteins (mainly ribosomal, 2-20 kD) from whole bacterial cell extracts creating a bacterial spectral fingerprint or profiles that discriminates microorganisms at a genus, species, and subspecies level [112, 113] . In the assay preparation, the sample is mixed with a matrix, an energy absorbent solution. The entrapped sample within the matrix crystalizes upon drying. Once the sample is hit by a laser beam it gets ionized, producing protonated ions which are accelerated by using a constant potential leading to their separation based on their mass to charge (m/z) ratio. This ratio is determined by measuring the time needed for each protonated ion to move along the length of the tube. A ""Peptide Mass Fingerprint"" (PMF), which is a distinctive mass spectrum, is generated according to the TOF information. The peaks obtained from the PMF are compared to a database with reference peaks specific to genera and species of known, well characterized microorganisms, thus, allowing for the identification of the sample [114, 115] . MALDI-TOF MS has also allowed the detection of antibiotic resistance mechanisms (e.g., carbapenemases) [116] . The standardization of the procedure is necessary to obtain reproducible results [117] . MALDI-TOF MS is considered a reliable, rapid (within minutes), accurate, easy to use, cost-effective, and environmentally friendly methodology [114] . Although MALDI-TOF MS has enormously decreased the TAT for bacterial identification and progress have been made towards the determination of AMR, the high cost (purchase and maintenance) as well as the large size of such systems pose significant restrictions for its implementation in low-resource settings or as a point-of-care (POC) AMR or AST testing platform [113] . Moreover, MALDI-TOF MS is not suitable for the characterization of mixed samples, since purification, cultivation as well as sample preparation procedures are required beforehand. Furthermore, additional chemicals, such as the matrix, are required for the execution of the tests [118] . Databases with spectra able to differentiate susceptible and resistant strains should be available.  Recently, great progress has been achieved in optical technologies and their applications in the biomedical and microbiology fields. Infrared (IR) spectroscopy and microscopy allows for enhanced spectral and spatial resolution facilitating the acquisition of biochemical information at molecular level for microorganisms. With respect to clinical microbiology applications, Fourier transform infrared (FTIR) spectroscopy is a phenotypic method that has emerged as an attractive and dynamic weapon enriching the tools employed for biochemical analysis, owing to the detailed information it can provide the chemical composition at molecular level. FTIR spectroscopy allows for the quantification of the IR light absorption by molecules such as lipids, lipopolysaccharides, carbohydrates, proteins, and nucleic acids, resulting in a characteristic FTIR spectrum that represents the complete composition of the sample [139] . These characteristic spectra of the cell biomolecules offer ample functional and structural information. IR spectroscopy has been applied to differentiate the molecular changes associated with the development of AMR in prokaryotes [140] [141] [142] . The coupling of IR spectroscopy of bacterial samples with data analysis employing artificial neural networks (ANNs) was able to detect uropathogenic E. coli strains susceptible to cephalothin, achieving a success rate of 95% [143] . In 2017, Sharaha et al. used FTIR to identify bacterial susceptibility to certain antibiotics based on the obtained IR bacterial spectra. An IR microscope was utilized, and a computational classification method was developed to analyze the IR spectra by novel pattern-recognition tools, to determine E. coli susceptibility to ceftazidime, gentamicin, nitrofurantoin, nalidixic acid, and ofloxacin. The results showed an 85% success rate in the classification into sensitive and resistant strains [144] . In 2017, Salman et al. demonstrated the detection of structural molecular changes linked AMR by employing FTIR microscopy coupled with a novel statistical classification approach developed in-house for spectral analysis [140] . Kochan et al. recently reported the identification of changes in the chemical composition of S. aureus associated with vancomycin and daptomycin antibiotic resistance. An innovative, single cell, nanoscale technique, namely atomic force microscopy-infrared spectroscopy (AFM-IR), coupled with chemometric analysis was employed [145] . AFM-IR combines IR and scanning probe microscopy to improve resolution and capacity to map cell structures at the atomic scale. FTIR shows many advantages, such as reliability, speed, cost-effectiveness, and environmentally friendly methodology in AMR study. Similar to other instrumental systems (i.e., MALDI-TOF MS), the purchase and maintenance costs and equipment size make its implementation very difficult in low-resource settings, or as a POC AMR, or AST testing platform. Purification, cultivation, as well as sample preparation procedures are required previously, and databases with spectra able to differentiate susceptible and resistant strains should be available. Lab-on-a-chip (LoC) devices using microfluidics represent a promising tool in numerous fields, such as clinical diagnostics [146] , food safety [147] and environmental monitoring [148] . Recently, LoC technology has also been applied in the detection of antibiotic-resistant bacteria [3] . Some of the advantages offered by the LoC technology compared to macro-scale methods are: fast and high throughput analysis, accurate fluid manipulation, low cost, low reagent, and power consumption, smaller sample volume, automation, integration, compactness, and portability [149] [150] [151] [152] . Genotypic and phenotypic assays are the two main categories of microfluidic-based detection methods. Genotypic microfluidic assays (e.g. PCR, LAMP) target genetic markers (e.g., ARG), thus circumventing bacterial growth and allowing for shorter TAT (several hours) [153] . The implementation of microfluidics combined with isothermal DNA amplification protocols offer enhanced features due to the elimination of thermal cycling [50] . This approach is highly promising for the development of cheap, convenient, and efficient diagnostic tools for food safety, clinical, and environmental applications [154] . On the other hand, phenotypic microfluidic assays monitor bacterial growth of bacteria in the presence of antibiotics, thus offering accurate AST results. In them, in general, bacteria are confined in small volumes (e.g., chambers, channels, or droplets) [155] , captured with the aid of antibodies on magnetic beads or membranes [156] , or encapsulated in chambers containing agarose [157] and hydrodynamic trapping [158] . For example, hydrodynamic trapping is a method used for the immobilization of the bacteria and is compatible with microfluidics offering highly dense trap arrays, easy integration, high scalability, and easy biosensing though, the trapping efficiency is quite low. A drawback regarding the use of antibodies is the high cost as well as the restricted availability to specific strains. As for the droplet-based method, typically they require expensive and sophisticated readout. The agarose-based method, although it can be applied to conventional multi-well plates, the arraying is not straightforward, which hinders both the automated detection and the data analysis. Due to these limitations, more research and improvements are needed in order for these systems to become commercially available. In the following sections, various approaches will be dis-cussed; namely spectroscopy-based, colorimetric-based, pH-based, and, last but not least, quartz-crystal microbalance (QCM) based, point-of-care (POC), multiplexing, single-cell, or single-molecule. Surface enhanced Raman spectroscopy (SERS) is considered a main biochemical fingerprinting approach since it can precisely reflect the macromolecular profiles as well as the changes occurring within the bacterial cells as a result of antibiotic action [118, 159] . SERS has been applied for the investigation of the resistance or susceptibility to antibiotics of bacteria, as well as for studying the working mechanism of antibiotics relying on the whole cells' spectral fingerprint. SERS is capable of providing rapid, accurate, and ultrasensitive detection of resistant bacteria with minimum requirement for sample preparation and handling [118, 160] . SERS has also been used in LoC platforms. Lu et al. reported the development of a microfluidic chip combined with SERS providing rapid detection and differentiation of MSSA and MRSA [161] . Chang et al. presented the development of an integrated multimodal microfluidic system capable of performing on-chip enrichment of bacteria, collection of metabolites, and in situ SERS measurements for AST, with a limit of detection (LoD) of 10 3 CFU/mL [162] . Liao et al. reported the development of a microfluidic platform integrating SERS with microwells allowing for low concentration (10 3 CFU/mL) encapsulation of bacteria followed by label-free detection and in situ AST [163] . However, while current advancements in SERS methodology have substantially improved the selectivity and sensitivity in bacterial biosensing, it still has some limitations. It usually requires a drying step of the sample prior to analysis that can lead to reproducibility issues. Although liquid phase detection of bacteria is favored when interrogation of cells is performed under their natural environment, this is frequently challenging because of scattering of the Raman laser source. Another limitation associated with SERS is the sample and the experimental conditions, i.e., typically, samples containing a single bacterial species are employed under regulated laboratory conditions. Furthermore, despite the progress made in the identification of the molecular spectral fingerprints (e.g. nucleobases), comprehensive databases of SERS spectra of biomolecules are still needed, as well as mathematical interpretation and processing of spectra (e.g., multivariate data analysis) [164] . Ideally, bacterial SERS biosensors should facilitate the simultaneous detection of multiple strains from complex samples. Further information on the SERS method can be found in the review of Galvan et al. [159] . Several studies also report the development of colorimetric-based microfluidic platforms addressing pathogen identification and AST. Lee et al. proposed an integrated, automated, microfluidic platform capable of performing AST for 1-2 antibiotic combinations against bacterial pathogens [165] . On-chip determination of MIC is also provided via a colorimetric assay using a pH-dependent colorimetric broth. The total TAT of the on-chip microfluidic assay is 16-24 h, approximately. Automated fluidic control (e.g., transportation, mixing) is achieved using a pneumatically controlled custom-made module connected to the microfluidic chip. The initial loading of all samples [250 µL of bacterial suspension (10 6 CFU/mL) /chamber] and reagents is performed manually [165] . Recently, Ma et al. proposed a polymer-based microfluidic device addressing the identification and AST of Campylobacter spp. The microdevice consisted of an array of incubation micro-chambers loaded with chromogenic medium and antibiotics. Bacterial growth was visualized through a color change (chromogenic reaction). Rapid and reliable on-chip identification and AST was performed within 24 h with a LoD of 10 2 CFU/mL. Some variations in terms of the TAT and the LoD were observed according to the food matrix used [166] . Tang et al. proposed a microfluidic device integrating polymer-based microfluidic channels with a pH-sensitive chitosan hydrogel capable of detecting small pH changes for rapid AST [167] . Fourier transform reflectometric interference spectroscopy (FT-RIFS) was used for the real-time observation of the changes in the pH. The TAT for detection of whole bacterial growth was less than 2 h [167] . Hu et al. developed a real-time, ultrafast electronic detection microdevice for ARG detection (resistance genes from E. coli and Klebsiella pneumoniae) using the RPA method for isothermal amplification coupled with a thin film transistor sensor for measuring changes in the pH. The TAT was less than 3 min for a LoD of 100 copies [168] . Xu et al. presented a polymer/paper hybrid microfluidic chip for a one-step identification and AST of multiple uropathogens. The multiplexed colorimetric assay was facilitated via the use of paper substrates within the cell culture microchambers, allowing for a versatile combination of the antimicrobial agents and the chromogenic media. The assay was completed within 15 h and the outcome of the chromogenic reaction was monitored via a camera. Snapshots were taken every 30 min and analyzed with an image analysis software [169] . Recently, He et al. reported a laser-pattern paper-based microfluidic device capable of performing E. coli identification and susceptibility testing via visual observation of a simple color change (colorimetric readout). Such a micro-device is suitable for low resource settings and can be used by minimally trained personnel [170] . Quartz-crystal microbalance (QCM) is a physical nanogram-sensitive device with a piezoelectric sensor. QCM facilitates the real-time, rapid, on-site detection of AMR bacteria [171] . Reyes et al. have demonstrated a highly sensitive, accurate, and dynamic (realtime) system with a dual purpose, allowing both for monitoring of antimicrobial effects on E. coli and Saccharomyces cerevisiae, as well as ARG detection employing a magnesium zinc oxide (MZO) nanostructure-modified quartz crystal microbalance (MZOnano-QCM) biosensor [172] . Low cost, low demand in clinical samples volume, and rapidity (within 10 min) are the main advantages of the proposed method [173] . Toosky et al. developed a POC system for AMR diagnostics and phenotypic AST addressing bacteriuria and urinary tract infection (UTI) [174] . The TAT is 2h with the ability of detection and quantification of bacterial concentrations ranging from 50 to 10 5 CFU/mL. The detection is based on a portable particle-counting instrument comprising a miniature confocal microscope coupled with a software for real-time data analysis. The detection system allows for growth curve measurements of fluorescently stained bacterial cells in control and antibiotic-treated samples. The main advantages of the proposed POC lie in the elimination of pre-processing steps (e.g., pre-culture, enrichment, centrifugation) of urine samples as well as in the sensitivity of the instrument [174] . Only preliminary data are available for this method; thus, further studies are needed. One limitation of this method, which is common in all AST methods, is the negative effect of mixed cultures both on the specificity and the sensitivity of the results. Recently, Abram et al. reported a RDT platform integrating a novel single step blood droplet digital PCR assay with a high throughput three-dimensional (3D) particle counter system capable of performing bacterial identification and AST directly from whole blood samples, eliminating the need of culture and sample processing steps [175] . The demonstrated technology could simultaneously achieve high sensitivity of 10 CFU/mL and fast TAT of one hour [175] . A multiplex (eight samples) microfluidic chip for high throughput rapid phenotypic AST was proposed [176] . A mix of bacterial isolates and agarose was loaded in an array of microchambers within the chip. The growth rate of bacterial colonies under antibiotic gradients is monitored with the aid of a custom-built dark-field microscope coupled to a motorized camera (taking snapshots every 10 min) followed by automated image analysis. The TAT is 5 h and the method achieves stable MIC values showing 100% agreement with reference (broth microdilution) MIC values. The key advantage of the proposed system is the ability of simultaneously and rapidly analyzing eight samples on a single chip, which can also allow for parallel testing of several antibiotics [176] . A rapid AST system based on a microfluidic agarose channel with immobilized bacteria allows for single cell growth and monitoring by microscopy [177] . MIC values were determined by analyzing the time lapse images of the single cell bacteria cultured under various antibiotic concentrations. The TAT for the aforementioned system was less than 4 h [177] . Baltekin et al. presented their rapid AST system, also based on single-cell imaging (phase contrast microscope), using a microfluidic chip (made of a micromolded silicon elastomer and a cover glass) with cell traps. The rapid AST system was used for the determination of urinary tract infections (UTIs) caused by resistant bacteria with a TAT of 30 min even when urine samples with low CFUs were used [178] . Li et al. reported a versatile microfluidic system for fast bacterial classification (3 min) and phenotypic AST at the single-cell level. The incorporation of tunable microfluidic valves coupled with realtime visual detection (microscopy) facilitated the cell entrapment and classification based on their size and shape. The TAT for determining susceptibility, by monitoring the growth of the bacteria (single-cell level) in the presence of antibiotics, was 30 min. Moreover, the proposed system can be extensively applied for bacteria detection and complex (blood cultures, urine, whole blood) polymicrobial samples analysis [179] . Table 3 summarizes the microfluidic platforms that have been described in the literature, together with their main characteristics. 1 LoD: limit of detection, 2 TAT: turnaround time, 3 N/A: not applicable (this piece of information was not mentioned in the article). In this section, a description of some common, commercially available systems for AST follows. Adagio™ Antimicrobial Susceptibility Testing System (Bio-Rad Laboratories) [180] is an automated system built around an imaging device. It measures the size of the inhibition zone around antibiotic discs. It is coupled with a sophisticated data management software allowing for rapid and accurate result generation and automated AST interpretation [181] . The Adagio system was evaluated for the automated reading and interpretation of disk diffusion AST results in bacteria. Good categorical agreement was observed after visual validation of the automated results [182] . VITEK®2 COMPACT (bioMérieux, Marcy l'Étoile, France) is a compact, automated instrument addressing microbial identification and AST by reducing hands-on time for enhanced workflow and rapid reporting. The TAT is 2 to 18 h, although primary organism isolation is required. VITEK®2 COMPACT is considered a cost-effective, space-saving system. The technology used by VITEK®2 COMPACT relies on a fluorogenic methodology for organism identification and a turbidimetric method for AST. Accelerate Pheno™ (Accelerated Diagnostics, USA) comprises a fully automated system capable of performing identification in approximately 2 h and AST within approximately 7 h directly from the sample without requiring culturing for isolates [183] . The clean-up process of the samples relies on gel electrofiltration. Pathogen detection, species identification, and quantitation are performed in a fast and fully automated manner using fluorescence in situ hybridization. It also incorporates an automated digital microscope for the morphokinetic cellular analysis (MCA), thus allowing tracking phenotypic features, such as size, shape, division rate of individual live cells, while being challenged by antibiotics, as well as extrapolating MIC values. The main advantage of this system is the user-friendliness, whereas the main disadvantages are the lack of freedom for any intervention and the necessity of processing solely fresh blood cultures. Alfred 60AST system (Alifax, S.r.l., Italy) is a fully automated system capable of performing bacterial culture, residual antimicrobial activity (RAA) and susceptibility testing including the processes of sample inoculation, reading, and result transmission. This system, which relies on light scattering, is capable of detecting not only the presence of live bacteria, providing real-time information on growth curves as well as bacterial counts, but also their drug resistance in a few hours (4-6 h) with high sensitivity and specificity. The Alfred 60AST system coupled with MALDI-TOF MS for direct identification is considered a rapid AST. The main advantage of this system is its plasticity, since it allows for interventions by the user, which could also be considered as its main drawback, since such interventions dictate the need of skilled personnel able to interpret the results (i.e., growth curves). MicroScan WalkAway plus System (Beckman Coulter, Inc.) (40 or 96-panel capacity models) provides identification of microorganisms and AST results efficiently with minimal labor in an automated manner from an isolate inoculum within 4 h (or overnight for some samples). BD Phoenix™ (Becton, Dickinson, and Company) is an AST system providing rapid, reliable and accurate results from colony inoculums. It employs an oxidation/reduction indicator and a turbidimetric growth detector. Moreover, 200 identifications (ID)/AST sets could be processed in less than 4.5 h. Sensititre™ ARIS™ 2X (Thermo Fisher) provides bacterial pathogen identification and emerging antibiotic resistance detection relying on the gold-standard of broth microdilution coupled with the time-saving advantages of automation, thus improving patient care and enhancing lab efficiency. Growth measurements and endpoint MIC determinations are based on the hydrolysis of a fluorogenic substrate by the bacterial isolates. GeneFluidics (GeneFluidics, Inc.) offers automated platforms for research use, addressing both identification and AST. More specifically, ProMax®, UtiMax®, and Bsi-Max®platforms are capable of providing identification (TAT: n/a, 1 h, and 6 h, respectively) and AST (TAT: 3 h, 2 h, and 3.5 h, respectively) results from isolates, urine, and whole blood samples, respectively. GeneFluidics' products rely on molecular-based, PCR-less identification of species-specific phenotypic markers of resistance and susceptibility (resistance profiling determined by the change in 16S rRNA content of each target pathogen under various antibiotics conditions). The detection technology relies on an electrochemical sensor array. Alfred 60AST coupled with MALDI-TOF MS has a faster TAT for identification and AST and it is more cost-effective compared to Accelerate Pheno™. However, Accelerate Pheno™ can provide identification and MIC determination using a single cartridge. Thus, it is considered an excellent candidate for small and medium laboratories, where MALDI-TOF MS equipment is not available [17] . From the above-mentioned platforms, VITEK2, BD Phoenix, MicroScan WalkAway and Sensititre ARIS 2X are cleared by the Food and Drug Administration (FDA) as IVD diagnostics. Although these platforms generate fast (2-18 h) results, it must be highlighted that a standardized microbial inoculum is required, which entails a culturing step of the specimen for 1-2 days prior introducing the inoculum into the AST platform [184] . Table 4 summarizes some of the most commonly used commercially available platforms for AST. @story_separate@The AMR crisis is imposing a joint response from academia, risk managers, risk assessors, government, and industry to enhance the current methodologies, both for diagnosis and treatment, by developing novel tools circumventing the drawbacks and limitations of the golden standards and existing AST methods. The main limitations of the currently available tools are: (i) the need for sample pre-treatment steps; (ii) their low sensitivity; (iii) the incapacity of microorganism identification in some occasions; and (iv) the lack of integration, automation, and portability. In relation to the three first points, lengthy biological protocols (culturing, isolation, identification) are required in order to detect a number of pathogens. It is highly important to focus on and strive for substantial advancement towards the development of new testing platforms with superior performance characteristics in this regard, in order to allow for their approval and marketing as soon as possible. Spending time and effort on improvements on existing methods, technologies, and platforms is also plausible. According to MarketsandMarkets™, by 2025, the AST market is projected to reach USD $4.2 billion. In this market report, it is highlighted that, despite the use of automated AST platforms reducing both the incubation and detection times, the high prices of these platforms are considerable constraining factors for the widespread adoption of such platforms by end-users, principally for small-budget institutions [192] . In terms of product type, manual AST products held the largest share of the overall AST market in 2019. This is mainly attributed to the lower cost of such products. Based on the method, in 2019, disk diffusion accounted for the biggest share of the AST market mainly attributed to the relatively low cost and the diversity of the commercially available disks. Regarding the end users, hospitals and diagnostic laboratories commanded the largest share of the AST market in 2019 [193] . The cost estimation of the methods and technologies reviewed in this paper is out of scope. Albeit some rough estimations on the cost related to AST methods is described in the following publications of El-Bouri et al, Vrioni et al. and Vasala et al. [26, 114, 194] . All of the methods and technologies described above have shown great potential towards the AMR challenge, though various issues remain unanswered. For example, how many of these methods are generally applicable? Have these methodologies been validated against reference methods? For those not commercialized yet, when is it anticipated to become commercially available on the market for broad use? Although many methods presented in the literature claim to be capable of performing AMR detection in a short amount of time (minutes-few hours), in reality, they do not consider tedious pre-treatment steps, such as culture enrichment and culture isolation. To sum up, standard cultivation tests for AST typically have a TAT of 18-36 h and can provide MIC, though they are not suitable for non-culturable pathogens. The commercially available automated platforms have a TAT of 2-24 h, some of them provide MIC, but they are not compatible with non-culturable pathogens. MALDI-TOF MS has a lower TAT of 2-4 h and, in some cases, MIC determination is also possible, though it shares the same limitation as the two previous technologies. In addition, it is not yet endowed with standardized AST protocols as well as companion software for data analysis. NAAT-based approaches have a TAT of 0.5-4 h, though MIC determination is not possible. On the other hand, NAAT is suitable for AST for non-culturable pathogens. In addition, NAAT-based systems are capable of easily integrating the detection of emerging ARGs or mutations. Nevertheless, new validations and standardization are needed for the diagnostics for each update. As for the WGS, it is still relatively newly introduced in the field of rapid AST. The biggest challenge related to WGS is the bioinformatics, since universal databases are required for the result interpretation. Microfluidics is an ever-growing field with great potential and versatility. Various microfluidic technologies, coupled with miniaturized biosensing schemes, hold a great promise for the future. Such microfluidic devices offer many advantages over conventional platforms, such as minimal resource (sample, reagents, power) use, low cost, user-friendly handling, rapid TAT, integration (multimodal), automa-tion, and portability. Regarding the microfluidic approaches, apart from the upscaling of the fabrication processes to allow for mass production at a low price [195] , a high degree of integration is needed for the pretreatment steps (e.g., sample preparation) and user-friendly interfacing, so as to become more appealing to users. Although all of these technologies struggle to meet the requirements for rapid AST, none of them is optimal. It is highly probable that some of them will claim a large share of rapid AST diagnostics market in the future. This market can be divided into two categories, the central lab-based and the PON-based. The first refers to organized and well-equipped labs (e.g., hospitals, research, and diagnostic centers) where WGS, WGM, PCR, MALDI-TOF MS, FTIR, and automated AST platforms can also be integrated, and the latter would be useful for small laboratories, practitioners, and pharmacists where microfluidic-based, portable AST platforms would be more appropriate, as they are superior in terms of portability and affordability, needing less laboratory space, and providing fast TAT at the same time. Table 5 summarizes the main advantages and disadvantages of the methods and technologies described. In conclusion, the development of reliable, sensitive and affordable diagnostics will facilitate combating the threat of AMR. Rapid diagnostic technologies employed mainly in primary care locations (i.e., rapid diagnostic tests), could enhance and facilitate the effective and targeted treatment. Moreover, advanced monitoring systems, such as mobile applications, coupled with surveillance programs, are essential to track antimicrobial consumption. Emerging approaches, such as machine learning and data mining in combination with automation, will play a key role for the next generation diagnostics. Epidemiological surveillance is of upmost importance for AMR since it provides the necessary input for developing and monitoring therapy guidelines, antibiotic stewardship programs, public health interventions, and novel antimicrobials and vaccines [196] . The developments on the cutting-edge methods and technologies addressing AMR and AST, coupled with the surveillance programs allowing for increased and simplified data transmission, would hugely contribute towards minimizing the detrimental effects of the AMR threat.","Antimicrobial resistance (AMR) is one of the most challenging threats in public health; thus, there is a growing demand for methods and technologies that enable rapid antimicrobial susceptibility testing (AST). The conventional methods and technologies addressing AMR diagnostics and AST employed in clinical microbiology are tedious, with high turnaround times (TAT), and are usually expensive. As a result, empirical antimicrobial therapies are prescribed leading to AMR spread, which in turn causes higher mortality rates and increased healthcare costs. This review describes the developments in current cutting-edge methods and technologies, organized by key enabling research domains, towards fighting the looming AMR menace by employing recent advances in AMR diagnostic tools. First, we summarize the conventional methods addressing AMR detection, surveillance, and AST. Thereafter, we examine more recent non-conventional methods and the advancements in each field, including whole genome sequencing (WGS), matrix-assisted laser desorption/ionization time-of-flight (MALDI-TOF) spectrometry, Fourier transform infrared (FTIR) spectroscopy, and microfluidics technology. Following, we provide examples of commercially available diagnostic platforms for AST. Finally, perspectives on the implementation of emerging concepts towards developing paradigm-changing technologies and methodologies for AMR diagnostics are discussed."
"Selenium (Se) is an essential element for humans and animals but not for plants (1) . The bioavailability of Se depends on the plant itself as well as on the concentration of Se in the soil (2, 3) . Selenium concentrations in three main soil types of the main agricultural region of Croatia (Osijek-Baranja County), namely haplic gelysol, stagnosol, and luvisol, were reported to be 538, 323, and 314 µg/kg, respectively (4), which means that there is a demand for Se supplementation in animal nutrition (5) . As a key component of glutathione peroxidase (GSH-GPx) and other selenoproteins, Se is essential and plays a crucial role in various biological processes, such as the fertilization capacity of spermatozoa (6), semen quality and fertility under heat stress conditions (7), innate and adaptive immune responses (8) , metabolic rate (9) , and reduced accumulation of heavy metals in tissues (10) . Many studies have attempted to produce Se-enriched animal products via feed-based nutritional interventions to increase Se deposition in meat, eggs, and milk (11) . Therefore, Se-enriched animal products have drawn extensive attention due to their potential to improve the Se health status of human consumers (12, 13) . Supplementation of animal feed with the mineral form of Se, also named inorganic form of Se, has some disadvantages, which are related to an interaction with other minerals, relative high toxicity, and inability to build and maintain Se reserves in the body (8) . Furthermore, selenite at high doses has been reported to act as a pro-oxidant. It has been suggested that organic selenium is more effective because it reaches tissues more efficiently and therefore the use of organic Se sources, such as selenomethionine has been shown to be superior to that of inorganic sources (14) . Zavodnik et al. (15) have demonstrated a 6-percent birth rate increase concerning the piglets fed by Se yeast supplement, an increase in saw litter weight to 11.1% and the concentration of Se in muscle increased up to 27.8%. In post-weaning piglets, an increase in liver and plasma selenium concentrations subsequent to a supplementation with Se from both organic and inorganic sources. Interestingly, the plasma activity of GSH-Px has been found to decrease with the increase in Se supplementation, but the hepatic activity of GSH-Px increases with increasing Se supplementation, regardless of the type of source (16) . According to Rovers (17) , Se deposition in muscle tissue is a good indicator of the selenium status of animals. The same author strongly suggests that selenized yeast with higher concentrations of selenomethionine significantly increases deposition of Se in muscle tissue compared with selenized yeast with a lower content of selenomethionine. Natural zeolite clinoptilolite has been used in veterinary and human medicine as feed ingredient due to its beneficial properties as immunostimulant (18) or as an adjuvant in antibiotics delivery (19) . One explanation of beneficial immune effects of silica, silicates, and aluminosilicates could be their action as nonspecific superantigen-like immunoglobulins (SAg) capable of activating a large population of T-cells. The activation occurs as a result of a simultaneous interaction between SAg, T cell receptor (TcR) variable region β, and major histocompatibility complex (MHC) class II molecules on the surface of antigen presenting cells (APC) (20) . In the weaned piglets which have received 0.5% clinoptilolite for 5 weeks, it was observed that the clinoptilolite was effective as an immunomodulatory agent by promoting the recruitment of circulating and intestinal immune cell subsets, even though it has not improved the growth in the weaned pigs, and generally failed to improve their feed conversion efficiency (21) . These findings encouraged us to investigate the combined effect of higher Se concentrations and natural zeolite clinoptilolite on Se deposition in pig tissues (muscle and liver) as well as on the immune and antioxidative status of the supplemented animals. The hypothesis is based on a knowledge that selenium and zeolite, separately, enhance an immune response and exert an antioxidant effect. It was our assumption that a higher amount of organic Se source (0.5 mg/kg DM) in combination with a natural zeolite clinoptilolite, will result in a better tissue deposition when compared with the same amount of inorganic Se and a lower amount of an organic Se source (0.3 mg/kg DM).@story_separate@Selenium (Se), an essential trace element for human and animal health, is covalently incorporated into amino acids, acts as a cofactor for antioxidant enzymes, and is involved in the maintenance of the immune system. The main goal of this investigation was to show the effect of Se supplementation, at levels slightly higher than the recommended values, combined with natural zeolite clinoptilolite on Se deposition in tissues (muscle and liver) and on the immune and antioxidative status of supplemented growing pigs. The experiment was carried out during a 98 d period on 60 pigs. Pigs were fed a standard feed mixture based on corn and soybean and were divided into four groups, according to the level of dietary selenium supplementation as follows: C-0.3 mg/kg DM organic Se, E1-0.5 mg/kg DM sodium selenite, E2-0.5 mg/kg DM organic selenium; E3-0.5 mg/kg DM organic Se+0.2% zeolite. Higher (P < 0.05) selenium concentrations were determined in the muscle and liver in growing pigs fed with higher organic Se in combination with zeolite compared to the lower organic Se concentration. Addition of organic Se increased (P < 0.05) Se deposition in muscle and liver compared to the equal amount of inorganic Se (E2 vs. E1). Higher organic Se in combination with natural zeolite addition increases (P < 0.05) proportion of pigs' cluster of differentiation (CD)45 + compared to the same amount of inorganic Se and lower organic Se addition. The proportion of CD45 + and CD4 + lymphocytes was higher (P < 0.05) in E3 group compared to the other groups. Higher (P < 0.05) proportion of CD21 + lymphocytes were measured in the E2 and E3 groups compared with the other groups. The highest (P < 0.01) activity of glutathione peroxidase (GSH-Px) in pig erythrocytes was observed in the E3 group, while higher (P < 0.05) activity of glutathione reductase (GR) was in all experimental groups related to the control one. A dietary addition of 0.5 mg/kg DM of organic Se in combination with zeolite (0.2% DM) has increased (P < 0.05) Se deposition in liver, muscle, and blood, compared to the dietary addition of 0.3 mg/kg DM of the organic Se. The experiment was carried out on commercial pig farm randomly distributing 60 animals (crossbred Large White × Swedish Landace × Pietrain) to four different boxes with full concrete floor and Big Dutchman R feeders. Animals (initial body weight 30.85 ± 0.30 kg) were fed over a period of 98 days with a standard feed mixture based on corn and soybean for fattening up to 60 kg (ST-1; Se concentration 0.058 mg/kg DM) and a mixture for fattening up to 100 kg (ST-2, Se concentration 0.050 mg/kg DM; Table 1 ). The groups were fed different dietary selenium treatments as follows: C-0.3 mg/kg DM organic Se, E1-0.5 mg/kg DM sodium selenite, E2-0.5 mg/kg DM organic selenium; E3-0.5 mg/kg DM organic Se+0.2% natural zeolite clinoptilolite (Zeotex; Mevex Ltd, Zagreb, Croatia; Table 2 ). The dietary treatment with 0.3 mg/kg DM organic Se in C was used as a standard recommended by NRC (22) (0.3 mg/kg for weaning pigs to 0.15 mg/kg for growing pigs). Because of the lack of Se in the soil, and consequently in plants, the current regulation allows up to 0.3 mg/kg of Se in the diet for all pigs, hence that level was used in our research as a gold standard. Feed and water were offered ad libitum, with an average ambient temperature of 25 • C during the day and 16 • C during the night. Pigs were weighted at the beginning of the trial, 50th and 98th day. The trial was conducted according to Directive 2010/63/EU of the European Parliament (2010) on the protection of animals used for scientific purposes, according to Croatian Animal Protection Act, other legal acts regarding the animal welfare and with Approval of Bioethics Committee for Research on Animals University in Osijek (2158-94-02-21-02). The feed composition was determined using standard methods (AOAC, 2006  Blood samples were collected from v. cava cranialis in vacuum tubes with heparin as an anticoagulant (Beckton Dickinson, Plymouth, UK) for selenium concentration and antioxidative enzymes. Other samples were taken with the EDTA for flow cytometry at 10 a.m. at each sampling point on eight pigs from each group. To measure selenium concentration in blood, immune parameters, and enzymes in antioxidant status blood samples were collected at the beginning of the trial (day 0) and at the 50th, 71st, and 98th days of trial. The samples of the m. longissimus dorsi and liver were taken at the end of the trial, subsequent to slaughter, at the abattoir, for the determination of selenium concentration. A piece of ∼7 cm from the left longissimus dorsi muscles were excised, starting at the joint between 12th and 13th thoracic vertebrae. A liver sample was taken from the apex of the left medial lobe (lobus hepatis sinister medialis). The concentration of selenium in blood, muscle, and liver tissue was determined using inductively coupled plasma optical emission spectrometry (ICP-OES, PerkinElmer Optima 2100 DV, USA). For the pre-reduction of Se, 20 mL of samples were placed in a clean 50 mL beaker, and 20 mL of concentrated HCl was added to reduce Se 6+ to Se 4+ (12) . The mixture was heated to 90 • C and cooled to room temperature. The wavelength for Se determination was 196.026 nm. For the quality control of the analytical method, the certified reference material, Cabbage (NCS ZC 73012, China National Analysis Center) was digested, and the total concentration was determined for method validation. The recovery rates of Se were within the range of 10%. All samples were analyzed in triplicate. The monoclonal antibodies (mAbs) reactive with swine leukocyte surface molecules (i.e., cluster of differentiation [CD] antigens) that we used for the identification and quantification of patterns of the lymphoid cell subsets are listed in Table 3 . Anti-swine mAbs to CD45 + (clone K252-1E4), CD4 + (clone 74-12-4), CD8 + (clone 76-2-11), and CD21 + molecules (clone BB6-11C9.6) were obtained from Abcam (Cambridge, UK). The cell suspensions were prepared and incubated with mAbs (50 µl/10 6 cells) in single color flow cytometry to determine the percentage of positively stained cells (23) . Flow cytometric analysis of the positively stained cells expressing CD45 + , CD4 + , CD8 + , or CD21 + molecules were performed for each animal, and the data are presented as the arithmetic mean ± pooled standard error of mean (mean ± SEM). The fluorescence of the mAb-labeled porcine lymphoid cells was quantified using a Coulter EPICS-XL flow cytometer (Beckman Coulter Miami FL, USA) as reported earlier (24) . The isotype-matched mouse immunoglobulins were used to detect non-specific fluorescence in control cell suspensions. For antioxidative enzyme determination, blood was centrifuged for 5 min at 1,500 g. After removing the plasma and buffy coat, erythrocytes were washed three times by resuspension in 0.9% NaCl and centrifuged for 5 min at 2,000 rpm after each wash. Erythrocyte samples were frozen at −80 • C until analysis. For the determination of antioxidant enzyme activity in erythrocyte lysate, packed erythrocytes were hemolyzed for 10 min at +4 • C by a 4-fold dilution with ice-cold Milli Q water, and the lysate was clarified by centrifugation (10, 000 g, 5 min, +4 • C) for analysis. Activity of enzymes (GSH-Px and GR) were determined by spectrophotometry in erythrocytes using the Ransel R and Glutathione Reductase R assay kits (Randox Laboratories Ltd, London, UK). For the evaluation of the treatment on the variability of body weight, immune parameters, oxidative parameters, and selenium concentration in blood following statistical model was used: Where: y ijk = estimated trait (body weight, immune parameters, oxidative parameters and selenium concentration in blood); µ = intercept; T i = fixed effect of treatment i (groups = C, E1, E2, and E3); D j = fixed effect of measurement day j (j = 0, 50, 71, and 98 day of measurement); e ijk = residual. For the evaluation of the treatment on the variability of selenium concentration in tissues (muscle and liver) following statistical model was used: Where: y ijk = estimated trait (selenium concentration in tissues); µ = intercept; T i = fixed effect of treatment i (groups = C, E1, E2, and E3); e ijk = residual. The significance of the differences between the analyzed traits due to fixed effect of treatment was tested by Fischer's test at level of P < 0.05; PROC GLM procedure in STATISTICA using TIBCO Software Inc., 2018. The growing pigs had similar body weights throughout the experimental period ( Table 4 ). Se concentration in blood was higher (P < 0.05) in the E2 and E3 groups than in the C and E1 groups, and clearly depended on the Se source and quantity ( Figure 1A) . Higher (P < 0.05) Se concentrations were determined in the muscle and liver in the E2 and E3 groups and compared with those of the E1 group, and the concentrations of the E3 group were compared with those of the C group (Figure 1) . The Se concentrations after dietary addition in the E1 group were lower (P < 0.05) in blood than in the E2 and E3 groups fed with the same amount of the organic source of Se (Figure 1) . Pigs fed with a lower amount of organic Se (C) had a numerically higher concentration of Se compared with the E1 group (Figure 1) . Recruitment of circulating immune cell subsets assessed by the cytometry analysis of proportions of CD45 + lymphoid cells, CD4 + , CD8 + , and CD 4 + CD8 + T cells, as well as of CD21 + B cells in the peripheral blood of growing pigs fed with different Se sources for 98 days are shown in Figure 2 . A higher (P < 0.05) proportion of total leucocytes was noted in the pigs of the E2 and E3 groups compared with groups C and E1. Interestingly, a higher (P < 0.05) proportion of CD4 + lymphocytes was observed in the pigs from the E3 group, while the proportion of CD8 + lymphocytes was higher (P < 0.05) in the E1 group. Pigs from the E2 and E3 groups had lower (P < 0.05) double-positive CD4 + CD8 + lymphocytes than pigs from the C and E1 groups. A higher (P < 0.05) proportion of CD21 + lymphocytes was measured in the E2 and E3 groups compared with the C and E1 groups. The highest (P < 0.01) activity of GSH-Px in pig erythrocytes in the E3 group was compared with that in the other groups. Dietary addition of higher concentrations of organic and inorganic Se increased the activity of GR in relation to the C group, with lower Se content in the feed. Selenium is a crucial trace element for antioxidant and immune functions in animals and humans (25) . Many studies have confirmed that organic Se acts as a real antioxidant, unlike inorganic Se, which can act as a prooxidant. Bearing in mind that many studies have proved that Se-enriched yeast is superior to inorganic sources in resorption and deposition (26-28), we used a source that contained organic Se at a concentration of 0.3 mg/kg DM in a control group. The experimental groups contained higher levels of Se (0.5 mg/kg) in inorganic (E1) and organic (E2) forms, and higher levels of organic Se combined with natural zeolite clinoptilolite (E3). Selenium deposition in muscle tissue is a good indicator of the Se status of animals (17) . Organic Se has an important benefit compared with inorganic Se due to the fact that selenomethionine is utilized by the tissues as an amino acid. The Se reserve in tissues can be mobilized for subsequent selenoprotein synthesis. Selenomethionine from Se yeast is known to be the best source for increasing the level of Se and depositing Se in tissues (29) . In our study, higher (0.5 mg/kg) dietary addition of Se-enriched yeast increased Se concentration in muscle and liver as compared to the addition of inorganic Se at 0.5 mg/kg (E2, E3 vs. E1). The addition of Se combined with zeolite clinoptilolite (E3) resulted in higher concentrations of Se in the muscle and liver compared with the C group. Similarly, Jiang et al. (30) found the highest deposition of Se in meat after the addition of 0.3 mg/kg Se with 1.5 mg linseed oil. The extent of tissue deposition in liver and muscle in our study was comparable to the finding of Zhan et al. (31) . Moreover, there was no difference between Se concentration in blood, muscle, and liver between basal diet according to the NRC (22) (C; 0.3 mg/kg DM) and inorganic Se supplementation (E1; 0.5 mg/kg DM), which is in agreement with the results of Mohamed et al. (32) in broiler chicken. The reason for an even higher Se concentration in the groups with zeolite addition (E3) compared with E2 is due to a positive effect of a zeolite as an adjuvant (18) . Clinoptilolite is the most prevalent zeolite in the nature. Its therapeutic applications are numerous; it is used for the maintenance of body's pH value, reduction of free radicals, neutralization or elimination of toxins and heavy metals, the improvement of tissue oxygenations, etc. (33) . Clinoptilolite is a great source of silicon in the form of orthosilicic acid which protects the body from heavy metals (34) . The zeolites have a protective effect in intoxication. That effect is evidenced by researchers who observed that the clinoptilolite could have some protective effect in organophosphorus poisoning in sheep, in lead intoxication in mice, and in pigs which have received CdCl2 (35) . The toxic elements generate reactive oxygen (ROS) or nitrogen (RNS) species that damage lipids, proteins, and deoxyribonucleic acid (DNA). Selenium forms a complex with transition metals and seleno-compounds that decrease their toxicity. Both complex formation and oxidative damages contribute to a decrease of seleno-compound concentrations like Se-methionine (36) . A zeolite supplementation reduces the toxic elements concentrations by combining with them in gastrointestinal tract. In that way less complex formation and oxidative damages allows for a more Se-methionine to be deposited in tissues. The other possible way of clinoptilolite action is explained through a better Se absorption, based on an observation in Wistar rats which have received the zeolite for 34 days. Some modifications of intestinal microvilli were observed. The microvilli length was higher and the number of microvilli per square µm was higher (37) , which could point to a better absorption capability. The other experiment with the newborn calves has demonstrated a better passive transfer of immunoglobulin into newborns (38) . In human medicine there are studies that support the beneficial properties of purified natural clinoptilolite as an antidiarrheic treatment (39) . More recent studies performed on aerobically trained subjects, highlighted the positive effects of zeolites on intestinal wall integrity (40) . To summarize all above zeolite decreases heavy metal and mycotoxin absorption from intestines and reduces oxidative burden and at the same time improves capacity for selenium absorption which at the end result in better selenium bioavailability and higher selenium concentrations in tissues. In our study, we found higher (P < 0.05) leukocyte common antigen (CD 45 + ) in the E2 and E3 groups than in the C and E1 groups, which means that Se and Se+Zeolite increase cellular immunity. Regarding the lymphocyte markers, there was a higher (P < 0.05) proportion of the CD4 + markers in the E3 group, which could be a positive effect attributed to the addition of Se+zeolite, because the E2 group with the same Se addition did not differ from the control group (C). Ivory et al. (41) found that Se supplementation did not enhance T-cell proliferation. In this case, the response was boosted by flu vaccination. In our case, the effect of increased CD4 + cell subsets were due to the non-specific stimulation by zeolite Se+zeolite addition ( Figure 2B ). In contrast, higher Se supplementation increased CD4 + proliferation in mice at low and medium doses (42) by modulating free thiol levels and specific signaling events during CD4 + activation. We can only speculate which dose is optimal for eliciting immune and antioxidative effects in the live organism and why in our research CD4 + was only increased in the E3 group. Namely, the proliferation of T cells is related to oxidized and reduced glutathione, which is a very important molecule for cell protection against oxidative damage. As reported by Ivory et al. (41) the addition of onion (rich in flavonoids) with a low Se dose increased the granzyme and perforin content of CD8 + cells, while the opposite effect was observed at higher Se doses. The pigs fed with a higher concentration of organic Se in the experimental groups had a lower (P < 0.05) ratio of CD8 + lymphocytes when compared to the pigs fed with the same concentration of inorganic Se. This is in accordance with Taylor et al. (43) who found that a higher Se content induces a plentiful production of selenoprotein P, which overlaps with the genes encoding several T cell-associated genes. Products from the cytolytic granules from CD8 + cells are also influenced by the dosage and form of Se; lower granzyme content with higher Se dosage has been reported by Ivory et al. (41) While Broom et al. (44) found a significant increase in CD4 + and CD8 + levels and a numerical increase in B lymphocytes, which could be explained by the lower Se status in the patients and the immunity elicited by the poliovirus vaccine. Dual-positive T lymphocytes in the peripheral circulation have been identified by researchers as part of a specific immune response, including a broad spectrum of T lymphocytes involved in the antiviral immune response in pigs (45, 46) . A smaller proportion of them was found in the peripheral circulation, but it was also proven that T lymphocytes increased by 20% during viral infections. This cell population comprises mature effective lymphocytes specific to the repertoire of antigens encountered in the past and latent and highly persistent viral infections (47) . Our results showed a lower proportion of dual positive T lymphocytes with the addition of organic Se and in combination with zeolite, which is probably due to a lack of proper challenge. Interestingly, higher dietary addition of Se elicited a share of the CD21 + lymphocytes, but only in the E2 and E3 groups, which is related to the signal transducer and set of cytokines that regulate this path of immunity. Confirmation of this could be found in Hofmann and Berry (48) , who noticed that Se affects different types of immune responses in different ways, depending on the starting Se status. Avery and Hoffmann (49) concluded that the use of selenium to increase innate immunity may be enhanced when prescribed along with other nutritional antioxidants (which is zeolite in our case). Adaptive immunity is affected by selenium intake, including the activation and function of T and B cells. Because Se is included in many selenoproteins in the body and the most commonly researched is GSH-Px, which is involved in protecting cells from oxidative damage, dietary deficiency of Se causes redistribution of intracellular Se among the selenoproteins and GSH-Px protein (50) . The high dependency of GSH-Px activity on Se source and concentration in the diet has been confirmed previously by many authors (51, 52) . A meta-analysis by Bermingham et al. (53) found a significant correlation of GSH-Px activity with Se dose and form, which is consistent with the results of Mahan et al. (54) . In contrast, Oliveira et al. (16) reported a linear reduction in plasma GSH-Px activity with increased supplementation levels of organic Se, and a linear increase in hepatic GSH-Px activity with increased supplementation, regardless of the type source in post-weaning piglets. In our research, the higher concentrations of dietary organic selenium and zeolite combination increased (P < 0.05) GSH-Px activity in E3 group (Figure 3 ) when compared to the other groups. A higher GSH-GPx activity in this group is explained through a higher Se-methionine availability due to a lesser Se complex formation and lesser toxic elements ROS and RNS damage, as previously described by a higher Se tissue concentrations. An increase in dietary Se concentration, either organic or inorganic, increased GR activity in blood. Glutathione reductase (GR) is an oxidoreductive enzyme primarily responsible for the maintenance of intracellular glutathione concentration, playing an important role in the protection of cellular components with regard to an oxidative damage, especially that of erythrocytes. It has been demonstrated that, under the conditions of an oxidative stress, the activities of the GR antioxidant enzyme have increased in serum or in erythrocytes, but, in our case, an increase in the GR activity is in connection with GSH-Px one. If selenium is sufficiently consumed in diet, the GSH-Px enzyme activity increases, and when the substrate increases, the enzyme levels increase, too, to bind the substrate, reaching the maximal steady-state rates. If the GSH-Px activity is sufficient, glutathione disulfide is produced at the levels sufficient to stimulate the GR and prevent its deactivation by the NADPH (55) . Under these investigation conditions, a higher GR activity in the experimental groups signify that more glutathione was restored. Therefore, a better antioxidative defense was achieved. Our research circumstantiates the benefits of feeding the growing pigs with slightly over the NRC recommended levels of organic selenium (0.5 mg/kg DM) with the zeolite on selenium concentrations in tissues for human consumption, additionally it improves immune defense and andioxidative capacity of the growing pigs. A future research should investigate a potential of different zeolite concentration in combination with selenium on selenium tissue deposition as a benefit for humans and immune and oxidative defense as a benefit for animals. The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation. The animal study was reviewed and approved by Bioethics Committee for Research on Animals J. J. Strossmayer University of Osijek (2158-94-02-21-02). TŠ and MŠ designed this study, planned and carried out the experiments and measurements, and drafted the manuscript. MÐ carried out the measurements and analysis and helped to write the manuscript. ZL, VP, and MP helped with the analysis of the samples. VG has made statistical analyses. All the authors read and approved the final manuscript.@story_separate@The addition of organic Se is favorable to the inorganic Se in the same concentration (0.5 mg/kg DM). Dietary addition of 0.5 mg/kg DM organic Se with a zeolite addition (0.2%) increased Se deposition in liver, muscle, and blood, compared to lower organic Se concentration (0.3 mg/kg) which has a positive implication for the pig industry as a way of producing a functional food for human benefit. A significant increase in the immune and antioxidative parameters in the group of pigs fed the combination of selenium and zeolite had the positive effect on animal health.","Selenium (Se), an essential trace element for human and animal health, is covalently incorporated into amino acids, acts as a cofactor for antioxidant enzymes, and is involved in the maintenance of the immune system. The main goal of this investigation was to show the effect of Se supplementation, at levels slightly higher than the recommended values, combined with natural zeolite clinoptilolite on Se deposition in tissues (muscle and liver) and on the immune and antioxidative status of supplemented growing pigs. The experiment was carried out during a 98 d period on 60 pigs. Pigs were fed a standard feed mixture based on corn and soybean and were divided into four groups, according to the level of dietary selenium supplementation as follows: C-0.3 mg/kg DM organic Se, E1-0.5 mg/kg DM sodium selenite, E2-0.5 mg/kg DM organic selenium; E3-0.5 mg/kg DM organic Se+0.2% zeolite. Higher (P < 0.05) selenium concentrations were determined in the muscle and liver in growing pigs fed with higher organic Se in combination with zeolite compared to the lower organic Se concentration. Addition of organic Se increased (P < 0.05) Se deposition in muscle and liver compared to the equal amount of inorganic Se (E2 vs. E1). Higher organic Se in combination with natural zeolite addition increases (P < 0.05) proportion of pigs' cluster of differentiation (CD)45(+) compared to the same amount of inorganic Se and lower organic Se addition. The proportion of CD45(+) and CD4(+) lymphocytes was higher (P < 0.05) in E3 group compared to the other groups. Higher (P < 0.05) proportion of CD21(+) lymphocytes were measured in the E2 and E3 groups compared with the other groups. The highest (P < 0.01) activity of glutathione peroxidase (GSH-Px) in pig erythrocytes was observed in the E3 group, while higher (P < 0.05) activity of glutathione reductase (GR) was in all experimental groups related to the control one. A dietary addition of 0.5 mg/kg DM of organic Se in combination with zeolite (0.2% DM) has increased (P < 0.05) Se deposition in liver, muscle, and blood, compared to the dietary addition of 0.3 mg/kg DM of the organic Se."
